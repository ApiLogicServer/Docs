{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"API Logic Server","text":""},{"location":"#what-is-genai-powered-microservice-automation","title":"What is GenAI-Powered Microservice Automation?","text":"<p>Microservice Automation means you can create microservices from a database with 1 command.  You get an Admin App and a JSON:API with Swagger.  Then, use your IDE to declare logic using spreadsheet-like rules (40X more concise than code), and Python as necessary.  It's fast - you are up in seconds - and flexible using your IDE and familiar tools.</p> <p>Power it with GenAI to make it even simpler.  Just describe the system in business terms, and the system is created.  Then, declare rules in natural language.</p> <p>Let's have a look.</p> <p> </p>"},{"location":"#1-simplicity-of-ai","title":"1. Simplicity of AI","text":"<p>To create system, provide a prompt in business terms:</p> Create an AI Prompt file named genai_demo.prompt Create an AI Prompt file named genai_demo.prompt<pre><code>Create a system with customers, orders, items and products.\n\nInclude a notes field for orders.\n\nEnforce the Check Credit requirement (do not generate check constraints):\n1. Customer.balance &lt;= credit_limit\n2. Customer.balance = Sum(Order.amount_total where date_shipped is null)\n3. Order.amount_total = Sum(Item.amount)\n4. Item.amount = quantity * unit_price\n5. Store the Item.unit_price as a copy from Product.unit_price\n</code></pre> <p></p> <p> </p> <p>That's all it takes to create a system.  Note:</p> <ul> <li> <p>This prompt is a high-level, business-oriented description of the system - not just the database, but the multi-table business logic too.</p> </li> <li> <p>It is not \"techno-babble\" of low-level framework details (routes...).  You don't need to provide. or even learn such details.  That would be a failure to communicate.</p> </li> </ul> <p> </p>"},{"location":"#2-speed-of-low-code","title":"2. Speed of Low Code","text":"<p>Then, 1 command creates the project (you can also create from an existing database), providing remarkable business agility:</p> Create the project<pre><code>als genai --using=genai_demo.prompt\n</code></pre> App and API are ready to run <p>The system creates the database, and an executable project providing API and App Automation.  The microservice is ready to run, instantly:</p> <p></p> <p> </p>"},{"location":"#3-flexibility-of-a-framework","title":"3. Flexibility of a Framework","text":"<p>Agility includes maintenance automation, using GenAI and Logic Automation, with standard tooling such as Python and your IDE:</p> Customize and Iterate the Logic and API <p>Declare executable spreadsheet-like rules - 40X more concise than code - using GenAI or code completion.  These address multi-table derivations and constraints, and role-based row filtering.</p> <p>Declarative rules promote iterative development with support for maintenance automation, with automation for invocation, ordering, dependency management and optimization.</p> <p>Use Python to extend the rules (e.g, to send a Kafka message), and use the Flask framework to extend the API:</p> <p>Use your IDE debugger and the logic log to debug logic.</p> <p></p> <p> </p>"},{"location":"#fully-delivering-on-simplicity-speed-flexibility","title":"Fully Delivering on Simplicity, Speed, Flexibility","text":"Technology Promises Limited By... Deliver the Promise With API Logic Server Framework Promises Flexibility - No API, Logic or App Automation- Months of complex development - Full Microservice Automation - Preserves Full framework access Low Code Promises Speed - No Logic Automation (nearly half the effort)- Manual Screen Painting- Proprietary IDE, Framework - Logic Automation - App Automation- Open IDE, Tools, Libraries  GenAI Promises Simplicity - No API, Logic or App Automation- Only Database Automation - API Logic Server uses GenAI, adding...- Full Microservice Automation\u00a0\u00a0\u00a0- No FrankenPrompt  <p>API Logic Server offers a fresh approach, relative to traditional technology:</p> <ul> <li> <p>Unlike Frameworks, API Logic Server:</p> <ol> <li>Eliminates weeks-to-months of complex development with Microservice Automation (APIs and App in a customizable project).  You're ready to run, not code.</li> <li>Provides Logic Automation.  </li> </ol> </li> <li> <p>Unlike Low Code, API Logic Server:</p> <ol> <li>Eliminates tedious screen painting and complex database definition, providing Microservice Automation. </li> <li>Provides Logic Automation.  For systems providing update, this is critical - nearly half the effort.  The promise of Low Code requires logic automation. </li> <li> <p>Not just faster/easier for business users, but IT friendly:</p> <ul> <li>Leverages standard dev languages and tools (IDE, source control).  All the power and flexibility of a framework.</li> <li>Provides deployment flexibility, creating containers you can deploy anywhere.</li> </ul> </li> </ol> </li> <li> <p>Unlike basic GenAI, API Logic Server creates:</p> <ol> <li>Complete microservices -- including logic automation.  You have working software.  With GenAI, you have a database.</li> <li>Avoids the FrankenPrompt.</li> </ol> </li> </ul> <p>For more information, see the FAQs.</p> How Does GenAI - With Microservice Automation - Avoid the FrankenPrompt? <p> GenAI brings well-known value to app development.  It's great for generating code snippets, particularly for driving automation engines, such as sql (e.g., \"create a database...\").  API Logic Server leverages both of these strengths, including GenAI Logic Automation.</p> <p>For large, complex systems (e.g., microservices and their logic), GenAI breaks down -- results can be inconsistent, sometimes wrong, occasionally head-scratching hallunications.</p> <p>Microservice Automation provides the missing pieces: logic, api and app automation engines (analogous to SQL), enabling GenAI to scale up to complex microservice creation, avoiding:</p> <ol> <li> <p>Avoids \"Franken-response\": the last thing you want is for AI to turn your 5 simple rules into 200 lines of code: hard to read, verify correctness, and change.  By contrast, creating declarative rules results in logic that is concise,  understandable, and provides Maintenance Automation.</p> </li> <li> <p>Avoids the \"Franken-prompt\": in the absence of automation engines, developers are forced into complex prompt engineering, requiring detailed knowledge of the target code.  This defeats the objective of simplicity.</p> </li> </ol> <p>So, Microserve Automation not only leverages the value of GenAI, but enables it to address complex system creation, preserving simplicity.</p>  Doesn't Low Code Make It Fast?  <p></p> <p>Yes, for retrieval-oriented systems.  But, if your system requires update logic, the multi-table derivations and constraints are nearly half the effort -- the iceberg under the surface of the API.  </p> <p>See the screenshot above: Customize the Logic and API.  Logic automation means logic is expressed in spreadsheet-like rules, not code.  These rules are 40X more concise than code, and are extensible with Python.  They are automatically invoked, and are multi-table, multi-field.  </p> <p>So:</p> <ol> <li> <p>Logic automation is required to fulfill the promise of fast.  Without it, your project will simply not get moving.</p> </li> <li> <p>GenAI simplifies database creation.  In the past, Low Code tools have found it challenging to make it easy for users to define foreign keys, indices, etc.</p> </li> <li> <p>Developers will appreciate that API Logic Server is standards-based - use your own IDE, familiar tools such as source control, etc.</p> </li> </ol> Don't frameworks make it easy to create endpoints? <p> They do.  But a microservice is far more than a single endpoint.  It's a horse of an entirely different feather, requiring:</p> <ul> <li> <p>Filtering, pagination, optimistic locking... for all the tables</p> </li> <li> <p>API design</p> </li> <li> <p>SQLAlchemy models</p> </li> <li> <p>Admin App</p> </li> <li> <p>Update APIs... and their logic</p> </li> </ul> <p>GenAI Microservice Automation does all of this, automatically.  It's a complete system, ready to run.</p> <p> </p>"},{"location":"#watch-it","title":"Watch it","text":""},{"location":"#create-from-genai","title":"Create from GenAI","text":""},{"location":"#create-from-existing-database","title":"Create from Existing Database","text":"Create and Customize Microservices from an existing database"},{"location":"#webgenai-zero-install","title":"Web/GenAI - Zero Install","text":"<p>Please see Web/GenAI for more information, including how to access.</p> <p> </p>"},{"location":"#in-depth","title":"In Depth","text":"Simplicity of AI, Speed of Low Code, Flexibility of a Framework, Modern Software Architecture <p> Instant Microservices, for Integration and App Backends</p> <p>For Developers and their organizations seeking to increase business agility, API Logic Server provides </p> <ul> <li> <p>AI Simplicity: create projects from a Natural Language business oriented prompts, or existing database, in seconds</p> </li> <li> <p>Microservice Automation: create executable projects with 1 command:</p> <ol> <li>API Automation: crud for each table, with pagination, optimistic locking, filtering and sorting, and</li> <li>App Automation: a multi-page, multi-table Admin App.</li> </ol> </li> <li> <p>Standards-Based Customization: use standard tools (your IDE, Python, Flask, SQLAlchemy, GitHub and Docker), with API Logic Server support for:</p> <ol> <li> <p>Logic Automation: unique rules - 40X more concise multi-table derivations and constraints. </p> </li> <li> <p>Deployment Automation: scripts created to containerize your system, and deploy to Azure. </p> </li> </ol> </li> </ul> <p>API Logic Server differentiates from traditional approaches:</p> <ul> <li> <p>Unlike basic GenAI, API Logic Server creates systems from prompts at the business level, without tedious framework-level AI prompt engineering.</p> </li> <li> <p>Unlike frameworks, API Logic Servers preserves full flexibility and standard Dev Tools, with microservice automation to eliminate weeks-to-months of complex development.</p> </li> <li> <p>Unlike Low Code, API Logic Server provides logic automation, and preserves the framework flexibility.</p> </li> </ul> <p> </p> <p>Enterprise-class Architecture, Standards and Flexibility</p> <p>API Logic Server creates projects with a modern, service-based architecture.  Systems are: </p> <ul> <li> <p>API-enabled by default; self-serve means most new requests will not require custom api development</p> </li> <li> <p>Shared logic enforced in the middle tier:  unlike manually coded frameworks which may result in non-sharable logic on UI controllers, shared logic enables not only traditional forms, but also services, AI-driven bots, etc.</p> </li> <li> <p>Servers are stateless for scalability</p> </li> <li> <p>Scripts are provided to automate containterization</p> </li> </ul> <p>Developers appreciate a standards-based development approach.</p> <ul> <li> <p>Projects are customized using standard IDEs, leveraging code completion for declaring logic. </p> </li> <li> <p>Projects can utilize modern tooling, such as Git for source control, testing tools, etc.</p> </li> </ul> <p>Developers require the flexibility of a framework. In fact, </p> <ul> <li> <p>API Logic Server is based on Flask, so you can add new endpoints as required.  </p> </li> <li> <p>You have the full power of Python and its many libaries, enabling you to address requirements such as integration (e,g, with message-based integration with systems like Kafka)</p> </li> </ul> <p> </p> <p>Speed of Low Code - including logic </p> <p>Unlike Low Code systems, API Logic Server:</p> <p></p> <ul> <li> <p>Provides unique Logic Automation: for anything beyond trivial logic, missing backend logic automation means your project will simply not get moving.</p> </li> <li> <p>Automates modern, standard architectures</p> </li> <li> <p>Is IDE based, unlocking a wealth of tooling for customization</p> </li> <li> <p>Automates Instant Admin Apps, eliminating the need to use (and learn) a screen painter, and are executeable instantly</p> </li> </ul> <p>And, for systems requiring highly customized interfaces for Business Intelligence, API Logic Server works with Low Code. </p> <p> </p> <p>Simplicity of AI </p> <p>Technology only becomes useful when it's simple enough for teams to be effective.  API Logic Server employs AI:</p> <ul> <li>Use Natural Language to create databases</li> <li>Use Natural Language to declare rules</li> </ul> <p> </p>"},{"location":"#videos-tour","title":"Videos, Tour","text":"<p>API Logic Server is an open source Python project.  It is a CLI for project creation, and set of runtimes (SAFRS API, Flask, SQLAlchemy ORM, business logic engine) for project execution.</p> <p>It runs as a standard pip install, or under Docker. For more on API Logic Server Architecture, see here.</p> <p>Explore it below.</p> Video Tutorial (4 min) <p> </p> <p>Click the image below for a video tutorial, showing complete project creation, execution, customization and debugging.  Or, see this article: click here.</p> <p></p> Quick Screenshot Tour of using API Logic Server: Create, Run, Customize, Deploy <p></p> <p>1. Create: Microservice Automation</p> <p>Plug into your database, or database model: Microservice Automation means create projects instantly, with a single CLI command:</p> <pre><code>ApiLogicServer create --project_name=ApiLogicProject --db_url=nw\n</code></pre> <p> </p> <p>2. Run: API Automation and App Automation</p> <p>Microservice Automation creates a project that is executable, with:</p> <ul> <li>API Automation means you have a running JSON:API</li> <li>App Automation means you have a running Admin App</li> </ul> <p>The API unblocks UI Developers from waiting on lengthy API development cycles. The Admin App can be used for instant business user collaboration.</p> See JSON:API and Admin App <p> </p> <p>You can run directly (<code>python api_logic_server_run.py</code>), or open it in your IDE and use the pre-created run configurations:</p> <p></p> <p>Unlike frameworks which require significant time and expertise, the create command builds a complete API for your database, with endpoints for each table, including swagger.  The Admin App provides a link to the Swagger:</p> <p></p> <p> </p> <p>3. Customize: Logic Automation, Python Flexibility</p> <p>Customize created projects in your IDE, with Python and standard libaries.  Significantly, Microservice Automation also includes:</p> <ul> <li>Logic Automation means you customize logic using Rules and Python in your IDE</li> </ul> <p>Rules are unique and confer significant business agility - 40X more concise than code, for security and multi-table derivations and constraints.</p> See Logic With Rules and Python <p> </p> <p>Rules are 40X more concise than code, and are extensible with Python:</p> <p></p> <p>For more on customization, click here.</p> <p> </p> <p>Customization also provides no-code ad hoc integrations,and enables Instant Business Relationships.</p> See Integration: APIs and Messages <p> </p> <p>The automatically created JSON:API provides no-code ad hoc integrations, enabling organizations to move beyond ETL.  For example, other applications might require a customer record, and their addresses.  The automatically created self-serve JSON:API requires no code, and reduces future custom API development:</p> <ol> <li>Create the JSON:API</li> <li>Declare security, to control access and row level authorization</li> </ol> <p>Integrate with B2B Partners by creating custom endpoints using Python and Flask, with under 10 lines of code.  Instant business relationships.  Observe that:</p> <ol> <li>Update logic is partitioned out of each service - or UI - into shared Logic</li> <li>Mapping between SQLAlchemy rows and requests is automated with the RowDictMapper</li> </ol> <p></p> <p></p> <p>Integrate internal systems with Kafka, using business logic events:</p> <p></p> <p>For more on integration, explore running code in the Application Integration Sample Tutorial.</p> <p> </p> <p>4. Deploy: Deployment Automation</p> <p>The system creates scripts to containerize your project, and deploy it to Azure.</p> See Deployment Automation <p> </p> <p>The <code>ApiLogicServer create</code> command builds scripts for containerizing your project, testing it locally, and deploying to Azure:</p> <p></p> <p> </p>"},{"location":"#key-features","title":"Key Features","text":"API Features Feature Notes API Automation Unlike Frameworks, API created automatically Logic Update requests automatically enforce relevant logic Security Role-based result filtering Self-Serve JSON:API UI Developers and Partners don't require API Dev Standards-based JSON:API Optimistic Locking Ensure User-1 does not overwrite changes from User-2 Multi-table Retrieve related data (e.g. customers, with orders) Pagination Performance - deliver large result sets a page at a time Filtering Injection-safe filtering Logic Features Feature Notes Conciseness Rules reduce the backend half your system by 40X Automatic Ordering Simplifies Maintenance Automatic Optimization Reduce SQLs by pruning and adjustment-based aggregates Automatic Invocation Rules called automatically to help ensure quality Multi-Field Formulas and contraints can access parent data, with optional cascade Multi-table Sum / Count Rules can aggregate child data, with optional qualification Extensible Formulas, Constraints and Events can invoke Python Debugging Use IDE Debugger, and logic log to see which rules fire Security Features Feature Notes Authentication Control login access Authorization Row level access based on roles, or user properties Authorization Global filters (e.g, multi-tenant) Extensible Use sql for authentication, or your own provider Admin App Features Feature Notes App Automation Unlike frameworks, Multi-Page App is created automatically Multi-Table - Parents Automatic Joins (e.g., Items show Product Name, not Product Id) Multi-Table - Children Parent pages provide tab sheets for related child data (e,g, Customer / Order List) Lookups E.g., Item Page provides pick-lists for Product Cascade Add E.g., Add Order defaults the Customer Id Declarative Hiding Hide fields based on expression, or insert/update/delete state Intelligent Layout Names and join fields at the start, Ids at the end Simple Customization Simple yaml file (not complex html, framework, JavaScript) Images Show image for fields containing URLs Data Types Define customfields for your data types Other Features Feature Notes Microservice Automation One-command API / App Projects Application Integration Microservice support API Automation, and Kafka Messages AI-Driven Automation Use Copilot to automate database creation Multiple Databases Application Integration Deployment Automation Automated Container Creation, Azure Deployment"},{"location":"#business-scenarios","title":"Business Scenarios","text":"Application Integration, B2B <p>As illustrated below, API Logic Server supports transactions from User Interfaces, and 3 alternatives for Application Integration:</p> <ol> <li> <p>Ad Hoc Integration: the automatically created JSON:API provides no-code ad hoc integrations, enabling organizations to move beyond ETL.  For example, other applications might require a customer record, and their addresses from an existing database.</p> <ul> <li> <p>JSON:API are a standard for self-serve APIs -- where clients can select the columns and the related data they require.</p> </li> <li> <p>Analogous to GraphQL, self-serve APIs reduce the need for ongoing custom API development.</p> </li> </ul> </li> <li> <p>B2B Partners: you can use Python, Flask and SQLAlchemy to create Custom APIs, e.g. for B2B Partners.  These are simplified by automatic reuse of Logic, and Integration Mapping.</p> </li> <li> <p>Messages: Application Integration support also provides automation for producing and consuming Kafka messages.  Here's an article: click here.  To see these services in a tutorial, click here.</p> </li> </ol> <p></p> Unblock Client App Dev <p>Framework-based API development is time-consuming and complex.  Since client App Dev depends on APIs, front-end dev is often blocked.  This serialized dev process reduces business agility, and increases pressure on the team.</p> <p>API Logic server can change that.  </p> <ol> <li> <p>API Automation means client App Dev can start as soon as you have a database</p> </li> <li> <p>Logic Automation means that</p> <ol> <li>Such logic - a substantial element of the system - is automatically partitioned out of each client into server-based logic.  This reduces client coding, and enables the logic to be shared between user interfaces and services.</li> <li>Logic development can proceed in parallel with client App Dev</li> </ol> </li> </ol> <p>Here's an article, here.  Or, the the Tutorial, here.</p> Instant Microservices with AI-Driven Schema Automation <p>API and Logic Automation begins with a database.  But what if it's a new project, and there is no database.</p> <p>You can certainly use your SQL tools.  But we all know that SQL can be... tiresome.</p> <p>AI provides a solution: Schema Automation.  You can use Copilot to create the SQL DDL like this:</p> <p>Create database definitions from Copilot</p> <p>Create a system with customers, orders, items and products.</p> <p>Include a notes field for orders.</p> <p>Enforce the Check Credit requirement (do not generate check constraints):</p> <ol> <li>Customer.balance &lt;= credit_limit</li> <li>Customer.balance = Sum(Order.amount_total where date_shipped is null)</li> <li>Order.amount_total = Sum(Item.amount)</li> <li>Item.amount = quantity * unit_price</li> <li>Store the Item.unit_price as a copy from Product.unit_price</li> </ol> <p>Then, employ API Logic Server API and Logic Automation, and use Python and standard frameworks to finish the job.</p> <p>Here's a tutorial you can to explore this: click here,or see this article.</p> Back Office - Admin Data Maintenance, Data Correction <p>Api Logic Server creates an executable multi-table Admin App.  Optionally add Logic and Security.</p> <p>Use this app for:</p> <ul> <li> <p>Admin Data Management: for lookup tables, table-driven meta data (e.g., General Ledger allocation definitions), etc.  These often fall off the schedule, requiring the use of SQL tools that are hard to use, and don't provide logic or security.</p> </li> <li> <p>Data Correction: the realities of database use can result in invalid data (data loading, poor quality feeds).  These often require manual effort with SQL tools to find and correct such data.  This requires manual data validation which may be inconsistent.  You can provide professional interface, back by logic and security.</p> </li> </ul> <p>\u00a0 For additional Use Cases, click here.</p>"},{"location":"#docs-install-eval-guide","title":"Docs, Install, Eval Guide","text":"<p>To see the docs, click here.</p>"},{"location":"API-Customize/","title":"Custom APIs","text":"<p>While a standards-based API is a great start, sometimes you need custom endpoints tailored exactly to your business requirement.  Initially the API exposes all your tables as collection endpoints.  You can add additional endpoints by editing <code>expose_services.py</code>, as illustrated below. </p>"},{"location":"API-Customize/#use-flask","title":"Use Flask","text":"<p>You will observe the standard \"Hello World\" endpoint, which directly uses Flask.  These do not appear in Swagger.</p> <p> </p>"},{"location":"API-Customize/#use-safrs-endpoint-with-swagger","title":"Use SAFRS: endpoint with swagger","text":"<p>You can create these as shown below, where we create an additional endpoint for <code>add_order</code>.</p> <p>For more on customization, see SAFRS Customization docs.</p> <p>To review the implementation, and how to use the debugger for your custom endpoints: </p> <ol> <li>Open Explorer &gt; api/customize_api.py:</li> <li>Set the breakpoint as shown</li> <li>Use the swagger to access the <code>ServicesEndPoint &gt; add_order</code>, and</li> <li>Try it out, then </li> <li>execute</li> <li>Your breakpoint will be hit</li> <li>You can examine the variables, step, etc.</li> <li>Click Continue on the floating debug menu (upper right in screen shot below)</li> </ol> <p></p>"},{"location":"API-Multi-Table/","title":"Multi-Table APIs","text":"<p> TL;DR - use Swagger to configure API</p> <p>Multi-Table APIs can be configured using the <code>include</code> argument in the API call, and tested in Swagger.</p> <p> </p>"},{"location":"API-Multi-Table/#best-practices","title":"Best Practices","text":""},{"location":"API-Multi-Table/#swagger","title":"Swagger","text":"<p>Provider-defined APIs are configured by the API caller - the client application.  It's usually best to test these before testing your client app by using the created Swagger.  Note it provides the ability to copy the URL to paste into your app.</p> <p>You may find it helpful to copy the json response to a json formatter, such as jsonformatter or jsongrid.</p>"},{"location":"API-Multi-Table/#disable-security","title":"Disable Security","text":"<p>It also makes things simpler if you temporarily disable security (unless that's what you are testing!).  Created projects include Run Configurations for this.</p> <p> </p>"},{"location":"API-Multi-Table/#use-include-for-related-data","title":"Use <code>include</code> for related data","text":"<p>The <code>include</code> argument enables you to specify what related data is returned.  For example, in the sample northwind database, you can obtain a Customer, their Orders, the OrderDetails, and the Product Data like this:</p> <pre><code>curl -X GET \"http://localhost:5656/api/Customer/ALFKI/?\\\ninclude=OrderList%2COrderList.OrderDetailList%2COrderList.OrderDetailList.Product&amp;\\\nfields%5BCustomer%5D=Id%2CCompanyName%2CContactName%2CContactTitle%2CAddress%2CCity%2CRegion%2CPostalCode%2CCountry%2CPhone%2CFax%2CBalance%2CCreditLimit%2COrderCount%2CUnpaidOrderCount%2CClient_id\" \\\n  -H 'accept: application/vnd.api+json' \\\n  -H 'Content-Type: application/vnd.api+json'\n</code></pre> <p>Note the <code>include</code> argument, repeated here with commas:</p> <pre><code>include=OrderList,OrderList.OrderDetailList,OrderList.OrderDetailList.Product\n</code></pre> <p>These terms are the Parent / Child Relationship names, from your data model.  Note they support multi-level navigations, such as <code>OrderList.OrderDetailList</code>.  For more on relationship names, click here.</p> <p>To explore the resultant json, click here.</p>"},{"location":"API-Opt-Lock/","title":"Optimistic Locking","text":"<p> TL;DR - Avoid Last Updates - insure row not altered since read</p> <p>You can optionally ensure your API rejects update attempts for rows that have been altered by other users since read.  It works as follows:</p> <ol> <li> <p>The system delivers response rows with a <code>CheckSum</code> attribute (the as-read CheckSum)</p> </li> <li> <p>Client updates return the <code>CheckSum</code></p> <ul> <li> <p>The system will compute the <code>Checksum</code> of the current value of the row</p> </li> <li> <p>Exceptions are raised if the as-read/current <code>CheckSums</code> mismatch</p> </li> </ul> </li> </ol> <p> </p>"},{"location":"API-Opt-Lock/#problem-statement","title":"Problem Statement","text":"<p>Optimistic locking is a valuable feature for interactive systems, to avoid update overwrites and maximize concurrency, without requiring special database columns.</p> <p> </p>"},{"location":"API-Opt-Lock/#constraints","title":"Constraints","text":"<p>Most systems operate under the following constraints:</p> <ol> <li>Maximize concurrency by be eliminating long-duration locks    * Rows cannot be locked (pessimistically) on read, in case they are updated</li> <li>No special columns, such as  <code>VersionNumber</code>    * Database design is often constrained by other applications, or by internal standards</li> <li>Minimize network traffic and keep client coding simple    * E.g., unwieldy to send all \"old\" values back  </li> </ol> <p> </p>"},{"location":"API-Opt-Lock/#avoid-update-overwrites","title":"Avoid Update Overwrites","text":"<p>Within these constraints, the key objective is avoid overwriting updates.  Consider the following scenario:</p> Time User Action T0 U1 Reads Row.Column with value V1 T1 U2 Reads same row T2 U1 Updates row with value V2 T3 U2 Updates row with value V3 - V2 value overwritten, U1 not happy <p>The objective, then, is to avoid overwriting U1's update.</p> <p> </p>"},{"location":"API-Opt-Lock/#optimistic-locking","title":"Optimistic Locking","text":"<p>A widely accepted solution is optimistic locking: </p> <ol> <li>On reads, no database locks are acquired</li> <li>On update, ensure the row has not changed since the user read it</li> </ol> <p> </p>"},{"location":"API-Opt-Lock/#approach-virtual-checksum-to-detect-changes","title":"Approach: virtual <code>CheckSum</code> to detect changes","text":"<p>Before summarizing the approach, we note some key elements provided by architectural components.</p> <p> </p>"},{"location":"API-Opt-Lock/#background-key-architectural-elements","title":"Background: Key Architectural Elements","text":""},{"location":"API-Opt-Lock/#1-safrs-jsonapi_attr","title":"1. SAFRS <code>@jsonapi_attr</code>","text":"<p>SAFRS API provides adding derived virtual (non-stored) attributes: <code>@jsonapi_attr</code>:</p> <ul> <li>This enables the server to compute unstored values, here, <code>S_CheckSum</code></li> <li>SAFRS supports sending such values on client <code>patch</code> operations, so it is visible in logic</li> </ul> <p> </p>"},{"location":"API-Opt-Lock/#2-sqlalchemy-loaded_as_persistent","title":"2. SQLAlchemy <code>loaded_as_persistent</code>","text":"<p>SQLAlchemy provides the <code>loaded_as_persistent</code> event, enabling us to compute the <code>CheckSum</code>, store it in the row, so we can later check it on update.</p> <p> </p>"},{"location":"API-Opt-Lock/#3-the-rules-engine-supports-generic-before_logic","title":"3. The rules engine supports generic <code>before_logic</code>","text":"<p>This enables us to check the row compare <code>CheckSum</code> values before updates; see `logic/declare_logic.  Note such logic has access to the about-to-be-updated row, and the old-row.</p> <p> </p>"},{"location":"API-Opt-Lock/#creation-options","title":"Creation options","text":"<p>You can configure optimistic locking when you create projects, with the following 2 CLI arguments:</p> <ol> <li> <p><code>--opt_locking_attr</code> - this is the name of the attribute that contains the CheckSum.  It defaults to <code>S_CheckSum</code></p> </li> <li> <p><code>--opt_locking</code> - select one of the following (default is optional):</p> </li> </ol> Option Included on <code>Get</code> Checked on <code>Patch</code> ignored Never Never optional Always Yes - but no error if omitted required Always Yes - error if omitted <p> </p>"},{"location":"API-Opt-Lock/#configuration-options","title":"Configuration options","text":"<p>You can override the created <code>opt_locking</code> on server startup:</p> <ul> <li>by updating the Config file, and</li> <li>by using the <code>OPT_LOCKING</code> Env variable.</li> </ul> <p>The options are the same as shown in the table above.</p> <p>Note the env variables can be set on your IDE Run Configurations.</p> <p> </p>"},{"location":"API-Opt-Lock/#processing-overview","title":"Processing Overview","text":"<p>The approach is summarized in the table below.  See the the code in <code>api/system/opt_locking/opt_locking.py</code> for details.</p> <p> </p> Phase Responsibility Action Notes Design Time System Declare &lt;<code>opt_locking_attr</code>&gt; as a <code>@jsonapi_attr</code> Project creation (CLI) builds <code>models.py</code> with @json_attr Runtime - Read System Compute Checksum <code>opt_locking#loaded_as</code> (setup from from api_logic_server_run.py) Runtime - Call Patch User App Code,Admin App Return as-read-Checksum See examples below Runtime - Process Patch System Compare CheckSums: as-read vs. current <code>opt_locking#opt_locking_patch</code>, via <code>logic/declare_logic.py</code>: generic before event <p> </p> <p> </p> <p> </p>"},{"location":"API-Opt-Lock/#exploring-optimistic-locking","title":"Exploring Optimistic Locking","text":"<p>You can explore this using the sample database with the the Admin App, or with the cURL commands below.</p> <p>Use the <code>No Security</code> run config.</p> <p> </p>"},{"location":"API-Opt-Lock/#category-patch-missing-s_checksum-passes","title":"Category <code>Patch</code> - Missing S_Checksum passes","text":"<p>This should bypass optlock check and report \"can't be x\"</p> <pre><code>curl -X 'PATCH' \\\n  'http://localhost:5656/api/Category/1/' \\\n  -H 'accept: application/vnd.api+json' \\\n  -H 'Content-Type: application/json' \\\n  -d '{\n  \"data\": {\n    \"attributes\": {\n      \"Description\": \"x\"\n    },\n    \"type\": \"Category\",\n    \"id\": \"1\"\n  }\n}'\n</code></pre> <p> </p>"},{"location":"API-Opt-Lock/#category-patch-invalid-s_checksum-raises-exception","title":"Category <code>Patch</code> - Invalid S_Checksum raises exception","text":"<p>This should fail \"Sorry, row altered by another user...\"</p> <pre><code>curl -X 'PATCH' \\\n  'http://localhost:5656/api/Category/1/' \\\n  -H 'accept: application/vnd.api+json' \\\n  -H 'Content-Type: application/json' \\\n  -d '{\n  \"data\": {\n    \"attributes\": {\n      \"Description\": \"x\",\n      \"S_CheckSum\": \"Invalid S_Checksum raises exception\"\n    },\n    \"type\": \"Category\",\n    \"id\": \"1\"\n  }\n}'\n</code></pre> <p> </p>"},{"location":"API-Opt-Lock/#category-9-patch-valid-s_checksum-passes","title":"Category 9 <code>Patch</code> valid S_CheckSum passes","text":"<p>This should bypass optlock check and report \"can't be x\"</p> <p><pre><code>curl -X 'PATCH' \\\n  'http://localhost:5656/api/Category/9/' \\\n  -H 'accept: application/vnd.api+json' \\\n  -H 'Content-Type: application/json' \\\n  -d '{\n  \"data\": {\n    \"attributes\": {\n      \"Description\": \"x\",\n      \"S_CheckSum\": \"83926768455664603\"\n    },\n    \"type\": \"Category\",\n    \"id\": \"9\"\n  }\n}'\n</code></pre> </p>"},{"location":"API-Opt-Lock/#order-10643-set-shipped-from-null","title":"Order 10643 Set Shipped (from null)","text":"<p>This case tests different attribute ordering (per alias attribute), resulting in different checksums.</p> <p>Be sure to replace the db.sqlite after the test, since this changes it.</p> <pre><code>curl -X 'PATCH' \\\n  'http://localhost:5656/api/Order/10643/' \\\n  -H 'accept: application/vnd.api+json' \\\n  -H 'Content-Type: application/json' \\\n  -d '{\n  \"data\": {\n    \"attributes\": {\n        \"RequiredDate\": \"2013-10-13\",\n        \"Id\": 10643\n    },\n    \"type\": \"Order\",\n    \"id\": 10643\n  }\n}'\n</code></pre> <pre><code>curl -X 'GET' \\\n  'http://localhost:5656/api/Order/10643/?include=parent%2COrderDetailList%2CCustomer%2CLocation%2CEmployee%2COrderList&amp;fields%5BOrder%5D=ShipZip%2CId%2CCustomerId%2CEmployeeId%2COrderDate%2CRequiredDate%2CShippedDate%2CShipVia%2CFreight%2CShipName%2CShipAddress%2CShipCity%2CShipRegion%2CShipCountry%2CAmountTotal%2CCountry%2CCity%2CReady%2COrderDetailCount%2CCloneFromOrder%2C_check_sum_%2CCheckSum' \\\n  -H 'accept: application/vnd.api+json' \\\n  -H 'Content-Type: application/vnd.api+json'\n</code></pre>"},{"location":"API-Opt-Lock/#testing-and-pythonhashseed","title":"Testing and <code>PYTHONHASHSEED</code>","text":"<p>You may want to build tests that require you to supply checksums.  Checksum values differ from run to run (as they should), which can interfere with tests.</p> <p>For test runs, you can set an environment variable for predictable checksum values:</p> <pre><code>export PYTHONHASHSEED=0\n</code></pre>"},{"location":"API-Self-Serve/","title":"Self-Serve APIs","text":"<p> TL;DR - API Consumers can self-serve, and reduce network traffic</p> <p>Unlike Custom APIs which require server development, Self-Serve APIs can be used directly by consumers.  They use Swagger to retrieve the data they want, then copying the URI to their code.  API consumers include:</p> <ul> <li> <p>UI Developers - progress no longer blocked on custom server development</p> </li> <li> <p>Application Integration - remote customers and organizations can similarly meet their own needs</p> </li> </ul> <p>For external use, consumer-defined APIs can reduce network traffic.</p> <p> </p>"},{"location":"API-Self-Serve/#provider-defined-vs-consumer-defined","title":"Provider-Defined vs. Consumer-Defined","text":"<p>Consider 2 classes of APIs:</p> <ul> <li> <p>Provider-Defined APIs are predefined by server developers</p> <ul> <li>These are useful when API structure is dictated by an external system, such as a pre-defined application integration (example here)</li> </ul> </li> </ul> <p>But, providers typically cannot predict needs for a large class of API consumers (e.g., UI Developers, business partners, or other teams in a large organization).   Given only predefined provider APIs, consumers are often forced to make multiple calls to obtain the data they need, or invoke APIs that return too much data.  These can increase network traffic.</p> <p>That leads to a second class of APIs, such as GraphQL and JSON:API:</p> <ul> <li> <p>Consumer-Defined APIs enable clients to provide parameters for exactly the fields and related data they need.  This can:</p> <ul> <li>Reduce network traffic by eliminating multiple API calls, or calls for excessive data, and</li> <li>Minimize organizational dependencies with self-serve APIs.</li> </ul> </li> </ul> <p> </p>"},{"location":"API-Self-Serve/#example","title":"Example","text":"<p>API Consumers can obtain the data they want as shown below.</p> <p> </p>"},{"location":"API-Self-Serve/#create-request-with-swagger","title":"Create Request With Swagger","text":"<p>First,</p> <ol> <li>Use the automatically created Swagger (available via the Admin App) to obtain the data you want</li> <li>Click <code>Try it out</code> to verify the result, as shown below</li> </ol> <p> </p>"},{"location":"API-Self-Serve/#copy-uri-to-client-app","title":"Copy URI to client app","text":"<p>Then, when it's correct,</p> <ol> <li>Copy the URL to your client app</li> <li>Optionally, save the cURL for interactive testing</li> </ol> <p></p>"},{"location":"API/","title":"Automatic Multi-Table API","text":"<p> TL;DR - Instant API, Related Data, Filtering, Sorting, Pagination, Swagger</p> <p>The <code>ApiLogicServer create</code> command creates an API Logic Project that implements your API.  No additional code is required.  Custom App Dev is unblocked.</p> <ul> <li> <p>Endpoint for each table, with CRUD support - create, read, update and delete.</p> </li> <li> <p>Filtering, sorting, pagination, including related data access, based on relationships in the models file (typically derived from foreign keys)</p> </li> <li> <p>Automatic Swagger</p> </li> <li> <p>Enforces logic and security - automatic partitioning of logic from (each) client app</p> </li> <li> <p>Add new endpoints using standard Flask and SQLAlchemy - customize <code>api/customize_api.py</code> - </p> </li> </ul> <p> </p>"},{"location":"API/#declare-customize-api","title":"Declare / Customize API","text":"<p>APIs are:</p> <ol> <li> <p>Declared in <code>api/expose_api_models.py</code> -- generated code which is typically not modified</p> </li> <li> <p>Customized in <code>api/customize_api.py</code> -- see below, and next page</p> </li> </ol> <p></p> <p> </p>"},{"location":"API/#automatic-swagger-generation","title":"Automatic Swagger Generation","text":"<p>API creation includes automatic swagger generation. Start the server, and open your Browser at <code>localhost:5656</code>.   </p> <p></p> <p> </p>"},{"location":"API/#self-serve","title":"Self-Serve","text":"<p>Unlike Custom APIs which require server development, Self-Serve APIs can be used directly by consumers.  They use Swagger to retrieve the data they want, then copying the URI to their code.  API consumers include:</p> <ul> <li> <p>UI Developers - progress no longer blocked on custom server development</p> </li> <li> <p>Application Integration - remote customers and organizations can similarly meet their own needs</p> </li> </ul> <p>For more information, see Self-Serve APIs.</p> <p> </p>"},{"location":"API/#logic-enabled","title":"Logic Enabled","text":"<p>API Logic Server is so-named because all the update APIs automatically enforce your business Logic.</p> <p>Key Take-away: your API encapsulates your logic, factoring it out of APIs for greater concisenss and sharing / consistency</p> <p> </p>"},{"location":"API/#examples","title":"Examples","text":"<p>The Behave Tests provide several examples of using the API.  You can review them here.</p> <p> </p>"},{"location":"API/#key-usage-custom-apps","title":"Key Usage: custom apps","text":"<p>The automatic Admin App is useful, but most systems will require custom User Interfaces.  Use your favorite framework (eg, React).</p> <p> </p>"},{"location":"API/#apilogicserver-curl","title":"<code>ApiLogicServer</code> curl","text":"<p>While swagger is the best way to explore your API, you may want to use curl during test cycles.  If you have activated security, this fails since the header is not provided.</p> <p>So, as of release 9.05.10, API Logic Server provides CLI commands for:</p> <ol> <li><code>login</code>:<ul> <li>Gets a token from the server (it must must be running)</li> <li>Stores it in <code>api_logic_server_cli/api_logic_server_info.yaml</code> </li> </ul> </li> <li><code>curl</code>:<ul> <li>Gets the saved token (so, you must login first)</li> <li>Appends security headers to the curl command provided as arg #2</li> </ul> </li> </ol> <p></p>"},{"location":"Admin-App-Learning/","title":"App Learning","text":"<p>The GenAI process uses this for learning.  It is part of the Manager so you can customize it:</p> <p></p>"},{"location":"Admin-App-Learning/#context","title":"Context","text":"<p>Generate a full React Admin application using the following instructions. The result must be a runnable React app (<code>npm start</code>) that connects to the supplied JSON:API, with fully implemented components (no placeholders or empty files).</p>"},{"location":"Admin-App-Learning/#app-features","title":"App Features","text":""},{"location":"Admin-App-Learning/#multi-page","title":"Multi-Page","text":"<p>For each resource:</p> <ul> <li>Create a List page showing 7 user-friendly columns</li> <li>Add pagination, sorting, and filtering</li> <li>Link each row to a Display (Show) page</li> </ul>"},{"location":"Admin-App-Learning/#multi-resource","title":"Multi-Resource","text":"<p>Each Display Page should:</p> <ul> <li>Show all fields in a multi-column layout</li> <li>Include a tab sheet (<code>&lt;TabbedShowLayout&gt;</code>) for each related resource using <code>&lt;ReferenceManyField&gt;</code></li> <li>Link child rows to their own display page</li> </ul> <p>Example:  </p> <ul> <li> <p>Customer Display has tab for OrderList </p> </li> <li> <p>The tab (with OrderList) is shown below all the Customer fields.</p> </li> <li>Each Order in the tab links to Order Display</li> </ul>"},{"location":"Admin-App-Learning/#automatic-joins","title":"Automatic Joins","text":"<p>For foreign keys:</p> <ul> <li>Display joined value (e.g., <code>product.name</code> instead of <code>product_id</code>)</li> <li>Use first string field from parent table containing <code>name</code>, <code>title</code>, or <code>description</code></li> </ul> <p>Numeric Primary key fields:</p> <ul> <li>Display at the end of forms/lists</li> </ul>"},{"location":"Admin-App-Learning/#lookups-foreign-keys","title":"Lookups (Foreign Keys)","text":"<p>For foreign key fields:</p> <ul> <li>Provide auto-complete dropdown (<code>&lt;ReferenceInput&gt;</code>)</li> <li>For numeric foreign keys, use the joined string field as lookup text</li> </ul>"},{"location":"Admin-App-Learning/#cascade-add","title":"Cascade Add","text":"<p>When adding a child row as a detail in a Master / Detail, default the Foreign Key to the Parent (Master) Primary Key.</p>"},{"location":"Admin-App-Learning/#implementation","title":"Implementation","text":""},{"location":"Admin-App-Learning/#architecture","title":"Architecture","text":"<ul> <li>Framework: React 18 + react-admin 4.x</li> <li> <p>Data Provider: Custom <code>dataProvider.js</code> using <code>fetchUtils</code> (no external <code>ra-jsonapi-client</code>)</p> </li> <li> <p>Must support: <code>getList</code>, <code>getOne</code>, <code>getMany</code>, <code>getManyReference</code>, <code>create</code>, <code>update</code>, <code>delete</code></p> </li> <li> <p>Must support: filters, joins, sorting, pagination</p> </li> <li> <p>Backend: JSON:API per <code>mcp_discovery.json</code></p> </li> <li>CORS: Ensure API allows <code>http://localhost:3000</code></li> </ul> <p><pre><code>  from flask_cors import CORS  \n  CORS(app, origins='*')  # or restrict to localhost:3000\n</code></pre> - Project Setup:</p> <ul> <li>Use <code>create-react-app</code></li> <li>Include: <code>react-admin</code>, <code>@mui/material</code>, <code>@emotion/react</code>, <code>@emotion/styled</code>, <code>react-router-dom</code></li> <li>Do not use any deprecated or unmaintained libraries</li> <li>Include complete and correct <code>App.js</code>, <code>index.js</code>, <code>dataProvider.js</code>, and <code>index.html</code></li> </ul>"},{"location":"Admin-App-Learning/#per-resource-files-required","title":"Per-Resource Files (Required)","text":"<p>For each resource (<code>Customer</code>, <code>Order</code> etc):</p> <ul> <li>Create a source file under <code>src/</code>, e.g., <code>Customer.js</code></li> <li>Each file must fully implement:<ul> <li><code>CustomerList</code></li> <li><code>CustomerShow</code></li> <li><code>CustomerCreate</code></li> <li><code>CustomerEdit</code></li> </ul> </li> </ul> <p>Use:</p> <ul> <li><code>&lt;ReferenceField&gt;</code> for foreign key displays</li> <li><code>&lt;ReferenceInput&gt;</code> for foreign key input</li> <li><code>&lt;ReferenceManyField&gt;</code> for tabbed child lists</li> <li> <p>For show pages</p> </li> <li> <p>Always start with <code>&lt;SimpleShowLayout&gt;</code>, followed by a <code>&lt;TabbedShowLayout&gt;</code> for related data</p> <ul> <li>DO NOT start with <code>&lt;TabbedShowLayout&gt;</code></li> </ul> </li> </ul> <p>Be sure to include all required imports.  ALWAYS use the following AS IS, plus whatever else is required:</p> <p><pre><code>import { List, FunctionField, Datagrid, TextField, DateField, NumberField, ReferenceField, ReferenceManyField, Show, TabbedShowLayout, Tab, SimpleShowLayout, TextInput, NumberInput, DateTimeInput, ReferenceInput, SelectInput, Create, SimpleForm, Edit, Filter, Pagination, BooleanField, BooleanInput } from 'react-admin';\n</code></pre> You may add other imports, but be sure all those are included.</p> <p>DO NOT use <code>&lt;EmailInput&gt;</code> - use <code>&lt;TextInput&gt;</code>.</p> <p>DO NOT put <code>&lt;ReferenceField&gt;</code> in <code>&lt;Datagrid&gt;</code>.</p> <p>Do not leave any file empty.</p>"},{"location":"Admin-App-Learning/#app-wiring","title":"App Wiring","text":"<p>Sample code for <code>App.js</code>:</p> <pre><code>import React from 'react';\nimport { Admin, Resource } from 'react-admin';\nimport { createTheme } from '@mui/material/styles';\n\n// import each resource\nimport { CustomerList, CustomerShow, CustomerCreate, CustomerEdit } from './Customer';\n...\n// import the data provider\nimport { dataProvider } from './dataProvider';\n\nconst theme = createTheme({\n    palette: {\n        primary: { main: '#1976d2' },    // Material-UI default blue\n        secondary: { main: '#1565c0' },  // A darker blue, or choose another color\n    },\n    typography: { fontSize: 14 },\n});\n\nconst App = () =&gt; {\n    return (\n        &lt;Admin dataProvider={dataProvider}&gt;  // register each resource...\n            &lt;Resource name=\"Customer\" list={CustomerList} show={CustomerShow} edit={CustomerEdit} create={CustomerCreate} /&gt;\n...\n        &lt;/Admin&gt;\n    );\n};\n\nexport default App;\n</code></pre> <p>For dataProvider:</p> <ol> <li>be sure it includes the braces: <code>import { dataProvider }</code></li> <li>Do Not generate either:</li> </ol> <pre><code>import jsonServerProvider from 'ra-data-json-server'\nconst dataProvider = jsonServerProvider('http://api.example.com');\n</code></pre>"},{"location":"Admin-App-Learning/#response-format","title":"Response Format","text":"<p>Format the response as a JSResponseFormat:</p> <p>class JSResponseFormat(BaseModel):  # must match system/genai/prompt_inserts/response_format.prompt     code : str # generated javascript code (only)</p>"},{"location":"Admin-Architecture/","title":"Admin Architecture","text":"<p> TL;DR - instant multi-page, multi-table apps</p> Feature Provides Example Multi-Page List/Show pages for each tableBuilt-in search, sort, export Customer Page, Order Page, etc Multi-Table Tab Sheet for related child data Page Transitions for related data Customer page has OrderListClick --&gt; Order/OrderDetails Automatic Joins for Parent Data Product Name - not just the Id Lookups for foreign keys Find Product for OrderDetail Declarative hide/show Salaried Employee: Hide Union Customize Simple - no HTML / JavaScript Edit <code>ui/admin/admin.yaml</code> Extend Build Custom UIs with your own framework, using the API API-enforced logic simplifies app dev <p>This page describes the Admin App architecture.</p> <p></p>"},{"location":"Admin-Architecture/#uses-global-react-admin","title":"Uses Global React Admin","text":"<p>The admin \"app\" created in your project is just a yaml file.  It is interpreted by a React Admin app (SAFRS React Admin - SRA by Thomas Pollet) that is part of the API Logic Server install, eg: </p> <pre><code>venv/lib/python3.12/site-packages/api_logic_server_cli/create_from_model/safrs-react-admin-npm-build\n</code></pre> <p>This contains the SRA code and the many react libraries it uses.</p> <p></p>"},{"location":"Admin-Architecture/#customized-apps","title":"Customized Apps","text":"<p>The objective of the Admin App is to create an highly functional app instantly, easily customized via the yaml (instead of more complex HTML, JS, CSS, etc).</p> <p>To create a more customized app, you can:</p> <ul> <li>Use the Automatic Custom Apps, or</li> <li>Create your own custom app using the API - by manual coding, or using Generative AI (\"Vibe\")</li> </ul> <p></p>"},{"location":"Admin-Architecture/#appendix-sample-adminyml","title":"Appendix: Sample admin.yml","text":"<p>The <code>admin.yaml</code> is located in your project here:</p> <p></p> Click here to see sample admin.yaml  <p></p> <pre><code>about:\n  date: May 26, 2025 06:57:17\n  recent_changes: works with modified safrs-react-admin\n  version: 0.0.0\napi_root: '{http_type}://{swagger_host}:{port}/{api}'\nauthentication: '{system-default}'\ninfo:\n  number_relationships: 4\n  number_tables: 6\ninfo_toggle_checked: true\nresources:\n  Customer:\n    attributes:\n    - label: ' name*'\n      name: name\n      search: true\n      sort: true\n    - name: balance\n      type: DECIMAL\n    - name: credit_limit\n      type: DECIMAL\n    - name: email\n    - name: email_opt_out\n      type: Boolean\n    - name: id\n    tab_groups:\n    - direction: tomany\n      fks:\n      - customer_id\n      name: OrderList\n      resource: Order\n    - direction: tomany\n      fks:\n      - customer_id\n      name: SysEmailList\n      resource: SysEmail\n    type: Customer\n    user_key: name\n  Item:\n    attributes:\n    - label: ' id*'\n      name: id\n      search: true\n      sort: true\n    - name: order_id\n    - name: product_id\n      required: true\n    - name: quantity\n      required: true\n    - name: amount\n      type: DECIMAL\n    - name: unit_price\n      type: DECIMAL\n    tab_groups:\n    - direction: toone\n      fks:\n      - order_id\n      name: order\n      resource: Order\n    - direction: toone\n      fks:\n      - product_id\n      name: product\n      resource: Product\n    type: Item\n    user_key: id\n  Order:\n    attributes:\n    - label: ' id*'\n      name: id\n      search: true\n      sort: true\n    - name: customer_id\n      required: true\n    - name: notes\n    - name: CreatedOn\n      type: DATE\n    - name: amount_total\n      type: DECIMAL\n    - name: date_shipped\n      type: DATE\n    tab_groups:\n    - direction: tomany\n      fks:\n      - order_id\n      name: ItemList\n      resource: Item\n    - direction: toone\n      fks:\n      - customer_id\n      name: customer\n      resource: Customer\n    type: Order\n    user_key: id\n  Product:\n    attributes:\n    - label: ' name*'\n      name: name\n      search: true\n      sort: true\n    - name: unit_price\n      type: DECIMAL\n    - name: id\n    tab_groups:\n    - direction: tomany\n      fks:\n      - product_id\n      name: ItemList\n      resource: Item\n    type: Product\n    user_key: name\n  SysEmail:\n    attributes:\n    - label: ' id*'\n      name: id\n      search: true\n      sort: true\n    - name: customer_id\n      required: true\n    - name: message\n    - name: subject\n    - name: CreatedOn\n      type: DATE\n    tab_groups:\n    - direction: toone\n      fks:\n      - customer_id\n      name: customer\n      resource: Customer\n    type: SysEmail\n    user_key: id\n  SysMcp:\n    attributes:\n    - name: request\n      type: textarea\n    - label: ' id*'\n      name: id\n      search: true\n      sort: true\n      show_when: isInserting == false\n    type: SysMcp\n    user_key: id\nsettings:\n  HomeJS: /admin-app/home.js\n  max_list_columns: 8\n  style_guide:\n    applicationLocales:\n    - en\n    - es\n    currency_symbol: $\n    currency_symbol_position: left\n    date_format: LL\n    decimal_max: '1000000000'\n    decimal_min: '2'\n    decimal_separator: .\n    detail_mode: tab\n    edit_on_mode: dblclick\n    exclude_listpicker: false\n    include_translation: 'false'\n    keycloak_client_id: alsclient\n    keycloak_realm: kcals\n    keycloak_url: http://localhost:8080\n    locale: en\n    max_decimal_digits: '4'\n    min_decimal_digits: '2'\n    new_mode: dialog\n    pick_style: list\n    row_height: small,\n    serviceType: JSONAPI\n    startSessionPath: /auth/login\n    style: light\n    thousand_separator: ','\n    use_keycloak: 'false'\n</code></pre>"},{"location":"Admin-Customization/","title":"Admin Customization","text":"<p>The creation process does not create hundreds of lines of JavaScript and HTML.  </p> <p>Instead, it creates an _application model, represented in the <code>admin.yaml</code> file.  So, you can customize it easily, without requiring extensive JavaScript/HTML background, or deciphering generated code.</p> <p>Key Take-away: instant admin app, with logic, easy to customize</p>"},{"location":"Admin-Customization/#intelligent-default-creation","title":"Intelligent Default Creation","text":"<p>The system makes reasonable attempts to create useful applications</p> <ul> <li>automatic joins</li> <li>\"favorite\" fields are displayed first, such as field named <code>name</code>.</li> <li>You can configure your favorite names when creating: <pre><code>ApiLogicServer create --project_name=my-project \\\n                      --db_url=nw+ \\\n                      --favorites='nom nommes'\n</code></pre></li> <li>non-favorites (such as <code>id</code>) can be identified with the <code>--non_favorites</code> argument.</li> </ul>"},{"location":"Admin-Customization/#edit-adminyaml","title":"Edit <code>admin.yaml</code>","text":"<p>While these defaults are useful in creating a recognizable application, you will want to control the display order, override labels and so forth.  You can specify such customizations by editing the <code>admin.yaml</code> file below.</p> <p>This file is created initially by the system, so it's not necessary to learn the syntax in detail.  Instead, it's straight-forward to alter the file using your IDE or text editor.</p> <p>Press Browser refresh to reload the application after you make changes; it is not necessary to restart the server</p> <p></p>"},{"location":"Admin-Customization/#models-and-admin-correlation","title":"Models and admin correlation","text":"<p>See this section.</p>"},{"location":"Admin-Customization/#not-altered-on-rebuild","title":"Not altered on <code>rebuild</code>","text":"<p>The rebuild commands do not override your customizations.  They do recreate <code>admin-created.yaml</code>.  You can use this to merge into your <code>admin.yaml</code>, e.g., to pick up new tables, relationships, etc.</p> <p> </p>"},{"location":"Admin-Customization/#show_when","title":"show_when","text":"<p>You can provide an expression that determines when a field (and its caption) are hidden.  For example, you might show the <code>Dues</code> only when the <code>EmployeeType</code> is Hourly, by declaring this in your <code>admin.yaml</code>:</p> <p></p> <p><code>Dues</code> is hidden for non Hourly:</p> <p></p> <p>and is visible for Hourly:</p> <p></p> <p>It also works on update, such as insert:</p> <p></p>"},{"location":"Admin-Customization/#hiding-fields-in-insert-mode","title":"Hiding Fields in Insert Mode","text":"<p>Note you can hide fields depending on the state of the form, e.g. for <code>OrderDetail</code>, we can hide the Id since it is generated by the system:</p> <pre><code>  OrderDetail:\n    attributes:\n      - label: ' Id*'\n        name: Id\n        search: true\n        sort: true\n        show_when: isInserting == false\n</code></pre> <p> </p>"},{"location":"Admin-Customization/#multiple-adminyaml-files","title":"Multiple <code>admin.yaml</code> files","text":"<p>When creating your own admin files, we recommend starting with the created one.</p> <p>Also, use caution in removing resources, since these may be used in joins and lookups.</p> <p>To run the app, the url would be something like: <code>localhost:5656/admin/my-app-name</code>.</p> <p> </p>"},{"location":"Admin-Customization/#appendix","title":"Appendix","text":""},{"location":"Admin-Customization/#browser-cache","title":"Browser Cache","text":"<p>Browsers cache data for performance.  This may required you to clear your Browser cache.</p>"},{"location":"Admin-Tour/","title":"Automatic Admin App","text":"<p> TL;DR - instant multi-page, multi-table apps</p> Feature Provides Example Multi-Page List/Show pages for each tableBuilt-in search, sort, export Customer Page, Order Page, etc Multi-Table Tab Sheet for related child data Page Transitions for related data Customer page has OrderListClick --&gt; Order/OrderDetails Automatic Joins for Parent Data Product Name - not just the Id Lookups for foreign keys Find Product for OrderDetail Declarative hide/show Salaried Employee: Hide Union Customize Simple - no HTML / JavaScript Edit <code>ui/admin/admin.yaml</code> Extend Build Custom UIs with your own framework, using the API API-enforced logic simplifies app dev <p>This page describes the Admin App automatically created during <code>ApiLogicServer create</code>.</p> <p></p> <p> </p>"},{"location":"Admin-Tour/#use-cases","title":"Use Cases","text":"<p>The system automatically creates multi-page, multi-table applications as you'll see below.  Typical usage is described here.</p>"},{"location":"Admin-Tour/#back-office-admin","title":"Back Office Admin","text":"<p>Systems commonly include a number of \"back office\" admin apps that need to be usable, but do not warrant the time and cost of custom app development.  These are costly to build by hand.</p> <p>Automatic creation of such apps eliminates the time and expense of such back office apps from your project.</p>"},{"location":"Admin-Tour/#prototyping-agile-collaboration","title":"Prototyping / Agile Collaboration","text":"<p>It's a common observation that business users relate poorly to technical documentation such as data model diagrams, but instantly related to running pages containing their data.</p> <p>API Logic Server can create apps instantly, from just the data model.  Users are able to run the screens - including updates - and begin the collaboration process, such as: * identify data model issues (\"hey, wait, customers have more than 1 address\")</p> <ul> <li>identify rules (\"hmm, it needs to verify that balances do not exceed credit limits\")</li> </ul> <p>As such items are noted, you can update the data model, recreate, and iterate the design very rapidly, since there is no cost to create the API or the UI.</p>"},{"location":"Admin-Tour/#complements-custom-api-based-apps-automatic-api-and-logic-reuse","title":"Complements Custom API-based Apps (Automatic API and Logic Reuse)","text":"<p>That said, it's common that you will need custom apps for complex functions, customer-facing branding, and so forth.</p> <ul> <li> <p>Create these in your favorite technology (React, Angular, etc)</p> </li> <li> <p>Base them on the automatically created API, which handles not only data retrieval and update, but also enforces your business logic, which dramatically reduces client app dev effort by factoring out business logic to the shared API.</p> </li> </ul>"},{"location":"Admin-Tour/#architecture-react-based-on-created-logic-enabled-api","title":"Architecture - React, based on created logic-enabled API","text":"<p>The Admin App is created in your ApiLogicProject, and operates as follows:</p> <ol> <li>Applications are declared in yaml files, automatically created from your database</li> <li>The applications are Single Page React applications executing in the Browser, acquiring data via the SAFRS JSON:API.  </li> <li>Updates are submitted to SQLAlchemy; LogicBank listens for <code>before_flush</code> events, and enforces the logic declared in your <code>declare_logic.py</code>.</li> </ol> <p>For more information on Architecture, see Architecture.</p> <p></p> <p>Key Take-away: instant admin apps, an api for custom apps, with enforcement of declarative logic.</p> <p> </p>"},{"location":"Admin-Tour/#declare-behavior-in-adminyaml","title":"Declare Behavior in <code>admin.yaml</code>","text":"<p>As described in Admin Customization, you can declare your own customized labels, field orders, help text in the <code>admin.yaml</code> file.</p>"},{"location":"Admin-Tour/#multi-app-projects","title":"Multi-App Projects","text":"<p>Explore the sample project <code>ui/admin</code> directory.  You will note it contains several admin files (new for release 6.1).  Each file defines a separate admin app:</p> <ul> <li> <p>the default app is accessed by <code>http://localhost:5656/</code>,corresponding to <code>ui/admin/admin.yaml</code></p> </li> <li> <p>custom apps are accessed by <code>http://localhost:5656/admin/custom_app/</code>,corresponding to <code>ui/admin/custom_app.yaml</code></p> </li> </ul> <p>See Multiple admin.yaml files.</p> <p>Tip: Group-specific terminology</p> <p>You can use these to customize terminology for different user groups within an organization.  </p> <p>For example, <code>custom_app.yaml</code> file might be used by Accounting, with labels such Customer Account instead of Customer, Account Balance instead of Balance, and a re-ordered left-side navigation.</p> <p> </p>"},{"location":"Admin-Tour/#basics-browsing-your-data","title":"Basics: browsing your data","text":"<p>Let's explore the admin app for the sample database.</p>"},{"location":"Admin-Tour/#multi-page-multi-table-automatic-joins","title":"Multi-Page, Multi-Table, Automatic Joins","text":"<p>Explore basic data browsing:</p> <ol> <li>Navigate to <code>Customer</code>    * Depending on your screen size, you may need to hit the \"hamburger menu\" (top left) to see the left menu    * Observe support for Pagination    * Observe support for Multi-Field Search</li> <li>Click the Customer row to drill down to see Customer Details</li> <li>Observe the <code>Placed Order List</code> tab at the bottom    * Observe the multi-table page: a tab is created for each foreign key relationship<ul> <li>You can customize your model if these are absent in your database</li> </ul> </li> <li>On the Customer page (shown below), click the first Placed Order row    * Observe you can navigate through your database, based on the foreign key relationships</li> </ol> <p></p> <ol> <li>On the Order Page    * Observe the Product information<ul> <li>This was not stored in the <code>OrderDetail</code> row, which contains only the <code>ProductId</code> -- which is not interesting to users.</li> <li>The system provides automatic joins, selecting the most likely \"parent\" attribute (the attribute called <code>name</code>, or containing <code>name</code>)<ul> <li>You can tune this (e.g. for different languages) using the <code>--favorites</code> argument when creating your project.</li> </ul> </li> <li>Click one of the <code>Product Id</code> values</li> <li>Observe the modal dialog</li> </ul> </li> </ol> <p> </p> <p>Key Take-away: instant multi-page / multi-table admin apps, suitable for back office, and instant agile collaboration.</p> Without Automatic Joins <p></p>"},{"location":"Admin-Tour/#search-and-sort","title":"Search and Sort","text":"<p>Click the left menu to see the Customer list again</p> <ol> <li>Observe the pagination controls at the bottom right</li> <li>Enter a in the <code>Search</code> box</li> <li>Click the <code>Contact Title</code> to observe sorting</li> </ol>"},{"location":"Admin-Tour/#declarative-hideshow-show_when","title":"Declarative Hide/Show: <code>show_when</code>","text":"<p>You can provide an expression that determines when a field (and its caption) are hidden.  For example, you might show the <code>Dues</code> only when the <code>EmployeeType</code> is Hourly, by declaring this in your <code>admin.yaml</code>:</p> <p></p> <p><code>Dues</code> is hidden for non Hourly:</p> <p></p> <p>and is visible for Hourly:</p> <p></p> <p>It also works on update, such as insert:</p> <p></p> <p> </p>"},{"location":"Admin-Tour/#data-types","title":"Data Types","text":"<p>Your yaml can designate data types.   Browse the sample for example, such as <code>Order.Ready</code>:</p> <pre><code>      - name: Ready\n        type : Boolean\n</code></pre> <p> </p>"},{"location":"Admin-Tour/#images-local-or-url","title":"Images: local or URL","text":"<p>As of release 6.03.06, data fields can refer to images.  Explore the Employee page to see images, using the field <code>PhotoPath</code>.  </p>"},{"location":"Admin-Tour/#declaring-image-fields","title":"Declaring Image Fields","text":"<p>Edit your <code>ui/admin/admin.yaml</code> to designate images, e.g.:</p> <pre><code>      - name: PhotoPath\n        type: Image\n</code></pre>"},{"location":"Admin-Tour/#locally-stored-images","title":"Locally Stored Images","text":"<p>Images can be stored on the server, by placing them as shown in the diagram below:</p> <p></p>"},{"location":"Admin-Tour/#url-based-images","title":"URL-based Images","text":"<p>You can also references images by url, such as Steele, specifying a value like:</p> <pre><code>https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcSWYaD6pHRUklVcWdaY4Jl2HOQCPfxJo8n2zj-ZYBvA8g&amp;s\n</code></pre> <p> </p>"},{"location":"Admin-Tour/#application-information","title":"Application Information","text":"<p>Developers can edit the <code>ui/admin/admin.yaml</code> to provide application help, as shown below.</p> <p>Users can elect to hide/show this info:</p> <ol> <li> <p>Info Toggle - on the personalization control, toggle the info control to display information at the top of each screen.  It's initial value is specified by the <code>ui/admin/admin.yaml</code> property: <code>info_toggle_checked: true</code>.</p> </li> <li> <p>Info Dialog - click this to show a pop-up dialog for help</p> </li> </ol> <p></p>"},{"location":"Admin-Tour/#update","title":"Update","text":"<p>Your admin app has important support for making updates.</p>"},{"location":"Admin-Tour/#lookup","title":"Lookup","text":"<p>Many databases uses automatically generated primary keys.  These can simplify design, but it is unreasonable to expect end users to use these.</p> <p>For example, Products are identified by an <code>Id</code>.  To refer to a parent <code>Product</code>, child <code>OrderDetail</code> rows declare a foreign key from <code>OrderDetail.ProductId</code>.</p> <p>When adding or altering an order, it's unreasonable to expect end users to enter <code>ProductIds.</code> Lookup support addresses this issue.</p> <p>To explore Lookup support:</p> <ol> <li>On the Customer list    * Click the column header for <code>Company Name</code>    * Remove the search criteria - this should return Alfreds Futterkiste to the top of the list</li> <li>Click that customer to drill down to the Customer Page</li> <li>Click the first Order</li> <li>On the Order page, click the pencil icon to enter update mode    * You should see the page shown below</li> <li>Position to the <code>Product</code> field, and begin typing to Lookup a different product    * Internally, the system will obtain the <code>Product.Id</code> and update the <code>OrderDetail.ProductId</code></li> <li>Click save</li> </ol> <p></p>"},{"location":"Admin-Tour/#cascade-add","title":"Cascade Add","text":"<p>Cascade Add sets child Foreign Key values to corresponding parent values, such as setting the CustomerId for a new Order.  Support is also provided to add multiple rows, such as the Order Details for an Order.</p> <p>For example:</p> <ol> <li>Click Customer List</li> <li>Click the first Customer (name is \"Alfreds Futterkiste\", CustomerID <code>ALFKI</code>)</li> <li>Click + Add New Order (the bottom of the screen)</li> <li>On the ensuing Add, note the defaulted Customer at the bottom of the page</li> <li>Lookup Employee (Sales Rep)</li> <li>Click Save and Show - you should see this page    </li> <li>Click Add New Order Detail</li> <li>Lookup Product</li> <li>Click Save and Add Another </li> <li>Lookup { start=10 } Product (choose a different one)</li> <li>Click Save </li> </ol> <p>Observe that Logic Enforcement has computed the <code>Order Amount</code>.</p> <p> </p>"},{"location":"Admin-Tour/#logic-enforcement","title":"Logic Enforcement","text":"<p>Repeat the process above, but note the <code>Customer.Balance</code> before and after.  This adjustment occurred not because of typical code in UI controllers or api services, but because of the following rules in <code>logic/declare_logic.py:</code> <pre><code>    # get Product Price (e,g., on insert, or ProductId change)\n    Rule.copy(derive=models.OrderDetail.UnitPrice,\n              from_parent=models.Product.UnitPrice)\n    # compute price * qty\n    Rule.formula(derive=models.OrderDetail.Amount,\n                 as_expression=lambda row: row.UnitPrice * row.Quantity)\n\n    # adjust AmountTotal iff Amount changes\n    Rule.sum(derive=models.Order.AmountTotal,\n             as_sum_of=models.OrderDetail.Amount)\n\n    # adjust Balance iff AmountTotal or ShippedDate or CustomerID changes\n    Rule.sum(derive=models.Customer.Balance,\n             as_sum_of=models.Order.AmountTotal,\n             where=lambda row: row.ShippedDate is None)  # adjusts - *not* a sql select sum...\n    Rule.constraint(validate=models.Customer,\n                    as_condition=lambda row: row.Balance &lt;= row.CreditLimit,\n\n\n\n    def units_in_stock(row: models.Product, old_row: models.Product, logic_row: LogicRow):\n        result = row.UnitsInStock - (row.UnitsShipped - old_row.UnitsShipped)\n        return result\n    Rule.sum(derive=models.Product.UnitsShipped, as_sum_of=models.OrderDetail.Quantity,\n             where=\"row.ShippedDate is not None\")\n    Rule.formula(derive=models.Product.UnitsInStock, calling=units_in_stock)\n</code></pre> Such logic is automatically re-used over transactions, and is therefore equivalent to several hundred lines of code.  So, these rules also govern:</p> <ul> <li>changing an <code>OrderDetail.ProductId</code> (as we did here)</li> <li>changing an <code>OrderDetail.Quantity</code> </li> <li>adding <code>OrderDetail</code> rows</li> <li>deleting <code>OrderDetail</code> rows</li> <li>moving an <code>Order</code> to a new <code>Customer</code></li> <li>changing <code>Order.ShippedDate</code></li> <li>deleting an <code>Order</code></li> </ul> <p>One of the mechanisms to debug logic is the logic log; here is the log from changing the Product, above, illustrating that our change was a multi-table transaction, altering 5 rows:</p> <pre><code>Logic Phase:        ROW LOGIC(session=0x1072b1d30) (sqlalchemy before_flush)             - 2021-12-29 20:19:07,564 - logic_logger - INFO\n..OrderDetail[1040] {Update - client} Id: 1040, OrderId: 10643, ProductId:  [28--&gt;] 1, UnitPrice:  [45.6000000000--&gt;] 45.60000000000000142108547152020037174224853515625, Quantity: 15, Discount: 0.25, Amount: 684, ShippedDate:   row: 0x1071f2280  session: 0x1072b1d30 - 2021-12-29 20:19:07,564 - logic_logger - INFO\n..OrderDetail[1040] {copy_rules for role: Product - UnitPrice} Id: 1040, OrderId: 10643, ProductId:  [28--&gt;] 1, UnitPrice:  [45.6000000000--&gt;] 18.0000000000, Quantity: 15, Discount: 0.25, Amount: 684, ShippedDate:   row: 0x1071f2280  session: 0x1072b1d30 - 2021-12-29 20:19:07,565 - logic_logger - INFO\n..OrderDetail[1040] {Formula Amount} Id: 1040, OrderId: 10643, ProductId:  [28--&gt;] 1, UnitPrice:  [45.6000000000--&gt;] 18.0000000000, Quantity: 15, Discount: 0.25, Amount:  [684--&gt;] 270.0000000000, ShippedDate:   row: 0x1071f2280  session: 0x1072b1d30 - 2021-12-29 20:19:07,565 - logic_logger - INFO\n..OrderDetail[1040] {Prune Formula: ShippedDate [['Order.ShippedDate']]} Id: 1040, OrderId: 10643, ProductId:  [28--&gt;] 1, UnitPrice:  [45.6000000000--&gt;] 18.0000000000, Quantity: 15, Discount: 0.25, Amount:  [684--&gt;] 270.0000000000, ShippedDate:   row: 0x1071f2280  session: 0x1072b1d30 - 2021-12-29 20:19:07,565 - logic_logger - INFO\n....Product[1] {Update - Adjusting Product: UnitsShipped, UnitsShipped} Id: 1, ProductName: Chai, SupplierId: 1, CategoryId: 1, QuantityPerUnit: 10 boxes x 20 bags, UnitPrice: 18.0000000000, UnitsInStock: 39, UnitsOnOrder: 0, ReorderLevel: 10, Discontinued: 0, UnitsShipped:  [0--&gt;] 15  row: 0x1071f2df0  session: 0x1072b1d30 - 2021-12-29 20:19:07,567 - logic_logger - INFO\n....Product[1] {Formula UnitsInStock} Id: 1, ProductName: Chai, SupplierId: 1, CategoryId: 1, QuantityPerUnit: 10 boxes x 20 bags, UnitPrice: 18.0000000000, UnitsInStock:  [39--&gt;] 24, UnitsOnOrder: 0, ReorderLevel: 10, Discontinued: 0, UnitsShipped:  [0--&gt;] 15  row: 0x1071f2df0  session: 0x1072b1d30 - 2021-12-29 20:19:07,567 - logic_logger - INFO\n....Product[28] {Update - Adjusting Old Product} Id: 28, ProductName: R\u00f6ssle Sauerkraut, SupplierId: 12, CategoryId: 7, QuantityPerUnit: 25 - 825 g cans, UnitPrice: 45.6000000000, UnitsInStock: 26, UnitsOnOrder: 0, ReorderLevel: 0, Discontinued: 1, UnitsShipped:  [0--&gt;] -15  row: 0x1072bd730  session: 0x1072b1d30 - 2021-12-29 20:19:07,568 - logic_logger - INFO\n....Product[28] {Formula UnitsInStock} Id: 28, ProductName: R\u00f6ssle Sauerkraut, SupplierId: 12, CategoryId: 7, QuantityPerUnit: 25 - 825 g cans, UnitPrice: 45.6000000000, UnitsInStock:  [26--&gt;] 41, UnitsOnOrder: 0, ReorderLevel: 0, Discontinued: 1, UnitsShipped:  [0--&gt;] -15  row: 0x1072bd730  session: 0x1072b1d30 - 2021-12-29 20:19:07,568 - logic_logger - INFO\n....Order[10643] {Update - Adjusting Order: AmountTotal} Id: 10643, CustomerId: ALFKI, EmployeeId: 6, OrderDate: 2013-08-25, RequiredDate: 2013-09-22, ShippedDate: None, ShipVia: 1, Freight: 29.4600000000, ShipName: Alfreds Futterkiste, ShipAddress: Obere Str. 57, ShipCity: Berlin, ShipRegion: Western Europe, ShipPostalCode: 12209, ShipCountry: Germany, AmountTotal:  [1086.00--&gt;] 672.0000000000, Country: None, City: None  row: 0x1072b1490  session: 0x1072b1d30 - 2021-12-29 20:19:07,569 - logic_logger - INFO\n......Customer[ALFKI] {Update - Adjusting Customer: Balance} Id: ALFKI, CompanyName: Alfreds Futterkiste, ContactName: Maria Anders, ContactTitle: Sales Representative, Address: Obere Str. 57, City: Berlin, Region: Western Europe, PostalCode: 12209, Country: Germany, Phone: 030-0074321, Fax: 030-0076545, Balance:  [2102.0000000000--&gt;] 1688.0000000000, CreditLimit: 2200.0000000000, OrderCount: 15, UnpaidOrderCount: 10  row: 0x107210670  session: 0x1072b1d30 - 2021-12-29 20:19:07,570 - logic_logger - INFO\nLogic Phase:        COMMIT(session=0x1072b1d30)                                          - 2021-12-29 20:19:07,572 - logic_logger - INFO\n....Order[10643] {Commit Event} Id: 10643, CustomerId: ALFKI, EmployeeId: 6, OrderDate: 2013-08-25, RequiredDate: 2013-09-22, ShippedDate: None, ShipVia: 1, Freight: 29.4600000000, ShipName: Alfreds Futterkiste, ShipAddress: Obere Str. 57, ShipCity: Berlin, ShipRegion: Western Europe, ShipPostalCode: 12209, ShipCountry: Germany, AmountTotal:  [1086.00--&gt;] 672.0000000000, Country: None, City: None  row: 0x1072b1490  session: 0x1072b1d30 - 2021-12-29 20:19:07,572 - logic_logger - INFO\n</code></pre> <p>Note: your log is truncated to make it easy to view on a console, as explained in the link above.</p>"},{"location":"Admin-Vibe-Sample/","title":"Vibe Example","text":"<p> TL;DR - Vibe for graphs, maps, trees, cards</p> <p>Use <code>genai-logic genai-add-app --vibe</code> to generate a standard react app.</p> <p>This page illustrates a number of customizations to the northwind sample (<code>samples/nw_sample</code> in the Manager).  These are shown below.</p> <p>These customizations were performed in VSCode using CoPilot, with the Claude Sonnet 4.5 Agent.</p> <p></p>"},{"location":"Admin-Vibe-Sample/#copilot-summary","title":"Copilot Summary","text":"<p>Here is the final transcript from CoPilot - it seems pleased with its work!</p> Demos, Tutorials, Samples <p>Fantastic! \ud83c\udf89 I'm thrilled that everything is working perfectly now!</p> <p>What We've Successfully Accomplished:</p> <ul> <li> <p>Employee List/Cards Toggle \u2705</p> <ul> <li>List view: Traditional data grid</li> <li>Cards view: Beautiful card layout with employee photos</li> <li>PhotoPath image support in both cards and show pages</li> <li>Professional styling with hover effects and responsive design</li> </ul> </li> <li> <p>Employee Show Page \u2705</p> <ul> <li>Single, prominent photo display at the top (no duplicates!)</li> <li>Comprehensive employee information in a clean grid layout</li> <li>Proper image handling with fallback avatars</li> <li>Seamless navigation from department tree \u2192 employee grid \u2192 employee details</li> </ul> </li> <li> <p>Department Tree View \u2705</p> <ul> <li>Hierarchical expandable tree with +/- icons for incremental expansion</li> <li>Split-panel interface with department details on the right</li> <li>Professional tabbed layout using Material-UI tabs</li> <li>Employee grid display with clickable navigation to employee details</li> </ul> </li> <li> <p>Supplier Map View Summary \u2705</p> <ul> <li> <p>Interactive World Map: Displays suppliers as red markers on a Leaflet.js world map with country-based positioning</p> </li> <li> <p>Dual View Toggle: Switch between traditional list view and geographic map view using Material-UI toggle buttons</p> </li> <li> <p>Click Navigation: Click markers or popup buttons to navigate directly to individual supplier detail pages</p> </li> <li> <p>Info Panel: Overlay showing supplier count (29 total) with usage instructions and map legend</p> </li> <li> <p>Global Coverage: Supports 20+ countries with fallback handling for unknown locations</p> </li> </ul> </li> <li> <p>Technical Excellence \u2705</p> <p>Robust error handling and data type consistency   Proper React Admin component patterns   Material-UI integration with consistent styling   Clean, maintainable code structure</p> </li> </ul> <p>This implementation provides a truly professional and intuitive user experience for navigating department hierarchies and employee information. The combination of the tree view, image support, and tabbed interfaces creates a modern, enterprise-quality application!</p> <p></p>"},{"location":"Admin-Vibe-Sample/#setup","title":"Setup","text":"<p>Node is required.</p> <p>In the Manager, <code>samples/nw_sample</code> has already been created.  You will need to <code>npm install</code> and <code>npm start</code>.</p> <p>If you want to start from scratch (e.g. to mimic the process with your own database):</p> Vibe Kickstart<pre><code>genai-logic create --project-name=nw, --db-url=nw\n\n# Open the project in your IDE, and issue Termimal commands:\ngenai-logic genai-add-app\n</code></pre> <p>Then, proceed with <code>npm install</code> and <code>npm start</code>.</p> <p>The Landing Page Graphics requires you <code>genai-logic genai-graphics</code>.  For more information, click here.</p> <p>Generated Apps do not yet support security; you must disable security: <code>als add-auth --provider-type=None</code></p> <p></p>"},{"location":"Admin-Vibe-Sample/#landing-page-with-graphs","title":"Landing Page with Graphs","text":"<p>We first created the graphics, as described here.</p> <p>We then requested a landing page (no hints on product architecture, by the way... we did not ask where it acquired this information).</p> Prompt -- Landing Page with Graphics<pre><code>In ui/reference_react_app, create a landing page that summarizes the architecture, and iFrame to \"http://localhost:5656/dashboard\"\n</code></pre> <p></p>"},{"location":"Admin-Vibe-Sample/#employee-cards","title":"Employee Cards","text":"<p>This example was easy and worked the first time:</p> Prompt -- Employee Cards<pre><code>Add an option on the Employee List page to show results as cards, and \nshow the employee image in the card.\n</code></pre> <p></p>"},{"location":"Admin-Vibe-Sample/#department-tree","title":"Department Tree","text":"<p>The examples above worked the first time.  The tree and map took many hours to work out.  See the discussion in the Appendix.</p> Prompt -- Department Tree<pre><code>Create a Department tree view component for the existing Department list page. \n\nMake it collapsible/expandable and integrate it into the existing Department.js file.\n\nThe tree should show just the Department Name as a link; \nclicking the link opens an Information panel to the right.\nThe panel is equivalent to Department Show: all the fields, plus tab sheets for related data.\nThe tab sheets should provide transitions to the related data show pages (eg, the Employee page).\n</code></pre> <p></p>"},{"location":"Admin-Vibe-Sample/#supplier-map","title":"Supplier Map","text":"<p>As with the tree, this took many hours to work out.</p> Prompt -- Supplier Map<pre><code>Enhance supplier list page to include a toggle for a professional, interactive world map view.\nThe map should display supplier icons on a real map with proper geography.  \nClick a supplier icon should open the Supplier show page.\n</code></pre>"},{"location":"Admin-Vibe-Sample/#required-learnings","title":"Required Learnings","text":"<p>The screenshot below shows how this worked in VSCode:</p> <ol> <li>GenAI-Logic project creation automatically included learnings for creating maps.</li> <li> <p>Your prompt, plus the learnings, created the revised page.</p> <ul> <li>Observe it differs from the screen shot below.  GenAI does not produce the same result every time!</li> </ul> </li> </ol> <p></p> <p></p>"},{"location":"Admin-Vibe-Sample/#learnings-creation","title":"Learnings Creation","text":"<p>It took many hours (not days) to build the learnings shown above. If you wish to build similar learnings for other UI paradidigms, the process is roughly:</p> <ol> <li>Make a request</li> <li>Iterate the request as required (this is the part that took hours)</li> <li>When the result is good, ask the GenAI tool to provide a prompt that is simple, and would have achieved the result without hours of iteration</li> <li>Create a file with the suggested prompt in the directory shown above</li> </ol>"},{"location":"Admin-Vibe/","title":"Generated React App","text":"<p> TL;DR - instant multi-page, multi-table apps</p> <p>Use <code>genai-logic genai-add-app --vibe</code> to generate a standard react app,   fully customizable using GenAI Vibe tools and/or your IDE.  You get a headstart:</p> <ul> <li>No data mockups - use the created server</li> <li>No starting from scratch - customize a running multi-page app</li> <li>Minimal background on html, javascript etc, you can begin using Vibe/Natural Language tools to create custom User Interfaces </li> </ul> <p>This complements the automated Admin App, which focuses on speed and simplicity.</p> <p>It provides:</p> Feature Provides Example Multi-Page List/Show pages for each tableBuilt-in search, sort, export Customer Page, Order Page, etc Multi-Table Tab Sheet for related child data Page Transitions for related data Customer page has OrderListClick --&gt; Order/OrderDetails Automatic Joins for Parent Data Product Name - not just the Id Lookups for foreign keys Find Product for OrderDetail Cascade Add to default foreign keys Add Line Items for this order Customize Use GenAI Vibe tools and/or your IDE Add new pages, controls, etc <p>See status, at end.</p> <p></p>"},{"location":"Admin-Vibe/#generation","title":"Generation","text":"<p>Pre-reqs:</p> <ol> <li>An OpenAI API Key (click here)</li> <li>Node</li> </ol> <p>Once your project is created, you can create a UI Application like this (e.g., use the Terminal Window of your project):</p> Create and Run React app<pre><code>genai-logic genai-add-app --vibe\ncd ui/react_admin\nnpm install\nnpm start\n</code></pre> <p>This can take a while (e.g., 6 min for northwind sample).  Enjoy your favorite warm beverage.</p> <p></p>"},{"location":"Admin-Vibe/#generated-app","title":"Generated App","text":"<p>The GenAI process uses these to drive creation:</p> <ol> <li>You projects' <code>ui/admin/admin.yaml</code> (click here), which provides information about the schema and basic layout</li> <li>The Managers' <code>Admin-App-Learning</code> (click here) - describes the functionality and architecture of the generated app</li> </ol> <p>It creates applications like this:</p> <p></p> <p></p>"},{"location":"Admin-Vibe/#running-app","title":"Running App","text":"<p>The running app looks like this:</p> <p></p> <p></p>"},{"location":"Admin-Vibe/#vibe-customization","title":"Vibe Customization","text":"<p>Not a bad app, but the objective here is that we can customize - simply, with Natural Language.  Let's try it.</p> <p>Here, we are using the Claude preview of VsCode, and make the request:</p> Vibe: Customize with Natural Language<pre><code>Update the Customer list to provide users an option to see results in a list, or in cards\n</code></pre> <p></p> <p>And we get:</p> <p></p>"},{"location":"Admin-Vibe/#northwind-reference-example","title":"Northwind Reference Example","text":"<p>The Northwind app (<code>samples/nw_sample/ui/reference_react_app</code> in the manager) has been customized to illustrate what you can do with vibe, including graphs and charts, maps, trees, cards, etc.</p> <p>To review, click here.</p> <p></p> <p></p>"},{"location":"Admin-Vibe/#or-update-the-training","title":"Or, Update the training","text":"<p>This customization example was a one-off.</p> <p>Since the app learning is a part of your project, you can alter it to create apps with lists / cards, automatically.</p> <p></p>"},{"location":"Admin-Vibe/#appendix-status","title":"Appendix: Status","text":"<p>As of July 1, 2025, this is under construction.  Please contact us at <code>support@genai-logic.com</code> for more information and early access.  We are actively seeking collaboration.</p> <p>We have tested this on the basic_demo project.  It creates runnable apps, using a dataProvider for safrs json:api.</p> <p>Note: \"ai can make errors\"* - these often require minor corrections to imports, etc.  We are tuning the learning to reduce these.</p> <p>Working:</p> <ul> <li>Master / Detail Tab Sheets, Grid (multi-column) Show pages, Automatic Joins, Filter, Transitions, Update with Validation, Lookups, Cascade Add</li> </ul> <p>ToDo:</p> <ul> <li>Security (disable with <code>als add-auth --provider-type=None</code>)</li> </ul> <p></p>"},{"location":"Admin-Vibe/#appendix-explore","title":"Appendix: Explore","text":"<p>The quickest way to get going...</p> <ol> <li>Install GenAI-Logic and the Manager (click here), and</li> <li>In the Manager, open a terminal window and create Basic Demo (Info here) as described in the Readme:</li> </ol> <pre><code>ApiLogicServer create --project_name=basic_demo --db_url=basic_demo\n</code></pre> <ol> <li>Open the created app, and run it (F5) to explore the Automatic Admin App and the API</li> <li>Execute the Generation procedure as described above</li> <li>Proceed with the readme to explore business logic, MCP, customization, and integration</li> </ol>"},{"location":"ApiLogicServer-create/","title":"API Logic Server","text":"<p> TL;DR: Instant Creation, Rules, Standard Tooling.  \u00a0 Open Source.</p> <p>Eliminate long dev cycles that delay Agile Collaboration and custom app dev with Working Software, Now.</p> <p>API Logic Server is the fastest and simplest way to create modern, scalable API-based database systems:</p> <ol> <li> <p>Create: <code>ApiLogicServer create</code> builds an executable project from your database, instantly:</p> <ul> <li> <p>Multi-page web app - enable agile collaboration </p> </li> <li> <p>Self-serve API - unblock custom App Dev</p> </li> </ul> </li> <li> <p>Customize: using Python, your IDE and standard libraries such as Flask and SQLAlchemy:</p> <ul> <li> <p>Declare <code>rules</code> that are 40X more concise than code -- unique to API Logic Server \u00a0\u00a0 </p> </li> <li> <p>Extend with standard Python</p> </li> <li> <p>Iterate from revised database designs, preserving customizations</p> </li> </ul> </li> <li> <p>Deploy: automated scripts create standard containers for deployment</p> </li> </ol> <p>Check out the new AI-Driven Tutorial -- article here, or watch the video.  Also, try the Basic Demo.</p> <p> </p> <p>Click to see Created Admin App, Project, Architecture</p> <p> </p> <p>Created Admin App</p> <p>The Admin App is shown below:</p> <p></p> <p> </p> <p>Customize in IDE</p> <p>VSCode and PyCharm users can customize and run/debug within their IDE with these steps.  Created projects include Launch and Docker configurations.  </p> <p></p> <p>Rebuild services are provided to accommodate changes to database structure or ORM classes.</p> <p> </p> <p>Standard, Scalable Modern Architecture</p> <ul> <li>A modern 3-tiered architecture, accessed by APIs</li> <li>Logic is automatically reused, factored out of web apps and custom services</li> <li>Containerized for scalable cloud deployment - the project includes a dockerfile to containerize it to DockerHub.</li> </ul> <p></p> <p> </p>"},{"location":"ApiLogicServer-create/#check-it-out","title":"Check it out","text":""},{"location":"ApiLogicServer-create/#instant-evaluation-no-install","title":"Instant Evaluation - no install","text":"<p>Run in the cloud: VSCode via your Browser, courtesy Codespaces.  Use your existing GitHub account (no signup is required), and:</p> <ol> <li> <p>Click here to open the Create Codespace page.</p> </li> <li> <p>Configure as desired, and click Create codespace.</p> </li> </ol> <p>This process takes about a minute.  Wait until you see the port created.</p> <p>We think you'll find Codespaces pretty amazing - check it out!</p> <p> </p>"},{"location":"ApiLogicServer-create/#self-demo","title":"Self Demo","text":"<p>You can build a sample app from a simple pre-installed database to see the key features:</p> <ol> <li> <p>To install, click here</p> </li> <li> <p>To demo the key features, click here</p> </li> </ol> <p>The navigation menu on the left contains the Tutorial and other samples.  These all use pre-installed databases.</p> <p> </p>"},{"location":"ApiLogicServer-create/#instant-cloud-deployment","title":"Instant Cloud Deployment","text":"<p>Follow this procedure to</p> <ol> <li> <p>Create a project from a sample dockerized database</p> </li> <li> <p>Containerize your project</p> </li> <li> <p>Deploy to Azure</p> </li> </ol> <p>Once you are installed, the entire process takes well under an hour.  You will need an Azure account for cloud deployment (but the prior steps are useful to run).</p> <p> </p>"},{"location":"ApiLogicServer-create/#in-a-nutshell","title":"In a Nutshell","text":"<p>Here is a quick screen-shot demo of the basic process:</p> 1. Instant App and API2. Flexible Customization3. Declarative Logic \u00a0\u00a0 4. Deployment <p>Create a Flask/SQLAlchemy project from your database:</p> Create Project from database, using API Logic Server CLI<pre><code>ApiLogicServer create --db_url=sqlite:///sample_db.sqlite --project_name=ApiLogicProject\n</code></pre> <p>That command creates a standard project you can open and execute in your IDE.  Here's the Admin App, ready for business user collaboration:</p> <p></p> <p>Expore API, Using Automatically Created Swagger - Custom Add Dev Ready</p> <p> </p> <p>The Admin App provides a link to the Swagger:</p> <p></p> <p>When you're ready, click 2. Flexible Customization, above.</p> <p>Customize and debug with standard dev tools.  Use your IDE (e.g. VSCode, PyCharm), Python, and Flask/SQLAlchemy to create new services.</p> <p></p> <p>When you're ready, click 3. Declarative Logic, above.</p> <p>Declare multi-table constraint/derivation logic, using Python and your IDE.  The 5 spreadsheet-like rules below are declarative, representing the same logic as 200 lines of procedural code (40X more concise):</p> <p></p> <p>Notes:</p> <ol> <li>You can extend rules with Python, as explained in the Eval</li> <li>Similar declarative facilities provide row level security, based on a users roles</li> </ol> <p> </p> <p>When you're ready, click 4. Deployment, above.</p> <p>Projects are container-ready.  The system provides configuration and scripts to containerize your project:</p> <p></p> <p>The container is ready to deploy, on-premise or in the cloud (eg, Azure, AWS, etc):</p> <ul> <li>A modern 3-tiered architecture, accessed by APIs</li> <li>Logic is automatically reused, factored out of web apps and custom services</li> <li>Scale using standard toooling such as Kubernetes</li> </ul> <p></p> <p> </p>"},{"location":"ApiLogicServer-create/#video-create-run-customize","title":"Video: Create, Run, Customize","text":"<p>API Logic Server is an open source Python project, consisting of a CLI and set of runtimes (SAFRS API, Flask, SQLAlchemy ORM, business logic engine) for project execution.</p> <p>It runs as a standard pip install, or under Docker. For more on API Logic Server Architecture, see here.</p> <p>Click the image below for a video tutorial, showing complete project creation, execution, customization and debugging (instructions here).  Or, see it using AI: click here.</p> <p></p> <p> </p> <p> </p>"},{"location":"ApiLogicServer-create/#why-it-matters","title":"Why It Matters:","text":""},{"location":"ApiLogicServer-create/#increased-agility-and-quality-reduced-risk","title":"Increased Agility and Quality, Reduced Risk","text":"<p>Agile wisely advises getting Working Software as fast as possible, to facilitate Business User Collaboration and Iteration.  This reduces requirements risk - substantial effort wasted in misunderstood requirements.</p> <p></p> <ol> <li> <p>Instant Collaboration: with automated creation of an API and an Admin App,  collaboration and UI dev can begin on Day 1.</p> <ul> <li>Tradtionally, API and UI Dev is required before Collaboration.  This might be weeks or months.</li> </ul> </li> <li> <p>Spreadsheet-like Rules, Self-Serve APIs: rules are 40X more concise, and automatically ordered and reused.  Also, APIs are self-serve -- UI developers can use Swagger to formulate requests for filtering, sorting, and multi-table data content.</p> <ul> <li>Tradtionally, Logic Development is by code.  Manual approaches can miss Use Cases, or be coded in UI controllers instead of the server.</li> <li>Tradtionally, Custom APIs are required for each client app.  This can block UI deveopment.</li> </ul> </li> <li> <p>Self-Serve APIs: ongoing API needs can be met by consumers, such as new application integration.</p> <ul> <li>Tradtionally, API Consumers may require new custom APIs, which may result in bottlenecks for server developers.</li> </ul> </li> </ol> <p>In addition to time, risk is also reduced:</p> <ol> <li>Early Collaboration: reduces requirements risk </li> <li>API Automation: reduces technical risk (e.g., pagination, optimistic locking, self-serve design).</li> </ol> <p>Finally, automation drives quality automatic re-use and ordering eliminates an entire class of error.</p> <p> </p>"},{"location":"ApiLogicServer-create/#simpler-modern-architecture","title":"Simpler, Modern Architecture","text":"<p>API Logic Server not only increases agility, it can make web app development simpler, and ensure the architectural result:</p> <ul> <li> <p>Automation makes it simpler: this reduces the risk of architectural errors, e.g., no logic reuse between Apps / Services, APIs without pagination, etc.</p> </li> <li> <p>Automation guarantees a modern software architecture: container-ready, API-based, with shared logic between UIs and APIs (no more logic in UI controllers), in a predictable structure for maintenance.</p> </li> </ul> <p> </p>"},{"location":"ApiLogicServer-create/#flexibility-of-a-framework-faster-than-low-code","title":"Flexibility of a Framework, Faster than Low Code","text":"<p>Current approaches for building database systems have shortcomings:   </p> <ul> <li>Frameworks: Frameworks like Flask or Django enable you to build a single endpoint or Hello World page, but<ul> <li>Require weeks or more for a multi-endpoint API and multi-page application</li> </ul> </li> <li>Low Code Tools: are great for building custom UIs, but<ul> <li>Slow Admin app creation, requiring layout for each screen</li> <li>Propietary IDEs don't preserve value of traditional IDEs like VSCode, PyCharm, etc</li> <li>No automation for backend business logic (it's nearly half the effort)</li> </ul> </li> </ul> <p>In contrast, API Logic Server provides:</p> <ul> <li> <p>Flexibility of a framework: use your IDE's code editor and debugger to customize the created project, with full access to underlying Flask and SQLAlchemy services</p> </li> <li> <p>Faster than low code for admin apps: you get a full API and Admin app instantly, no screen painting required</p> </li> </ul> <p> </p>"},{"location":"ApiLogicServer-create/#use-cases","title":"Use Cases","text":"<p>There are a variety of ways for getting value from API Logic Server:</p> <ul> <li> <p>Create and Customize database web apps - the core target of the project</p> </li> <li> <p>Admin App for your database - the Admin App is a create way to navigate through your database, particularly to explore data relationships</p> </li> <li> <p>Agile Integrations replace cumbersome and inefficent ETL approaches with Agile Integrations</p> </li> <li> <p>Data Repair - using the Admin App with logic to ensure integrity, repair data for which you may not have had time to create custom apps</p> </li> <li> <p>Project Creation - even if you do not intend to use the API, Admin App or logic, you can use API Logic Server to create projects you then edit by hand.  Created projects will include the SQLAlchemy Data Models, and project structure</p> </li> <li> <p>Learning - explore the Learning Center to learn about key concepts of Flask and SQLAlchemy</p> </li> </ul> <p> </p>"},{"location":"ApiLogicServer-create/#feature-summary","title":"Feature Summary","text":"Feature Providing Why it Matters Instant 1. Admin App Instant multi-page, multi-table app Business Users engaged earlyBack-office Admin 2. JSON:API and Swagger Endpoint for each table, with... Filtering, pagination, related data Custom UI DevApp Integration 3. Data Model Class Creation Classes for Python-friendly ORM Custom Data AccessUsed by API Customizable 4. Customizable Project Custom Endpoints, Logic Use Python and your IDE Customize and run Re-creation not required Unique Logic 5. Spreadsheet-like Business Rules 40X more concise - compare legacy code Unique backend automation  ... nearly half the system Customizable with Python Familiar Event Model Eg., Send messages, email Testing 6. Behave Test Framework Test Suite AutomationBehave Logic ReportDrive Automation with Agile Optimize Automation to get it fastGet it Right with Agile Collaboration"},{"location":"ApiLogicServer-create/#getting-started-install-tutorial","title":"Getting Started - Install, Tutorial","text":"<p>API Logic Server is designed to make it easy to get started:</p> <ul> <li> <p>Install and run Tutorial -  install, and explore the tutorial.  The tutorial creates 2 versions of the sample database</p> <ul> <li>without customizations - so you to see exactly what is automated from the <code>ApiLogicServer create</code> command</li> <li>with customizations - so you can see how to customize </li> </ul> </li> <li> <p>Installed Sample Databases - Here are some installed sample databases you can use with simplified abbreviations for <code>db_url</code>.</p> </li> <li> <p>Dockerized Test Databases -  Then, you might like to try out some of our dockerized test databases.</p> </li> <li> <p>Your Database - Finally, try your own database.</p> </li> </ul> <p> </p> <p>In addition to this app dev oriented tutorial, you can also explore:</p> <ul> <li> <p>Deployment: the Deployment Tutorial illustrates various ways to containerize and deploy your applications</p> </li> <li> <p>Using AI: the AI-Driven Automation Tutorial shows how you can use ChatGPT to create new databases from english descriptions, to bootstrap a very rapid create / collaborate / iterate Agile cycle.</p> </li> </ul> <p> </p>"},{"location":"ApiLogicServer-create/#project-information","title":"Project Information","text":""},{"location":"ApiLogicServer-create/#making-contributions","title":"Making Contributions","text":"<p>This is an open source project.  We are open to suggestions for enhancements.  Some of our ideas include:</p> Component Provides Consider Adding 1. JSON:API and Swagger API Execution Kubernetes - extend containerization 2. Transactional Logic Rule Enforcement New rule types 3. SAFRS React Admin Admin UI Enhancements Maps, trees, ... 4. This project API Logic Project Creation Support for features described above <p>To get started, please see  the Architecture.</p>"},{"location":"ApiLogicServer-create/#preview-version","title":"Preview Version","text":"<p>This pre-release includes:</p> <ul> <li> <p>Running Kafka publish; consume now working.</p> </li> <li> <p>Fix for MySQL CHAR/String import Issue 26</p> </li> </ul> <p>You can try it at (you may need to use <code>python3</code>):</p> <pre><code>python -m pip install --index-url https://test.pypi.org/simple/ --extra-index-url https://pypi.org/simple ApiLogicServer==10.0.0\n</code></pre> <p>Or use (not available currently):</p> <pre><code>docker run -it --name api_logic_server --rm -p 5656:5656 -p 5002:5002 -v ~/dev/servers:/localhost apilogicserver/api_logic_server_x\n</code></pre> <p>Or, you can use the beta version on codespaces.</p> <p> </p>"},{"location":"ApiLogicServer-create/#status","title":"Status","text":"<p>We have tested several databases - see status here..</p> <p>We track issues in git (formerly here).</p> <p>We communicate via slack.</p> <p> </p>"},{"location":"ApiLogicServer-create/#acknowledgements","title":"Acknowledgements","text":"<p>Many thanks to:</p> <ul> <li>Thomas Pollet, for SAFRS, SAFRS-react-admin, and invaluable design partnership</li> <li>Tyler Band, for major contributions on security, testing, features and much more</li> <li>Nitheish Munusamy, for contributions to Safrs React Admin</li> <li>Marelab, for react-admin</li> <li>Armin Ronacher, for Flask</li> <li>Mike Bayer, for SQLAlchemy</li> <li>Alex Gr\u00f6nholm, for Sqlacodegen</li> <li>Meera Datey, for React Admin prototyping</li> <li>Denny McKinney, for Tutorial review</li> <li>Achim G\u00f6tz, for design collaboration and testing</li> <li>Max Tardiveau, for testing and help with Docker</li> <li>Michael Holleran, for design collaboration and testing</li> <li>Nishanth Shyamsundar, for review and testing</li> <li>Thomas Peters, for review and testing</li> <li>Gloria Huber and Denny McKinney, for doc review</li> </ul> <p> </p>"},{"location":"ApiLogicServer-create/#articles","title":"Articles","text":"<p>There are a few articles that provide some orientation to API Logic Server:</p> <ul> <li>How Automation Activates Agile</li> <li>How Automation Activates Agile - providing working software rapidly drives agile collaboration to define systems that meet actual needs, reducing requirements risk</li> <li>How to create application systems in moments</li> <li>Stop coding database backends\u2026Declare them with one command.</li> <li>Instant Database Backends</li> <li>Extensible Rules - defining new rule types, using Python</li> <li>Declarative - exploring multi-statement declarative technology</li> <li>Automate Business Logic With Logic Bank - general introduction, discussions of extensibility, manageability and scalability</li> <li>Agile Design Automation With Logic Bank - focuses on automation, design flexibility and agile iterations</li> <li>Instant Web Apps </li> </ul> <p> </p> <ol> <li> <p>See the FAQ for Low Code \u21a9</p> </li> </ol>"},{"location":"App-Custom-Ontimize-Overview/","title":"Ontimize Overview","text":"<p>Under Construction - Beta</p> <p> TL;DR - Front Office App Dev</p> <p>To complement the Admin App, API Logic Server can automatically create a 'starter kit' Angular app, using Ontimize, a proven app framework.  This approach provides the features outlined in Custom Web Apps:</p> <ol> <li> <p>Faster and simpler automated creation: the system creates a default app model, and uses that to create a default app, in seconds.</p> </li> <li> <p>Simpler customization: it is orders of magnitude simpler to tweak the properties of a generated app than to create the app by hand.  You can customize at 2 levels: </p> <p>a. The generated app for full control: you can edit the generated app (HTML, Typescript, CSS).</p> <p>b. The app model: the app is generated from a yaml model that designates the components for tables (grid, card, tree, dialog) and fields (text, image, combo, etc).  You can modify the yaml model to rebuild the app.</p> </li> </ol> <p>This technology is currently in preview state - not ready for production.  Please contact us if you would like to try it, and provide feedback.</p> <p> </p>"},{"location":"App-Custom-Ontimize-Overview/#ontimize-angular-starter-kit","title":"Ontimize - Angular Starter Kit","text":"<p>What is Ontimize Web?  See the Playground Ontimize Web site:</p> <p>Ontimize Web is web application framework based on Angular for building business software. Ontimize Web makes use of Angular framework and its UI Component framework (Angular Material) to provide a set of reusable, well-tested and accessible components apart from a number of standard services and functionalities.  This includes a wealth of rich UI components (editable grid, charts, reports, tree, etc).</p> <p> </p>"},{"location":"App-Custom-Ontimize-Overview/#api-logic-server-integration","title":"API Logic Server Integration","text":"<p>While a separate product, Ontimize is highly integrated with API Logic Server:</p> <ol> <li>Unified Database: driven by the same Data Model, and underlying JSON:API / logic</li> <li>Unified Repository: Artifacts are files stored in your project directory for unified source, and managed by any standard IDE</li> <li>Shared Dev Server: the API Logic Server serves the API, the Admin App, and the Ontimize App.  This simplifies development</li> </ol> <p>It should be possible for users with limited Python, Flask, SQLAlchemy, JavaScript technology (<code>npm</code> build, etc), or Ontimize knowledge to 1. Create a backend API2. Declare rules for multi-table derivations and constraints3. Create a front office Ontimize app, and4. Make HTML UX page customizations</p> <p>As you can see below, you are no longer limited to simple master/detail screens:</p> <ol> <li>A Chart (via the hamburger window - charts on demand)</li> </ol> <p></p> <ol> <li>Card/Grid Template This will show employees as image cards. The grid_items are the attributes to show below the image. The grid_image is the path to display the image using an href style path.</li> </ol> <p></p> <p><pre><code>    home_template: grid_template.html\n    grid_items: 'EmployeeType, LastName,FirstName,Address, Country, HomePhone'\n    grid_image: PhotoPath\n</code></pre> 3. A nested grid example below which nests an Item grid within an Order grid:</p> <p> \u00a0 This will show the normal Home page grid but it will select the first tabgroup (onetomany) to include as an expandable grid. In the Northwind admin_model.yaml file - change the entity Order home_template.</p> <p><pre><code> home_template: home_template_expand.html\n</code></pre> 4. A Customer Tree: </p> <p> </p>"},{"location":"App-Custom-Ontimize-Overview/#ontimize-components","title":"Ontimize Components","text":"<p>Components (like nested grid) are a key element.  As you can see from the grid component, using a component means you provide a combination of html, css and typescript.  There are analogous components for cards, trees, dialogs, graphs, charts, maps and fields (text, image, combo, etc).  </p> <p> </p>"},{"location":"App-Custom-Ontimize-Overview/#concepts-templates-models","title":"Concepts: Templates, Models","text":"<p>Each component has its own unique html code (including properties), css and typescript.  So, changing from a list to a grid would be a complex task.</p> <p>So, API Logic Server introduces a template-based application model:</p> <ul> <li> <p>Template: a macro-expansible version of a template, bundling its html, css and typescript.  The template is a 'generation ready' component.</p> </li> <li> <p>Model: a YAML file that designates the templates for tables (grid, card, tree, dialog) and fields (text, image, combo, date, currency, etc).  The creation process macro-expands the designated templates, creating the full app, which you can then customize.</p> </li> </ul> <p>So, typical dev cycle would be to tune the model to designate the templates,  then fine-tune the generated app by editing components.</p> <p>Templates are created into your project:</p> <p></p> <p> </p>"},{"location":"App-Custom-Ontimize-Overview/#custom-app-procedures","title":"Custom App Procedures","text":"<p>A default Ontimize app is created automatically when you create projects with security.  You can also create additional apps using the <code>als app-create</code> as described below.</p> <p> </p>"},{"location":"App-Custom-Ontimize-Overview/#1-create-project","title":"1. Create Project","text":"<p>One way is to <code>create</code> an ApiLogicServer project, specifying <code>--auth-provider-type=sql</code>:</p> <p><pre><code>als create --project_name=ApiLogicProject --db-url= --auth-provider-type=sql\n</code></pre> Note: Security must be enabled for Ontimize client (see: als add-auth --provider-type=sql)</p> <p>This creates a project from your database (here, the default sample), which you can open and execute in your IDE.  It includes an API, the Admin App, and the default custom app.</p> <p>Initially, you may wish to skip to step 2 to run the default custom app.</p> <p> </p>"},{"location":"App-Custom-Ontimize-Overview/#-default-app-created","title":"- Default App Created","text":"<p>If you create your app with authorization, a default Ontimize app will be created as a <code>ui/app</code> directory, with a full Ontimize default app.</p> <p> </p>"},{"location":"App-Custom-Ontimize-Overview/#-parallel-logicapi-dev","title":"- Parallel Logic/API Dev","text":"<p>At this point, distinct dev teams can safely proceed in parallel:</p> <ul> <li>backend: develop logic and custom APIs (e.g., for application integration)</li> <li>ui: proceed as described below</li> </ul> <p>As noted earlier:</p> <ul> <li> <p>logic is automatically factored out of ui code (in particular, not in controllers).  This increases re-use across apps, and re-use for integration</p> </li> <li> <p>ui dev is not dependent on server api creation -- JSON:APIs are self-serve, so ui developers are not blocked by backend api </p> </li> </ul> <p> </p>"},{"location":"App-Custom-Ontimize-Overview/#2-run","title":"2. Run","text":"<p>Execution is standard to Ontimize (assumes the installation of NPM and NodeJS). </p> <pre><code>cd ui/app\nnpm install\nnpm start\n</code></pre> <p>Browse to localhost:4299, and login as <code>user: admin password:p</code>.</p> <p> </p>"},{"location":"App-Custom-Ontimize-Overview/#3-customize","title":"3. Customize","text":"<p>The simplest way to introduce rich components is to specify them in the app model, and the rebuild the app.  Iterate this process until you have the right templates, then customize the created app.</p> <p></p>"},{"location":"App-Custom-Ontimize-Overview/#3a-enable-security","title":"3a. Enable Security","text":"<p>To enable Keycloak - both ApiLogicServer and your Ontimize application need to be configured for Keycloak.  Go to config/configy.py and modify the Keycloak settings below (if you are running our local Keycloak Docker container use these defaults.)</p> <pre><code>keycloak_url: http://localhost:8080\nkeycloak_realm: kcals\nkeycloak_client_id: alsclient\n</code></pre> <p>\u00a0 This will inject into src/app.module.ts the keycloak settings. <pre><code>    {% if use_keycloak %}\n    const keycloakOptions: KeycloakOptions = {\n    config: {\n        url: \"{{ keycloak_url }}\",\n        realm: \"{{ keycloak_realm }}\",\n        clientId: \"{{ keycloak_client_id }}\"\n    },\n    initOptions: {\n        onLoad: 'login-required'\n    }\n    };\n{% endif %}\n</code></pre> Enable Keycloak for the ALS server and Ontimize client to use: <pre><code>    als add-auth --provider-type=keycloak\n</code></pre> </p>"},{"location":"App-Custom-Ontimize-Overview/#3b-edit-the-yaml-model","title":"3b. Edit the YAML Model","text":"<p>Edit to remove unwanted entities, order columns, define column or page templates, etc. </p> <p>You can edit the ui/app/app_model.yaml file directly, or use the provided model editor gui.</p>  Show me how -- Edit Model  <p> </p> <p></p>"},{"location":"App-Custom-Ontimize-Overview/#3c-rebuild-app","title":"3c. Rebuild App","text":"<p>Then, rebuild your application (Note: this will overwrite all files in your Ontimize app directory):</p> <p>PRO TIP: create a new application (app-create) with the edited app_model.yaml and merge the changes for the selected components back into the original app. <pre><code>ApiLogicServer app-build --app=app\n\n# Build or Rebuild a single API Endpoint\nApiLogicServer app-build --app=app --api-endpoint=Customer\n\n# Build or Rebuild a user defined template directory\nApiLogicServer app-build --app=app --template-dir=/User/{username}/templates\n</code></pre></p>"},{"location":"App-Custom-Ontimize-Overview/#3d-customize-created-app","title":"3d. Customize Created App","text":"<p>This will use the data model to build an Ontimize app.</p> <p>You can then use your IDE or other tooling (e.g., Ontimize CLI) to edit the artifacts to customize the look and feel.</p> <p>Then, repeat 2. Run, above.</p>  Show me how -- Customize Application  <p> </p> <p></p> <p> </p>"},{"location":"App-Custom-Ontimize-Overview/#4-create-additional-apps","title":"4. Create Additional Apps","text":"<p>To create a new Ontimize application (perhaps the model or database has changed) or you have new templates to test.</p> <p>With the project open in your IDE, use the terminal window to create a new Ontimize application in a named directory under 'ui':</p> <pre><code>ApiLogicServer app-create --app=app2\ncd ui/app2\nnpm install\n</code></pre> <p>This creates <code>ui/app2/app_model.yaml</code> and installs the Ontimize 'seed' NodejS package and dependent node_modules.</p> <pre><code>ApiLogicServer app-build --app=app2\ncd ui/app2\nnpm install\nnpm start\n\n# Build or Rebuild a user defined template directory\nApiLogicServer app-build --app=app2 --template-dir=/User/{username}/user_templates\n</code></pre>"},{"location":"App-Custom-Ontimize-Overview/#dockerize-yaml","title":"Dockerize Yaml","text":"<p>Each application already has a Dockerfile (which can be edited)  <pre><code>cd ui/{myapp}\ndocker build -f Dockerfile -t {gitrepo}/{myappname} --rm .  \n</code></pre></p>"},{"location":"App-Custom-Ontimize-Overview/#appendices","title":"Appendices","text":""},{"location":"App-Custom-Ontimize-Overview/#yaml-model-editor","title":"Yaml Model Editor","text":"<p>The Yaml editor allows the developer the ability to manage yaml files for editing using an Ontimize built application. Use the \"Manage yaml files\" New - to add your yaml file and then click upload (save) to populate the screens with entities, attributes, and tab groups. Once complete, use the download_flag (save)  to export the yaml to the 'ui' directory (ui/admin_model_merge.yaml) and compare/merge to your original admin_model.yaml in your ontimize application folder. The open source application can be found here: <pre><code>git clone https://github.com/tylerm007/ontimize_yaml_view\ncd ontimize_yaml_view\ncode .\npress f5\n</code></pre></p>"},{"location":"App-Custom-Ontimize-Overview/#start-ontimize-app-model-editor","title":"Start Ontimize App Model Editor","text":"<p>The App Model Editor simplifies managing yaml files, using an Ontimize built application.  See App Model Editor for more information. <pre><code>cd ui/yaml\nnpm install\nnpm start\n\n#go to http://localhost:4298 (user: admin password: p)\n</code></pre></p>"},{"location":"App-Custom-Ontimize-Overview/#ontimize-app_modelyaml","title":"Ontimize app_model.yaml","text":"<p>The app_model.yaml file is created during the \"app-create\" or \"create\" phase and is based on the react-admin ui/admin.yaml file. Each entity, column, and tab_group is exposed with additional metadata.  When the \"app-build\" is invoked, these properties are used to populate the templates (html, scss, and typescript) for each page. If the \"exclude\" flag is set to 'false' - the entity, attribute, or relationship will be excluded from the page. The \"visible\" column flag only applies to the Home table columns appearing in the grid.</p>"},{"location":"App-Custom-Ontimize-Overview/#entity","title":"Entity","text":"<p>Use the Ontimize editor to exclude a selected entity or change the titles. </p>"},{"location":"App-Custom-Ontimize-Overview/#edit-entity","title":"Edit Entity","text":"field Description Entity name name of API endpoint {{ entity }} Title display name used for {{ title }} Primary Key array of primary keys {{ primaryKeys }} Favorite used for list-picker display Mode tab or dialog style {{ editMode }} Exclude if true - skip this API endpoint in the first page generation"},{"location":"App-Custom-Ontimize-Overview/#attributes","title":"Attributes","text":"<p>Use the Ontimize editor to change the label, tooltip, exclude selected attributes, include attribute in the search or sort, enable or mark fields as required, and include visible in the home table display. </p>"},{"location":"App-Custom-Ontimize-Overview/#edit-attributes","title":"Edit Attributes","text":"field Description Entity Name name of api endpoint Attribute name of API attribute {{ attr }} Title label used for this attribute {{ label }} Template Name column template (pick list) Search is this field included in search Sort is this field included in sort Required is this field marked as required Excluded exclude this attribute from detail/new/home pages Visible is this attribute visible on home table {{ visibleColumns }} DataType the internal datatype Tooltip hover value for attribute Default Value value to show on new page"},{"location":"App-Custom-Ontimize-Overview/#relationships-tabgroup","title":"Relationships (TabGroup)","text":"<p>Use the Ontimize editor to exclude tab on detail page (tomany) or change the tile used to display. </p>"},{"location":"App-Custom-Ontimize-Overview/#edit-tab-groups","title":"Edit Tab Groups","text":"field Description Entity Name name of api endpoint Tab Entity the name of the other end of the relationship Direction toone (parent) or tomnay (children) Relationship name defined in SQLAlchemy label Tab Display name Exclude skip this relationship for all tabs and lookups Foreign Keys array of values"},{"location":"App-Custom-Ontimize-Overview/#global-settings","title":"Global Settings","text":"<p>These values are injected into the various entity and attribute to provide and set global values.  New values can be added for new templates.</p>"},{"location":"App-Custom-Ontimize-Overview/#values","title":"Values","text":"field Description Include Translation set to true and then do an app-build to generate Spanish translation (assets/Ii8n/es.json) Currency Symbol set for locale $"},{"location":"App-Custom-Ontimize-Overview/#existing-column-templates","title":"Existing Column Templates","text":"<pre><code>    (\"checkbox\", \"o_checkbox.html\"),\n    (\"check_circle\", \"check_circle_template.html\"),\n    (\"combo\", \"o_combo_input.html\"),\n    (\"currency\", \"currency_template.html\"),\n    (\"date\", \"date_template.html\"),\n    (\"email\", \"email_template.html\"),\n    (\"file\", \"file_template.html\"),\n    (\"html\", \"html_template.html\"),\n    (\"integer\", \"integer_template.html\"),\n    (\"list\", \"list-picker.html\"),\n    (\"nif\", \"o_nif_input.html\"),\n    (\"password\", \"password_template.html\"),\n    (\"percent\", \"percent_template.html\"),\n    (\"phone\", \"phone_template.html\"),\n    (\"real\", \"real_template.html\"),\n    (\"text\", \"text_template.html\"),\n    (\"textarea\", \"textarea_template.html\"),\n    (\"time\", \"time_template.html\"),\n    (\"timestamp\", \"timestamp_template.html\"),\n    (\"toggle\", \"o_slide_toggle.html\")\n</code></pre>"},{"location":"App-Custom-Ontimize-Overview/#custom-templates","title":"Custom Templates","text":"<p>Ontimize templates can be modified in the local /templates directory.  There are a few examples of using advanced template customizations.  Once the local template is changed use the 'als app-build --app={myApp}' to rebuild your entire app.  If you wish to preserve your prior customizations, we suggest building a new application and merge changes back into your customized Ontimize app.</p>"},{"location":"App-Custom-Ontimize-Overview/#yaml-overview","title":"Yaml Overview","text":"<p>The Application is a hierarchy of the each Ontimize definition which is used by the command line (app-build) to create a set of pages (new, home, detail) for each API endpoint (menu-item is a module linked to the API).  Menu Group is a category grouping for the sidebar navigation.</p> <pre><code>application\n  app:\n   menu-group\n    data:\n     menu_title: Customer Info\n     menu-item:\n       Customer:\n         page:\n            new:\n            home:\n            detail:\nentities:\n  Customer:\n    columns:\n      -- name: CustomerName\n         label: Name\n    tab-groups:\nsettings:\n  style_guide:    \n</code></pre>"},{"location":"App-Custom/","title":"Custom Web Apps","text":"<p> TL;DR - Rich Custom Apps - Full Control</p> <p>The Admin App is useful, but most systems will require custom User Interfaces.  Use your favorite framework (eg, React, Angular, Vue) to create rich, custom apps.  </p> <ul> <li> <p>App creation is much simpler since you can use the API to access your data, with logic automation.  This reduces your app code, within a modern architecture that shares logic for both apps and services.</p> </li> <li> <p>The API is available instantly.  App Dev is not blocked on API creation.</p> </li> </ul> <p> </p>"},{"location":"App-Custom/#app-dev-open-faster-simpler","title":"App Dev: Open, Faster, Simpler","text":"<p>API Logic Server provides for open App Dev.  Use any framework you are comfortable with.  </p> <p>App Dev can be complex and time-consuming.  Below are some considerations to make it simpler and faster.</p> <p> </p>"},{"location":"App-Custom/#model-driven-automation","title":"Model-Driven Automation","text":"<p>A proven approach is provide a simple description of an app, identifying the tables, fields, with some basic layout hints.  This is much simpler than the detailed JavaScript/HTML that ultimately execute.</p> <ul> <li>In the ideal case, the system can create a default app model from the data model.</li> </ul> <p>This model can be automated to create a complete application much faster -- saving weeks of effort.  </p> <p>This approach supports agile collaboration with stake holders.  If the app is not even close, little effort is wasted (\"fail fast\").</p> <p> </p>"},{"location":"App-Custom/#edit-vs-create","title":"Edit vs. Create","text":"<p>In most cases, it's easier to edit an running app, instead of creating the entire thing from scratch.</p> <p>This avoids starting from a \"clean white sheet of paper\".</p> <p> </p>"},{"location":"App-Custom/#template-driven","title":"Template-Driven","text":"<p>Template are fragments of app code (html, JavaScript, CSS, etc).  They might define small items like buttons, or fields, or larger constructs like grids or forms.</p> <p>These are then \"macro-expanded\" during automated creation, providing proper values from the data / app models (column names etc).)</p> <p>This approach pre-specifies the set of properties apprpriate for the type of control.  The simplifies app dev, and reduces errors.</p> <p> </p>"},{"location":"App-Custom/#consider-ontimize","title":"Consider Ontimize","text":"<p>In addition to any API-based framework, API Logic Server is integrated with Ontimize.  It is based on the approach described above, and can create apps with rich features such as maps, charts, and nested grids, like this:</p> <p></p> <p>For more information, click here.</p>"},{"location":"App-Model-Editor/","title":"App Model Editor","text":"<p>Under Construction - Beta (Images broken)</p> <p> TL;DR - Model-Based App Definitions</p> <p>The fastest way to develop your custom app is to edit the model file before you alter the created components.  Edit the model file to make changes such as:</p> <ol> <li> <p>Choose which Entities / Attributes are exposed, and their order</p> </li> <li> <p>Specify the templates for Entities and Attributes.</p> </li> </ol> <p>The App Model Editor is a simpler way of editing the App Yaml file.</p> <p> </p>"},{"location":"App-Model-Editor/#app-model-editor","title":"App Model Editor","text":"<p>The Yaml editor allows the developer the ability to manage yaml files for editing using an Ontimize built application. Use the \"Manage yaml files\" New - to add your yaml file and then click upload to populate the screens with entities, attributes, and tab groups. Once complete, use the download flag to export the yaml to the 'ui' directory (ui/admin_model_merge.yaml) and compare to your original admin_model.yaml in the ontimize application folder.</p> <p>The App Model Editor is installed automatically in the Manager (<code>system/app_model_editor</code>).  It runs on a different port, so you can run it at the same time as your app.</p> <p> </p>"},{"location":"App-Model-Editor/#1-run-prepare","title":"1. Run &gt; Prepare","text":"<p>Use the Run Config as shown below:</p> <p></p>"},{"location":"App-Model-Editor/#2-run-start-server","title":"2. Run &gt; Start Server","text":"<p>Execute Run Config &gt; <code>Start Server</code>.  This starts an API Logic Server.</p>"},{"location":"App-Model-Editor/#3-run-start","title":"3. Run &gt; Start","text":"<p>Execute Run Config &gt; <code>Start</code>.  This starts the App Model Editor (an Ontimize App).</p>"},{"location":"App-Model-Editor/#4-open-in-the-browser","title":"4. Open in the Browser","text":"<p>Browse to http://localhost:4298</p> <p></p>"},{"location":"App-Model-Editor/#5-create-new-yaml-entry","title":"5. Create New yaml entry","text":"<p>The App Model Editor operates by editing a yaml file that represents the App Model.  </p> <p>Create a new entry:</p> <p></p>"},{"location":"App-Model-Editor/#6-upload","title":"6. Upload","text":"<p>And upload your app_model.yaml file to the server.</p> <p></p>"},{"location":"App-Model-Editor/#7-process-yaml","title":"7. Process Yaml","text":"<p>The process button will replace all the Entities, Attributes, and Relationships with the uploaded content.</p> <p></p>"},{"location":"App-Model-Editor/#8-edit-model","title":"8. Edit Model","text":"<p>Edit your <code>Entities</code>, <code>Attributes</code> and <code>Relationships</code> using the various screens.</p> <p></p>"},{"location":"App-Model-Editor/#9-process-or-download","title":"9. Process or Download","text":"<p>The big Process Yaml button will take the 'original content' and process this into entities, attributes, and relationships. Once you have edited these values, use the download flag (and save) to populate the downloaded content box.  </p> <p></p>"},{"location":"App-Model-Editor/#10-copy-to-your-app","title":"10. Copy to your app","text":"<p>Copy the downloaded yaml file to your ontimize <code>app_model.yaml</code> project, as shown in the screenshot below.</p> <p></p>"},{"location":"App-Model-Editor/#11-rebuild","title":"11. Rebuild","text":"<p>Rebuild your Ontimize app using the command line below. <pre><code>als app-build --app=${name_of_ontimize_app}\n</code></pre></p> <p></p> <p> </p>"},{"location":"App-Model-Editor/#ontimize-app_modelyaml","title":"Ontimize app_model.yaml","text":"<p>The app_model.yaml file is created during the \"app-create\" or \"create\" phase and is based on the react-admin ui/admin.yaml file. Each entity, column, and tab_group is exposed with additional metadata.  When the Ontimize \"app-build\" is invoked, these properties are used to populate the templates (html, scss, and typescript) for each page. If the \"exclude\" flag is set to 'true' - the entity or attribute will be excluded from the page. The \"visible\" column flag only applies to the Home table columns appearing in the grid (all columns are true by default).</p> <pre><code>entities:\n  {EntityName}\n    detail_template: detail_template.html\n    home_template: home_template.html\n    new_template:: new_template.html\n    favorite: {SomeAttribute}\n    mode: {tab | dialog}\n    primary_key: \n       - {SomeAttribute(s)}\n    type: {Entity}\n    title: {title}\n    info_list: {Html}\n    group: menu_group \n    columns:\n        enabled: true\n        exclude: false\n        label: {Label}\n        name: {Attribute}\n        required: false\n        search: false\n        sort: false\n        template: {template}\n        type: {DataType}\n        visible: true\n        default: 'some string'\n    tab_groups:\n        direction: tomany | toone\n        exclude: false\n        fks:\n            - {SomeAttribute(s)}\n        label: {Label}\n        name: {Entity Relationship}\n        resource: {Entity}\nsettings:\n  style_guide:\n    include_translation: false\n    use_keycloak: false\n</code></pre> <p> </p>"},{"location":"App-Model-Editor/#existing-column-templates","title":"Existing Column Templates","text":"<pre><code>    (\"checkbox\", \"o_checkbox.html\"),\n    (\"combo\", \"o_combo_input.html\"),\n    (\"currency\", \"currency_template.html\"),\n    (\"date\", \"date_template.html\"),\n    (\"email\", \"email_template.html\"),\n    (\"file\", \"file_template.html\"),\n    (\"html\", \"html_template.html\"),\n    (\"integer\", \"integer_template.html\"),\n    (\"list\", \"list-picker.html\"),\n    (\"nif\", \"o_nif_input.html\"),\n    (\"password\", \"password_template.html\"),\n    (\"percent\", \"percent_template.html\"),\n    (\"phone\", \"phone_template.html\"),\n    (\"real\", \"real_template.html\"),\n    (\"text\", \"text_template.html\"),\n    (\"textarea\", \"textarea_template.html\"),\n    (\"time\", \"time_template.html\"),\n    (\"timestamp\", \"timestamp_template.html\"),\n    (\"toggle\", \"o_slide_toggle.html\")\n</code></pre>"},{"location":"App-Model-Editor/#entity-fields","title":"Entity Fields","text":"field Description Entity name name of API endpoint {{ entity }} Title display name used for {{ title }} Primary Key array of primary keys {{ primaryKeys }} Favorite used for list-picker display Mode tab or dialog style {{ editMode }} Menu Group used to organize entity into side bar menu groups(moved to menu_group) Exclude if true - skip this API endpoint in the first page generation home_template This is the grid or home template used for the Entity (moved to pages) detail_template This is the drill down page from home for each row - it can include relationships (tabgroup) (moved to pages) new_template This template is used to insert new rows into the selected Entity (moved to pages)"},{"location":"App-Model-Editor/#attribute-fields","title":"Attribute Fields","text":"<p>Use the Ontimize editor to change the label, tooltip, exclude selected attributes, include attribute in the search or sort, enable or mark fields as required, and include visible in the home table display.</p> field Description Entity Name name of api endpoint (case sensitive) Attribute name of API attribute {{ attr }} Title label used for this attribute {{ label }} Template Name column template (used by template pick list) Search is this field included in search Sort is this field included in sort Required is this field marked as required Excluded exclude this attribute from detail/new/home pages Visible is this attribute visible on home table {{ visibleColumns }} DataType the internal datatype (do not change) Tooltip hover value for the attribute Default Value string value to show on new page"},{"location":"App-Model-Editor/#relationship-fields-aka-tabgroup","title":"Relationship Fields (aka TabGroup)","text":"<p>Use the Ontimize editor to exclude tab on detail page (tomany) or change the tile used to display. |field|Description| :------|:---------------| |Entity Name|name of api endpoint| |Tab Entity|the name of the other end of the relationship| |Direction|toone (to parent - used by list_picker) or tomnay (to children - used by tab panel)| |Relationship name|defined in SQLAlchemy database/models.py| |label|Tab Display name| |Exclude|skip this relationship for all tabs and lookups| |Foreign Keys|array of values (do not change)|</p>"},{"location":"App-Model-Editor/#global-settings","title":"Global Settings","text":"<p>These values are injected into the various entity and attribute to provide and set global values.  New values will be added for any templates created.</p> field Description Include Translation set to true and then do an app-build to generate Spanish translation (assets/Ii8n/es.json) Currency Symbol set for locale $"},{"location":"App-Model-Editor/#existing-column-templates_1","title":"Existing Column Templates","text":"<p>These templates can be found in the directory ui/app/templates and can be modified or cloned. When the app-build is invoked these local templates are used first (then the global system templates are used). <pre><code>    (\"checkbox\", \"o_checkbox.html\"),\n    (\"check_circle\", \"check_circle_template.html\"),\n    (\"combo\", \"o_combo_input.html\"),\n    (\"currency\", \"currency_template.html\"),\n    (\"date\", \"date_template.html\"),\n    (\"email\", \"email_template.html\"),\n    (\"file\", \"file_template.html\"),\n    (\"html\", \"html_template.html\"),\n    (\"integer\", \"integer_template.html\"),\n    (\"list\", \"list-picker.html\"),\n    (\"nif\", \"o_nif_input.html\"),\n    (\"password\", \"password_template.html\"),\n    (\"percent\", \"percent_template.html\"),\n    (\"phone\", \"phone_template.html\"),\n    (\"real\", \"real_template.html\"),\n    (\"text\", \"text_template.html\"),\n    (\"textarea\", \"textarea_template.html\"),\n    (\"time\", \"time_template.html\"),\n    (\"timestamp\", \"timestamp_template.html\"),\n    (\"toggle\", \"o_slide_toggle.html\")\n</code></pre></p>"},{"location":"App-Model-Editor/#application","title":"Application","text":"field Description name app name short_name abbreviation description notes"},{"location":"App-Model-Editor/#menu-group","title":"Menu Group","text":"field Description menu_name name of group menu_title Title for group icon material icon opened is the group open (default:True)"},{"location":"App-Model-Editor/#menu-item","title":"Menu Item","text":"field Description entity_name API Entity for module menu_name name on menu template_name default: module.jinja icon material icon to display"},{"location":"App-Model-Editor/#page-new-home-detail","title":"Page (new, home, detail)","text":"field Description page_name new, home, detail title used on page template_name new, home, detail html template typescript_name new, home, detail jinja columns list of columns visible_columns used on home page grid include_children boolean - detail page only"},{"location":"Architecture-Declarative-Automation/","title":"Declarative Automation","text":"<p>While the most striking element of ApiLogicServer is automation - a running UI and API from a database - there are some important underlying aspects, described below.</p> <p> </p>"},{"location":"Architecture-Declarative-Automation/#declarative-models","title":"Declarative Models","text":"<p>Observe that the key files for defining API, UI and Logic are not procedural code.  They are declarative: specifications of what you want to happen, not how it's implemented:</p> <ul> <li> <p>Logic looks more like a specification than code</p> </li> <li> <p>UI looks like a list of Objects and Attributes to display</p> </li> <li> <p>API looks like a list of Objects</p> </li> </ul> <p>This is important because they are orders of magnitude shorter, and therefore far easier to understand, and to customize.</p> <p>For example, consider the UI, defined by <code>ui/admin/admin.yaml</code>.  This is in lieu of hundreds of lines of very complex HTML and JavaScript.</p> <p></p>"},{"location":"Architecture-Declarative-Automation/#customizable-standard-dev-tools","title":"Customizable, Standard Dev Tools","text":"<p>ApiLogicServer makes provisions for you to add standard Python code for aspects of your project that are automated - custom end points, extensions to the data model, logic (rules plus Python).  </p> <p>Using Python for both declarative models and customization presents a uniform, predictable environment for developers.  It enables their use of preferred tools - IDE, code editor with code completion, debugging, source code management, etc.</p> <p> </p>"},{"location":"Architecture-Declarative-Automation/#includes-backend-logic-rules","title":"Includes Backend Logic - Rules","text":"<p>As noted above, multi-table constraints and derivations can constitute nearly half the effort in transactional systems.</p> <p>Unlike most systems that address such logic with \"your code goes here\", ApiLogicServer provides declarative spreadsheet-like rules, customizable with Python, as described here.  Rules are 40X more concise than code.  </p> <p>Rule execution is via a transaction logic engine, a complementary technology to traditional RETE engines.  The transaction logic engine is specifically designed to optimize integrity and performance for transactional logic, which is not possible in RETE engines. See here for more information on their operation.</p>"},{"location":"Architecture-Internals-BLT/","title":"Build, Load and Test","text":"<p> TL;DR - rebuild, local install, run tests</p> <p>The Build Load and Test Run Configuration:</p> <ol> <li>Rebuilds the project locally</li> <li> <p>Installs it from the local build </p> <ul> <li>At: <code>ApiLogicServer/ApiLogicServer-dev/build_and_test/ApiLogicServer</code></li> </ul> </li> <li> <p>Runs a series of tests</p> <ul> <li>Tests are configurable, which can reduce setup.  </li> </ul> </li> </ol> <p>The resultant install provides a <code>venv</code> which is used in unit testing as the default venv.  A Run Configuration is provided for build-only, to enable such unit testing. </p> <p>As of version 6.02.20, test automation provides automated regression testing.  These have been verified on Mac, Linux (Ubuntu) and Windows.</p> <p> </p>"},{"location":"Architecture-Internals-BLT/#best-practice-smoke-test-first","title":"Best Practice: Smoke Test First","text":"<p>The tests take several minutes, and errors can be slightly difficult to diagnose.</p> <p>The bulk of the tests are in the Sample Projects's Behave tests. These reveal most of the errors, and are simplest to debug using a created project. </p> <p>We therefore recommend that, before you run the full regression, first:</p> <ol> <li>Create the BLT <code>venv</code> (useful for running the smoke test app - see here)</li> </ol> <p></p> <ol> <li>Verify the smoke test with the Sample App</li> </ol>"},{"location":"Architecture-Internals-BLT/#optional-docker-setup","title":"Optional Docker Setup","text":"<p>Full testing requires Docker:</p> <ul> <li>To build docker projects</li> <li>To build the API Logic Server Docker container</li> <li>For docker test databases</li> </ul> <p>You can reduce or completely eliminate docker requirements by configuring the tests as described in the next section.</p> <p> </p>"},{"location":"Architecture-Internals-BLT/#install-setuptools","title":"Install SetupTools","text":"<p>As of release, the system uses setuptools.</p> <p>You may need verify build is installed.  You can install it manually:</p> <pre><code>python -m pip install build\npython -m pip install setuptools\n</code></pre> <p> </p>"},{"location":"Architecture-Internals-BLT/#configuring-the-tests","title":"Configuring the Tests","text":"<p>The automated test (use the launch configuration <code>Build Load &amp; Test</code>) performs a number of steps.  You can configure the test to run some or all of these by editing the <code>env_xxx.py</code> files shown here:</p> <p></p> <p>Key aspects are described in the sub-sections below.</p> <p> </p>"},{"location":"Architecture-Internals-BLT/#do_install_api_logic_server","title":"<code>do_install_api_logic_server</code>","text":"<p>This:</p> <ol> <li>Runs the standard Python build: <code>python3 setup.py sdist bdist_wheel</code></li> <li> <p>Installs it into a Python environment</p> <ul> <li><code>ApiLogicServer/ApiLogicServer-dev/build_and_test/ApiLogicServer</code></li> </ul> </li> <li> <p>Installs <code>pyodbc</code>.  Note this requires you have installed <code>odbc</code>, but install failures are intentionally ignored (instead, skip the Sql/Server database with<code>do_docker_sqlserver = False</code> )</p> </li> </ol> <p> venv can be used for created projects</p> <p>You will find it helpful to use this as a shared venv.</p> <p> </p>"},{"location":"Architecture-Internals-BLT/#do_create_api_logic_project","title":"<code>do_create_api_logic_project</code>...","text":"<p>This creates the sample project, runs the server, and tests the logic using the behave tests.  It produces quite a lot of output which you can ignore.  The test is designed to terminate if the tests fail.</p> <p>These are extensive tests which verify project creation, server startup, logic and some minimal API testing (the Behave tests issue APIs to read/write data).</p> <p> </p>"},{"location":"Architecture-Internals-BLT/#do_allocation_test","title":"<code>do_allocation_test</code>","text":"<p>This is a complex rule example.</p> <p> </p>"},{"location":"Architecture-Internals-BLT/#do_docker_database","title":"<code>do_docker_&lt;database&gt;</code>","text":"<p>These create projects from docker databases (see here) which are expected to be running.  They perform minimal validation to ensure the server starts by executing the hello world API.  </p> <pre><code>This in fact verifies that the `models.py` file is created and runs.\n</code></pre> <p>If you don't wish to install or run the docker databases, edit your <code>tests/build_and_test/env.py</code> to disable <code>do_docker_creation_tests</code>.</p>"},{"location":"Architecture-Internals-BLT/#windows-issues","title":"Windows Issues","text":"<p>I was able to build in Windows (12/27/2024), with the following issues.</p>"},{"location":"Architecture-Internals-BLT/#path-length","title":"Path Length","text":"<p>For many Windows installs, the path length exceeds the max.</p> <ol> <li> <p>Prevents git pull for the <code>api_logic_server_cli/prototypes/manager/system/genai/examples/genai_demo/wg_dev_merge/base_genai_demo_no_logic</code>.  I had to download the zip and skip these files on unzip.</p> <ul> <li>If you do that, don't forget the setup procedure for SafrsReactAdmin</li> </ul> </li> <li> <p>The BLT recognizes that the Ont app (<code>api_logic_server_cli/prototypes/manager/system/app_model_editor</code>) is too big, and deletes it.</p> <ul> <li>So, you can build on Windows, but you cannot release.</li> </ul> </li> </ol>"},{"location":"Architecture-Internals-CLI/","title":"Internals - CLI","text":"<p>This page does not address created projects, rather, it is about the API Logic Server system used to create projects.  It is for those who want to extend the product or understand how it works, not for those simply using the product.</p>"},{"location":"Architecture-Internals-CLI/#created-api-logic-project-structure","title":"Created API Logic Project Structure","text":"<p>For reference, projects are created with this structure:</p> <p></p> <p>To create using the source code (e.g, from an IDE), using the <code>venv</code> created from above (note: to get the full log, you must must set <code>APILOGICSERVER_DEBUG</code> as in Run Config <code>2 - Create servers/ApiLogicProject (DEFAULTS)</code>):</p> <pre><code>(venv) val@Vals-MPB-14 ApiLogicServer % als create\nPatch to enable import of outer directories\n\nWelcome to API Logic Server 11.00.12\n\nProject Name [ApiLogicProject]: \nSQLAlchemy Database URI [default = nw.sqlite, ? for help]: \n.. ..Manager path: /Users/val/dev/ApiLogicServer/ApiLogicServer-dev/build_and_test/ApiLogicServer\n.. ..Interp path: manager_path / venv/bin/python\n\n\nCreating ApiLogicProject with options:\n  --db_url=default = nw.sqlite, ? for help\n  --project_name=ApiLogicProject   (pwd: /Users/val/dev/ApiLogicServer/ApiLogicServer-dev/build_and_test/ApiLogicServer)\n  --from_model=\n  --bind_key=\n  --api_name=api\n  --admin_app=True\n  --react_admin=False\n  --flask_appbuilder=False\n  --id_column_alias=Id\n  --from_git=\n  --run=False\n  --host=localhost\n  --port=5656\n  --swagger_host=localhost\n  --not_exposed=ProductDetails_V\n  --open_with=code\n  --use_model=\n  --favorites=name description\n  --non_favorites=id\n  --extended_builder=\n  --include_tables=\n  --multi_api=False\n  --infer_primary_key=False\n  --opt_locking=optional\n  --opt_locking_attr=S_CheckSum\n\nApiLogicServer 11.00.12 Creation Log:\n0. Using Sample DB from: sqlite:////Users/val/dev/ApiLogicServer/ApiLogicServer-dev/build_and_test/ApiLogicServer/venv/lib/python3.12/site-packages/api_logic_server_cli/database/nw-gold.sqlite\n1. Delete dir: /Users/val/dev/ApiLogicServer/ApiLogicServer-dev/build_and_test/ApiLogicServer/ApiLogicProject\n2. Create Project: /Users/val/dev/ApiLogicServer/ApiLogicServer-dev/build_and_test/ApiLogicServer/ApiLogicProject\n.. ..Clone from /Users/val/dev/ApiLogicServer/ApiLogicServer-dev/build_and_test/ApiLogicServer/venv/lib/python3.12/site-packages/api_logic_server_cli/prototypes/base \n.. ..Copy in nw- customizations: readme\n.. ..Copy in sqlite devops\n.. ..Sqlite database setup /Users/val/dev/ApiLogicServer/ApiLogicServer-dev/build_and_test/ApiLogicServer/ApiLogicProject/database/db.sqlite...\n.. .. ..From /Users/val/dev/ApiLogicServer/ApiLogicServer-dev/build_and_test/ApiLogicServer/venv/lib/python3.12/site-packages/api_logic_server_cli/database/nw-gold.sqlite\n.. .. ..db_uri set to: sqlite:////Users/val/dev/ApiLogicServer/ApiLogicServer-dev/build_and_test/ApiLogicServer/ApiLogicProject/database/db.sqlite in &lt;project&gt;/config/config.py\n.. ..project_directory_actual: /Users/val/dev/ApiLogicServer/ApiLogicServer-dev/build_and_test/ApiLogicServer/ApiLogicProject\n3. Create/verify database/models.py, then use that to create api/ and ui/ models\n a.  Create Models - create database/models.py, using sqlcodegen\n.. .. ..For database:  sqlite:////Users/val/dev/ApiLogicServer/ApiLogicServer-dev/build_and_test/ApiLogicServer/ApiLogicProject/database/db.sqlite\n                 .. .. .. ..Create ProductDetails_View as table, because no Unique Constraint   \nSpecial case: avoid collision if fkname = parent table name\n...\nExcluded single field fl on Order.Country\nExcluded single field fl on Order.City\nrender_column show name is true: ProductDetails_View.Id\n...\n.. .. ..Create resource_list - dynamic import database/models.py, inspect 18 classes in &lt;project&gt;/database\n b.  Create api/expose_api_models.py from models\n c.  Create ui/admin/admin.yaml from models\n4. Final project fixup\n b.   Update api_logic_server_run.py with project_name=ApiLogicProject and api_name, host, port\n c.   Fixing api/expose_services - port, host\n d.   Updated customize_api_py with port=5656 and host=localhost\n e.   Updated python_anywhere_wsgi.py with /Users/val/dev/ApiLogicServer/ApiLogicServer-dev/build_and_test/ApiLogicServer/ApiLogicProject\n d.   Fixing devops/docker-image/build_image.sh - project name\n.. ..Updated .vscode/settings.json with \"python.defaultInterpreterPath\": \"/Users/val/dev/ApiLogicServer/ApiLogicServer-dev/build_and_test/ApiLogicServer/venv/bin/python\"...\n d.  Create Ontimize from models\n a.  Use existing ApiLogicProject/database/models.py - no copy\n.. .. ..Create resource_list - dynamic import database/models.py, inspect 0 classes in &lt;project&gt;/database\n code \"ApiLogicProject\" \n</code></pre> <p> </p>"},{"location":"Architecture-Internals-CLI/#creation-internals","title":"Creation Internals","text":"<p> TL/;DR - Deep Copy for default project, create models from schema, create api/ui from models</p> <p>The basic process of creating a project is a deep copy of <code>api_logic_server_cli/project_prototype</code>, overlaid (as appropriate) from <code>project_prototype_nw</code>.</p> <p>Much of the logic is the process of creating the models from the database, using an altered variant of <code>sqlacodegen</code>.  The created model is then re-opened to create the internal meta data that drives the builders.</p> <p>The builders use this to create the api and ui.</p> <p> </p> <p>The ApiLogicServer source code looks like this:</p> <p></p> <p>And here are the prototypes (note this looks much like a runnable project):</p> <p></p> <p>Execution begins at <code>ApiLogicServer/api_logic_server_cli/cli.py</code>.  It gathers command line arguments and creates an instance of <code>ProjectRun(Project)</code>, which proceeds to <code>ProjectRun.create_project()</code>.  Its operation is described in the sections below.</p>"},{"location":"Architecture-Internals-CLI/#1-delete-dir","title":"1. Delete Dir","text":"<p>The target project directory is deleted.  This does not work on Windows, which requires the directory to not exist.</p>"},{"location":"Architecture-Internals-CLI/#2-create-project-copy-or-git-clone","title":"2. Create Project - copy or <code>git clone</code>","text":"<p>The basic project structure is then created, either by a directory copy or <code>git clone</code>.  By default, project is created from <code>ApiLogicServer/prototype</code>.</p>"},{"location":"Architecture-Internals-CLI/#2a-customize","title":"2a. Customize","text":"<p>With limited flexibility, you can provide your own <code>from-git</code> url/path.</p>"},{"location":"Architecture-Internals-CLI/#nw-examples","title":"NW Examples","text":"<p>For demonstration purposes, the system copies pre-defined logic and services so you can explore them.  These are copied from the <code>api_logic_server_cli</code> directory,  This is indicated by the following console log entry:</p> <pre><code>.. ..Append logic/declare_logic.py with pre-defined nw_logic, rpcs\n</code></pre>"},{"location":"Architecture-Internals-CLI/#3-createverify-databasemodelspy-then-use-that-to-create-api-and-ui-models","title":"3. Create/verify <code>database/models.py</code>, then use that to create api/ and ui/ models","text":"<p>The main driver instantiates <code>create_from_models/model_creation_services.ModelCreationServics()</code>, whose constructor calls <code>create_models</code>.  Described below, this provides access to the model, plus verious services to do things like return favorite fields, joins, etc.</p> <p>The main driver then executes <code>invoke_creators</code> which calls the <code>create_from_models</code> modules to create api and ui models, based on the <code>create_from_models/model_creation_services</code> object.  Before writing <code>models.py</code>, import fixes are made in <code>fix_database_models</code>.</p> <p>Here is the key excerpt of the main driver in <code>api_logic_server_cli/cli.py</code>:</p> <pre><code>    print(f'3. Create/verify database/models.py, then use that to create api/ and ui/ models')\n    model_creation_services = ModelCreationServices(  ...)\n    fix_database_models(project_directory, db_types, nw_db_status)\n    invoke_creators(model_creation_services)  # MAJOR! creates api/expose_api_models, ui/admin &amp; basic_web_app\n</code></pre>"},{"location":"Architecture-Internals-CLI/#3a-create-models-create-databasemodelspy","title":"3a. Create Models - create <code>database/models.py</code>","text":"<p>The essence of the project creator is that, given a database model (description), we can  generate APIs and UIs.  These models are created in `model_creation_services.py - ModelCreationServices.</p> <p>The essence of the process is illustrated in the <code>key_module_map</code> at the end of <code>ApiLogicServer/api_logic_cli/cli.py</code>.  <code>ModelCreationServices</code> provides the model (<code>resource_list</code>) and various services (e.g, <code>findChildList</code>).  A key function is to create the model, which starts in the <code>__init()__</code> constructor:</p> <ul> <li>It calls <code>sqlacodegen_wrapper.create_models_py</code> to create a string of the models file, which is then written to disk in <code>write_models_py()</code><ul> <li>See the code comments for the function: <code>create_models_py</code> </li> </ul> </li> <li>It then calls <code>create_resource_list()</code> (non-trivial)<ul> <li>It dynamically loads the created <code>models.py</code></li> <li>And builds the model using metadata create by the SAFRS package</li> </ul> </li> </ul> <p>For more information, see the comments in <code>create_models_py()</code>, easily reached via the <code>key_module_map</code> in <code>ApiLogicServer/api_logic_cli/cli.py</code>:</p> <pre><code>def key_module_map():\n    \"\"\" not called - just index of key code - use this for hover, goto etc \n        ctl-l (^l) for last edit\n    \"\"\"\n    import create_from_model.ui_admin_creator as ui_admin_creator\n    import create_from_model.api_expose_api_models_creator as api_expose_api_models\n    import sqlacodegen_wrapper.sqlacodegen_wrapper as sqlacodegen_wrapper\n\n    api_logic_server()                                          # main driver, calls...\n    create_project_with_nw_samples()                            # clone project, overlay nw\n    model_creation_services = ModelCreationServices()           # creates resource_list (python db model); ctor calls...\n    def and_the_ctor_calls():\n        sqlacodegen_wrapper.create_models_py({})                # creates models.py via sqlacodegen\n        model_creation_services.create_resource_list()          # creates resource_list via dynamic import of models.py\n    invoke_creators(model_creation_services)                    # creates api, ui via create_from_model...\n    api_expose_api_models.create()                              # creates api/expose_api_models.py, key input to SAFRS        \n    ui_admin_creator.create()                                   # creates ui/admin/admin.yaml from resource_list\n    get_abs_db_url()                                            # nw set here, dbname```\n</code></pre> <p> </p>"},{"location":"Architecture-Internals-CLI/#create-resource_list-dynamic-import-databasemodelspy-inspect-each-class","title":"Create <code>resource_list</code> - dynamic import database/models.py, inspect each class","text":"<p>Called from <code>create_models</code>', this dynamically imports the created (or, rebuild, the existing) <code>models.py</code>, and creates teh <code>resource_list</code> used by the creator modules.</p> <p>create_resource_model_from_safrs is a complex process due to dynamic import of models.py - failures may manifest here.</p> <p></p>"},{"location":"Architecture-Internals-CLI/#if-option-use_model","title":"If option: <code>use_model</code>","text":"<p>SQL dialects and bugs can result in failures here.  The system therefore enables you to provide your own model, as described in TroubleShooting.</p> <p>If you elect this option, you should see the following in the console log: <pre><code>.. ..Copy /Users/val/dev/ApiLogicServer/tests/models.py to /Users/val/dev/servers/sqlserver-types/database/models.py\n</code></pre></p>"},{"location":"Architecture-Internals-CLI/#extensible-generate-from-models","title":"Extensible generate from models","text":"<p>The <code>models.py</code> file provides <code>resource_list</code> metadata used to create APIs, the admin app, and a react-admin app (steps 31, 3b and 3c), as shown below:</p> <p></p>"},{"location":"Architecture-Internals-CLI/#3b-create-apiexpose_api_modelspy-import-iterate-models","title":"3b. Create <code>api/expose_api_models.py</code> (import / iterate models)","text":"<p>The first creator to be invoked is <code>create_from_model/api_expose_api_models</code> to create <code>expose_api_models</code>.</p> <p>It uses <code>model_creation_services.resource_list</code> to create <code>create_from_model/model_creation_services#create_models</code>.  It is straightforward.</p> <p>The remaining steps make small updates to the created code to insert database names.</p>"},{"location":"Architecture-Internals-CLI/#3c-create-uiadmin-app-import-iterate-models","title":"3c. Create <code>ui/admin app</code> (import / iterate models)","text":"<p>The main thing in <code>ui_admin_creator</code> is to create a <code>admin.yaml</code> file - an executable description of the pages and content.</p>"},{"location":"Architecture-Internals-CLI/#3d-create-uibasic_web_app-with-command-flask-fab-create-app","title":"3d. Create <code>ui/basic_web_app</code> with command: <code>flask fab create-app</code>","text":"<p>The system then creates the admin app.  The main thing here is to create the <code>views.py</code> file.</p> <p> </p>"},{"location":"Architecture-Internals/","title":"Internal Dev Procedures","text":""},{"location":"Architecture-Internals/#technology-lineage-40-years-of-production-success","title":"Technology Lineage: 40+ Years of Production Success","text":"<p>TL;DR: API Logic Server represents the modern evolution of business rules technology proven across 6,000+ enterprise deployments spanning four decades, from Wang Labs PACE through Versata to today's cloud-native architecture.</p>"},{"location":"Architecture-Internals/#historical-evolution","title":"Historical Evolution","text":"<p>1. Wang Labs PACE (1980s-1990s) - Original commercial business rules platform - 6,000+ corporate customers running mission-critical systems - Pioneered declarative multi-table derivations and constraints - Proved \"5 rules replace 200 lines of code\" at enterprise scale - Established automatic dependency ordering and chaining</p> <p>2. Versata (1990s-2010s) - $3.4 billion startup backed by founders of Microsoft, Sybase, Ingres, Informix - Fortune 500 enterprise deployments - Advanced the rules engine with optimization (pruning, delta-based adjustments) - Demonstrated correctness and performance at massive scale - Validated the declarative paradigm across thousands of production systems</p> <p>3. API Logic Server / GenAI-Logic (2020s-present) - Modern evolution: same proven patterns, contemporary stack - Python/SQLAlchemy (vs. Java/JDBC) - Cloud-native (Docker/Kubernetes) - Open source and extensible - GenAI integration (natural language \u2192 declarative rules) - Modern integration patterns (REST/JSON:API, Kafka, webhooks)</p> <p>Key Insight: This technology is not experimental. The core architectural patterns (declarative rules, automatic dependency discovery, multi-table chaining, foreign key change handling) have been validated across 40+ years and thousands of production deployments.</p> <p> </p>"},{"location":"Architecture-Internals/#why-declarative-architecture-matters-the-nl-dsl-engines-pattern","title":"Why Declarative Architecture Matters: The NL \u2192 DSL \u2192 Engines Pattern","text":"<p>Read: Declarative GenAI: The Architecture Behind Enterprise Vibe Automation</p> <p>This Medium article explains the fundamental architectural distinction that makes GenAI-Logic different:</p> <p>The Problem: \"FrankenCode\"</p> <p>Traditional GenAI vibe tools generate 200+ lines of buggy procedural code that: - Misses corner cases (e.g., changing customer on order, changing product on item) - Violates SOA principles (logic dumped on client) - Creates instant technical debt (unmaintainable, opaque) - Requires explicit handlers for every possible change path</p> <p>The Solution: Declarative GenAI</p> <p>Natural Language \u2192 Domain-Specific Language \u2192 Runtime Engines</p> <p>Instead of generating procedural code, GenAI generates declarative specifications executed by proven runtime engines:</p> <ol> <li>Database Layer: SQLAlchemy ORM with intelligent defaulting</li> <li>API Layer: JSON:API engine with full rule enforcement, Swagger docs, MCP support</li> <li>UI Layer: YAML-driven React Admin (working app, not scaffolding)</li> <li>Logic Layer: Rules engine providing:    - Automatic pruned invocation (attribute-level granularity)    - Dependency ordering (auto-discovered from rule definitions)    - Optimized chaining (delta-based, avoids expensive SQL aggregates)    - Automatic completeness (handles ALL change paths, not just obvious ones)</li> </ol> <p>Critical: Rules as Correctness Guarantee</p> <p>Declarative rules aren't optional or a \"coding style\" - they're a fundamental architectural requirement for correctness in multi-table logic:</p> <ul> <li>Dependency chains: <code>Product.unit_price</code> change transitively affects <code>Item.unit_price</code> \u2192 <code>Item.amount</code> \u2192 <code>Order.amount_total</code> \u2192 <code>Customer.balance</code></li> <li>Foreign key changes: When <code>Order.customer_id</code> changes, engine automatically adjusts both old and new customer balances</li> <li>Automatic completeness: Engine handles ALL possible change paths; procedural code inherently misses corner cases</li> </ul> <p>Why procedural fails: Even AI-generated code misses critical cases because it requires explicit handlers for every change path. The rules engine eliminates this entire class of bugs through automatic dependency analysis and chaining.</p> <p>The Paradox Resolution: Declarative DSL in Python, executed by runtime engine handling 95% of typical business logic (remaining 5% uses standard Python event handlers).</p> <p> </p>"},{"location":"Architecture-Internals/#genai-prompt-engineering-natural-language-structured-specifications","title":"GenAI Prompt Engineering: Natural Language \u2192 Structured Specifications","text":""},{"location":"Architecture-Internals/#the-chatgpt-project-creation-pipeline","title":"The ChatGPT Project Creation Pipeline","text":"<p>The <code>genai-logic create</code> command translates natural language requirements into complete working projects using fine-tuned ChatGPT with structured prompt engineering.</p> <p>Key Principle: AI generates declarative specifications (models + rules), not procedural code. The runtime engines provide correctness guarantees.</p>"},{"location":"Architecture-Internals/#prompt-engineering-architecture","title":"Prompt Engineering Architecture","text":"<p>Location: <code>system/genai/prompt_inserts/</code></p> <p>Core Templates:</p> <ol> <li> <p><code>sqlite_inserts.prompt</code> - Main orchestrator:    <pre><code>Use SQLAlchemy to create a sqlite database for: {{prompt}}\n{% include 'sqlite_inserts_model_test_hints.prompt' %}\n{% include 'graphics.prompt' %}\n{% include 'response_format.prompt' %}\n</code></pre></p> </li> <li> <p><code>sqlite_inserts_model_test_hints.prompt</code> - Critical generation rules:    - \"If you create sum, count or formula Logic Bank rules, then you MUST create a corresponding column in the data model\"    - Use autonum keys for ALL tables (including junction tables)    - Create classes, never tables (singular names, capitalized)    - No check constraints (use rules instead)    - Foreign key columns (not relationship names) for test data</p> </li> <li> <p><code>logic_inserts.prompt</code> - Rule generation:    <pre><code>Use LogicBank to enforce these requirements (do not generate check constraints);\nbe sure to update the data model and *all* test data with any attributes used in the logic\n</code></pre></p> </li> <li> <p><code>response_format.prompt</code> - Structured output schema:    <pre><code>class WGResult(BaseModel):\n    models: List[Model]              # SQLAlchemy classes\n    rules: List[Rule]                # LogicBank declarations  \n    test_data: str                   # Python test data creation\n    test_data_sqlite: str            # INSERT statements\n    graphics: List[Graphic]          # Dashboard queries\n    name: str                        # Suggested project name\n</code></pre></p> </li> </ol>"},{"location":"Architecture-Internals/#model-logic-co-generation-key-insight","title":"Model + Logic Co-Generation (Key Insight)","text":"<p>Unlike existing database projects, GenAI creation modifies the data model to support logic:</p> <p>Example Input: <pre><code>Customer.balance = Sum(Order.amount_total where date_shipped is null)\nOrder.amount_total = Sum(Item.amount)\nOrder.item_count = Count(Items); can't ship if item_count == 0\n</code></pre></p> <p>ChatGPT Automatically Creates: - <code>Customer</code> class with <code>balance</code> column (Decimal) - <code>Order</code> class with <code>amount_total</code> column (Decimal) - <code>Order</code> class with <code>item_count</code> column (Integer) - Corresponding LogicBank rules for all derivations - Test data with derived attributes pre-initialized</p> <p>Critical Pattern: Derived attributes materialize as database columns. This enables: - Efficient queries (indexed, no runtime aggregation) - Scalable performance (pruning, delta adjustments) - Simple constraints (balance &lt;= credit_limit works on stored value)</p>"},{"location":"Architecture-Internals/#training-examples-teaching-chatgpt-rule-patterns","title":"Training Examples: Teaching ChatGPT Rule Patterns","text":"<p>Location: <code>org_git/ApiLogicServer-src/tests/genai_tests/logic_training/</code></p> <p>Format: <code>*.prompt</code> (input) + <code>*.txt</code> (expected output) \u2192 <code>ft.jsonl</code> (fine-tuning data)</p> <p>Pattern Categories:</p> <ol> <li> <p>Chain Up (Aggregation + Constraint)    - <code>emp_depts.prompt</code>: Department.total_salary = sum(Employee.salary); total_salary &lt;= budget    - <code>genai_demo.prompt</code>: Customer.balance = sum(Order.amount_total); balance &lt;= credit_limit    - Teaches: Derive first, constrain second (two-step pattern)</p> </li> <li> <p>Counts as Existence Checks    - <code>genai_demo.prompt</code>: Order.item_count = Count(Items); constraint: can't ship if item_count == 0    - Teaches: Use count for validation, not just analytics</p> </li> <li> <p>Cardinality Patterns (Qualified Any)    - <code>products.prompt</code>: Total notices + severity 5 notices; error if orderable with bad notices    - <code>graduate.prompt</code>: Probation count + sick days count; graduation eligibility constraint    - Teaches: Multiple counts (total + qualified) for complex conditions</p> </li> <li> <p>Ready Flag (Conditional Aggregations)    - <code>ready_flag.prompt</code>: Customer.balance = sum(Order.amount_total where ready == True AND date_shipped is None)    - Teaches: Qualified sums with multiple conditions, cascading flags</p> </li> <li> <p>Chain Down (Copy/Formula Propagation)    - Item.unit_price = copy(Product.unit_price) - price change doesn't affect old orders    - Item.ready = Order.ready (formula propagation)    - Teaches: Difference between copy (point-in-time) and formula (live reference)</p> </li> </ol>"},{"location":"Architecture-Internals/#common-ai-mistakes-corrections","title":"Common AI Mistakes (Corrections)","text":"<p>Several <code>*_corrected_prompt.txt</code> files document typical errors:</p> <p>1. Wrong Relationship Path (<code>airport_corrected_prompt.txt</code>): - \u274c Original: \"airplane's passengers must be less than seating capacity\" - Problem: No direct Airplane \u2192 Passenger relationship - \u2705 Corrected: \"flight's passengers must be less than its Airplane's seating capacity\" - Lesson: AI needs explicit relationship path</p> <p>2. Constraint Depends on Derived Flag (<code>products_corrected_prompt.txt</code>): - \u274c Original: \"product is orderable IF no severity 5 notices\" - Problem: Makes <code>orderable</code> derived, then uses it in constraint (circular) - \u2705 Corrected: \"RAISE ERROR if product.orderable == True AND has severity 5 notices\" - Lesson: Flag is input, constraint validates it (not derived from constraint conditions)</p> <p>3. Negative Condition Logic: - \u274c Harder: \"if student.can_graduate, then must have &lt; 3 probations\" - \u2705 Easier: \"error if can_graduate == True AND probation_count &gt; 2\" - Pattern: <code>not(row.flag and bad_condition)</code> is clearest for AI</p>"},{"location":"Architecture-Internals/#fine-tuning-process","title":"Fine-Tuning Process","text":"<p>Training Data: <code>logic_training/ft.jsonl</code> (~374KB) - JSONL format for ChatGPT fine-tuning API - Generated from 10+ prompt/response pairs - Format: <code>{\"messages\": [{\"role\": \"system\", ...}, {\"role\": \"user\", ...}, {\"role\": \"assistant\", ...}]}</code></p> <p>Generation Script: <code>logic_training/create_json_l.py</code> - Converts pattern examples \u2192 training data - System prompt + user prompt + expected response - Updates <code>ft.jsonl</code> with new examples</p>"},{"location":"Architecture-Internals/#cli-commands-using-this-system","title":"CLI Commands Using This System","text":"<p>Create from natural language: <pre><code>genai-logic create --project-name=my_system --using=\"your requirements here\"\n# Pipeline: assemble prompts \u2192 ChatGPT API \u2192 parse WGResult \u2192 generate project\n</code></pre></p> <p>Translate logic (existing DB): <pre><code>genai-logic logic-translate --project-name=. --using-file=docs/logic\n# Uses logic_translate.prompt: NL in docs/logic \u2192 rules in logic/logic_discovery/\n</code></pre></p> <p>Add logic to existing project: <pre><code>genai-logic add-logic --using=\"The Order's amount_total is sum of Item amounts\"\n# Appends rules to logic/declare_logic.py or logic/logic_discovery/\n</code></pre></p>"},{"location":"Architecture-Internals/#why-this-architecture-succeeds","title":"Why This Architecture Succeeds","text":"<p>Traditional GenAI Code Generation: - Outputs: 200+ lines of procedural code - Problems: Misses corner cases, violates SOA, creates technical debt - Example miss: Foreign key change (Order.customer_id) requires adjusting BOTH old and new customer balances</p> <p>Declarative GenAI (This System): - Outputs: 5 rules (declarative specifications) - Execution: Proven rules engine (40+ years, 6,000+ deployments) - Coverage: Engine handles ALL change paths automatically via dependency analysis - Result: Correctness guarantee + 40X code reduction</p> <p>Critical Insight: AI doesn't need to \"think through\" all possible change paths. It translates requirements \u2192 rules, and the engine provides completeness.</p> <p>Natural Language \u2192 DSL \u2192 Runtime Engine (not NL \u2192 procedural code)</p>"},{"location":"Architecture-Internals/#testing-examples","title":"Testing Examples","text":"<p>Location: <code>system/genai/examples/</code></p> <p>Each directory contains: - <code>*.prompt</code> - User requirements (various formality levels) - <code>*.response_example</code> - Expected ChatGPT output - Subdirectories for iterations (<code>genai_demo_iteration/</code>, <code>genai_demo_iteration_discount/</code>)</p> <p>Key Examples: - <code>genai_demo/</code> - Complete Check Credit + No Empty Orders (primary teaching example) - <code>genai_demo_informal.prompt</code> - Less structured input (tests robustness) - <code>ready_flag/</code> - Multi-use-case with conditional logic - <code>airport/</code> - Complex 10+ table system - <code>time_tracking_billing/</code> - Real-world business scenario</p> <p>Purpose: Validate prompt engineering works across formality levels and complexity ranges.</p> <p> </p>"},{"location":"Architecture-Internals/#critical-understanding-the-nested-manager-architecture","title":"CRITICAL: Understanding the Nested Manager Architecture","text":"<p>The development environment has two distinct Manager workspaces:</p> <p>1. Seminal Manager - <code>~/dev/ApiLogicServer/ApiLogicServer-dev/</code> - Original Manager installation from <code>als start</code> - Stable, persistent workspace - Contains <code>build_and_test/</code> directory - Used to run the BLT process - Houses <code>org_git/</code> with source repositories</p> <p>2. BLT Manager (Nested) - <code>~/dev/ApiLogicServer/ApiLogicServer-dev/build_and_test/ApiLogicServer/</code> - Created and refreshed by the BLT (Build, Load and Test) process - Contains rebuilt/tested version of API Logic Server - Contains sample projects (<code>basic_demo</code>, <code>nw_sample</code>, etc.) for testing - Has its own venv shared by test projects - Gets regenerated with each BLT run - Contains <code>system/ApiLogicServer-Internal-Dev/copilot-dev-context.md</code> for AI context restoration</p> <p>Complete Directory Structure: <pre><code>~/dev/ApiLogicServer/ApiLogicServer-dev/          # Seminal Manager\n\u251c\u2500\u2500 build_and_test/\n\u2502   \u2514\u2500\u2500 ApiLogicServer/                           # BLT Manager (nested workspace)\n\u2502       \u251c\u2500\u2500 samples/                              # Sample/test projects\n\u2502       \u2502   \u251c\u2500\u2500 basic_demo_sample/\n\u2502       \u2502   \u251c\u2500\u2500 nw_sample/\n\u2502       \u2502   \u2514\u2500\u2500 ...\n\u2502       \u251c\u2500\u2500 venv/                                 # Shared venv for test projects\n\u2502       \u251c\u2500\u2500 system/\n\u2502       \u2502   \u2514\u2500\u2500 ApiLogicServer-Internal-Dev/      # Internal dev tooling\n\u2502       \u2502       \u251c\u2500\u2500 copilot-dev-context.md        # AI context restoration\n\u2502       \u2502       \u2514\u2500\u2500 install-ApiLogicServer-dev.sh # Dev environment setup\n\u2502       \u2514\u2500\u2500 docs/                                 # Training materials\n\u2514\u2500\u2500 org_git/\n    \u251c\u2500\u2500 ApiLogicServer-src/                       # Framework source (edit here)\n    \u2502   \u2514\u2500\u2500 api_logic_server_cli/\n    \u2502       \u2514\u2500\u2500 prototypes/\n    \u2502           \u251c\u2500\u2500 base/                         # Templates for created projects\n    \u2502           \u2514\u2500\u2500 manager/                      # Manager workspace templates\n    |       \u2514\u2500\u2500 tests/\n    |           \u2514\u2500\u2500 build_and_test/               # system rebuild and test -&gt; build_and_test \n    \u2514\u2500\u2500 Docs/                                     # Documentation project\n        \u2514\u2500\u2500 docs/\n            \u2514\u2500\u2500 Architecture-Internals.md         # This page\n</code></pre></p> <p>Development Workflow: 1. Edit framework code in <code>org_git/ApiLogicServer-src/</code> 2. Run BLT from Seminal Manager (rebuilds, tests, regenerates BLT Manager) 3. Test with sample projects in BLT Manager workspace 4. BLT Manager gets fresh context from <code>system/ApiLogicServer-Internal-Dev/copilot-dev-context.md</code> after each rebuild</p> <p>Why This Architecture: - Isolation: Changes being tested don't affect stable Seminal Manager - Clean slate: Each BLT run creates fresh testing environment - Shared venv: Test projects reuse BLT Manager's venv (speeds testing) - Context preservation: <code>system/ApiLogicServer-Internal-Dev/copilot-dev-context.md</code> re-establishes understanding after rebuild</p> <p> </p>"},{"location":"Architecture-Internals/#cross-references-for-full-context","title":"Cross-References for Full Context","text":"<p>For Strategic Architecture Understanding: - <code>system/ApiLogicServer-Internal-Dev/copilot-dev-context.md</code> - Technology lineage, declarative architecture, NL\u2192DSL\u2192Engines pattern - Medium Article - Complete architectural rationale</p> <p>For Created Project Development: - Manager-level <code>.copilot-instructions.md</code> - How to CREATE projects - Project-level <code>.copilot-instructions.md</code> - How to EXTEND/CUSTOMIZE projects - <code>docs/training/logic_bank_api.prompt</code> - LogicBank API reference (in each project) - <code>docs/training/testing.md</code> - Behave testing guide (1755 lines, in each project)</p> <p>For End Users: - API Logic Server Documentation - Complete user guide - Installation - Setup procedures - Tutorial - Step-by-step learning</p> <p> </p> <p> </p> <p>This page does not address created projects, rather, it is about the API Logic Server system used to create projects.  It is for those who want to extend the product or understand how it works, not for those simply using the product.</p>"},{"location":"Architecture-Internals/#how-to-install-it","title":"How to Install it","text":"<p>The subsections below described the steps to:</p> <ol> <li>Obtain the software from GitHub</li> <li>Open the dev workspace in your IDE</li> <li>Create the \"initial 'venv'\"</li> <li>Perform the critical \"Smoke Test\" to ensure system operation</li> </ol>"},{"location":"Architecture-Internals/#manager-internal-development-setup","title":"Manager Internal Development Setup","text":"<p>To create the dev enviroment (result shown above): </p> <ol> <li> <p>Install the user version of the API Logic Server</p> <ul> <li>let's assume it's <code>~/dev/ApiLogicServer-dev</code></li> </ul> </li> <li> <p>Start the Manager: <code>als start</code></p> </li> <li>Be sure you have installed the VSCode CLI - see the VSCode CLI procedure</li> <li>In your CLI terminal window:<ul> <li>Note: Windows users use <code>install-ApiLogicServer-dev.ps1</code>)</li> </ul> </li> </ol> <p>Install API Logic Server Development environment<pre><code>sh system/ApiLogicServer-Internal-Dev/install-ApiLogicServer-dev.sh\n</code></pre> 5. In your newly created dev source, create <code>ApiLogicServer/ApiLogicServer-dev/org_git/ApiLogicServer-src/api_logic_server_cli/api_logic_server_info.yaml</code>, with: <pre><code>last_created_date: May 28, 2025 12:08:45\nlast_created_project_name: /Users/val/dev/ApiLogicServer/ApiLogicServer-dev/servers/basic_demo\nlast_created_version: 14.05.16\n</code></pre></p> <p>The install procedure will use <code>git clone</code> to create folders in <code>~/dev/ApiLogicServer/ApiLogicServer-dev/org/:</code></p> <p></p> <p> </p>"},{"location":"Architecture-Internals/#admin-app-source","title":"Admin App Source","text":"<p>This section is only if you did not load from the script.  You need to obtain the build of safrs react admin.</p> <p>It's basically straightforward, though note the <code>cp</code> command which copies the <code>safrs-react-admin</code> runtime to API Logic Server for subsequent creation of API Logic Projects:</p> <pre><code>echo \"\\ncopying build (sra - safrs-react-admin) --&gt; ApiLogicServer\"\ncp -r ../build api_logic_server_cli/create_from_model/safrs-react-admin-npm-build\n</code></pre> <p>For more information, see Admin App Reuse.</p> <p>Note: <code>curl</code> must be installed for this procedure.</p> <p> </p>"},{"location":"Architecture-Internals/#determine-your-ide","title":"Determine your IDE","text":"<p>API Logic Server has been developed with both VSCode and PyCharm.  While in many cases we prefer PyCharm, we have gravitated to VSCode since it supports an \"initial <code>venv</code>\".  </p> <p>This means that for the many test projects, there is no need to create a per-project <code>venv</code>.  This speeds unit testing considerably.</p> <p>Importantly, this relies on the Build and Test procedure to create the \"initial <code>venv</code>\".</p> <p>You will find that the VSCode install has a large number of Run Configs for these test projects.  In general, the created project can be run immediately in another window of VSCode, using the \"initial <code>venv</code>\".</p> <p> </p>"},{"location":"Architecture-Internals/#open-the-dev-workspace","title":"Open the dev workspace","text":"<p><code>install-ApiLogicServer...</code> will create a project workspace (<code>~/dev/ApiLogicServer/ApiLogicServer-dev/org_git/ApiLogicServer-src/.vscode/ApiLogicServerDev.code-workspace</code>), and open it VS Code or PyCharm.</p> open the dev project<pre><code>cd ~/dev/ApiLogicServer/ApiLogicServer-dev/org_git/ApiLogicServer-src/.vscode\ncode ApiLogicServerDev.code-workspace\n</code></pre> <p>Python requires a virtual environment; the procedure differs for <code>vscode</code> vs. <code>charm</code>:</p> <ul> <li><code>vscode</code> projects are created with a <code>venv</code> and are ready to run the Launch Configurations to create the sample</li> <li><code>charm</code> projects require that you create the <code>venv</code> with the PyCharm</li> </ul> <p>It should look something like this:</p> <p></p> <p> </p>"},{"location":"Architecture-Internals/#run-the-blt","title":"Run the BLT","text":"<p>It is tiresome to create a <code>venv</code> for each project.  So, the system creates projects with a VSCode property identifying the <code>venv</code>.</p> <ul> <li> <p>In actual practice, this is the manager's <code>venv</code>.  </p> </li> <li> <p>For the dev environment, it is calculated to the <code>venv</code> of the BLT: </p> <ul> <li>Note: the dev env BLT is not valid here, since it does not contain the CLI (which is needed for projects)</li> </ul> </li> </ul> <p></p> <ol> <li> <p>So, your first task is to run the BLT.  It is simplest to run it without testing, just to create the <code>venv</code> (and verify your installation).  </p> <ul> <li>Execute the 2nd Run Config (BLT - Hold the Tomato) to create the <code>venv</code> used for created projects, such as the Sample (see next section):</li> </ul> </li> </ol> <p></p> <ol> <li>Verify you have a <code>venv</code> at as shown above at:<code>ApiLogicServer/ApiLogicServer-dev/build_and_test/ApiLogicServer</code></li> </ol> <p> </p>"},{"location":"Architecture-Internals/#setup-required","title":"Setup Required","text":"<p>If this fails, a common error is that sra is not installed at <code>api_logic_server_cli/create_from_model/safrs-react-admin-npm-build</code>.  This can happen if the install procedure was not followed, or failed.</p> <p>Obtain the sra build folder, and copy it to the location above.</p> <p> </p>"},{"location":"Architecture-Internals/#critical-smoke-test","title":"Critical \"Smoke Test\"","text":"<p>This is the \"smoke test\" of API Logic Server.  In general, this should be successful prior to pushing changes.</p> <p> </p>"},{"location":"Architecture-Internals/#create-the-sample","title":"Create the Sample","text":"<p>Once in your IDE, you can run the pre-defined launch configuration <code>2 - Create servers/ApiLogicProject (new IDE)</code> to create and run the sample.  This creates <code>~/dev/servers/ApiLogicProject</code>.</p> <p></p> <p> </p>"},{"location":"Architecture-Internals/#run-the-sample","title":"Run the Sample","text":"<p>Open it in another window of VSCode and ensure it runs. </p> <ol> <li>Run the admin app, and</li> <li>Use the documented procedures to add customizations for APIs, Logic and Security.</li> </ol> <p> </p>"},{"location":"Architecture-Internals/#run-behave-tests","title":"Run Behave Tests","text":"<p>A critical test is the Behave Test.  It tests a dozen or so transactions, exercising the API and Logic.  </p> <ol> <li>Use the Run Config in the created project: <code>Behave Run</code>.</li> </ol>"},{"location":"Architecture-Internals/#ongoing-dev","title":"Ongoing dev","text":"<p>Follow these procesures to introduce changes, test them, and perform releases.</p> <p> </p>"},{"location":"Architecture-Internals/#introduce-enhancements-test","title":"Introduce enhancements, test","text":"<p>Note the Run Configurations below:</p> <p></p> <p>Consider using Run Config #1 to create project inside your current IDE instance.  Note:</p> <ul> <li> <p>You can use the debugger (inside the IDE dev instance) to debug the altered project</p> </li> <li> <p>The created/altered project is git-ignored, so is not part of any branch</p> </li> <li> <p>Note you can create 2 projects, eg, to test base vs. dev</p> </li> </ul> <p>You can then use Run Config #2 to test it in a new project / ide instance.</p> <ol> <li>Run the behave tests to ensure existing functionality is not broken</li> </ol> <p> </p>"},{"location":"Architecture-Internals/#update-cli-creation","title":"Update CLI creation","text":"<p>Update <code>api_logic_server_cli/project_prototype</code> (and probably <code>api_logic_server_cli/project_prototype_nw</code>) for enchanced creation</p> <p> </p>"},{"location":"Architecture-Internals/#build-and-test","title":"Build and Test","text":"<p>This is a VSCode Run Configuration used for final pre-release testing.  It builds the project, installs, it, and runs several dozen tests.</p> <ol> <li>Update the version number first in <code>api_logic_server_cli/api_logic_server.py</code></li> </ol> <p> venv can be used for projects</p> <p>You will be using this as a shared venv.</p> <p>For more information, see here.</p> <p> </p>"},{"location":"Architecture-Internals/#releasing","title":"Releasing","text":"<p>Build and Test should run on Macs, Linux (Ubuntu) and Windows 11.  Once these are successful, release as follows:</p> <ol> <li>At the root of <code>ApiLogicServer-src</code>, with no <code>venv</code></li> <li>Run <pre><code>python3 setup.py sdist bdist_wheel\n\npython3 -m twine upload  --skip-existing dist/* \n</code></pre></li> </ol> <p>This will upload to Pypi.  You of course need credentials.</p> <ol> <li>Delete the build folders: <code>ApiLogicServer.egg-info</code>, <code>build</code>, <code>dist</code></li> <li>Open <code>docker/api_logic_server.Dockerfile</code></li> <li>Update the build number (line 4: <code>--tag apilogicserver/api_logic_server:10.03.16</code>)</li> <li>Copy/paste/run the instructions at the top: <pre><code># GA release -- DELETE BUILD DIRS FIRST\n\n# docker buildx build --push -f docker/api_logic_server.Dockerfile --tag apilogicserver/api_logic_server:10.03.16 -o type=image --platform=linux/arm64,linux/amd64 .\n# docker buildx build --push -f docker/api_logic_server.Dockerfile --tag apilogicserver/api_logic_server:latest -o type=image --platform=linux/arm64,linux/amd64 .\n</code></pre></li> </ol> <p> </p>"},{"location":"Architecture-Internals/#get-docs-working","title":"Get Docs working","text":"<p>The install procedure also installs <code>Org-ApiLogicServer/Docs</code>.  Follow it's readme.</p> <p> </p>"},{"location":"Architecture-Internals/#testing-packages","title":"Testing Packages","text":"<p>In some cases, you may wish to test using experimental version of underlying packages, such as <code>safrs</code> or <code>logicbank</code>.  You can add multiple paths to Python Path like this:</p> <p>1. Edit <code>ApiLogicServer/.vscode/settings.json</code> to identify the desired packages, e.g.:</p> <pre><code>    \"terminal.integrated.env.osx\": \n        { \"PYTHONPATH\": \"/Users/val/dev/safrs\" }\n</code></pre> <p>If yu have more than one, separate them with colons.</p> <p>2. With the ApiLogicServer venv active, <code>pip uninstall</code> the packages you want to test</p> <p>3. Exit the ApiLogicServer workspace, and restart VSCode on the <code>ApiLogicServer</code> folder (not workspace)</p> <p>4. Use the Run Configs to create/test the app, e.g., <code>2 - Debug ApiLogicProject</code></p> <p>Note: you will need to perform a similar process if you want an installed local version of ApiLogicServer using the <code>tests/build_and_test</code> procedure.</p> <p>This procedure sometimes fails.  You can also try adding your package to the `env' in the Run Config:</p> <p><pre><code>        {\n            \"name\": \"No Security ApiLogicServer (e.g., simpler swagger)\",\n            \"type\": \"python\",\n            \"request\": \"launch\",\n            \"program\": \"api_logic_server_run.py\",\n            \"redirectOutput\": true,\n            \"env\": {\"PYTHONPATH\": \"/Users/val/dev/safrs\", \"SECURITY_ENABLED\": \"False\", \"PYTHONHASHSEED\": \"0\", \"OPT_LOCKING\": \"optional\", \"verbose\": \"True\"},\n            \"justMyCode\": false,\n            \"args\": [\"--flask_host=localhost\", \"--port=5656\", \"--swagger_host=localhost\", \"--verbose=False\"],\n            \"console\": \"internalConsole\",\n            \"internalConsoleOptions\": \"openOnSessionStart\"\n        },\n</code></pre> </p>"},{"location":"Architecture-Internals/#simpler-for-logicbank-local-install","title":"Simpler for LogicBank: local install","text":"<p>It's easy to create a local install for LogicBank.  First, you need to install the source:</p> <pre><code>cd ~/dev\ngit clone https://github.com/valhuber/LogicBank.git\n</code></pre> <p>Then, build it and add to the ApiLogicServer venv:</p> <p>1. Create Logic Bank installer on your hard drive</p> <pre><code>python3 setup.py sdist bdist_wheel\n</code></pre> <p>2. With the ApiLogicServer venv active, <code>pip uninstall LogicBank</code></p> <p>3. With the ApiLogicServer venv active, <code>python3 -m pip install ~/dev/LogicBank</code></p> <p> </p>"},{"location":"Architecture-Internals/#develop-debug-admin-app","title":"Develop / Debug admin app","text":"<p>Once you have created the API Logic Project, you can restart the server like this (it is not necessary to recreate the sample each time you run):</p> Start API Logic Project<pre><code>cd ~/dev/servers/ApiLogicProject\npython3 api_logic_server_run.py\n</code></pre> <p>You can obtain an editable version of the admin app like this:</p> Get Data Provider<pre><code>cd ~/dev/safrs-react-admin\ngit clone https://github.com/thomaxxl/rav3-jsonapi-client # modified data provider used, installed in the project root\n</code></pre> <p>Then, to debug (with server running):</p> Execute debug version of admin app<pre><code>npm install --global yarn # required only once\nyarn install\nyarn run build\n\nyarn start\n</code></pre> <p>To make this the runtime used to create API Logic Projects:</p> Update ApiLogicServer to use your admin app<pre><code>cp -a /build/. ../ApiLogicServer/api_logic_server_cli/create_from_model/admin/\n</code></pre> <p> </p>"},{"location":"Architecture-Internals/#docker-setup","title":"Docker Setup","text":""},{"location":"Architecture-Internals/#docker-startup","title":"Docker Startup","text":"<p>You can review the dockerfile on <code>github</code>.  Note that the normal operation is to start a terminal session as the last step:</p> <pre><code>CMD [\"bash\"]\n</code></pre> <p>When bash sessions are started, Linux runs <code>.bashrc</code>.  This checks for environment variables which can be used to load an existing project from git, and run it.  (Note: this defeats the normal terminal startup).  For example, start Docker using <code>-e</code> arguments, like this:</p> <pre><code>docker run -it --name api_logic_server --rm --net dev-network \\\n-p 5656:5656 -p 5002:5002 -v ${PWD}:/localhost \\\n-e APILOGICSERVER_GIT='https://github.com/valhuber/Tutorial-ApiLogicProject.git' \\\n-e APILOGICSERVER_FIXUP='/localhost/Project-Fixup.sh' \\\napilogicserver/api_logic_server\n</code></pre> <p>Alternatively, you can start Docker specifying an initial command, like this: <pre><code>docker run -it --name api_logic_server --rm --net dev-network \\\n-p 5656:5656 -p 5002:5002 -v ${PWD}:/localhost \\\napilogicserver/api_logic_server \\\nsh /home/api_logic_server/bin/run-project.sh https://github.com/valhuber/Tutorial-ApiLogicProject.git /localhost/Project-Fixup.sh\n</code></pre></p> <p>In both cases, the git load is performed by <code>bin/run-project.sh</code>, which you can explore on github.</p> <p> </p>"},{"location":"Architecture-Internals/#sql-server-testing-with-vscode","title":"SQL Server testing with VSCode","text":"<p>While Sql/Server itself runs nicely under docker, there is considerable complexity in installing OCBC, regarding pyodbc:</p> <p><code>pyodbc</code> is not pip-installed by default, since installs fail unless odbc is installed, which is complex and might not be needed</p>"},{"location":"Architecture-Internals/#for-users","title":"For users","text":"<p>For users requiring pyodbc (SqlServer), there are 2 installs:</p> <ul> <li> <p>ODBC Driver: using <code>brew</code> as described here</p> </li> <li> <p><code>pip install pyodbc==5.2.00</code></p> </li> </ul> <p> </p>"},{"location":"Architecture-Internals/#for-apilogicserver-dev","title":"For ApiLogicServer-dev","text":"<p>ApiLogicServer-dev <code>requirements.txt</code> does not install odbc.  If you wish to test Sql/Server in ApiLogicServer-dev, follow the user setup instructions above.</p> <p> </p>"},{"location":"Architecture-Internals/#multi-arch-docker-images","title":"Multi-arch Docker images","text":"<p>Docker creation provides the opportunity to pre-install odbc and simplify life for Sql/Server users.  This procedure was used to create <code>apilogicserver/api_logic_server</code>, providing an image that supports odbc, and supports devcontainers for both arm and amd.  </p> <pre><code># GA release\n# docker buildx build --push -f docker/api_logic_server_all.Dockerfile --tag apilogicserver/api_logic_server_all:9.01.17 -o type=image --platform=linux/arm64,linux/amd64 .\n\n# Beta - test codespaces with tutorial, API_Fiddle (change .devcontainer.json -&gt; apilogicserver/api_logic_server_all_x)\n# docker buildx build --push -f docker/api_logic_server_all.Dockerfile --tag apilogicserver/api_logic_server_all_x:9.01.17 -o type=image --platform=linux/arm64,linux/amd64 .\n\n# Internal - verify what is done with build_and_test\n# docker build -f docker/api_logic_server_all.Dockerfile -t apilogicserver/api_logic_server_local --rm .\n</code></pre> <p> </p>"},{"location":"Architecture-Internals/#pre-push-testing","title":"Pre-push testing","text":"<p>In our (internal) case, we needed to build multi-arch images, but note the <code>buildx</code> command combines build and push in single procedure.  This prevents local testing prior to push.  That is why we use the \"Internal\" docker build, as shown above.</p> <p> </p>"},{"location":"Architecture-Internals/#vsc-bug-run-configs","title":"VSC Bug - Run Configs","text":"<p>VSCode has a bug where it cannot parse Run Configs for SqlSvr:</p> <pre><code>zsh: no matches found: --db_url=mssql+pyodbc://sa:Posey3861@localhost:1433/NORTHWND?driver=ODBC+Driver+18+for+SQL+Server&amp;trusted_connection=no&amp;Encrypt=no\n</code></pre> <p> </p>"},{"location":"Architecture-Internals/#behave-reports","title":"Behave Reports","text":"<p>The doc file <code>Behave-Logic-Report.md</code> is derived from using the behave tests from nw+ (run the test, then create the report).</p> <p>The report is copied into:</p> <ol> <li>`api_logic_server_cli/prototypes/base/test/api_logic_server_behave/reports/Behave Logic Report Sample.md'</li> <li><code>Behave-Logic-Report.md</code> --     a. Edit the report and remove the path information at the end     b. Paste the report into <code>Behave-Logic-Report.md</code> over the old contents.</li> </ol> <p> </p>"},{"location":"Architecture-Internals/#testing","title":"Testing","text":"<p>There are several important testing configurations.</p> <p> </p>"},{"location":"Architecture-Internals/#1-apilogicserver-dev","title":"1. ApiLogicServer-dev","text":"<p>To get around the VSC bug, hacks were made to the Run Configs, and the CLI, as described below.</p> <p>The run config has entries like this:</p> <pre><code>        {\n            \"name\": \"SQL Server nw (bypass vsc bug)\",\n            \"type\": \"python\",\n            \"request\": \"launch\",\n            \"cwd\": \"${workspaceFolder}/api_logic_server_cli\",\n            \"program\": \"cli.py\",\n            \"redirectOutput\": true,\n            \"argsExpansion\": \"none\",\n            \"args\": [\"create\",\n                \"--project_name=../../../servers/sqlsvr_nw\",\n                \"--db_url=sqlsvr-nw\"\n            ],\n            \"console\": \"integratedTerminal\"\n        },\n</code></pre> <p>The CLI detects db_url's like <code>sqlsvr-nw</code>, and converts them to strings like this for Database Connectivity &gt; Docker Databases: <pre><code>    elif project.db_url == 'sqlsvr-nw':  # work-around - VSCode run config arg parsing\n        rtn_abs_db_url = 'mssql+pyodbc://sa:Posey3861@localhost:1433/NORTHWND?driver=ODBC+Driver+18+for+SQL+Server&amp;trusted_connection=no&amp;Encrypt=no'\n    elif project.db_url == 'sqlsvr-nw-docker':  # work-around - VSCode run config arg parsing\n        rtn_abs_db_url = 'mssql+pyodbc://sa:Posey3861@HOST_IP:1433/NORTHWND?driver=ODBC+Driver+17+for+SQL+Server&amp;trusted_connection=no'\n        host_ip = \"10.0.0.234\"  # ApiLogicServer create  --project_name=/localhost/sqlsvr-nw-docker --db_url=sqlsvr-nw-docker\n        if os.getenv('HOST_IP'):\n            host_ip = os.getenv('HOST_IP')  # type: ignore # type: str\n        rtn_abs_db_url = rtn_abs_db_url.replace(\"HOST_IP\", host_ip)\n    elif project.db_url == 'sqlsvr-nw-docker-arm':  # work-around - VSCode run config arg parsing\n        rtn_abs_db_url = 'mssql+pyodbc://sa:Posey3861@10.0.0.77:1433/NORTHWND?driver=ODBC+Driver+18+for+SQL+Server&amp;trusted_connection=no&amp;Encrypt=no'\n        host_ip = \"10.0.0.77\"  # ApiLogicServer create  --project_name=/localhost/sqlsvr-nw-docker --db_url=sqlsvr-nw-docker-arm\n        if os.getenv('HOST_IP'):\n            host_ip = os.getenv('HOST_IP')  # type: ignore # type: str\n        rtn_abs_db_url = rtn_abs_db_url.replace(\"HOST_IP\", host_ip)\n</code></pre></p> <p>So, on ApiLogicServer-dev:</p> <ol> <li>Verify your machine has odbc 18 (using <code>brew which</code>)</li> <li>Use Run Config: <code>SQL Server nw (bypass vsc bug)</code></li> </ol> <p> </p>"},{"location":"Architecture-Internals/#2-local-pip-install","title":"2. Local <code>pip</code> install","text":"<p>Note: since the docker image is odbc17, the following commands fail in docker, but run in pip install when you've installed odbc18:</p> <pre><code>ApiLogicServer create --project_name=sqlsvr-nw --db_url=sqlsvr-nw\n</code></pre> <p> </p>"},{"location":"Architecture-Internals/#useful-links","title":"Useful links","text":"<p>As a contributor, you will likely work with:</p> <ul> <li>Docker Databases</li> <li>Shared virtual environments</li> </ul>"},{"location":"Architecture-Project-Operation/","title":"Project Operation","text":""},{"location":"Architecture-Project-Operation/#project-creation","title":"Project Creation","text":"<p>The ApiLogicServer CLI <code>create</code> (or <code>create-and-run</code>) command creates the project structure shown below - for more information, see here.</p> <p> </p>"},{"location":"Architecture-Project-Operation/#api-execution-api_logic_server_runpy","title":"API Execution: <code>api_logic_server_run.py</code>","text":"<p>Execution begins in <code>api_logic_server_run.py</code>.  Your customizations are done to the files noted in the callouts below.</p> <p></p> <p><code>api_logic_server_run.py</code> (a file created in your ApiLogicProject) sets up a Flask app, the database, logic and api:</p> <ol> <li> <p>Database Setup: It imports<code>api/expose_api_models</code> which imports <code>database/models.py</code>, which then imports <code>database/customize_models.py</code> for your model extensions.  <code>api_logic_server_run.py</code> then sets up flask, and opens the  database with <code>db = safrs.DB</code></p> </li> <li> <p>Logic Setup: It then calls <code>LogicBank.activate</code>, passing <code>declare_logic</code> which loads your declared rules into Logic Bank.</p> </li> <li> <p>API Setup: It next invokes <code>api/expose_api_models</code>.  This calls safrs to create the end points and the swagger information, based on the created <code>database/models.py</code> (the models used by the SQLAlchemy ORM).   It finally calls <code>api/customize.py</code> where you can add your own services.  The sample includes a trivial Hello World, as well as <code>add_order</code>.</p> </li> </ol> <p></p>"},{"location":"Architecture-Project-Operation/#logic-execution","title":"Logic Execution","text":"<p>SAFRS API listens for API calls, e.g., from the Admin App.  When updates are issued:</p> <p>L1. Invokes SQLAlchemy updates: SAFRS calls SQLAlchemy, passing a set of rows comprising a database transaction</p> <p>L2. <code>before_flush</code>: SQLAlchemy provides a <code>before_flush</code> event, where all the update rows are assembled and passed to <code>Logic Bank</code>  (no relation to retail!).</p> <p>L3. Logic Execution: Logic Bank reviews the rows, and based on what has change, prunes rules for unchanged data, and executes / optimizes relevant logic in an appropriate order.  </p> <p> </p>"},{"location":"Architecture-Project-Operation/#rowcommit-logic","title":"Row/Commit Logic","text":"<p>The console log below illustrates that the rows are processed in 2 distinct \"logic loops\":</p> <p></p> <ul> <li>Row Logic - rules are executed, with chaining, as received in the <code>before_flush</code> event</li> <li>Commit Logic - commit constraints and events are executed after all row logic is complete*</li> </ul> <p>Two logic loops are provided so that parent logic can see all the adjustments of the child logic. </p> <ul> <li> <p>When the Order is first seen at the top of the log, the OrderDetails have not yet been processed, so their adjustment logic has not been run.  So, sums/counts will be 0 (e.g. <code>OrderDetailCount</code>).</p> </li> <li> <p>The Commit Logic loop is therefore provided after all the adjustment processing has occurred.</p> <ul> <li>So, if you want to verify that Orders have 1 or more OrderDetails by placing a constraint on <code>OrderDetailCount</code>, this would need to be a CommitConstraint.</li> </ul> </li> </ul> <p>Row Logic processing:</p> <p></p> <p> </p>"},{"location":"Architecture-Project-Operation/#admin-app-execution-uiadminadminyaml","title":"Admin App Execution: <code>ui/admin/admin.yaml</code>","text":"<p>http://localhost:5656/ redirects to <code>ui/admin/index.html</code> which loads the react-admin single-page app into your browser.</p> <p>It then loads your <code>ui/admin/admin.yaml</code>, and responds to the various clicks by invoking the API (and hence the update logic), or the swagger at http://localhost:5656/api.</p>"},{"location":"Architecture-Security-Auth/","title":"Authentication","text":""},{"location":"Architecture-Security-Auth/#authentication-flow","title":"Authentication Flow","text":"<p>The overall flow is shown below, where:</p> <ul> <li>Green - represents developer responsibilities</li> <li>Blue - System processing</li> </ul> <p> </p> <p></p>"},{"location":"Architecture-What-Is-GenAI/","title":"What is GenAI-Logic","text":"<p> TL;DR - WebGenAI is a web app that uses ChatGPT and API Logic Server</p> <p>WebGenAI:</p> <p>Uses ChatGPT for Data Model (Data Base), Natural Language Logic - translation to rules, and Test Data.</p> <p>It includes storage for downloadable projects and SQLite databases.</p> <p>It uses API Logic Server to create and run projects from the Data Model (Data Base).</p>"},{"location":"Architecture-What-Is-GenAI/#what-is-genai-logic","title":"What is GenAI Logic","text":""},{"location":"Architecture-What-Is-GenAI/#runtime-stack","title":"Runtime Stack","text":""},{"location":"Architecture-What-Is-GenAI/#how-does-it-work","title":"How Does It Work","text":""},{"location":"Architecture-What-Is/","title":"What is API Logic Server","text":"<p> TL;DR - modern 3-tiered architecture, API-accessed, scalable containers</p> <p>Deployment Architecture</p> <ul> <li>A modern 3-tiered architecture, accessed by APIs</li> <li>Logic is automatically reused, factored out of web apps and custom services</li> <li>Containerized for scalable cloud deployment - the project includes a dockerfile to containerize it to DockerHub.</li> </ul> <p>Development Architecture</p> <ul> <li>Installed as Docker, <code>pip</code>, or use Codespaces</li> <li>Standards-based customization - debug in a standard IDE (VSCode, PyCharm), using standard packages (Flask, SQLAlchemy)</li> </ul>"},{"location":"Architecture-What-Is/#runtimes-and-cli","title":"Runtimes and CLI","text":"<p>API Logic Server is a Python Application, consisting of:</p> <ol> <li>Runtimes for ApiLogicProject execution (see below)</li> <li>CLI (Command Language Interface - provides <code>ApiLogicServer create</code>\u2026`)</li> </ol> <p>It executes either as a locally install (venv), or a Docker image (which includes Python).  In either case, the contents are the same:</p> <p></p> <p> </p>"},{"location":"Architecture-What-Is/#key-runtime-components","title":"Key Runtime Components","text":"<p>The following </p> Component Provides Flask enables you to write custom web apps, and custom api end points SQLAlchemy Python-friendly ORM (analogous to Hiberate, JPA) Logic Bank Listens for SQLAlchemy updates, provides Multi-Table Derivations and Constraint RulesPython Events (e.g., send mail, message)Customizable with Python SAFRS JSON:API and swagger, based on SQLAlchemy SAFRS-RA Admin App, using SAFRS"},{"location":"Architecture-What-Is/#model-execution-engines","title":"Model Execution Engines","text":"<p>When you create a project (<code>als create</code> or <code>als genai</code>), the system creates models shown below.  These model files are \"executed\" by the corresponding Model Execution Engines, as noted.</p> <p></p> <p>This model driven approach has substantial advantages, as described below.</p> <p> </p>"},{"location":"Architecture-What-Is/#maintainable","title":"Maintainable","text":"<p>In traditional framework-based implementations, the amount of code required is massive.  The last thing you want to take a high level of abstraction turned into low level code you need to understand and maintain.</p> <p>By contrast, the models above are concise and clear.  They are declarative: they state what is to be done, not how:</p> <ul> <li> <p>the rules are 40X more concise than code</p> </li> <li> <p>for APIs, just the line <code>api.expose_object(database.models.Category</code> represents multiple verbs -- and the swagger</p> </li> <li> <p>for apps, you just list the attributes; JavaScript and HTML would be massive (and unitelligable to most).</p> </li> </ul> <p>By way of analogy, you would not want a compiler to generate machine code, and then have to maintain the machine code.</p> <p> </p>"},{"location":"Architecture-What-Is/#platform-independent","title":"Platform Independent","text":"<p>Given rapid technology advancement, it is strategic advantage to preserve IT investment over such change.  This enables organizations to take advantage of new languages, new architectures, etc.  That has simply impossible in the past - existing procedural systems are necessarilty technology-dependent.</p> <p>By contrast, the models are architecture-independant.  For example, the rule <code>Derive the Customer.Balance as sum(Orders where Date_shipped is None)</code> is architecture neutral.  So, it can be translated into different languages and architectures.</p> <p>This is not a thoeretical proposition.  In fact, past implementations of this techology have proved the migration:</p> <ul> <li> <p>from minicomputers, to Visual Basic, to J2EE</p> </li> <li> <p>from JavaScript to Python</p> </li> </ul> <p>As shown below, your investment is preserved with a Model Migrator, and a Logic Engine.  The Logic Engine provides the ordering, optimizations and data access (possibly using an ORM) for logic execution.</p> <p></p> <p> </p>"},{"location":"Architecture-What-Is/#execution-3-tiered-architecture","title":"Execution: 3-tiered architecture","text":"<p>The API Logic Server executes as an application server, accessed by an API, in a standard 3-tiered architecture.  </p> <p>Observe that logic plugs into SQLAlchemy.  Logic is thus automatically shared (factored out) of custom services, and web or browser-based apps.</p> <p>In most cases, the API Logic Server executes in a container, so scales horizontally like any other Flask-based server.</p> <p></p> <p> </p>"},{"location":"Architecture-What-Is/#standard-containers","title":"Standard Containers","text":"<p>Scripts are created to create standard containers, for deployment to the cloud or your local site.</p> <p></p>"},{"location":"Architecture-admin-app-reuse/","title":"Admin App Architecture","text":"<p> TL;DR: Admin App Runtime stored in <code>venv</code></p> <p>The Admin App is implemented by SRA (Safrs React Admin), a separate / stand-alone project in GitHub.  Yet, the user experience makes API Logic Server and SRA feel like a single, integrated system.</p> <p>That is because we have followed key Microservice principles, bundling all the elements to deliver value in a single service.  For API Logic Server/SRA, this means:</p> <ol> <li> <p>Using Shared Data / API Models to drive automation</p> </li> <li> <p>A single integrated server to simplify deployment and administration</p> </li> <li> <p>A single shared source code repository for models and code</p> </li> <li> <p>System resources extracted from the shared repository</p> </li> </ol> <p>API Logic Server supports extended builders, which enables you to introduce additional client technologies.  We encourage this, and suggest these principles merit strong consideration.</p> <p> </p>"},{"location":"Architecture-admin-app-reuse/#1-model-driven-automation","title":"1. Model Driven Automation","text":"<p>To maintain simplicity through a high level of abstraction, we seek to maximize automation based on declarative models.  This applies to:</p> <ul> <li> <p>shared use of the underlying data model</p> </li> <li> <p>expressing application behavior by a yaml file, instead of complex html, JavaScript and CSS</p> </li> </ul> <p> </p>"},{"location":"Architecture-admin-app-reuse/#2-single-integrated-server","title":"2. Single Integrated Server","text":"<p>Deployment and application adminstration are simplified if there is 1 server to deploy and administer, serving both APIs and Apps... a microservice.</p> <p>This is provided by <code>admin_loader.py</code>, which: </p> <ul> <li>finds (see <code>get_sra_directory()</code>) the minified Admin App,</li> <li>returns (see <code>return_spa()</code>) the minified Admin App, and</li> <li>returns the <code>admin.yaml</code> file</li> </ul> <p> </p>"},{"location":"Architecture-admin-app-reuse/#3-integrated-source-control","title":"3. Integrated Source Control","text":"<p>Apps are dependent on the models and APIs, so administration is simplified if these are in the same git repository.</p> <p> </p>"},{"location":"Architecture-admin-app-reuse/#4-sra-runtime-extraced-from-project","title":"4. SRA runtime extraced from project","text":"<p>To save project space, the admin app source (JavaScript, CSS etc) is not stored in each created app.  This would \"pollute\" the git repository.  Instead, it is stored in the <code>venv</code>.</p> <p>Further, so that admin app changes do not cause unnecessary changes to ApiLogicServer git, these files are not stored in the GitHub project.</p> <p>Recall that the Admin App is defined by a yaml file.  The actual app is a minified React Admin JavaScript app, safrs-react-admin.</p> <p>It's about 34MB.  Not huge, but 10X bigger than most API Logic Projects.  So, we want to share it, making it available in the run-venv.</p> <p>Moreover, we don't want it to take up space in the ApiLogicServer git repository.</p> <p>So, when you create the dev project, the installer places a copy into your source tree, but denotes it as <code>.gitignore</code>.</p> <p>It looks like this in the dev source:</p> <p></p> <p>It looks like this in the run-venv (though, your project may be using a shared venv):</p> <p></p> <p> </p>"},{"location":"Architecture-genai-app/","title":"App Gen: genai-app","text":"<p> TL;DR: Admin App Runtime stored in <code>venv</code></p> <p>The generated Admin App is created using Natural Language, and creates full source code to faciliate unrestricted customization, e.g., through vibe.</p> <p>Creation is driven by:</p> <ul> <li>learning files and templates as described below,</li> <li>the schema, e.g. <code>ui/admin/admin.yaml</code></li> </ul> <p>This approach enables users to tune/extend the generation process.</p> <p> </p>"},{"location":"Architecture-genai-app/#1-learning-and-templates","title":"1. Learning and Templates","text":"<p>These files are cloned into the Manager when it is created:</p> <p></p> <p> </p>"},{"location":"Architecture-genai-app/#2-implementation","title":"2. Implementation","text":"<p>The CLI invokes the code shown below:</p> <p></p>"},{"location":"Architecture-python/","title":"Python (internals)","text":"<p>Upgrading to major versions of Python (e.g., 3.12) can be non-trivial; here's a good article.  I recently upgraded API Logic Server, and offer this information in hopes it can make things a bit easier for you.</p> <p>Aside: API Logic Server is open source.  It creates executable API / Admin App projects from a database with 1 command; customize with rules and Python in your IDE.</p> <p>There were 2 areas that required attention:</p> <ol> <li>Packaging: preparing a project for <code>pip install</code> access.  This issue was unique to Python 3.12 -- the old setup procedures have been removed</li> <li>Dependent Libraries: this is a consideration for any new release.  In general, I found this page helpful</li> </ol> <p>My project is database oriented (using SQLAlchemy), so key risk areas usually involve database access.  MySQL and Oracle are generally straight-forward, but I always need to address Postgres (psycopg) and Sql/Server (pyodbc).  These affect <code>requirements.txt</code>, and product packaging.  </p> <p>Let's consider packaging first.</p> <p> </p>"},{"location":"Architecture-python/#project-packaging","title":"Project Packaging","text":"<p>My project requires packaging for PyPi.  This has changed in Python 3.12.</p> <p>Some quick background.  To make a package available for <code>pip install</code>, you must upload it to PyPi -- here's an uploaded example.  This is 2 step process</p> <ol> <li>Build local install files: this gathers your dependent libraries, CLI entry points, and so forth</li> <li>Upload to PyPi: this is unchanged -- <code>python3 -m twine upload  --skip-existing dist/*</code></li> </ol> <p>The first step has changed in two ways - how you run the setup process, and how you specify your dependent libraries.</p> <p> </p>"},{"location":"Architecture-python/#run-setup-dependencies-etc","title":"Run setup (dependencies etc)","text":"<p>This process prepares for <code>python3 -m twine upload...</code>, by creating local files that identify the libraries you require, CLI entry points, and so forth.</p> <p>In the past, you ran <code>python3 setup.py sdist bdist_wheel</code>; that's no longer supported.  It's replaced by:</p> <pre><code>python3 -m build\n</code></pre> <p>You may first need: <pre><code>python -m pip install build\n</code></pre></p> <p> </p>"},{"location":"Architecture-python/#pyprojecttoml-not-setuppy","title":"<code>pyproject.toml</code> (not <code>setup.py</code>)","text":"<p>In the past, your <code>setup.py</code> file identified the libraries you require, CLI entry points, and so forth.  <code>setup.py</code> is no longer supported in Python 3.12.  </p> <p>Instead, you must provide a <code>pyproject.toml</code> file, as described in this guide.  The <code>python3 -m build</code> uses this file.</p> <p>For me, this set off a mild panic - I was unable to find a setup-to-toml migration utility, except for those looking to replace the entire <code>pip install</code> workflow.</p> <p>As it turned out, migrating <code>setup.py</code> was not so painful by hand -- mainly a series of copy/paste procedures as shown below.  Here's a working <code>pyproject.toml</code> shown in the diagram below.</p> <p></p> <p> </p>"},{"location":"Architecture-python/#psycopg2-binary-postgres","title":"<code>psycopg2-binary</code> - Postgres","text":"<p>This is used by SQLAlchemy for Postgres access.  In addition to <code>pyproject.toml</code>, I had to change <code>requirements.txt</code>, as shown here.  I changed <code>psycopg2-binary==2.9.5</code> to:</p> <pre><code>psycopg2-binary==2.9.9\n</code></pre> <p>My project is large, so I found it convenient to create a small <code>venv</code>, and test the install.  It took a few tries to straighten out the -binary bit.</p> <p> </p>"},{"location":"Architecture-python/#odbc-sqlserver","title":"odbc - SQL/Server","text":"<p>Microsoft SQL/Server requires 3 packages (this on a mac):</p> <p> </p>"},{"location":"Architecture-python/#unixodbc","title":"unixodbc","text":"<p>Install unixobdbc; you might get:</p> <pre><code>==&gt; Running `brew cleanup unixodbc`...\nDisable this behaviour by setting HOMEBREW_NO_INSTALL_CLEANUP.\nHide these hints with HOMEBREW_NO_ENV_HINTS (see `man brew`).\nRemoving: /opt/homebrew/Cellar/unixodbc/2.3.11... (48 files, 2.3MB)\nWarning: The following dependents of upgraded formulae are outdated but will not\nbe upgraded because they are not bottled:\n  msodbcsql18\n(venv) val@Vals-MPB-14 Desktop % \n</code></pre> <p>but, it seemed to work.</p> <p> </p>"},{"location":"Architecture-python/#odbc-driver","title":"odbc driver","text":"<p>I required the Microsoft odbc driver</p> <p> </p>"},{"location":"Architecture-python/#pyodbc","title":"pyodbc","text":"<p>This is used by SQLAlchemy.  In <code>requirements.txt</code> and <code>pyproject.toml</code>, I had to change pyodbc==4.0.34 --&gt; pyodbc==5.0.0</p> <p> </p>"},{"location":"Architecture-python/#minor-issues-escape-characters","title":"Minor Issues - escape characters","text":"<p>As noted in Python docs, mistakes in strings (e.g, <code>\\but I forgot the n</code>) were previously not flagged; now they are.</p> <p>I mention this because unexpected messages show up when you start your program under the debugger.</p>"},{"location":"Architecture-venv-defaulting/","title":"VENV (defaulting)","text":""},{"location":"Architecture-venv-defaulting/#vs-code-python-virtual-environment-activation-workarounds","title":"VS Code Python Virtual Environment Activation Workarounds","text":""},{"location":"Architecture-venv-defaulting/#problem-summary","title":"Problem Summary","text":"<p>Issue: VS Code Python extension (version 1.102.0) fails to automatically activate virtual environments in both terminal and application execution contexts, despite correct configuration settings.</p> <p>Impact:  - New users cannot run generated projects without manual venv activation - Breaks the \"computed default virtual environments\" feature that solves the \"default venv for new users\" problem - Affects both terminal activation and Python application execution - Represents a critical regression in VS Code Python extension functionality</p>"},{"location":"Architecture-venv-defaulting/#root-cause","title":"Root Cause","text":"<p>The VS Code Python extension has a regression where standard settings like <code>python.defaultInterpreterPath</code> and <code>python.terminal.activateEnvironment</code> are not reliably working. This is documented in GitHub issue #22879.</p>"},{"location":"Architecture-venv-defaulting/#vs-code-background","title":"VS Code Background","text":""},{"location":"Architecture-venv-defaulting/#how-vs-code-handles-virtual-environments","title":"How VS Code Handles Virtual Environments","text":"<p>Project Opening: - VS Code reads <code>.vscode/settings.json</code> and applies workspace settings - Python extension detects interpreter path and configures IntelliSense - <code>.env</code> file is loaded for environment variables - Terminal profiles are configured but not executed - No scripts run automatically - the project is ready but no terminal activation occurs</p> <p>Terminal Creation: - When you open a new terminal (Terminal \u2192 New Terminal), VS Code uses the default terminal profile - Our custom \"venv\" profile executes: <code>source .vscode/venv_init.sh &amp;&amp; exec zsh --no-rcs</code> - The <code>venv_init.sh</code> script runs, activates the virtual environment, and sets the prompt - A new shell starts with the virtual environment already activated</p> <p>Key Point: Virtual environment activation is \"lazy loaded\" - it only happens when you actually create a terminal, not when the project opens.</p>"},{"location":"Architecture-venv-defaulting/#comprehensive-solution","title":"Comprehensive Solution","text":""},{"location":"Architecture-venv-defaulting/#1-enhanced-vs-code-settings-template","title":"1. Enhanced VS Code Settings Template","text":"<p>File: <code>api_logic_server_cli/prototypes/base/.vscode/settings.json</code></p> <p>Key Changes: <pre><code>{\n    \"python.defaultInterpreterPath\": \"ApiLogicServerPython\",\n    \"python.terminal.activateEnvironment\": true,\n    \"python.terminal.activateEnvInCurrentTerminal\": true,\n    \"python.envFile\": \"${workspaceFolder}/.env\",\n    \"python.analysis.autoImportCompletions\": true,\n    \"python.analysis.extraPaths\": [\"ApiLogicServerVenvSitePackages\"],\n\n    // Custom terminal profiles for reliable venv activation\n    \"terminal.integrated.profiles.osx\": {\n        \"venv\": {\n            \"path\": \"/bin/zsh\",\n            \"args\": [\"-c\", \"source ${workspaceFolder}/.vscode/venv_init.sh &amp;&amp; exec zsh --no-rcs\"]\n        }\n    },\n    \"terminal.integrated.profiles.linux\": {\n        \"venv\": {\n            \"path\": \"/bin/bash\",\n            \"args\": [\"-c\", \"source ${workspaceFolder}/.vscode/venv_init.sh &amp;&amp; exec bash --noprofile --norc\"]\n        }\n    },\n    \"terminal.integrated.defaultProfile.osx\": \"venv\",\n    \"terminal.integrated.defaultProfile.linux\": \"venv\"\n}\n</code></pre></p>"},{"location":"Architecture-venv-defaulting/#2-generated-project-files","title":"2. Generated Project Files","text":"<p>The project generator now creates additional files to ensure reliable virtual environment activation:</p>"},{"location":"Architecture-venv-defaulting/#env-file","title":"<code>.env</code> File","text":"<p>Purpose: Explicit Python path configuration for VS Code Python extension Content:  <pre><code>PYTHONPATH=&lt;computed_python_path&gt;\n</code></pre></p>"},{"location":"Architecture-venv-defaulting/#vscodevenv_initsh-script","title":"<code>.vscode/venv_init.sh</code> Script","text":"<p>Purpose: Reliable terminal virtual environment activation with optional debugging Content: <pre><code>#!/bin/bash\n# Virtual Environment Initialization Script\n# This script activates the virtual environment for terminal use\n\n# Set DEBUG_VENV_INIT=1 to enable debug output\nDEBUG_VENV_INIT=0\n\nif [ \"$DEBUG_VENV_INIT\" = \"1\" ]; then\n    echo \"=== VENV INIT DEBUG ===\"\n    echo \"Shell: $0\"\n    echo \"ZSH_VERSION: $ZSH_VERSION\"\n    echo \"BASH_VERSION: $BASH_VERSION\"\n    echo \"Current PS1: $PS1\"\n    echo \"VIRTUAL_ENV before: $VIRTUAL_ENV\"\nfi\n\n# Source the virtual environment activation script\nif [ -f \"&lt;venv_path&gt;/bin/activate\" ]; then\n    if [ \"$DEBUG_VENV_INIT\" = \"1\" ]; then\n        echo \"Found activation script: &lt;venv_path&gt;/bin/activate\"\n    fi\n    source &lt;venv_path&gt;/bin/activate\n    echo \"Virtual environment activated: &lt;venv_name&gt;\"\n\n    if [ \"$DEBUG_VENV_INIT\" = \"1\" ]; then\n        echo \"VIRTUAL_ENV after activation: $VIRTUAL_ENV\"\n    fi\n\n    # Don't let virtualenv override the prompt\n    export VIRTUAL_ENV_DISABLE_PROMPT=1\n    if [ \"$DEBUG_VENV_INIT\" = \"1\" ]; then\n        echo \"Set VIRTUAL_ENV_DISABLE_PROMPT=1\"\n    fi\n\n    # Override the prompt to ensure (venv) shows\n    if [ -n \"${ZSH_VERSION}\" ]; then\n        if [ \"$DEBUG_VENV_INIT\" = \"1\" ]; then\n            echo \"Setting zsh prompt\"\n        fi\n        export PS1=\"(venv) %n@%m %1~ %# \"\n    elif [ -n \"${BASH_VERSION}\" ]; then\n        if [ \"$DEBUG_VENV_INIT\" = \"1\" ]; then\n            echo \"Setting bash prompt\"\n        fi\n        export PS1=\"(venv) \\\\u@\\\\h \\\\W \\\\$ \"\n    else\n        if [ \"$DEBUG_VENV_INIT\" = \"1\" ]; then\n            echo \"Unknown shell - trying generic prompt\"\n        fi\n        export PS1=\"(venv) $ \"\n    fi\n\n    if [ \"$DEBUG_VENV_INIT\" = \"1\" ]; then\n        echo \"Final PS1: $PS1\"\n        echo \"Final VIRTUAL_ENV: $VIRTUAL_ENV\"\n    fi\n\nelse\n    echo \"Warning: Virtual environment activation script not found at &lt;venv_path&gt;/bin/activate\"\nfi\n\nif [ \"$DEBUG_VENV_INIT\" = \"1\" ]; then\n    echo \"=== END DEBUG ===\"\nfi\n</code></pre></p>"},{"location":"Architecture-venv-defaulting/#3-template-placeholder-system","title":"3. Template Placeholder System","text":"<p>Placeholders in settings.json: - <code>ApiLogicServerPython</code> \u2192 Replaced with actual Python interpreter path - <code>ApiLogicServerVenvSitePackages</code> \u2192 Replaced with venv site-packages path</p> <p>Generation Code Integration: - Enhanced <code>api_logic_server.py</code> to create <code>.env</code> files - Added logic to generate <code>venv_init.sh</code> scripts - Implemented robust path computation and replacement</p>"},{"location":"Architecture-venv-defaulting/#technical-implementation-details","title":"Technical Implementation Details","text":""},{"location":"Architecture-venv-defaulting/#path-computation-logic","title":"Path Computation Logic","text":"<pre><code># Compute virtual environment paths\nvenv_python_path = os.path.join(venv_directory, 'bin', 'python')\nvenv_site_packages = os.path.join(venv_directory, 'lib', f'python{python_version}', 'site-packages')\n\n# Generate .env file\nenv_content = f\"PYTHONPATH={venv_site_packages}\\n\"\nwith open(os.path.join(project_directory, '.env'), 'w') as f:\n    f.write(env_content)\n\n# Generate venv_init.sh\ninit_script = f\"\"\"#!/bin/bash\nif [ -f \"{venv_python_path}\" ]; then\n    source {os.path.join(venv_directory, 'bin', 'activate')}\n    export PYTHONPATH=\"{venv_site_packages}\"\n    echo \"Virtual environment activated\"\nelse\n    echo \"Warning: Virtual environment not found\"\nfi\n\"\"\"\nwith open(os.path.join(project_directory, '.vscode', 'venv_init.sh'), 'w') as f:\n    f.write(init_script)\n</code></pre>"},{"location":"Architecture-venv-defaulting/#cross-platform-compatibility","title":"Cross-Platform Compatibility","text":"<ul> <li>macOS: Uses <code>zsh</code> with custom terminal profile</li> <li>Linux: Uses <code>bash</code> with custom terminal profile  </li> <li>Windows: Inherits default behavior (not affected by the regression)</li> </ul>"},{"location":"Architecture-venv-defaulting/#testing-and-validation","title":"Testing and Validation","text":""},{"location":"Architecture-venv-defaulting/#validation-steps","title":"Validation Steps","text":"<ol> <li>Terminal Activation: Open new terminal \u2192 Should show <code>(venv)</code> prefix</li> <li>Python Execution: Run Python files \u2192 Should use venv interpreter</li> <li>Package Access: Import project packages \u2192 Should work without PYTHONPATH issues</li> <li>Debug Configuration: VS Code debugging \u2192 Should use correct interpreter</li> </ol>"},{"location":"Architecture-venv-defaulting/#known-limitations","title":"Known Limitations","text":"<ul> <li>Requires VS Code restart after project generation for full effect</li> <li>Custom terminal profiles may need user acknowledgment on first use</li> <li>Some VS Code Python extension features may still be unreliable</li> <li>Terminal starts without loading user's shell configuration files (zsh/bash rc files)</li> </ul>"},{"location":"Architecture-venv-defaulting/#troubleshooting","title":"Troubleshooting","text":"<p>If virtual environment activation is not working:</p> <ol> <li>Enable Debug Mode: Edit <code>.vscode/venv_init.sh</code> and change <code>DEBUG_VENV_INIT=0</code> to <code>DEBUG_VENV_INIT=1</code></li> <li>Open New Terminal: The debug output will show exactly what's happening</li> <li>Check Debug Output: Look for:    - Whether the activation script is found    - Which shell is being detected    - Whether the virtual environment variables are set correctly    - Whether the prompt is being set properly</li> </ol> <p>Common issues and solutions: - Script not found: Check that the virtual environment path is correct - Wrong shell detected: The script should detect zsh on macOS - Prompt not showing: Ensure <code>--no-rcs</code> is working and not loading conflicting configurations</p>"},{"location":"Architecture-venv-defaulting/#future-considerations","title":"Future Considerations","text":""},{"location":"Architecture-venv-defaulting/#issue-tracking","title":"Issue Tracking","text":"<ul> <li>Reported to Microsoft: vscode-python #22879</li> <li>Monitoring for official fix from VS Code Python extension team</li> <li>Workarounds can be removed once regression is resolved</li> </ul>"},{"location":"Architecture-venv-defaulting/#maintenance-strategy","title":"Maintenance Strategy","text":"<ol> <li>Short-term: Maintain comprehensive workarounds</li> <li>Medium-term: Monitor VS Code Python extension updates</li> <li>Long-term: Simplify back to standard settings when regression is fixed</li> </ol>"},{"location":"Architecture-venv-defaulting/#user-experience-impact","title":"User Experience Impact","text":""},{"location":"Architecture-venv-defaulting/#before-workarounds","title":"Before Workarounds","text":"<ul> <li>Users had to manually activate virtual environments</li> <li>Python execution used system interpreter</li> <li>Import errors and dependency issues</li> <li>Poor new user experience</li> </ul>"},{"location":"Architecture-venv-defaulting/#after-workarounds","title":"After Workarounds","text":"<ul> <li>Automatic virtual environment activation</li> <li>Correct Python interpreter usage</li> <li>Seamless package imports</li> <li>Improved new user onboarding</li> </ul>"},{"location":"Architecture-venv-defaulting/#documentation-updates","title":"Documentation Updates","text":""},{"location":"Architecture-venv-defaulting/#readme-updates","title":"README Updates","text":"<p>Add section explaining: - Virtual environment is automatically configured - No manual activation required - Troubleshooting steps if issues occur</p>"},{"location":"Architecture-venv-defaulting/#developer-documentation","title":"Developer Documentation","text":"<ul> <li>Document the template system enhancements</li> <li>Explain placeholder replacement mechanism</li> <li>Provide debugging guide for environment issues</li> </ul>"},{"location":"Architecture-venv-defaulting/#conclusion","title":"Conclusion","text":"<p>These workarounds provide a robust solution to the VS Code Python extension regression while maintaining the goal of \"computed default virtual environments for new users.\" The implementation is comprehensive enough to handle the current issues while being designed for easy removal once the upstream regression is resolved.</p> <p>The solution ensures that generated projects work out-of-the-box for new users, which is critical for the ApiLogicServer user experience and adoption.</p>"},{"location":"Architecture-venv/","title":"VENV (internals)","text":"<p> TL;DR: 2 venvs: Run-venv, Dev-venv (no CLI)</p> <p>For internal API Logic Server Developers, there are 2 distinct <code>venv</code> environents:</p> <ol> <li> <p>Run-venv: contains key libs (Flask, SQLAlchemy, SAFRS), and the CLI</p> <ul> <li>This is used for created projects</li> </ul> </li> <li> <p>Dev-venv: key libs only (no CLI)</p> <ul> <li>This is used to develop API Logic Server (the internals)</li> </ul> </li> </ol> <p> </p>"},{"location":"Architecture-venv/#run-venv","title":"Run <code>venv</code>","text":"<p>This is used by created projects.  It supports:</p> <ul> <li>Execution</li> <li>CLI operations such as adding authentication, rebuild etc.</li> </ul> <p>As such, this <code>venv</code> includes the entire API Logic Server package - source here:</p> <pre><code># this includes the key libraries (Flask, SQLAlchemy, SAFRS), and the API Logic Server CLI\n\nApiLogicServer\n</code></pre> <p>The sections below describe the general components, and why CLI elements are included in the Run <code>venv</code></p> <p> </p>"},{"location":"Architecture-venv/#key-libs","title":"Key Libs","text":"<p>As you'd expect, this <code>venv</code> includes the key runtime libs, such as Flask, SQLAlchemy, Safrs, LogicBank, etc.</p> <p> </p>"},{"location":"Architecture-venv/#cli-services","title":"CLI Services","text":"<p>The CLI provides commands such as <code>add-auth</code> and <code>rebuild</code>.  These are required for existing projects.</p> <p> </p>"},{"location":"Architecture-venv/#admin-app-runtime","title":"Admin App Runtime","text":"<p>In addition, this <code>venv</code> contains the Admin App Runtime.  Note it's not in the GitHub project; it's placed in your source tree by the dev install procedure as a <code>gitignore</code> directory.</p> <p>For more information, see Admin App Reuse.</p> <p>If the dev inst fails to include this (e.g., improper dev-install, or dev-install failures), the Admin App will fail to run.</p> <p> </p>"},{"location":"Architecture-venv/#changes-july-2025","title":"Changes July 2025","text":""},{"location":"Architecture-venv/#dev-venv","title":"Dev <code>venv</code>","text":"<p>The dev <code>dev venv</code> includes all the key libs, *but not the CLI.  </p> <p>Note it's also defined in the <code>setup.py</code>.</p> <p>Note this does not include the CLI.  That is because the dev environment is focused on changing the CLI, so it's important not to confuse you/Python about whether you are running code from the <code>venv</code>, or from the source tree.  We want the latter, so we omit this from the <code>venv</code>.</p> <p>There are 2 reasonable strategies for testing CLI changes:</p> <ol> <li>Use the Manager: use a launch-config to run the cli, and alter the api_logic_server code in the <code>vwnv</code></li> <li> <p>Use the dev env, and</p> <ul> <li>create <code>.vscpde/launch.json</code> entries that set <code>cwd</code> to the target project (see: Basic Demo - add-app), and</li> <li>ensure that manager files can be found (openAI learning) with <code>\"env\": {\"APILOGICSERVER_DEBUG\": \"True\", \"APILOGICSERVER_HOME\": \"${workspaceFolder}\"}</code></li> </ul> </li> </ol>"},{"location":"Article-Dcl-GenAI-1/","title":"Article Dcl GenAI 1","text":""},{"location":"Article-Dcl-GenAI-1/#the-missing-half-of-genai-and-why-microsofts-ceo-says-its-the-future","title":"The Missing Half of GenAI \u2014 and Why Microsoft\u2019s CEO Says It\u2019s the Future","text":""},{"location":"Article-Dcl-GenAI-1/#introducing-declarative-genai-a-3-part-series","title":"Introducing Declarative GenAI - A 3-Part Series","text":"<p>Love Your GenAI Tools? You\u2019re Missing the Half That Matters Most.</p> <p>GenAI vibe tools like Cursor, v0, and Bolt are incredible at creating beautiful UIs. But here\u2019s what Microsoft CEO Satya Nadella recently predicted: the future business app is just a \u201cthin UI over a bunch of business logic,\u201d managed by agents.</p> <p>Current GenAI tools are excellent at the thin UI. But they don\u2019t yet address the business logic layer \u2014 the part Nadella says matters most.</p> <p>That\u2019s where Declarative GenAI comes in \u2014 the missing half that completes the future.</p>"},{"location":"Article-Dcl-GenAI-1/#the-gap-in-todays-genai","title":"The Gap in Today\u2019s GenAI","text":"<p>We love the GenAI vibe tools too, but they\u2019re only part way to the future Nadella described:</p> <ul> <li>Baseline (pre-AI): 100 units of effort  </li> <li>Current GenAI (thin UI only): 56 units of effort  </li> <li>Declarative GenAI (UI + Business Logic): 20 units of effort  </li> </ul> <p>We\u2019re leaving major productivity gains on the table \u2014 and missing the entire business logic layer that delivers the value.</p> <p>[INSERT Bar Chart: 100 \u2192 56 \u2192 20]</p> <p>AI-only vibe tools stop at the UI \u2014 Declarative GenAI adds the business logic, reducing total effort by 80%.</p>"},{"location":"Article-Dcl-GenAI-1/#where-current-tools-hit-the-wall","title":"Where Current Tools Hit the Wall","text":"<p>I tested our standard enterprise prompt \u2013 shown above \u2013 across the popular GenAI vibe tools. The results were clear:</p> <ul> <li>Subtle corner-case bugs, buried in hundreds of lines of unmaintainable FrankenCode </li> <li>Often dumped on the client side  </li> <li>This fails to adhere to service-oriented architecture (SOA) principles that seek to share logic for reuse and automated invocation  </li> </ul> <p>This isn\u2019t the fast path to enterprise-ready business logic \u2014 it\u2019s instant tech debt that creates a maintenance burden.</p> <p>[INSERT Prompt Screenshot]</p>"},{"location":"Article-Dcl-GenAI-1/#the-missing-half-business-logic-agents","title":"The Missing Half: Business Logic Agents","text":"<p>The future Nadella described requires declarative business logic that is:</p> <ul> <li>Natural Language \u2013 business users and developers provide logic requirements in natural language  </li> <li>Governable \u2013 no AI hallucinations; implements your requirements exactly  </li> <li>Maintainable \u2013 self-documenting code that looks like the requirements, easy to maintain  </li> <li>Enterprise-ready \u2013 proper architecture, not logic embedded in client-side hacks  </li> </ul>"},{"location":"Article-Dcl-GenAI-1/#the-missing-half-declarative-genai","title":"The Missing Half: Declarative GenAI","text":"<p>When used with GenAI-Logic, the same prompt shown above produces exactly what Nadella described:</p> <ul> <li>Real generated code \u2013 extend in your IDE  </li> <li>What you get: complete database, admin UI, REST API, and integrations \u2014 all implementing your business logic exactly as specified  </li> <li>Time: 1 minute for a complete, future-ready system  </li> </ul> <p>The critical difference is the use of Declarative GenAI for the business logic half of the system:</p> <ul> <li>Declarative GenAI: 5 rules, clean, transparent, and enterprise-ready </li> <li>Procedural GenAI: 200+ lines of brittle FrankenCode </li> </ul> <p>[INSERT FrankenCode vs. Declarative Rules Graphic]</p> <p>There\u2019s no hallucination, because Declarative GenAI is translating your logic, not making up its own. The resultant Domain Specific Language (DSL) code is executed at runtime by the Declarative Rules Engine, operating as an ORM listener. This runtime (non-RETE) engine is a sophisticated piece of software, providing automatic invocation, dependency-based ordering, and optimization.</p>"},{"location":"Article-Dcl-GenAI-1/#declarative-genai-complete-your-favorite-tools","title":"Declarative GenAI: Complete Your Favorite Tools","text":"<p>This isn\u2019t about replacing the GenAI tools you love for UI development. It\u2019s about completing them with the missing half:</p> <ul> <li>Keep using Cursor/v0/Bolt for the \u201cthin UI\u201d layer  </li> <li>Add Declarative GenAI for enterprise-ready business logic </li> <li>Deploy systems that actually work in enterprise environments  </li> </ul> <p>The result? 80% less total effort and applications ready for the future Nadella described.</p>"},{"location":"Article-Dcl-GenAI-1/#coming-up-in-this-series","title":"Coming Up in This Series","text":"<ul> <li>Part 2: Business User / IT Collaboration \u2013 how business users can create enterprise logic themselves, iterate to get the requirements right, then hand off working systems to IT  </li> <li>Part 3: Living with Logic \u2013 logic management and debugging using your existing IDE, and deployment via standard containers  </li> </ul>"},{"location":"Article-Dcl-GenAI-1/#complete-your-genai-stack-today","title":"Complete Your GenAI Stack Today","text":"<p>Microsoft\u2019s CEO showed us where development is heading. Current GenAI tools give you half of it.</p> <p>\ud83d\udc49 Try our free WebGenAI tool \u2014 see what complete Declarative GenAI looks like. Build future-ready systems in 1 minute, then download the working code to your IDE.</p> <p>What\u2019s your biggest challenge implementing business logic with current GenAI tools? I\u2019d love to hear your story in the comments.</p>"},{"location":"Article-Dcl-GenAI-1/#declarativegenai-genai-enterprise-businesslogic-satyanadella-ai-series-vibe","title":"DeclarativeGenAI #GenAI #Enterprise #BusinessLogic #SatyaNadella #AI #Series #Vibe","text":""},{"location":"Behave-Creation/","title":"Create Tests From Logic","text":"<p> TL;DR - Executable Test Suite, Documentation</p> <p>New in 15.01.18 - Transform 30-40 years of testing requests into 3-4 days of automated test generation!</p> <p>You can use your AI Assistant to automatically:   * Create Behave tests from declarative rules   * Execute test suites, and    * Generate automated documentation with complete logic traceability</p> <p>The tests focus on dependencies discovered from logic, and use the API to run transactions and test for expected results.</p> <p>Important: </p> <ol> <li>tests update your database</li> <li>tests can be re-run</li> <li>current status: technology preview</li> </ol> <p> </p>"},{"location":"Behave-Creation/#overview-behave-bdd-testing-framework","title":"Overview: Behave BDD Testing Framework","text":"<p>Behave is a framework for defining and executing tests based on TDD (Test Driven Development), an Agile approach for defining system requirements as executable tests.</p> <p>The Key Innovation: Behave tests in API Logic Server create living documentation that connects:</p> <ol> <li>Business Requirements (Features)</li> <li>Test Scenarios (Given/When/Then)</li> <li>Test Implementation (Python code)</li> <li>Declarative Rules (the actual business logic)</li> <li>Execution Trace (Logic Log showing which rules fired)</li> </ol>"},{"location":"Behave-Creation/#explore-with-basic_demo","title":"Explore with basic_demo","text":"<p>\u23f1\ufe0f Estimated time: 15-20 minutes to complete walkthrough</p> <p>Use basic_demo to explore:</p> <ol> <li>Open the Manager</li> <li>Create basic_demo: <code>genai-logic create --project_name=basic_demo --db_url=sqlite:///samples/dbs/basic_demo.sqlite</code></li> <li>Add logic</li> </ol> <ul> <li>Open the project, and establish your virtual environment</li> <li>Add rules: <code>gail add-cust</code></li> <li>Add APIs:  <code>gail add-cust</code></li> <li>Update the data model (as recommended from prior command): <code>genai-logic rebuild-from-database --db_url=sqlite:///database/db.sqlite</code></li> </ul> <ol> <li>Use your AI Assistant: <code>Create Logic</code></li> </ol> <p>See the example here.</p>"},{"location":"Behave-Creation/#prerequisites-and-configuration","title":"Prerequisites and Configuration","text":""},{"location":"Behave-Creation/#critical-security-configuration","title":"Critical: Security Configuration","text":"<p>Tests must match the project's security settings defined in <code>config/default.env</code>:</p> <pre><code># In config/default.env\nSECURITY_ENABLED = false  # or True\n</code></pre> <p>The test framework automatically adapts:</p> <ul> <li><code>test_utils.login()</code> returns empty headers <code>{}</code> when <code>SECURITY_ENABLED = false</code></li> <li><code>test_utils.login()</code> authenticates and returns token headers when <code>SECURITY_ENABLED = True</code></li> </ul> <p>Common Bug: Tests fail with <code>405 Method Not Allowed</code> on <code>/auth/login</code></p> <ul> <li>Cause: Server running without security, but tests expect security enabled (or vice versa)</li> <li>Solution: Check <code>config/default.env</code> - ensure <code>SECURITY_ENABLED</code> matches how server was started</li> <li>Test Location: Behave runs from <code>test/api_logic_server_behave/</code> and logs found in <code>logs/behave.log</code></li> </ul>"},{"location":"Behave-Creation/#test-data-requirements","title":"Test Data Requirements","text":"<p>Tests require specific database state:</p> <ol> <li>Document test data in <code>TEST_SUITE_OVERVIEW.md</code> or feature file comments</li> <li>Restore data after test runs (tests should be idempotent)</li> <li>Seed database with known customer IDs, product IDs, order IDs before first run</li> </ol> <p>Example: If testing Customer balance rules, document: <pre><code>Test Data Used:\n\n- Customer: CUST-1 (balance 0, credit_limit 1000)\n- Product: PROD-A (unit_price 5.00)\n- Order: ORD-1 (customer CUST-1, not shipped)\n</code></pre></p>"},{"location":"Behave-Creation/#running-the-server","title":"Running the Server","text":"<p>Before running tests, start the API Logic Server:</p> <p>Option 1: VS Code Launch Configuration</p> <ul> <li>Use \"ApiLogicServer\" launch config</li> <li>Respects <code>config/default.env</code> settings</li> </ul> <p>Option 2: Command Line <pre><code>python api_logic_server_run.py\n</code></pre></p> <p>Verify server is running: <pre><code>curl http://localhost:5656/api/Customer/\n</code></pre></p>"},{"location":"Behave-Creation/#executing-tests","title":"Executing Tests","text":""},{"location":"Behave-Creation/#run-test-suite","title":"Run Test Suite","text":"<p>Use Launch Configuration \"Behave Run\" (or \"Windows Behave Run\" on Windows):</p> <pre><code># Or from terminal:\ncd test/api_logic_server_behave\nbehave\n</code></pre> <p>Output:</p> <ul> <li><code>logs/behave.log</code> - Test execution summary</li> <li><code>logs/scenario_logic_logs/&lt;scenario&gt;.log</code> - Logic execution trace for each scenario</li> </ul> <p>Prerequisites: - Server must be running (use \"ApiLogicServer\" launch config or <code>python api_logic_server_run.py</code>)</p>"},{"location":"Behave-Creation/#run-single-scenario-debug","title":"Run Single Scenario (Debug)","text":"<p>Use Launch Configuration \"Behave Scenario\" - useful for:</p> <ul> <li>Debugging specific tests</li> <li>Setting breakpoints in test code</li> <li>Iterating on test development</li> </ul>"},{"location":"Behave-Creation/#generating-documentation","title":"Generating Documentation","text":""},{"location":"Behave-Creation/#create-behave-logic-report","title":"Create Behave Logic Report","text":"<p>Run Launch Configuration \"Behave Report\":</p> <pre><code># Or from terminal:\ncd test/api_logic_server_behave\npython behave_logic_report.py run\n</code></pre> <p>Output: - <code>reports/Behave Logic Report.md</code> - Complete wiki documentation</p> <p>What Gets Generated:</p> <ol> <li>Test Results - All scenarios with pass/fail status</li> <li>Logic Documentation - Docstrings from <code>@when</code> steps</li> <li>Rules Used - Which declarative rules fired during each scenario</li> <li>Logic Log - Detailed execution trace showing rule chaining</li> </ol>"},{"location":"Behave-Creation/#example-output","title":"Example Output","text":"<pre><code>### Scenario: Good Order Custom Service\n  Given Customer Account: ALFKI\n  When Good Order Placed\n  Then Logic adjusts Balance (demo: chain up)\n\n&lt;details&gt;\n**Logic Doc** for scenario: Good Order Custom Service\n  Place an order with multiple items.\n  This tests the complete dependency chain:\n  - OrderDetail.UnitPrice copied from Product.UnitPrice\n  - OrderDetail.Amount = Quantity * UnitPrice\n  ...\n\n**Rules Used** in Scenario:\n  Rule.copy(OrderDetail.UnitPrice from Product.UnitPrice)\n  Rule.formula(OrderDetail.Amount = Quantity * UnitPrice)\n  Rule.sum(Order.AmountTotal from OrderDetail.Amount)\n  Rule.sum(Customer.Balance from Order.AmountTotal)\n\n**Logic Log** in Scenario:\n  Logic Phase: ROW LOGIC\n  ..OrderDetail[1040] {Insert - client}\n  ....OrderDetail.UnitPrice [None--&gt;18.0000000000] (copy from Product.UnitPrice)\n  ....OrderDetail.Amount [None--&gt;18.0000000000] (formula: Quantity * UnitPrice)\n  ......Order.AmountTotal [1086--&gt;1104] (sum OrderDetail.Amount)\n  ........Customer.Balance [2102--&gt;2120] (sum Order.AmountTotal)\n&lt;/details&gt;\n</code></pre>"},{"location":"Behave-Creation/#requirements-traceability","title":"Requirements Traceability","text":"<p>The Behave Logic Report provides complete traceability:</p> <pre><code>Business Requirement (Feature)\n  \u2193\nTest Scenario (Given/When/Then)\n  \u2193\nTest Implementation (Python code)\n  \u2193\nDeclarative Rules (5 lines)\n  \u2193\nExecution Trace (Logic Log)\n</code></pre> <p>This solves the traditional problem: - Before: Requirements \u2192 Code (opaque, 200+ lines) - Now: Requirements \u2192 Tests \u2192 Rules \u2192 Trace (transparent, 5 lines)</p> <p>The 44X advantage extends to testing: - Tests are simple API calls - Business logic verified by checking which rules fired - Complete audit trail from requirement to execution - Living documentation auto-generated from test runs</p>"},{"location":"Behave-Creation/#internals","title":"Internals","text":"<p>Training instruction for the AI Assistant (e.g., Copilot) is included in your project at <code>docs/training/testing.md</code>.  It is usually discovered by the Best Practice to load <code>.github/.copilot-instructions.md</code> when opening the project.</p>"},{"location":"Behave-Creation/#summary","title":"Summary","text":"<p>Creating tests from rules provides:</p> <ol> <li>Correctness verification - Ensures rules work as intended</li> <li>Dependency chain validation - Tests transitive effects (Product \u2192 Item \u2192 Order \u2192 Customer)</li> <li>Foreign key change testing - Verifies old/new parent adjustments (the \"missed bugs\")</li> <li>Automated documentation - Living documentation with complete traceability</li> <li>Regression prevention - Executable test suite protects against future breaks</li> </ol> <p>The key insight: Declarative rules make testing dramatically simpler because:</p> <ul> <li>Tests focus on \"what\" not \"how\"</li> <li>Rule execution is logged automatically</li> <li>Dependency chains are traced automatically</li> <li>Complete audit trail from requirement to execution</li> </ul>"},{"location":"Behave-Logic-Report-Basic-Demo/","title":"Sample: basic_demo","text":""},{"location":"Behave-Logic-Report-Basic-Demo/#basic-demo-sample","title":"Basic Demo Sample","text":"<p>This is a basic demonstration project created from a simple natural language prompt using API Logic Server's GenAI capabilities.</p>"},{"location":"Behave-Logic-Report-Basic-Demo/#data-model","title":"Data Model","text":""},{"location":"Behave-Logic-Report-Basic-Demo/#creation-prompt","title":"Creation Prompt","text":"<p>This project was created from the following natural language prompt:</p> <pre><code>Create a system with customers, orders, items and products.\n\nInclude a notes field for orders.\n\nUse case: Check Credit    \n    1. The Customer's balance is less than the credit limit\n    2. The Customer's balance is the sum of the Order amount_total where date_shipped is null\n    3. The Order's amount_total is the sum of the Item amount\n    4. The Item amount is the quantity * unit_price\n    5. The Item unit_price is copied from the Product unit_price\n\nUse case: App Integration\n    1. Send the Order to Kafka topic 'order_shipping' if the date_shipped is not None.\n</code></pre> <p>The sample Scenarios below were chosen to illustrate the basic patterns of using rules. Open the disclosure box (\"Tests - and their logic...\") to see the implementation and notes.</p> <p>The following report was created during test suite execution.</p> <p> </p>"},{"location":"Behave-Logic-Report-Basic-Demo/#behave-logic-report","title":"Behave Logic Report","text":""},{"location":"Behave-Logic-Report-Basic-Demo/#feature-about-sample","title":"Feature: About Sample","text":""},{"location":"Behave-Logic-Report-Basic-Demo/#scenario-transaction-processing","title":"Scenario: Transaction Processing","text":"<p>\u2003  Scenario: Transaction Processing \u2003\u2003    Given Sample Database \u2003\u2003    When Transactions are submitted \u2003\u2003    Then Enforce business policies with Logic (rules + code)  </p> Tests - and their logic - are transparent.. click to see Logic <p> </p> <p>Rules Used in Scenario: Transaction Processing  Logic Log in Scenario: Transaction Processing <pre><code>Logic Phase:        ROW LOGIC       (session=0x1098628b0) (sqlalchemy before_flush)          - 2025-10-26 17:10:57,158 - logic_logger - INF\n..Customer[None] {Insert - client} id: None, name: Alice 1761523857156, balance: 0, credit_limit: 1000, email: None, email_opt_out: None  row: 0x10991f6d0  session: 0x1098628b0  ins_upd_dlt: ins, initial: ins - 2025-10-26 17:10:57,158 - logic_logger - INF\n..Customer[None] {server aggregate_defaults: balance } id: None, name: Alice 1761523857156, balance: 0, credit_limit: 1000, email: None, email_opt_out: None  row: 0x10991f6d0  session: 0x1098628b0  ins_upd_dlt: ins, initial: ins - 2025-10-26 17:10:57,158 - logic_logger - INF\nLogic Phase:        COMMIT LOGIC        (session=0x1098628b0)                                            - 2025-10-26 17:10:57,158 - logic_logger - INF\nLogic Phase:        AFTER_FLUSH LOGIC   (session=0x1098628b0)                                            - 2025-10-26 17:10:57,158 - logic_logger - INF\n</code></pre></p> <p> </p>"},{"location":"Behave-Logic-Report-Basic-Demo/#feature-order-processing-with-business-logic","title":"Feature: Order Processing with Business Logic","text":""},{"location":"Behave-Logic-Report-Basic-Demo/#scenario-good-order-created-via-b2b-api","title":"Scenario: Good Order Created via B2B API","text":"<p>\u2003  Scenario: Good Order Created via B2B API \u2003\u2003    Given Customer \"Alice\" with balance 0 and credit limit 1000 \u2003\u2003    When B2B order placed for \"Alice\" with 5 Widget \u2003\u2003    Then Customer balance should be 450     And Order amount_total should be 450     And Each item amount calculated correctly  </p> Tests - and their logic - are transparent.. click to see Logic <p> </p> <p>Rules Used in Scenario: Good Order Created via B2B API <pre><code>  Customer  \n    1. Derive &lt;class 'database.models.Customer'&gt;.balance as Sum(Order.amount_total Where Rule.sum(derive=Customer.balance, as_sum_of=Order.amount_total, where=lambda row: row.date_shipped is None) - &lt;function declare_logic.&lt;locals&gt;.&lt;lambda&gt; at 0x10883d260&gt;)  \n  Item  \n    2. Derive &lt;class 'database.models.Item'&gt;.unit_price as Copy(product.unit_price)  \n    3. Derive &lt;class 'database.models.Item'&gt;.amount as Formula (1): &lt;function&gt;  \n  Order  \n    4. Derive &lt;class 'database.models.Order'&gt;.amount_total as Sum(Item.amount Where  - None)  \n    5. RowEvent Order.send_order_to_shipping()   \n</code></pre> Logic Log in Scenario: Good Order Created via B2B API <pre><code>Logic Phase:        ROW LOGIC       (session=0x109863f00) (sqlalchemy before_flush)          - 2025-10-26 17:10:57,165 - logic_logger - INF\n..Product[2] {Update - client} id: 2, name: Widget, unit_price: 90.0000000000, carbon_neutral: None  row: 0x109a510f0  session: 0x109863f00  ins_upd_dlt: upd, initial: upd - 2025-10-26 17:10:57,165 - logic_logger - INF\n..Item[None] {Insert - client} id: None, order_id: None, product_id: None, quantity: 5, amount: None, unit_price: None  row: 0x109a4d3d0  session: 0x109863f00  ins_upd_dlt: ins, initial: ins - 2025-10-26 17:10:57,165 - logic_logger - INF\n..Item[None] {copy_rules for role: product - unit_price} id: None, order_id: None, product_id: None, quantity: 5, amount: None, unit_price: 90.0000000000  row: 0x109a4d3d0  session: 0x109863f00  ins_upd_dlt: ins, initial: ins - 2025-10-26 17:10:57,165 - logic_logger - INF\n..Item[None] {Formula amount} id: None, order_id: None, product_id: None, quantity: 5, amount: 450.0000000000, unit_price: 90.0000000000  row: 0x109a4d3d0  session: 0x109863f00  ins_upd_dlt: ins, initial: ins - 2025-10-26 17:10:57,165 - logic_logger - INF\n....Order[None] {server aggregate_defaults: amount_total } id: None, notes: Test order 1761523857162, customer_id: 50, CreatedOn: None, date_shipped: None, amount_total:  [None--&gt;] 0  row: 0x109a33f50  session: 0x109863f00  ins_upd_dlt: *, initial: * - 2025-10-26 17:10:57,165 - logic_logger - INF\n..Item[None] {TODO DB adjust_from_inserted/adopted_child adjusts Derive &lt;class 'database.models.Order'&gt;.amount_total as Sum(Item.amount Where  - None)} id: None, order_id: None, product_id: None, quantity: 5, amount: 450.0000000000, unit_price: 90.0000000000  row: 0x109a4d3d0  session: 0x109863f00  ins_upd_dlt: ins, initial: ins - 2025-10-26 17:10:57,165 - logic_logger - INF\n....Order[None] {Adjustment logic chaining deferred for this parent parent do_defer_adjustment: True, is_parent_submitted: True, is_parent_row_processed: False, order} id: None, notes: Test order 1761523857162, customer_id: 50, CreatedOn: None, date_shipped: None, amount_total:  [None--&gt;] 450.0000000000  row: 0x109a33f50  session: 0x109863f00  ins_upd_dlt: *, initial: * - 2025-10-26 17:10:57,165 - logic_logger - INF\n..Order[None] {Insert - client} id: None, notes: Test order 1761523857162, customer_id: 50, CreatedOn: None, date_shipped: None, amount_total: 450.0000000000  row: 0x109a33f50  session: 0x109863f00  ins_upd_dlt: ins, initial: ins - 2025-10-26 17:10:57,165 - logic_logger - INF\n..Order[None] {early_row_event_all_classes - handle_all did stamping} id: None, notes: Test order 1761523857162, customer_id: 50, CreatedOn: 2025-10-26 17:10:57.165840, date_shipped: None, amount_total: 450.0000000000  row: 0x109a33f50  session: 0x109863f00  ins_upd_dlt: ins, initial: ins - 2025-10-26 17:10:57,165 - logic_logger - INF\n..Order[None] {TODO DB adjust_from_inserted/adopted_child adjusts Derive &lt;class 'database.models.Customer'&gt;.balance as Sum(Order.amount_total Where Rule.sum(derive=Customer.balance, as_sum_of=Order.amount_total, where=lambda row: row.date_shipped is None) - &lt;function declare_logic.&lt;locals&gt;.&lt;lambda&gt; at 0x10883d260&gt;)} id: None, notes: Test order 1761523857162, customer_id: 50, CreatedOn: 2025-10-26 17:10:57.165840, date_shipped: None, amount_total: 450.0000000000  row: 0x109a33f50  session: 0x109863f00  ins_upd_dlt: ins, initial: ins - 2025-10-26 17:10:57,166 - logic_logger - INF\n....Customer[50] {Update - Adjusting customer: balance} id: 50, name: Alice 1761523857156, balance:  [0E-10--&gt;] 450.0000000000, credit_limit: 1000.0000000000, email: None, email_opt_out: None  row: 0x109a4db50  session: 0x109863f00  ins_upd_dlt: upd, initial: upd - 2025-10-26 17:10:57,166 - logic_logger - INF\nLogic Phase:        COMMIT LOGIC        (session=0x109863f00)                                            - 2025-10-26 17:10:57,166 - logic_logger - INF\nLogic Phase:        AFTER_FLUSH LOGIC   (session=0x109863f00)                                            - 2025-10-26 17:10:57,167 - logic_logger - INF\n..Order[47] {AfterFlush Event} id: 47, notes: Test order 1761523857162, customer_id: 50, CreatedOn: 2025-10-26 17:10:57.165840, date_shipped: None, amount_total: 450.0000000000  row: 0x109a33f50  session: 0x109863f00  ins_upd_dlt: ins, initial: ins - 2025-10-26 17:10:57,167 - logic_logger - INF\n..Order[47] {Sending Order to Shipping [Note: **Kafka not enabled** ]} id: 47, notes: Test order 1761523857162, customer_id: 50, CreatedOn: 2025-10-26 17:10:57.165840, date_shipped: None, amount_total: 450.0000000000  row: 0x109a33f50  session: 0x109863f00  ins_upd_dlt: ins, initial: ins - 2025-10-26 17:10:57,167 - logic_logger - INF\n</code></pre></p> <p> </p>"},{"location":"Behave-Logic-Report-Basic-Demo/#scenario-carbon-neutral-discount-applied","title":"Scenario: Carbon Neutral Discount Applied","text":"<p>\u2003  Scenario: Carbon Neutral Discount Applied \u2003\u2003    Given Customer \"Bob\" with balance 0 and credit limit 2000 \u2003\u2003    When B2B order placed for \"Bob\" with 10 carbon neutral Gadget \u2003\u2003    Then Customer balance should be 900     And Item amount reflects 10% discount  </p> Tests - and their logic - are transparent.. click to see Logic <p> </p> <p>Rules Used in Scenario: Carbon Neutral Discount Applied <pre><code>  Customer  \n    1. Derive &lt;class 'database.models.Customer'&gt;.balance as Sum(Order.amount_total Where Rule.sum(derive=Customer.balance, as_sum_of=Order.amount_total, where=lambda row: row.date_shipped is None) - &lt;function declare_logic.&lt;locals&gt;.&lt;lambda&gt; at 0x10883d260&gt;)  \n  Item  \n    2. Derive &lt;class 'database.models.Item'&gt;.unit_price as Copy(product.unit_price)  \n    3. Derive &lt;class 'database.models.Item'&gt;.amount as Formula (1): &lt;function&gt;  \n  Order  \n    4. Derive &lt;class 'database.models.Order'&gt;.amount_total as Sum(Item.amount Where  - None)  \n    5. RowEvent Order.send_order_to_shipping()   \n</code></pre> Logic Log in Scenario: Carbon Neutral Discount Applied <pre><code>Logic Phase:        ROW LOGIC       (session=0x109863570) (sqlalchemy before_flush)          - 2025-10-26 17:10:57,186 - logic_logger - INF\n..Product[1] {Update - client} id: 1, name: Gadget, unit_price: 100.0000000000, carbon_neutral: True  row: 0x1099600c0  session: 0x109863570  ins_upd_dlt: upd, initial: upd - 2025-10-26 17:10:57,186 - logic_logger - INF\n..Item[None] {Insert - client} id: None, order_id: None, product_id: None, quantity: 10, amount: None, unit_price: None  row: 0x10991f3d0  session: 0x109863570  ins_upd_dlt: ins, initial: ins - 2025-10-26 17:10:57,186 - logic_logger - INF\n..Item[None] {copy_rules for role: product - unit_price} id: None, order_id: None, product_id: None, quantity: 10, amount: None, unit_price: 100.0000000000  row: 0x10991f3d0  session: 0x109863570  ins_upd_dlt: ins, initial: ins - 2025-10-26 17:10:57,187 - logic_logger - INF\n..Item[None] {Formula amount} id: None, order_id: None, product_id: None, quantity: 10, amount: 900.0000000000000222044604925, unit_price: 100.0000000000  row: 0x10991f3d0  session: 0x109863570  ins_upd_dlt: ins, initial: ins - 2025-10-26 17:10:57,187 - logic_logger - INF\n....Order[None] {server aggregate_defaults: amount_total } id: None, notes: Carbon neutral test 1761523857184, customer_id: 51, CreatedOn: None, date_shipped: None, amount_total:  [None--&gt;] 0  row: 0x10984f9d0  session: 0x109863570  ins_upd_dlt: *, initial: * - 2025-10-26 17:10:57,187 - logic_logger - INF\n..Item[None] {TODO DB adjust_from_inserted/adopted_child adjusts Derive &lt;class 'database.models.Order'&gt;.amount_total as Sum(Item.amount Where  - None)} id: None, order_id: None, product_id: None, quantity: 10, amount: 900.0000000000000222044604925, unit_price: 100.0000000000  row: 0x10991f3d0  session: 0x109863570  ins_upd_dlt: ins, initial: ins - 2025-10-26 17:10:57,187 - logic_logger - INF\n....Order[None] {Adjustment logic chaining deferred for this parent parent do_defer_adjustment: True, is_parent_submitted: True, is_parent_row_processed: False, order} id: None, notes: Carbon neutral test 1761523857184, customer_id: 51, CreatedOn: None, date_shipped: None, amount_total:  [None--&gt;] 900.0000000000000222044604925  row: 0x10984f9d0  session: 0x109863570  ins_upd_dlt: *, initial: * - 2025-10-26 17:10:57,187 - logic_logger - INF\n..Order[None] {Insert - client} id: None, notes: Carbon neutral test 1761523857184, customer_id: 51, CreatedOn: None, date_shipped: None, amount_total: 900.0000000000000222044604925  row: 0x10984f9d0  session: 0x109863570  ins_upd_dlt: ins, initial: ins - 2025-10-26 17:10:57,187 - logic_logger - INF\n..Order[None] {early_row_event_all_classes - handle_all did stamping} id: None, notes: Carbon neutral test 1761523857184, customer_id: 51, CreatedOn: 2025-10-26 17:10:57.187415, date_shipped: None, amount_total: 900.0000000000000222044604925  row: 0x10984f9d0  session: 0x109863570  ins_upd_dlt: ins, initial: ins - 2025-10-26 17:10:57,187 - logic_logger - INF\n..Order[None] {TODO DB adjust_from_inserted/adopted_child adjusts Derive &lt;class 'database.models.Customer'&gt;.balance as Sum(Order.amount_total Where Rule.sum(derive=Customer.balance, as_sum_of=Order.amount_total, where=lambda row: row.date_shipped is None) - &lt;function declare_logic.&lt;locals&gt;.&lt;lambda&gt; at 0x10883d260&gt;)} id: None, notes: Carbon neutral test 1761523857184, customer_id: 51, CreatedOn: 2025-10-26 17:10:57.187415, date_shipped: None, amount_total: 900.0000000000000222044604925  row: 0x10984f9d0  session: 0x109863570  ins_upd_dlt: ins, initial: ins - 2025-10-26 17:10:57,187 - logic_logger - INF\n....Customer[51] {Update - Adjusting customer: balance} id: 51, name: Bob 1761523857179, balance:  [0E-10--&gt;] 900.0000000000000222044604925, credit_limit: 2000.0000000000, email: None, email_opt_out: None  row: 0x10991eed0  session: 0x109863570  ins_upd_dlt: upd, initial: upd - 2025-10-26 17:10:57,187 - logic_logger - INF\nLogic Phase:        COMMIT LOGIC        (session=0x109863570)                                            - 2025-10-26 17:10:57,187 - logic_logger - INF\nLogic Phase:        AFTER_FLUSH LOGIC   (session=0x109863570)                                            - 2025-10-26 17:10:57,188 - logic_logger - INF\n..Order[48] {AfterFlush Event} id: 48, notes: Carbon neutral test 1761523857184, customer_id: 51, CreatedOn: 2025-10-26 17:10:57.187415, date_shipped: None, amount_total: 900.0000000000000222044604925  row: 0x10984f9d0  session: 0x109863570  ins_upd_dlt: ins, initial: ins - 2025-10-26 17:10:57,188 - logic_logger - INF\n..Order[48] {Sending Order to Shipping [Note: **Kafka not enabled** ]} id: 48, notes: Carbon neutral test 1761523857184, customer_id: 51, CreatedOn: 2025-10-26 17:10:57.187415, date_shipped: None, amount_total: 900.0000000000000222044604925  row: 0x10984f9d0  session: 0x109863570  ins_upd_dlt: ins, initial: ins - 2025-10-26 17:10:57,188 - logic_logger - INF\n</code></pre></p> <p> </p>"},{"location":"Behave-Logic-Report-Basic-Demo/#scenario-multi-item-order-totals-correctly","title":"Scenario: Multi-Item Order Totals Correctly","text":"<p>\u2003  Scenario: Multi-Item Order Totals Correctly \u2003\u2003    Given Customer \"Diana\" with balance 0 and credit limit 3000 \u2003\u2003    When B2B order placed for \"Diana\" with 3 Widget and 2 Gadget \u2003\u2003    Then Customer balance should be 470     And Order contains 2 items  </p> Tests - and their logic - are transparent.. click to see Logic <p> </p> <p>Rules Used in Scenario: Multi-Item Order Totals Correctly <pre><code>  Customer  \n    1. Derive &lt;class 'database.models.Customer'&gt;.balance as Sum(Order.amount_total Where Rule.sum(derive=Customer.balance, as_sum_of=Order.amount_total, where=lambda row: row.date_shipped is None) - &lt;function declare_logic.&lt;locals&gt;.&lt;lambda&gt; at 0x10883d260&gt;)  \n  Item  \n    2. Derive &lt;class 'database.models.Item'&gt;.unit_price as Copy(product.unit_price)  \n    3. Derive &lt;class 'database.models.Item'&gt;.amount as Formula (1): &lt;function&gt;  \n  Order  \n    4. Derive &lt;class 'database.models.Order'&gt;.amount_total as Sum(Item.amount Where  - None)  \n    5. RowEvent Order.send_order_to_shipping()   \n</code></pre> Logic Log in Scenario: Multi-Item Order Totals Correctly <pre><code>Logic Phase:        ROW LOGIC       (session=0x109863bd0) (sqlalchemy before_flush)          - 2025-10-26 17:10:57,204 - logic_logger - INF\n..Product[1] {Update - client} id: 1, name: Gadget, unit_price: 100.0000000000, carbon_neutral: True  row: 0x1098b25f0  session: 0x109863bd0  ins_upd_dlt: upd, initial: upd - 2025-10-26 17:10:57,204 - logic_logger - INF\n..Item[None] {Insert - client} id: None, order_id: None, product_id: 2, quantity: 3, amount: None, unit_price: None  row: 0x10991f650  session: 0x109863bd0  ins_upd_dlt: ins, initial: ins - 2025-10-26 17:10:57,204 - logic_logger - INF\n..Item[None] {copy_rules for role: product - unit_price} id: None, order_id: None, product_id: 2, quantity: 3, amount: None, unit_price: 90.0000000000  row: 0x10991f650  session: 0x109863bd0  ins_upd_dlt: ins, initial: ins - 2025-10-26 17:10:57,204 - logic_logger - INF\n..Item[None] {Formula amount} id: None, order_id: None, product_id: 2, quantity: 3, amount: 270.0000000000, unit_price: 90.0000000000  row: 0x10991f650  session: 0x109863bd0  ins_upd_dlt: ins, initial: ins - 2025-10-26 17:10:57,204 - logic_logger - INF\n....Order[None] {server aggregate_defaults: amount_total } id: None, notes: Multi-item test 1761523857201, customer_id: 52, CreatedOn: None, date_shipped: None, amount_total:  [None--&gt;] 0  row: 0x1098b69d0  session: 0x109863bd0  ins_upd_dlt: *, initial: * - 2025-10-26 17:10:57,204 - logic_logger - INF\n..Item[None] {TODO DB adjust_from_inserted/adopted_child adjusts Derive &lt;class 'database.models.Order'&gt;.amount_total as Sum(Item.amount Where  - None)} id: None, order_id: None, product_id: 2, quantity: 3, amount: 270.0000000000, unit_price: 90.0000000000  row: 0x10991f650  session: 0x109863bd0  ins_upd_dlt: ins, initial: ins - 2025-10-26 17:10:57,204 - logic_logger - INF\n....Order[None] {Adjustment logic chaining deferred for this parent parent do_defer_adjustment: True, is_parent_submitted: True, is_parent_row_processed: False, order} id: None, notes: Multi-item test 1761523857201, customer_id: 52, CreatedOn: None, date_shipped: None, amount_total:  [None--&gt;] 270.0000000000  row: 0x1098b69d0  session: 0x109863bd0  ins_upd_dlt: *, initial: * - 2025-10-26 17:10:57,204 - logic_logger - INF\n..Item[None] {Insert - client} id: None, order_id: None, product_id: None, quantity: 2, amount: None, unit_price: None  row: 0x10991fe50  session: 0x109863bd0  ins_upd_dlt: ins, initial: ins - 2025-10-26 17:10:57,204 - logic_logger - INF\n..Item[None] {copy_rules for role: product - unit_price} id: None, order_id: None, product_id: None, quantity: 2, amount: None, unit_price: 100.0000000000  row: 0x10991fe50  session: 0x109863bd0  ins_upd_dlt: ins, initial: ins - 2025-10-26 17:10:57,205 - logic_logger - INF\n..Item[None] {Formula amount} id: None, order_id: None, product_id: None, quantity: 2, amount: 200.0000000000, unit_price: 100.0000000000  row: 0x10991fe50  session: 0x109863bd0  ins_upd_dlt: ins, initial: ins - 2025-10-26 17:10:57,205 - logic_logger - INF\n..Item[None] {TODO DB adjust_from_inserted/adopted_child adjusts Derive &lt;class 'database.models.Order'&gt;.amount_total as Sum(Item.amount Where  - None)} id: None, order_id: None, product_id: None, quantity: 2, amount: 200.0000000000, unit_price: 100.0000000000  row: 0x10991fe50  session: 0x109863bd0  ins_upd_dlt: ins, initial: ins - 2025-10-26 17:10:57,205 - logic_logger - INF\n....Order[None] {Adjustment logic chaining deferred for this parent parent do_defer_adjustment: True, is_parent_submitted: True, is_parent_row_processed: False, order} id: None, notes: Multi-item test 1761523857201, customer_id: 52, CreatedOn: None, date_shipped: None, amount_total:  [270.0000000000--&gt;] 470.0000000000  row: 0x1098b69d0  session: 0x109863bd0  ins_upd_dlt: *, initial: * - 2025-10-26 17:10:57,205 - logic_logger - INF\n..Order[None] {Insert - client} id: None, notes: Multi-item test 1761523857201, customer_id: 52, CreatedOn: None, date_shipped: None, amount_total: 470.0000000000  row: 0x1098b69d0  session: 0x109863bd0  ins_upd_dlt: ins, initial: ins - 2025-10-26 17:10:57,205 - logic_logger - INF\n..Order[None] {early_row_event_all_classes - handle_all did stamping} id: None, notes: Multi-item test 1761523857201, customer_id: 52, CreatedOn: 2025-10-26 17:10:57.205310, date_shipped: None, amount_total: 470.0000000000  row: 0x1098b69d0  session: 0x109863bd0  ins_upd_dlt: ins, initial: ins - 2025-10-26 17:10:57,205 - logic_logger - INF\n..Order[None] {TODO DB adjust_from_inserted/adopted_child adjusts Derive &lt;class 'database.models.Customer'&gt;.balance as Sum(Order.amount_total Where Rule.sum(derive=Customer.balance, as_sum_of=Order.amount_total, where=lambda row: row.date_shipped is None) - &lt;function declare_logic.&lt;locals&gt;.&lt;lambda&gt; at 0x10883d260&gt;)} id: None, notes: Multi-item test 1761523857201, customer_id: 52, CreatedOn: 2025-10-26 17:10:57.205310, date_shipped: None, amount_total: 470.0000000000  row: 0x1098b69d0  session: 0x109863bd0  ins_upd_dlt: ins, initial: ins - 2025-10-26 17:10:57,205 - logic_logger - INF\n....Customer[52] {Update - Adjusting customer: balance} id: 52, name: Diana 1761523857196, balance:  [0E-10--&gt;] 470.0000000000, credit_limit: 3000.0000000000, email: None, email_opt_out: None  row: 0x10991e3d0  session: 0x109863bd0  ins_upd_dlt: upd, initial: upd - 2025-10-26 17:10:57,205 - logic_logger - INF\nLogic Phase:        COMMIT LOGIC        (session=0x109863bd0)                                            - 2025-10-26 17:10:57,205 - logic_logger - INF\nLogic Phase:        AFTER_FLUSH LOGIC   (session=0x109863bd0)                                            - 2025-10-26 17:10:57,206 - logic_logger - INF\n..Order[49] {AfterFlush Event} id: 49, notes: Multi-item test 1761523857201, customer_id: 52, CreatedOn: 2025-10-26 17:10:57.205310, date_shipped: None, amount_total: 470.0000000000  row: 0x1098b69d0  session: 0x109863bd0  ins_upd_dlt: ins, initial: ins - 2025-10-26 17:10:57,206 - logic_logger - INF\n..Order[49] {Sending Order to Shipping [Note: **Kafka not enabled** ]} id: 49, notes: Multi-item test 1761523857201, customer_id: 52, CreatedOn: 2025-10-26 17:10:57.205310, date_shipped: None, amount_total: 470.0000000000  row: 0x1098b69d0  session: 0x109863bd0  ins_upd_dlt: ins, initial: ins - 2025-10-26 17:10:57,206 - logic_logger - INF\n</code></pre></p> <p> </p>"},{"location":"Behave-Logic-Report-Basic-Demo/#scenario-item-quantity-change-updates-totals","title":"Scenario: Item Quantity Change Updates Totals","text":"<p>\u2003  Scenario: Item Quantity Change Updates Totals \u2003\u2003    Given Customer \"Alice\" with balance 0 and credit limit 1000     And Order is created for \"Alice\" with 5 Widget \u2003\u2003    When Item quantity changed to 10 \u2003\u2003    Then Item amount should be 900     And Order amount_total should be 900     And Customer balance should be 900  </p> Tests - and their logic - are transparent.. click to see Logic <p> </p> <p>Rules Used in Scenario: Item Quantity Change Updates Totals <pre><code>  Customer  \n    1. Derive &lt;class 'database.models.Customer'&gt;.balance as Sum(Order.amount_total Where Rule.sum(derive=Customer.balance, as_sum_of=Order.amount_total, where=lambda row: row.date_shipped is None) - &lt;function declare_logic.&lt;locals&gt;.&lt;lambda&gt; at 0x10883d260&gt;)  \n  Item  \n    2. Derive &lt;class 'database.models.Item'&gt;.amount as Formula (1): &lt;function&gt;  \n  Order  \n    3. RowEvent Order.send_order_to_shipping()   \n    4. Derive &lt;class 'database.models.Order'&gt;.amount_total as Sum(Item.amount Where  - None)  \n</code></pre> Logic Log in Scenario: Item Quantity Change Updates Totals <pre><code>Logic Phase:        ROW LOGIC       (session=0x109861e10) (sqlalchemy before_flush)          - 2025-10-26 17:10:57,246 - logic_logger - INF\n..Item[60] {Update - client} id: 60, order_id: 50, product_id: 2, quantity:  [5--&gt;] 10, amount: 450.0000000000, unit_price: 90.0000000000  row: 0x10991cad0  session: 0x109861e10  ins_upd_dlt: upd, initial: upd - 2025-10-26 17:10:57,246 - logic_logger - INF\n..Item[60] {Formula amount} id: 60, order_id: 50, product_id: 2, quantity:  [5--&gt;] 10, amount:  [450.0000000000--&gt;] 900.0000000000, unit_price: 90.0000000000  row: 0x10991cad0  session: 0x109861e10  ins_upd_dlt: upd, initial: upd - 2025-10-26 17:10:57,246 - logic_logger - INF\n....Order[50] {Update - Adjusting order: amount_total} id: 50, notes: Test order 1761523857230, customer_id: 53, CreatedOn: 2025-10-26, date_shipped: None, amount_total:  [450.0000000000--&gt;] 900.0000000000  row: 0x10991f7d0  session: 0x109861e10  ins_upd_dlt: upd, initial: upd - 2025-10-26 17:10:57,247 - logic_logger - INF\n......Customer[53] {Update - Adjusting customer: balance} id: 53, name: Alice 1761523857220, balance:  [450.0000000000--&gt;] 900.0000000000, credit_limit: 1000.0000000000, email: None, email_opt_out: None  row: 0x109a4c150  session: 0x109861e10  ins_upd_dlt: upd, initial: upd - 2025-10-26 17:10:57,247 - logic_logger - INF\nLogic Phase:        COMMIT LOGIC        (session=0x109861e10)                                            - 2025-10-26 17:10:57,247 - logic_logger - INF\nLogic Phase:        AFTER_FLUSH LOGIC   (session=0x109861e10)                                            - 2025-10-26 17:10:57,248 - logic_logger - INF\n....Order[50] {AfterFlush Event} id: 50, notes: Test order 1761523857230, customer_id: 53, CreatedOn: 2025-10-26, date_shipped: None, amount_total:  [450.0000000000--&gt;] 900.0000000000  row: 0x10991f7d0  session: 0x109861e10  ins_upd_dlt: upd, initial: upd - 2025-10-26 17:10:57,248 - logic_logger - INF\n</code></pre></p> <p> </p>"},{"location":"Behave-Logic-Report-Basic-Demo/#scenario-changing-customer-adjusts-both-balances","title":"Scenario: Changing Customer Adjusts Both Balances","text":"<p>\u2003  Scenario: Changing Customer Adjusts Both Balances \u2003\u2003    Given Customer \"Alice\" with balance 0 and credit limit 1000     And Customer \"Bob\" with balance 0 and credit limit 2000     And Order is created for \"Alice\" with 3 Widget \u2003\u2003    When Order customer changed to \"Bob\" \u2003\u2003    Then Customer \"Alice\" balance should be 0     And Customer \"Bob\" balance should be 270  </p> Tests - and their logic - are transparent.. click to see Logic <p> </p> <p>Rules Used in Scenario: Changing Customer Adjusts Both Balances <pre><code>  Customer  \n    1. Derive &lt;class 'database.models.Customer'&gt;.balance as Sum(Order.amount_total Where Rule.sum(derive=Customer.balance, as_sum_of=Order.amount_total, where=lambda row: row.date_shipped is None) - &lt;function declare_logic.&lt;locals&gt;.&lt;lambda&gt; at 0x10883d260&gt;)  \n  Order  \n    2. RowEvent Order.send_order_to_shipping()   \n</code></pre> Logic Log in Scenario: Changing Customer Adjusts Both Balances <pre><code>Logic Phase:        ROW LOGIC       (session=0x109862f10) (sqlalchemy before_flush)          - 2025-10-26 17:10:57,278 - logic_logger - INF\n..Order[51] {Update - client} id: 51, notes: Test order 1761523857266, customer_id:  [54--&gt;] 55, CreatedOn: 2025-10-26, date_shipped: None, amount_total: 270.0000000000  row: 0x109a4c3d0  session: 0x109862f10  ins_upd_dlt: upd, initial: upd - 2025-10-26 17:10:57,278 - logic_logger - INF\n....Customer[55] {Update - Adjusting customer: balance, balance} id: 55, name: Bob 1761523857259, balance:  [0E-10--&gt;] 270.0000000000, credit_limit: 2000.0000000000, email: None, email_opt_out: None  row: 0x109a4c9d0  session: 0x109862f10  ins_upd_dlt: upd, initial: upd - 2025-10-26 17:10:57,279 - logic_logger - INF\n....Customer[54] {Update - Adjusting Old customer} id: 54, name: Alice 1761523857255, balance:  [270.0000000000--&gt;] 0E-10, credit_limit: 1000.0000000000, email: None, email_opt_out: None  row: 0x109a4cad0  session: 0x109862f10  ins_upd_dlt: upd, initial: upd - 2025-10-26 17:10:57,279 - logic_logger - INF\nLogic Phase:        COMMIT LOGIC        (session=0x109862f10)                                            - 2025-10-26 17:10:57,279 - logic_logger - INF\nLogic Phase:        AFTER_FLUSH LOGIC   (session=0x109862f10)                                            - 2025-10-26 17:10:57,280 - logic_logger - INF\n..Order[51] {AfterFlush Event} id: 51, notes: Test order 1761523857266, customer_id:  [54--&gt;] 55, CreatedOn: 2025-10-26, date_shipped: None, amount_total: 270.0000000000  row: 0x109a4c3d0  session: 0x109862f10  ins_upd_dlt: upd, initial: upd - 2025-10-26 17:10:57,280 - logic_logger - INF\n</code></pre></p> <p> </p>"},{"location":"Behave-Logic-Report-Basic-Demo/#scenario-delete-item-reduces-order-total","title":"Scenario: Delete Item Reduces Order Total","text":"<p>\u2003  Scenario: Delete Item Reduces Order Total \u2003\u2003    Given Customer \"Charlie\" with balance 0 and credit limit 2000     And Order is created for \"Charlie\" with 2 Widget and 3 Gadget \u2003\u2003    When First item is deleted \u2003\u2003    Then Order amount_total should be 300     And Customer balance should be 300  </p> Tests - and their logic - are transparent.. click to see Logic <p> </p> <p>Rules Used in Scenario: Delete Item Reduces Order Total <pre><code>  Customer  \n    1. Derive &lt;class 'database.models.Customer'&gt;.balance as Sum(Order.amount_total Where Rule.sum(derive=Customer.balance, as_sum_of=Order.amount_total, where=lambda row: row.date_shipped is None) - &lt;function declare_logic.&lt;locals&gt;.&lt;lambda&gt; at 0x10883d260&gt;)  \n  Order  \n    2. RowEvent Order.send_order_to_shipping()   \n    3. Derive &lt;class 'database.models.Order'&gt;.amount_total as Sum(Item.amount Where  - None)  \n</code></pre> Logic Log in Scenario: Delete Item Reduces Order Total <pre><code>Logic Phase:        ROW LOGIC       (session=0x109863570) (sqlalchemy before_flush)          - 2025-10-26 17:10:57,310 - logic_logger - INF\n..Item[62] {Delete - client} id: 62, order_id: 52, product_id: 2, quantity: 2, amount: 180.0000000000, unit_price: 90.0000000000  row: 0x10991fe50  session: 0x109863570  ins_upd_dlt: dlt, initial: dlt - 2025-10-26 17:10:57,310 - logic_logger - INF\n....Order[52] {Update - Adjusting order: amount_total} id: 52, notes: Test order 1761523857290, customer_id: 56, CreatedOn: 2025-10-26, date_shipped: None, amount_total:  [480.0000000000--&gt;] 300.0000000000  row: 0x10991f6d0  session: 0x109863570  ins_upd_dlt: upd, initial: upd - 2025-10-26 17:10:57,310 - logic_logger - INF\n......Customer[56] {Update - Adjusting customer: balance} id: 56, name: Charlie 1761523857285, balance:  [480.0000000000--&gt;] 300.0000000000, credit_limit: 2000.0000000000, email: None, email_opt_out: None  row: 0x109a4cb50  session: 0x109863570  ins_upd_dlt: upd, initial: upd - 2025-10-26 17:10:57,311 - logic_logger - INF\nLogic Phase:        COMMIT LOGIC        (session=0x109863570)                                            - 2025-10-26 17:10:57,311 - logic_logger - INF\nLogic Phase:        AFTER_FLUSH LOGIC   (session=0x109863570)                                            - 2025-10-26 17:10:57,311 - logic_logger - INF\n....Order[52] {AfterFlush Event} id: 52, notes: Test order 1761523857290, customer_id: 56, CreatedOn: 2025-10-26, date_shipped: None, amount_total:  [480.0000000000--&gt;] 300.0000000000  row: 0x10991f6d0  session: 0x109863570  ins_upd_dlt: upd, initial: upd - 2025-10-26 17:10:57,311 - logic_logger - INF\n</code></pre></p> <p> </p>"},{"location":"Behave-Logic-Report-Basic-Demo/#scenario-ship-order-excludes-from-balance","title":"Scenario: Ship Order Excludes from Balance","text":"<p>\u2003  Scenario: Ship Order Excludes from Balance \u2003\u2003    Given Customer \"Diana\" with balance 0 and credit limit 2000     And Order is created for \"Diana\" with 2 Widget \u2003\u2003    When Order is shipped \u2003\u2003    Then Customer balance should be 0  </p> Tests - and their logic - are transparent.. click to see Logic <p> </p> <p>Rules Used in Scenario: Ship Order Excludes from Balance <pre><code>  Customer  \n    1. Derive &lt;class 'database.models.Customer'&gt;.balance as Sum(Order.amount_total Where Rule.sum(derive=Customer.balance, as_sum_of=Order.amount_total, where=lambda row: row.date_shipped is None) - &lt;function declare_logic.&lt;locals&gt;.&lt;lambda&gt; at 0x10883d260&gt;)  \n  Order  \n    2. RowEvent Order.send_order_to_shipping()   \n</code></pre> Logic Log in Scenario: Ship Order Excludes from Balance <pre><code>Logic Phase:        ROW LOGIC       (session=0x109863ce0) (sqlalchemy before_flush)          - 2025-10-26 17:10:57,333 - logic_logger - INF\n..Order[53] {Update - client} id: 53, notes: Test order 1761523857322, customer_id: 57, CreatedOn: 2025-10-26, date_shipped:  [None--&gt;] 2025-10-26 00:00:00, amount_total: 180.0000000000  row: 0x109a4d250  session: 0x109863ce0  ins_upd_dlt: upd, initial: upd - 2025-10-26 17:10:57,333 - logic_logger - INF\n....Customer[57] {Update - Adjusting customer: balance} id: 57, name: Diana 1761523857316, balance:  [180.0000000000--&gt;] 0E-10, credit_limit: 2000.0000000000, email: None, email_opt_out: None  row: 0x109a4e150  session: 0x109863ce0  ins_upd_dlt: upd, initial: upd - 2025-10-26 17:10:57,334 - logic_logger - INF\nLogic Phase:        COMMIT LOGIC        (session=0x109863ce0)                                            - 2025-10-26 17:10:57,334 - logic_logger - INF\nLogic Phase:        AFTER_FLUSH LOGIC   (session=0x109863ce0)                                            - 2025-10-26 17:10:57,334 - logic_logger - INF\n..Order[53] {AfterFlush Event} id: 53, notes: Test order 1761523857322, customer_id: 57, CreatedOn: 2025-10-26, date_shipped:  [None--&gt;] 2025-10-26 00:00:00, amount_total: 180.0000000000  row: 0x109a4d250  session: 0x109863ce0  ins_upd_dlt: upd, initial: upd - 2025-10-26 17:10:57,334 - logic_logger - INF\n</code></pre></p> <p> </p>"},{"location":"Behave-Logic-Report-Basic-Demo/#scenario-unship-order-includes-in-balance","title":"Scenario: Unship Order Includes in Balance","text":"<p>\u2003  Scenario: Unship Order Includes in Balance \u2003\u2003    Given Customer \"Alice\" with balance 0 and credit limit 2000     And Shipped order is created for \"Alice\" with 4 Widget \u2003\u2003    When Order is unshipped \u2003\u2003    Then Customer balance should be 360  </p> Tests - and their logic - are transparent.. click to see Logic <p> </p> <p>Rules Used in Scenario: Unship Order Includes in Balance <pre><code>  Customer  \n    1. Derive &lt;class 'database.models.Customer'&gt;.balance as Sum(Order.amount_total Where Rule.sum(derive=Customer.balance, as_sum_of=Order.amount_total, where=lambda row: row.date_shipped is None) - &lt;function declare_logic.&lt;locals&gt;.&lt;lambda&gt; at 0x10883d260&gt;)  \n  Order  \n    2. RowEvent Order.send_order_to_shipping()   \n</code></pre> Logic Log in Scenario: Unship Order Includes in Balance <pre><code>Logic Phase:        ROW LOGIC       (session=0x109a648d0) (sqlalchemy before_flush)          - 2025-10-26 17:10:57,355 - logic_logger - INF\n..Order[54] {Update - client} id: 54, notes: Shipped order 1761523857344, customer_id: 58, CreatedOn: 2025-10-26, date_shipped:  [2025-10-26--&gt;] None, amount_total: 360.0000000000  row: 0x109a4d5d0  session: 0x109a648d0  ins_upd_dlt: upd, initial: upd - 2025-10-26 17:10:57,355 - logic_logger - INF\n....Customer[58] {Update - Adjusting customer: balance} id: 58, name: Alice 1761523857337, balance:  [0E-10--&gt;] 360.0000000000, credit_limit: 2000.0000000000, email: None, email_opt_out: None  row: 0x109a4ead0  session: 0x109a648d0  ins_upd_dlt: upd, initial: upd - 2025-10-26 17:10:57,355 - logic_logger - INF\nLogic Phase:        COMMIT LOGIC        (session=0x109a648d0)                                            - 2025-10-26 17:10:57,355 - logic_logger - INF\nLogic Phase:        AFTER_FLUSH LOGIC   (session=0x109a648d0)                                            - 2025-10-26 17:10:57,356 - logic_logger - INF\n..Order[54] {AfterFlush Event} id: 54, notes: Shipped order 1761523857344, customer_id: 58, CreatedOn: 2025-10-26, date_shipped:  [2025-10-26--&gt;] None, amount_total: 360.0000000000  row: 0x109a4d5d0  session: 0x109a648d0  ins_upd_dlt: upd, initial: upd - 2025-10-26 17:10:57,356 - logic_logger - INF\n</code></pre></p> <p> </p>"},{"location":"Behave-Logic-Report-Basic-Demo/#scenario-exceed-credit-limit-rejected","title":"Scenario: Exceed Credit Limit Rejected","text":"<p>\u2003  Scenario: Exceed Credit Limit Rejected \u2003\u2003    Given Customer \"Bob\" with balance 0 and credit limit 500 \u2003\u2003    When B2B order placed for \"Bob\" with 10 Widget \u2003\u2003    Then Order creation should fail     And Error message mentions credit limit  </p> Tests - and their logic - are transparent.. click to see Logic <p> </p> <p>Rules Used in Scenario: Exceed Credit Limit Rejected <pre><code>  Customer  \n    1. Derive &lt;class 'database.models.Customer'&gt;.balance as Sum(Order.amount_total Where Rule.sum(derive=Customer.balance, as_sum_of=Order.amount_total, where=lambda row: row.date_shipped is None) - &lt;function declare_logic.&lt;locals&gt;.&lt;lambda&gt; at 0x10883d260&gt;)  \n    2. Constraint Function: None   \n  Item  \n    3. Derive &lt;class 'database.models.Item'&gt;.unit_price as Copy(product.unit_price)  \n    4. Derive &lt;class 'database.models.Item'&gt;.amount as Formula (1): &lt;function&gt;  \n  Order  \n    5. Derive &lt;class 'database.models.Order'&gt;.amount_total as Sum(Item.amount Where  - None)  \nLogic Phase:        ROW LOGIC       (session=0x1098638a0) (sqlalchemy before_flush)          - 2025-10-26 17:10:57,369 - logic_logger - INFO  \n..Customer[None] {Insert - client} id: None, name: Alice 1761523857368, balance: 0, credit_limit: 2000, email: None, email_opt_out: None  row: 0x10991f850  session: 0x1098638a0  ins_upd_dlt: ins, initial: ins - 2025-10-26 17:10:57,369 - logic_logger - INFO  \n..Customer[None] {server aggregate_defaults: balance } id: None, name: Alice 1761523857368, balance: 0, credit_limit: 2000, email: None, email_opt_out: None  row: 0x10991f850  session: 0x1098638a0  ins_upd_dlt: ins, initial: ins - 2025-10-26 17:10:57,370 - logic_logger - INFO  \nLogic Phase:        COMMIT LOGIC        (session=0x1098638a0)                                            - 2025-10-26 17:10:57,370 - logic_logger - INFO  \nLogic Phase:        AFTER_FLUSH LOGIC   (session=0x1098638a0)                                            - 2025-10-26 17:10:57,370 - logic_logger - INFO  \nThese Rules Fired (see Logic Phases, above, for actual order):  \n</code></pre> Logic Log in Scenario: Exceed Credit Limit Rejected <pre><code>Logic Phase:        ROW LOGIC       (session=0x109a64160) (sqlalchemy before_flush)          - 2025-10-26 17:10:57,365 - logic_logger - INF\n..Product[2] {Update - client} id: 2, name: Widget, unit_price: 90.0000000000, carbon_neutral: None  row: 0x109a523c0  session: 0x109a64160  ins_upd_dlt: upd, initial: upd - 2025-10-26 17:10:57,365 - logic_logger - INF\n..Item[None] {Insert - client} id: None, order_id: None, product_id: None, quantity: 10, amount: None, unit_price: None  row: 0x109a4ddd0  session: 0x109a64160  ins_upd_dlt: ins, initial: ins - 2025-10-26 17:10:57,365 - logic_logger - INF\n..Item[None] {copy_rules for role: product - unit_price} id: None, order_id: None, product_id: None, quantity: 10, amount: None, unit_price: 90.0000000000  row: 0x109a4ddd0  session: 0x109a64160  ins_upd_dlt: ins, initial: ins - 2025-10-26 17:10:57,365 - logic_logger - INF\n..Item[None] {Formula amount} id: None, order_id: None, product_id: None, quantity: 10, amount: 900.0000000000, unit_price: 90.0000000000  row: 0x109a4ddd0  session: 0x109a64160  ins_upd_dlt: ins, initial: ins - 2025-10-26 17:10:57,365 - logic_logger - INF\n....Order[None] {server aggregate_defaults: amount_total } id: None, notes: Test order 1761523857363, customer_id: 59, CreatedOn: None, date_shipped: None, amount_total:  [None--&gt;] 0  row: 0x109a33ed0  session: 0x109a64160  ins_upd_dlt: *, initial: * - 2025-10-26 17:10:57,366 - logic_logger - INF\n..Item[None] {TODO DB adjust_from_inserted/adopted_child adjusts Derive &lt;class 'database.models.Order'&gt;.amount_total as Sum(Item.amount Where  - None)} id: None, order_id: None, product_id: None, quantity: 10, amount: 900.0000000000, unit_price: 90.0000000000  row: 0x109a4ddd0  session: 0x109a64160  ins_upd_dlt: ins, initial: ins - 2025-10-26 17:10:57,366 - logic_logger - INF\n....Order[None] {Adjustment logic chaining deferred for this parent parent do_defer_adjustment: True, is_parent_submitted: True, is_parent_row_processed: False, order} id: None, notes: Test order 1761523857363, customer_id: 59, CreatedOn: None, date_shipped: None, amount_total:  [None--&gt;] 900.0000000000  row: 0x109a33ed0  session: 0x109a64160  ins_upd_dlt: *, initial: * - 2025-10-26 17:10:57,366 - logic_logger - INF\n..Order[None] {Insert - client} id: None, notes: Test order 1761523857363, customer_id: 59, CreatedOn: None, date_shipped: None, amount_total: 900.0000000000  row: 0x109a33ed0  session: 0x109a64160  ins_upd_dlt: ins, initial: ins - 2025-10-26 17:10:57,366 - logic_logger - INF\n..Order[None] {early_row_event_all_classes - handle_all did stamping} id: None, notes: Test order 1761523857363, customer_id: 59, CreatedOn: 2025-10-26 17:10:57.366212, date_shipped: None, amount_total: 900.0000000000  row: 0x109a33ed0  session: 0x109a64160  ins_upd_dlt: ins, initial: ins - 2025-10-26 17:10:57,366 - logic_logger - INF\n..Order[None] {TODO DB adjust_from_inserted/adopted_child adjusts Derive &lt;class 'database.models.Customer'&gt;.balance as Sum(Order.amount_total Where Rule.sum(derive=Customer.balance, as_sum_of=Order.amount_total, where=lambda row: row.date_shipped is None) - &lt;function declare_logic.&lt;locals&gt;.&lt;lambda&gt; at 0x10883d260&gt;)} id: None, notes: Test order 1761523857363, customer_id: 59, CreatedOn: 2025-10-26 17:10:57.366212, date_shipped: None, amount_total: 900.0000000000  row: 0x109a33ed0  session: 0x109a64160  ins_upd_dlt: ins, initial: ins - 2025-10-26 17:10:57,366 - logic_logger - INF\n....Customer[59] {Update - Adjusting customer: balance} id: 59, name: Bob 1761523857359, balance:  [0E-10--&gt;] 900.0000000000, credit_limit: 500.0000000000, email: None, email_opt_out: None  row: 0x109a4e950  session: 0x109a64160  ins_upd_dlt: upd, initial: upd - 2025-10-26 17:10:57,366 - logic_logger - INF\n....Customer[59] {Constraint Failure: Customer balance (900.0000000000) exceeds credit limit (500.0000000000)} id: 59, name: Bob 1761523857359, balance:  [0E-10--&gt;] 900.0000000000, credit_limit: 500.0000000000, email: None, email_opt_out: None  row: 0x109a4e950  session: 0x109a64160  ins_upd_dlt: upd, initial: upd - 2025-10-26 17:10:57,366 - logic_logger - INF\n</code></pre></p> <p> </p>"},{"location":"Behave-Logic-Report-Basic-Demo/#scenario-change-product-updates-unit-price","title":"Scenario: Change Product Updates Unit Price","text":"<p>\u2003  Scenario: Change Product Updates Unit Price \u2003\u2003    Given Customer \"Alice\" with balance 0 and credit limit 2000     And Order is created for \"Alice\" with 5 Widget \u2003\u2003    When Item product changed to \"Gadget\" \u2003\u2003    Then Item unit_price should be 100     And Item amount should be 500     And Customer balance should be 500  </p> Tests - and their logic - are transparent.. click to see Logic <p> </p> <p>Rules Used in Scenario: Change Product Updates Unit Price <pre><code>  Customer  \n    1. Derive &lt;class 'database.models.Customer'&gt;.balance as Sum(Order.amount_total Where Rule.sum(derive=Customer.balance, as_sum_of=Order.amount_total, where=lambda row: row.date_shipped is None) - &lt;function declare_logic.&lt;locals&gt;.&lt;lambda&gt; at 0x10883d260&gt;)  \n  Item  \n    2. Derive &lt;class 'database.models.Item'&gt;.unit_price as Copy(product.unit_price)  \n    3. Derive &lt;class 'database.models.Item'&gt;.amount as Formula (1): &lt;function&gt;  \n  Order  \n    4. Derive &lt;class 'database.models.Order'&gt;.amount_total as Sum(Item.amount Where  - None)  \n    5. RowEvent Order.send_order_to_shipping()   \n</code></pre> Logic Log in Scenario: Change Product Updates Unit Price <pre><code>Logic Phase:        ROW LOGIC       (session=0x109862cf0) (sqlalchemy before_flush)          - 2025-10-26 17:10:57,389 - logic_logger - INF\n..Item[66] {Update - client} id: 66, order_id: 55, product_id:  [2--&gt;] 1, quantity: 5, amount: 450.0000000000, unit_price: 90.0000000000  row: 0x109a4e050  session: 0x109862cf0  ins_upd_dlt: upd, initial: upd - 2025-10-26 17:10:57,389 - logic_logger - INF\n..Item[66] {copy_rules for role: product - unit_price} id: 66, order_id: 55, product_id:  [2--&gt;] 1, quantity: 5, amount: 450.0000000000, unit_price:  [90.0000000000--&gt;] 100.0000000000  row: 0x109a4e050  session: 0x109862cf0  ins_upd_dlt: upd, initial: upd - 2025-10-26 17:10:57,389 - logic_logger - INF\n..Item[66] {Formula amount} id: 66, order_id: 55, product_id:  [2--&gt;] 1, quantity: 5, amount:  [450.0000000000--&gt;] 500.0000000000, unit_price:  [90.0000000000--&gt;] 100.0000000000  row: 0x109a4e050  session: 0x109862cf0  ins_upd_dlt: upd, initial: upd - 2025-10-26 17:10:57,389 - logic_logger - INF\n....Order[55] {Update - Adjusting order: amount_total} id: 55, notes: Test order 1761523857375, customer_id: 60, CreatedOn: 2025-10-26, date_shipped: None, amount_total:  [450.0000000000--&gt;] 500.0000000000  row: 0x109a4ced0  session: 0x109862cf0  ins_upd_dlt: upd, initial: upd - 2025-10-26 17:10:57,390 - logic_logger - INF\n......Customer[60] {Update - Adjusting customer: balance} id: 60, name: Alice 1761523857368, balance:  [450.0000000000--&gt;] 500.0000000000, credit_limit: 2000.0000000000, email: None, email_opt_out: None  row: 0x109a4d0d0  session: 0x109862cf0  ins_upd_dlt: upd, initial: upd - 2025-10-26 17:10:57,390 - logic_logger - INF\nLogic Phase:        COMMIT LOGIC        (session=0x109862cf0)                                            - 2025-10-26 17:10:57,390 - logic_logger - INF\nLogic Phase:        AFTER_FLUSH LOGIC   (session=0x109862cf0)                                            - 2025-10-26 17:10:57,391 - logic_logger - INF\n....Order[55] {AfterFlush Event} id: 55, notes: Test order 1761523857375, customer_id: 60, CreatedOn: 2025-10-26, date_shipped: None, amount_total:  [450.0000000000--&gt;] 500.0000000000  row: 0x109a4ced0  session: 0x109862cf0  ins_upd_dlt: upd, initial: upd - 2025-10-26 17:10:57,391 - logic_logger - INF\n</code></pre></p> <p>  /Users/val/dev/ApiLogicServer/ApiLogicServer-dev/build_and_test/ApiLogicServer/basic_demo/test/api_logic_server_behave/behave_run.py completed at October 26, 2025 17:10:5  </p>"},{"location":"Behave-Logic-Report/","title":"Behave Logic Report","text":"<p> TL;DR - Executable Test Suite, Documentation</p> <p>You can optionally use the Behave test framework to (here is an Agile Approach for using Behave) to capture requirements, and execute a test suite.  </p> <ul> <li> <p>As shown below, you can then create a wiki Behave Logic Report report that documents your requirements (Features), and the tests (Scenarios) that confirm their proper operation.</p> <ul> <li>Integrated Logic Documentation: the report integrates your logic, including a logic report showing your logic (rules and Python), and a Logic Log that shows exactly how the rules executed.  Logic Doc is transparent to business users, so can further contribute to Agile Collaboration.</li> </ul> </li> </ul> <p> </p>"},{"location":"Behave-Logic-Report/#northwind-sample","title":"Northwind Sample","text":"<p>This is the sample project from API Logic Server, based on the Northwind database (sqlite database located in the <code>database</code> folder - no installation required):</p> <p></p> <p>The sample Scenarios below were chosen to illustrate the basic patterns of using rules.  Open the disclosure box (\"Tests - and their logic...\") to see the implementation and notes.</p> <p>The following report was created during test suite execution.</p> <p> </p>"},{"location":"Behave-Logic-Report/#behave-logic-report","title":"Behave Logic Report","text":""},{"location":"Behave-Logic-Report/#feature-about-sample","title":"Feature: About Sample","text":""},{"location":"Behave-Logic-Report/#scenario-transaction-processing","title":"Scenario: Transaction Processing","text":"<p>\u2003  Scenario: Transaction Processing \u2003\u2003    Given Sample Database \u2003\u2003    When Transactions are submitted \u2003\u2003    Then Enforce business policies with Logic (rules + code)  </p> Tests - and their logic - are transparent.. click to see Logic <p> </p> <p>Rules Used in Scenario: Transaction Processing <pre><code>  Category  \n    1. Constraint Function: &lt;function declare_logic.&lt;locals&gt;.valid_category_description at 0x10b83fba0&gt;   \n</code></pre> Logic Log in Scenario: Transaction Processing <pre><code>The following rules have been activate\n - 2024-07-12 14:57:05,237 - logic_logger - DEBU\nRule Bank[0x10a431ca0] (loaded 2024-07-12 14:56:46.929015\nMapped Class[Customer] rules\n  Constraint Function: None\n  Constraint Function: None\n  Derive Customer.Balance as Sum(Order.AmountTotal Where &lt;function declare_logic.&lt;locals&gt;.&lt;lambda&gt; at 0x10b83fd80&gt;\n  RowEvent Customer.customer_defaults()\n  Derive Customer.UnpaidOrderCount as Count(&lt;class 'database.models.Order'&gt; Where &lt;function declare_logic.&lt;locals&gt;.&lt;lambda&gt; at 0x10b9596c0&gt;\n  Derive Customer.OrderCount as Count(&lt;class 'database.models.Order'&gt; Where None\nMapped Class[Employee] rules\n  Constraint Function: None\n  Constraint Function: &lt;function declare_logic.&lt;locals&gt;.raise_over_20_percent at 0x10b959940&gt;\n  Copy to: EmployeeAudi\nMapped Class[Category] rules\n  Constraint Function: &lt;function declare_logic.&lt;locals&gt;.valid_category_description at 0x10b83fba0&gt;\nMapped Class[Order] rules\n  Derive Order.AmountTotal as Sum(OrderDetail.Amount Where None\n  RowEvent Order.send_order_to_shipping()\n  RowEvent Order.congratulate_sales_rep()\n  RowEvent Order.do_not_ship_empty_orders()\n  Constraint Function: &lt;function declare_logic.&lt;locals&gt;.ship_ready_orders_only at 0x10b9591c0&gt;\n  RowEvent Order.order_defaults()\n  Derive Order.OrderDetailCount as Count(&lt;class 'database.models.OrderDetail'&gt; Where None\n  RowEvent Order.clone_order()\n  Derive Order.OrderDate as Formula (1): as_expression=lambda row: datetime.datetime.now()\nMapped Class[OrderDetail] rules\n  Derive OrderDetail.Amount as Formula (1): as_expression=lambda row: row.UnitPrice * row.Qua [...\n  Derive OrderDetail.UnitPrice as Copy(Product.UnitPrice\n  RowEvent OrderDetail.order_detail_defaults()\n  Derive OrderDetail.ShippedDate as Formula (2): row.Order.ShippedDat\nMapped Class[Product] rules\n  Derive Product.UnitsInStock as Formula (1): &lt;function\n  Derive Product.UnitsShipped as Sum(OrderDetail.Quantity Where &lt;function declare_logic.&lt;locals&gt;.&lt;lambda&gt; at 0x10b959580&gt;\nLogic Bank - 32 rules loaded - 2024-07-12 14:57:05,243 - logic_logger - INF\nLogic Bank - 32 rules loaded - 2024-07-12 14:57:05,243 - logic_logger - INF\n\nLogic Phase:        ROW LOGIC       (session=0x10dbbc710) (sqlalchemy before_flush)          - 2024-07-12 14:57:06,076 - logic_logger - INF\n..Shipper[1] {Delete - client} Id: 1, CompanyName: Speedy Express, Phone: (503) 555-9831  row: 0x10dbbce30  session: 0x10dbbc710  ins_upd_dlt: dlt - 2024-07-12 14:57:06,077 - logic_logger - INF\n\nLogic Phase:        ROW LOGIC       (session=0x10dcac9e0) (sqlalchemy before_flush)          - 2024-07-12 14:57:06,151 - logic_logger - INF\n..Category[1] {Update - client} Id: 1, CategoryName: Beverages, Description:  [Soft drinks, coffees, teas, beers, and ales--&gt;] x, Client_id: 1  row: 0x10dcad6a0  session: 0x10dcac9e0  ins_upd_dlt: upd - 2024-07-12 14:57:06,151 - logic_logger - INF\n..Category[1] {Constraint Failure: Description cannot be 'x'} Id: 1, CategoryName: Beverages, Description:  [Soft drinks, coffees, teas, beers, and ales--&gt;] x, Client_id: 1  row: 0x10dcad6a0  session: 0x10dcac9e0  ins_upd_dlt: upd - 2024-07-12 14:57:06,152 - logic_logger - INF\n</code></pre></p> <p> </p>"},{"location":"Behave-Logic-Report/#feature-application-integration","title":"Feature: Application Integration","text":""},{"location":"Behave-Logic-Report/#scenario-get-customer","title":"Scenario: GET Customer","text":"<p>\u2003  Scenario: GET Customer \u2003\u2003    Given Customer Account: VINET \u2003\u2003    When GET Orders API \u2003\u2003    Then VINET retrieved  </p> <p> </p>"},{"location":"Behave-Logic-Report/#scenario-get-department","title":"Scenario: GET Department","text":"<p>\u2003  Scenario: GET Department \u2003\u2003    Given Department 2 \u2003\u2003    When GET Department with SubDepartments API \u2003\u2003    Then SubDepartments returned  </p> <p> </p>"},{"location":"Behave-Logic-Report/#feature-authorization","title":"Feature: Authorization","text":""},{"location":"Behave-Logic-Report/#scenario-grant","title":"Scenario: Grant","text":"<p>\u2003  Scenario: Grant \u2003\u2003    Given NW Test Database \u2003\u2003    When u1 GETs Categories \u2003\u2003    Then Only 1 is returned  </p> <p> </p>"},{"location":"Behave-Logic-Report/#scenario-multi-tenant","title":"Scenario: Multi-tenant","text":"<p>\u2003  Scenario: Multi-tenant \u2003\u2003    Given NW Test Database \u2003\u2003    When sam GETs Customers \u2003\u2003    Then only 3 are returned  </p> <p> </p>"},{"location":"Behave-Logic-Report/#scenario-global-filters","title":"Scenario: Global Filters","text":"<p>\u2003  Scenario: Global Filters \u2003\u2003    Given NW Test Database \u2003\u2003    When sam GETs Departments \u2003\u2003    Then only 8 are returned  </p> <p> </p>"},{"location":"Behave-Logic-Report/#scenario-global-filters-with-grants","title":"Scenario: Global Filters With Grants","text":"<p>\u2003  Scenario: Global Filters With Grants \u2003\u2003    Given NW Test Database \u2003\u2003    When s1 GETs Customers \u2003\u2003    Then only 1 customer is returned  </p> <p> </p>"},{"location":"Behave-Logic-Report/#scenario-crud-permissions","title":"Scenario: CRUD Permissions","text":"<p>\u2003  Scenario: CRUD Permissions \u2003\u2003    Given NW Test Database \u2003\u2003    When r1 deletes a Shipper \u2003\u2003    Then Operation is Refused  </p> <p> </p>"},{"location":"Behave-Logic-Report/#feature-optimistic-locking","title":"Feature: Optimistic Locking","text":""},{"location":"Behave-Logic-Report/#scenario-get-category","title":"Scenario: Get Category","text":"<p>\u2003  Scenario: Get Category \u2003\u2003    Given Category: 1 \u2003\u2003    When Get Cat1 \u2003\u2003    Then Expected Cat1 Checksum  </p> <p> </p>"},{"location":"Behave-Logic-Report/#scenario-valid-checksum","title":"Scenario: Valid Checksum","text":"<p>\u2003  Scenario: Valid Checksum \u2003\u2003    Given Category: 1 \u2003\u2003    When Patch Valid Checksum \u2003\u2003    Then Valid Checksum, Invalid Description  </p> <p> </p>"},{"location":"Behave-Logic-Report/#scenario-missing-checksum","title":"Scenario: Missing Checksum","text":"<p>\u2003  Scenario: Missing Checksum \u2003\u2003    Given Category: 1 \u2003\u2003    When Patch Missing Checksum \u2003\u2003    Then Valid Checksum, Invalid Description  </p> <p> </p>"},{"location":"Behave-Logic-Report/#scenario-invalid-checksum","title":"Scenario: Invalid Checksum","text":"<p>\u2003  Scenario: Invalid Checksum \u2003\u2003    Given Category: 1 \u2003\u2003    When Patch Invalid Checksum \u2003\u2003    Then Invalid Checksum  </p> <p> </p>"},{"location":"Behave-Logic-Report/#feature-place-order","title":"Feature: Place Order","text":""},{"location":"Behave-Logic-Report/#scenario-order-made-not-ready","title":"Scenario: Order Made Not Ready","text":"<p>\u2003  Scenario: Order Made Not Ready \u2003\u2003    Given Customer Account: ALFKI \u2003\u2003    When Ready Flag is Reset \u2003\u2003    Then Logic Decreases Balance  </p> Tests - and their logic - are transparent.. click to see Logic <p> </p> <p>Logic Doc for scenario: Order Made Not Ready</p> <p>We reset <code>Order.Ready</code>.</p> <p>This removes the order from contingent derivations (e.g., the <code>Customer.Balance</code>), and constraints.</p> <p>Key Takeaway: adjustment from change in qualification condition</p> <p> </p> <p>Rules Used in Scenario: Order Made Not Ready <pre><code>  Customer  \n    1. Derive Customer.UnpaidOrderCount as Count(&lt;class 'database.models.Order'&gt; Where &lt;function declare_logic.&lt;locals&gt;.&lt;lambda&gt; at 0x105744ea0&gt;)  \n    2. Derive Customer.Balance as Sum(Order.AmountTotal Where &lt;function declare_logic.&lt;locals&gt;.&lt;lambda&gt; at 0x105623740&gt;)  \n    3. RowEvent Customer.customer_defaults()   \n    4. Derive Customer.OrderCount as Count(&lt;class 'database.models.Order'&gt; Where None)  \n  Order  \n    5. RowEvent Order.order_defaults()   \n    6. RowEvent Order.clone_order()   \n    7. RowEvent Order.congratulate_sales_rep()   \n    8. RowEvent Order.do_not_ship_empty_orders()   \n    9. RowEvent Order.send_order_to_shipping()   \n</code></pre> Logic Log in Scenario: Order Made Not Ready <pre><code>Logic Phase:        ROW LOGIC       (session=0x12061d190) (sqlalchemy before_flush)          - 2024-08-31 21:14:53,887 - logic_logger - INF\n..Order[11011] {Update - client} Id: 11011, CustomerId: ALFKI, EmployeeId: 3, OrderDate: 2014-04-09, RequiredDate: 2014-05-07, ShippedDate: None, ShipVia: 1, Freight: 1.2100000000, ShipName: Alfred's Futterkiste, ShipAddress: Obere Str. 57, ShipCity: Berlin, ShipRegion: Western Europe, ShipZip: 12209, ShipCountry: Germany, AmountTotal: 960.00, Country: None, City: None, Ready:  [True--&gt;] False, OrderDetailCount: 2, CloneFromOrder: None  row: 0x12061f860  session: 0x12061d190  ins_upd_dlt: upd - 2024-08-31 21:14:53,888 - logic_logger - INF\n..Order[11011] {Prune Formula: OrderDate [[]]} Id: 11011, CustomerId: ALFKI, EmployeeId: 3, OrderDate: 2014-04-09, RequiredDate: 2014-05-07, ShippedDate: None, ShipVia: 1, Freight: 1.2100000000, ShipName: Alfred's Futterkiste, ShipAddress: Obere Str. 57, ShipCity: Berlin, ShipRegion: Western Europe, ShipZip: 12209, ShipCountry: Germany, AmountTotal: 960.00, Country: None, City: None, Ready:  [True--&gt;] False, OrderDetailCount: 2, CloneFromOrder: None  row: 0x12061f860  session: 0x12061d190  ins_upd_dlt: upd - 2024-08-31 21:14:53,889 - logic_logger - INF\n....Customer[ALFKI] {Update - Adjusting Customer: Balance} Id: ALFKI, CompanyName: Alfreds Futterkiste, ContactName: Maria Anders, ContactTitle: Sales Representative, Address: Obere Str. 57A, City: Berlin, Region: Western Europe, PostalCode: 12209, Country: Germany, Phone: 030-0074321, Fax: 030-0076545, Balance:  [2102.0000000000--&gt;] 1142.0000000000, CreditLimit: 2300.0000000000, OrderCount: 15, UnpaidOrderCount: 10, Client_id: 1  row: 0x1207563c0  session: 0x12061d190  ins_upd_dlt: upd - 2024-08-31 21:14:53,893 - logic_logger - INF\nLogic Phase:        COMMIT LOGIC        (session=0x12061d190)                                            - 2024-08-31 21:14:53,896 - logic_logger - INF\n..Order[11011] {Commit Event} Id: 11011, CustomerId: ALFKI, EmployeeId: 3, OrderDate: 2014-04-09, RequiredDate: 2014-05-07, ShippedDate: None, ShipVia: 1, Freight: 1.2100000000, ShipName: Alfred's Futterkiste, ShipAddress: Obere Str. 57, ShipCity: Berlin, ShipRegion: Western Europe, ShipZip: 12209, ShipCountry: Germany, AmountTotal: 960.00, Country: None, City: None, Ready:  [True--&gt;] False, OrderDetailCount: 2, CloneFromOrder: None  row: 0x12061f860  session: 0x12061d190  ins_upd_dlt: upd - 2024-08-31 21:14:53,897 - logic_logger - INF\n..Order[11011] {Commit Event} Id: 11011, CustomerId: ALFKI, EmployeeId: 3, OrderDate: 2014-04-09, RequiredDate: 2014-05-07, ShippedDate: None, ShipVia: 1, Freight: 1.2100000000, ShipName: Alfred's Futterkiste, ShipAddress: Obere Str. 57, ShipCity: Berlin, ShipRegion: Western Europe, ShipZip: 12209, ShipCountry: Germany, AmountTotal: 960.00, Country: None, City: None, Ready:  [True--&gt;] False, OrderDetailCount: 2, CloneFromOrder: None  row: 0x12061f860  session: 0x12061d190  ins_upd_dlt: upd - 2024-08-31 21:14:53,897 - logic_logger - INF\nLogic Phase:        AFTER_FLUSH LOGIC   (session=0x12061d190)                                            - 2024-08-31 21:14:53,903 - logic_logger - INF\n..Order[11011] {AfterFlush Event} Id: 11011, CustomerId: ALFKI, EmployeeId: 3, OrderDate: 2014-04-09, RequiredDate: 2014-05-07, ShippedDate: None, ShipVia: 1, Freight: 1.2100000000, ShipName: Alfred's Futterkiste, ShipAddress: Obere Str. 57, ShipCity: Berlin, ShipRegion: Western Europe, ShipZip: 12209, ShipCountry: Germany, AmountTotal: 960.00, Country: None, City: None, Ready:  [True--&gt;] False, OrderDetailCount: 2, CloneFromOrder: None  row: 0x12061f860  session: 0x12061d190  ins_upd_dlt: upd - 2024-08-31 21:14:53,904 - logic_logger - INF\n</code></pre></p> <p> </p>"},{"location":"Behave-Logic-Report/#scenario-order-made-ready","title":"Scenario: Order Made Ready","text":"<p>\u2003  Scenario: Order Made Ready \u2003\u2003    Given Customer Account: ALFKI \u2003\u2003    When Ready Flag is Set \u2003\u2003    Then Logic Increases Balance  </p> Tests - and their logic - are transparent.. click to see Logic <p> </p> <p>Logic Doc for scenario: Order Made Ready</p> <p>This illustrates the ready flag pattern: 1. Add a ready flag to the Order 2. Make logic contingent on the ready flag:     * Customer.Balance is increased only if the Order is ready     * Empty Orders are not rejected</p> <p>This enables the user to submit multiple transactions (add order details, alter them etc), before making the order ready (like a checkout).</p> <p>Until then, Customer's Balance adjustments, or empty orders constraints do not fire.</p> <p>Key Takeaway: the ready flag defers constraints/derivations until the user is ready.</p> <p>Key Takeaway: adjustment from change in qualification condition</p> <p> </p> <p>Rules Used in Scenario: Order Made Ready <pre><code>  Customer  \n    1. Derive Customer.UnpaidOrderCount as Count(&lt;class 'database.models.Order'&gt; Where &lt;function declare_logic.&lt;locals&gt;.&lt;lambda&gt; at 0x105744ea0&gt;)  \n    2. Derive Customer.Balance as Sum(Order.AmountTotal Where &lt;function declare_logic.&lt;locals&gt;.&lt;lambda&gt; at 0x105623740&gt;)  \n    3. RowEvent Customer.customer_defaults()   \n    4. Derive Customer.OrderCount as Count(&lt;class 'database.models.Order'&gt; Where None)  \n  Order  \n    5. RowEvent Order.order_defaults()   \n    6. RowEvent Order.clone_order()   \n    7. RowEvent Order.congratulate_sales_rep()   \n    8. RowEvent Order.do_not_ship_empty_orders()   \n    9. RowEvent Order.send_order_to_shipping()   \n</code></pre> Logic Log in Scenario: Order Made Ready <pre><code>Logic Phase:        ROW LOGIC       (session=0x12078f650) (sqlalchemy before_flush)          - 2024-08-31 21:14:54,247 - logic_logger - INF\n..Order[11011] {Update - client} Id: 11011, CustomerId: ALFKI, EmployeeId: 3, OrderDate: 2014-04-09, RequiredDate: 2014-05-07, ShippedDate: None, ShipVia: 1, Freight: 1.2100000000, ShipName: Alfred's Futterkiste, ShipAddress: Obere Str. 57, ShipCity: Berlin, ShipRegion: Western Europe, ShipZip: 12209, ShipCountry: Germany, AmountTotal: 960.00, Country: None, City: None, Ready:  [False--&gt;] True, OrderDetailCount: 2, CloneFromOrder: None  row: 0x12078d280  session: 0x12078f650  ins_upd_dlt: upd - 2024-08-31 21:14:54,248 - logic_logger - INF\n..Order[11011] {Prune Formula: OrderDate [[]]} Id: 11011, CustomerId: ALFKI, EmployeeId: 3, OrderDate: 2014-04-09, RequiredDate: 2014-05-07, ShippedDate: None, ShipVia: 1, Freight: 1.2100000000, ShipName: Alfred's Futterkiste, ShipAddress: Obere Str. 57, ShipCity: Berlin, ShipRegion: Western Europe, ShipZip: 12209, ShipCountry: Germany, AmountTotal: 960.00, Country: None, City: None, Ready:  [False--&gt;] True, OrderDetailCount: 2, CloneFromOrder: None  row: 0x12078d280  session: 0x12078f650  ins_upd_dlt: upd - 2024-08-31 21:14:54,249 - logic_logger - INF\n....Customer[ALFKI] {Update - Adjusting Customer: Balance} Id: ALFKI, CompanyName: Alfreds Futterkiste, ContactName: Maria Anders, ContactTitle: Sales Representative, Address: Obere Str. 57A, City: Berlin, Region: Western Europe, PostalCode: 12209, Country: Germany, Phone: 030-0074321, Fax: 030-0076545, Balance:  [1142.0000000000--&gt;] 2102.0000000000, CreditLimit: 2300.0000000000, OrderCount: 15, UnpaidOrderCount: 10, Client_id: 1  row: 0x12078fd40  session: 0x12078f650  ins_upd_dlt: upd - 2024-08-31 21:14:54,251 - logic_logger - INF\nLogic Phase:        COMMIT LOGIC        (session=0x12078f650)                                            - 2024-08-31 21:14:54,254 - logic_logger - INF\n..Order[11011] {Commit Event} Id: 11011, CustomerId: ALFKI, EmployeeId: 3, OrderDate: 2014-04-09, RequiredDate: 2014-05-07, ShippedDate: None, ShipVia: 1, Freight: 1.2100000000, ShipName: Alfred's Futterkiste, ShipAddress: Obere Str. 57, ShipCity: Berlin, ShipRegion: Western Europe, ShipZip: 12209, ShipCountry: Germany, AmountTotal: 960.00, Country: None, City: None, Ready:  [False--&gt;] True, OrderDetailCount: 2, CloneFromOrder: None  row: 0x12078d280  session: 0x12078f650  ins_upd_dlt: upd - 2024-08-31 21:14:54,255 - logic_logger - INF\n..Order[11011] {Commit Event} Id: 11011, CustomerId: ALFKI, EmployeeId: 3, OrderDate: 2014-04-09, RequiredDate: 2014-05-07, ShippedDate: None, ShipVia: 1, Freight: 1.2100000000, ShipName: Alfred's Futterkiste, ShipAddress: Obere Str. 57, ShipCity: Berlin, ShipRegion: Western Europe, ShipZip: 12209, ShipCountry: Germany, AmountTotal: 960.00, Country: None, City: None, Ready:  [False--&gt;] True, OrderDetailCount: 2, CloneFromOrder: None  row: 0x12078d280  session: 0x12078f650  ins_upd_dlt: upd - 2024-08-31 21:14:54,255 - logic_logger - INF\nLogic Phase:        AFTER_FLUSH LOGIC   (session=0x12078f650)                                            - 2024-08-31 21:14:54,257 - logic_logger - INF\n..Order[11011] {AfterFlush Event} Id: 11011, CustomerId: ALFKI, EmployeeId: 3, OrderDate: 2014-04-09, RequiredDate: 2014-05-07, ShippedDate: None, ShipVia: 1, Freight: 1.2100000000, ShipName: Alfred's Futterkiste, ShipAddress: Obere Str. 57, ShipCity: Berlin, ShipRegion: Western Europe, ShipZip: 12209, ShipCountry: Germany, AmountTotal: 960.00, Country: None, City: None, Ready:  [False--&gt;] True, OrderDetailCount: 2, CloneFromOrder: None  row: 0x12078d280  session: 0x12078f650  ins_upd_dlt: upd - 2024-08-31 21:14:54,258 - logic_logger - INF\n..Order[11011] {Sending Order to Shipping &lt;&lt; not activated &gt;&gt;} Id: 11011, CustomerId: ALFKI, EmployeeId: 3, OrderDate: 2014-04-09, RequiredDate: 2014-05-07, ShippedDate: None, ShipVia: 1, Freight: 1.2100000000, ShipName: Alfred's Futterkiste, ShipAddress: Obere Str. 57, ShipCity: Berlin, ShipRegion: Western Europe, ShipZip: 12209, ShipCountry: Germany, AmountTotal: 960.00, Country: None, City: None, Ready:  [False--&gt;] True, OrderDetailCount: 2, CloneFromOrder: None  row: 0x12078d280  session: 0x12078f650  ins_upd_dlt: upd - 2024-08-31 21:14:54,267 - logic_logger - INF\n</code></pre></p> <p> </p>"},{"location":"Behave-Logic-Report/#scenario-good-order-custom-service","title":"Scenario: Good Order Custom Service","text":"<p>\u2003  Scenario: Good Order Custom Service \u2003\u2003    Given Customer Account: ALFKI \u2003\u2003    When Good Order Placed \u2003\u2003    Then Logic adjusts Balance (demo: chain up) \u2003\u2003    Then Logic adjusts Products Reordered \u2003\u2003    Then Logic sends email to salesrep \u2003\u2003    Then Logic sends kafka message \u2003\u2003    Then Logic adjusts aggregates down on delete order  </p> Tests - and their logic - are transparent.. click to see Logic <p> </p> <p>Logic Doc for scenario: Good Order Custom Service</p> <p>Familiar logic patterns:</p> <ul> <li>Constrain a derived result (Check Credit)</li> <li>Chain up, to adjust parent sum/count aggregates (AmountTotal, Balance)</li> <li>Events for Lib Access (Kafka, email messages)</li> </ul> <p>Logic Design (\"Cocktail Napkin Design\")</p> <ul> <li>Customer.Balance &lt;= CreditLimit</li> <li>Customer.Balance = Sum(Order.AmountTotal where unshipped)</li> <li>Order.AmountTotal = Sum(OrderDetail.Amount)</li> <li>OrderDetail.Amount = Quantity * UnitPrice</li> <li>OrderDetail.UnitPrice = copy from Product</li> </ul> <p>We place an Order with an Order Detail.  It's one transaction.</p> <p>Note how the <code>Order.AmountTotal</code> and <code>Customer.Balance</code> are adjusted as Order Details are processed. Similarly, the <code>Product.UnitsShipped</code> is adjusted, and used to recompute <code>UnitsInStock</code></p> <p>Key Takeaway: sum/count aggregates (e.g., <code>Customer.Balance</code>) automate chain up multi-table transactions.</p> <p>Events - Extensible Logic</p> <p>Inspect the log for Hi, Andrew - Congratulate Nancy on their new order. </p> <p>The <code>congratulate_sales_rep</code> event illustrates logic  Extensibility  - using Python to provide logic not covered by rules,  like non-database operations such as sending email or messages.</p> <p>There are actually multiple kinds of events:</p> <ul> <li>Before row logic</li> <li>After row logic</li> <li>On commit, after all row logic has completed (as here), so that your code \"sees\" the full logic results</li> </ul> <p>Events are passed the <code>row</code> and <code>old_row</code>, as well as <code>logic_row</code> which enables you to test the actual operation, chaining nest level, etc.</p> <p>You can set breakpoints in events, and inspect these.</p> <p> </p> <p>Rules Used in Scenario: Good Order Custom Service <pre><code>  Customer  \n    1. Derive Customer.UnpaidOrderCount as Count(&lt;class 'database.models.Order'&gt; Where &lt;function declare_logic.&lt;locals&gt;.&lt;lambda&gt; at 0x105744ea0&gt;)  \n    2. Derive Customer.Balance as Sum(Order.AmountTotal Where &lt;function declare_logic.&lt;locals&gt;.&lt;lambda&gt; at 0x105623740&gt;)  \n    3. RowEvent Customer.customer_defaults()   \n    4. Derive Customer.OrderCount as Count(&lt;class 'database.models.Order'&gt; Where None)  \n  Order  \n    5. RowEvent Order.order_defaults()   \n    6. RowEvent Order.do_not_ship_empty_orders()   \n    7. Derive Order.OrderDate as Formula (1): as_expression=lambda row: datetime.datetime.now())  \n    8. Derive Order.AmountTotal as Sum(OrderDetail.Amount Where None)  \n    9. RowEvent Order.clone_order()   \n    10. RowEvent Order.congratulate_sales_rep()   \n    11. Derive Order.OrderDetailCount as Count(&lt;class 'database.models.OrderDetail'&gt; Where None)  \n    12. RowEvent Order.send_order_to_shipping()   \n  OrderDetail  \n    13. RowEvent OrderDetail.order_detail_defaults()   \n    14. Derive OrderDetail.UnitPrice as Copy(Product.UnitPrice)  \n    15. Derive OrderDetail.Amount as Formula (1): as_expression=lambda row: row.UnitPrice * row.Qua [...]  \n    16. Derive OrderDetail.ShippedDate as Formula (2): row.Order.ShippedDate  \n  Product  \n    17. Derive Product.UnitsShipped as Sum(OrderDetail.Quantity Where &lt;function declare_logic.&lt;locals&gt;.&lt;lambda&gt; at 0x105744d60&gt;)  \n    18. Derive Product.UnitsInStock as Formula (1): &lt;function&gt;  \n</code></pre> Logic Log in Scenario: Good Order Custom Service <pre><code>Logic Phase:        ROW LOGIC       (session=0x1207d6f30) (sqlalchemy before_flush)          - 2024-08-31 21:14:54,620 - logic_logger - INF\n..OrderDetail[None] {Insert - client} Id: None, OrderId: None, ProductId: 1, UnitPrice: None, Quantity: 1, Discount: 0, Amount: None, ShippedDate: None  row: 0x1207d6f00  session: 0x1207d6f30  ins_upd_dlt: ins - 2024-08-31 21:14:54,621 - logic_logger - INF\n..OrderDetail[None] {copy_rules for role: Product - UnitPrice} Id: None, OrderId: None, ProductId: 1, UnitPrice: 18.0000000000, Quantity: 1, Discount: 0, Amount: None, ShippedDate: None  row: 0x1207d6f00  session: 0x1207d6f30  ins_upd_dlt: ins - 2024-08-31 21:14:54,625 - logic_logger - INF\n..OrderDetail[None] {Formula Amount} Id: None, OrderId: None, ProductId: 1, UnitPrice: 18.0000000000, Quantity: 1, Discount: 0, Amount: 18.0000000000, ShippedDate: None  row: 0x1207d6f00  session: 0x1207d6f30  ins_upd_dlt: ins - 2024-08-31 21:14:54,625 - logic_logger - INF\n....Order[None] {Adjustment logic chaining deferred for this parent parent do_defer_adjustment: True, is_parent_submitted: True, is_parent_row_processed: False, Order} Id: None, CustomerId: ALFKI, EmployeeId: 1, OrderDate: None, RequiredDate: None, ShippedDate: None, ShipVia: None, Freight: 11, ShipName: None, ShipAddress: None, ShipCity: None, ShipRegion: None, ShipZip: None, ShipCountry: None, AmountTotal:  [None--&gt;] 18.0000000000, Country: None, City: None, Ready: True, OrderDetailCount:  [None--&gt;] 1, CloneFromOrder: None  row: 0x1207d7ce0  session: 0x1207d6f30  ins_upd_dlt: * - 2024-08-31 21:14:54,627 - logic_logger - INF\n....Product[1] {Update - Adjusting Product: UnitsShipped} Id: 1, ProductName: Chai, SupplierId: 1, CategoryId: 1, QuantityPerUnit: 10 boxes x 20 bags, UnitPrice: 18.0000000000, UnitsInStock: 39, UnitsOnOrder: 0, ReorderLevel: 10, Discontinued: 0, UnitsShipped:  [0--&gt;] 1  row: 0x1207d60c0  session: 0x1207d6f30  ins_upd_dlt: upd - 2024-08-31 21:14:54,627 - logic_logger - INF\n....Product[1] {Formula UnitsInStock} Id: 1, ProductName: Chai, SupplierId: 1, CategoryId: 1, QuantityPerUnit: 10 boxes x 20 bags, UnitPrice: 18.0000000000, UnitsInStock:  [39--&gt;] 38, UnitsOnOrder: 0, ReorderLevel: 10, Discontinued: 0, UnitsShipped:  [0--&gt;] 1  row: 0x1207d60c0  session: 0x1207d6f30  ins_upd_dlt: upd - 2024-08-31 21:14:54,628 - logic_logger - INF\n..Order[None] {Insert - client} Id: None, CustomerId: ALFKI, EmployeeId: 1, OrderDate: None, RequiredDate: None, ShippedDate: None, ShipVia: None, Freight: 11, ShipName: None, ShipAddress: None, ShipCity: None, ShipRegion: None, ShipZip: None, ShipCountry: None, AmountTotal: 18.0000000000, Country: None, City: None, Ready: True, OrderDetailCount: 1, CloneFromOrder: None  row: 0x1207d7ce0  session: 0x1207d6f30  ins_upd_dlt: ins - 2024-08-31 21:14:54,629 - logic_logger - INF\n..Order[None] {server_defaults: -- skipped: Ready[BOOLEAN (not handled)] } Id: None, CustomerId: ALFKI, EmployeeId: 1, OrderDate: None, RequiredDate: None, ShippedDate: None, ShipVia: None, Freight: 11, ShipName: None, ShipAddress: None, ShipCity: None, ShipRegion: None, ShipZip: None, ShipCountry: None, AmountTotal: 18.0000000000, Country: None, City: None, Ready: True, OrderDetailCount: 1, CloneFromOrder: None  row: 0x1207d7ce0  session: 0x1207d6f30  ins_upd_dlt: ins - 2024-08-31 21:14:54,630 - logic_logger - INF\n..Order[None] {Formula OrderDate} Id: None, CustomerId: ALFKI, EmployeeId: 1, OrderDate: 2024-08-31 21:14:54.637311, RequiredDate: None, ShippedDate: None, ShipVia: None, Freight: 11, ShipName: None, ShipAddress: None, ShipCity: None, ShipRegion: None, ShipZip: None, ShipCountry: None, AmountTotal: 18.0000000000, Country: None, City: None, Ready: True, OrderDetailCount: 1, CloneFromOrder: None  row: 0x1207d7ce0  session: 0x1207d6f30  ins_upd_dlt: ins - 2024-08-31 21:14:54,637 - logic_logger - INF\n....Customer[ALFKI] {Update - Adjusting Customer: Balance, UnpaidOrderCount, OrderCount} Id: ALFKI, CompanyName: Alfreds Futterkiste, ContactName: Maria Anders, ContactTitle: Sales Representative, Address: Obere Str. 57A, City: Berlin, Region: Western Europe, PostalCode: 12209, Country: Germany, Phone: 030-0074321, Fax: 030-0076545, Balance:  [2102.0000000000--&gt;] 2120.0000000000, CreditLimit: 2300.0000000000, OrderCount:  [15--&gt;] 16, UnpaidOrderCount:  [10--&gt;] 11, Client_id: 1  row: 0x1207d44a0  session: 0x1207d6f30  ins_upd_dlt: upd - 2024-08-31 21:14:54,638 - logic_logger - INF\n..OrderDetail[None] {Insert - client} Id: None, OrderId: None, ProductId: 2, UnitPrice: None, Quantity: 2, Discount: 0, Amount: None, ShippedDate: None  row: 0x1207d70e0  session: 0x1207d6f30  ins_upd_dlt: ins - 2024-08-31 21:14:54,641 - logic_logger - INF\n..OrderDetail[None] {copy_rules for role: Product - UnitPrice} Id: None, OrderId: None, ProductId: 2, UnitPrice: 19.0000000000, Quantity: 2, Discount: 0, Amount: None, ShippedDate: None  row: 0x1207d70e0  session: 0x1207d6f30  ins_upd_dlt: ins - 2024-08-31 21:14:54,643 - logic_logger - INF\n..OrderDetail[None] {Formula Amount} Id: None, OrderId: None, ProductId: 2, UnitPrice: 19.0000000000, Quantity: 2, Discount: 0, Amount: 38.0000000000, ShippedDate: None  row: 0x1207d70e0  session: 0x1207d6f30  ins_upd_dlt: ins - 2024-08-31 21:14:54,644 - logic_logger - INF\n....Order[None] {Update - Adjusting Order: AmountTotal, OrderDetailCount} Id: None, CustomerId: ALFKI, EmployeeId: 1, OrderDate: 2024-08-31 21:14:54.637311, RequiredDate: None, ShippedDate: None, ShipVia: None, Freight: 11, ShipName: None, ShipAddress: None, ShipCity: None, ShipRegion: None, ShipZip: None, ShipCountry: None, AmountTotal:  [18.0000000000--&gt;] 56.0000000000, Country: None, City: None, Ready: True, OrderDetailCount:  [1--&gt;] 2, CloneFromOrder: None  row: 0x1207d7ce0  session: 0x1207d6f30  ins_upd_dlt: upd - 2024-08-31 21:14:54,645 - logic_logger - INF\n....Order[None] {Prune Formula: OrderDate [[]]} Id: None, CustomerId: ALFKI, EmployeeId: 1, OrderDate: 2024-08-31 21:14:54.637311, RequiredDate: None, ShippedDate: None, ShipVia: None, Freight: 11, ShipName: None, ShipAddress: None, ShipCity: None, ShipRegion: None, ShipZip: None, ShipCountry: None, AmountTotal:  [18.0000000000--&gt;] 56.0000000000, Country: None, City: None, Ready: True, OrderDetailCount:  [1--&gt;] 2, CloneFromOrder: None  row: 0x1207d7ce0  session: 0x1207d6f30  ins_upd_dlt: upd - 2024-08-31 21:14:54,646 - logic_logger - INF\n......Customer[ALFKI] {Update - Adjusting Customer: Balance} Id: ALFKI, CompanyName: Alfreds Futterkiste, ContactName: Maria Anders, ContactTitle: Sales Representative, Address: Obere Str. 57A, City: Berlin, Region: Western Europe, PostalCode: 12209, Country: Germany, Phone: 030-0074321, Fax: 030-0076545, Balance:  [2120.0000000000--&gt;] 2158.0000000000, CreditLimit: 2300.0000000000, OrderCount: 16, UnpaidOrderCount: 11, Client_id: 1  row: 0x1207d44a0  session: 0x1207d6f30  ins_upd_dlt: upd - 2024-08-31 21:14:54,647 - logic_logger - INF\n....Product[2] {Update - Adjusting Product: UnitsShipped} Id: 2, ProductName: Chang, SupplierId: 1, CategoryId: 1, QuantityPerUnit: 24 - 12 oz bottles, UnitPrice: 19.0000000000, UnitsInStock: 17, UnitsOnOrder: 40, ReorderLevel: 25, Discontinued: 0, UnitsShipped:  [0--&gt;] 2  row: 0x1207d64e0  session: 0x1207d6f30  ins_upd_dlt: upd - 2024-08-31 21:14:54,650 - logic_logger - INF\n....Product[2] {Formula UnitsInStock} Id: 2, ProductName: Chang, SupplierId: 1, CategoryId: 1, QuantityPerUnit: 24 - 12 oz bottles, UnitPrice: 19.0000000000, UnitsInStock:  [17--&gt;] 15, UnitsOnOrder: 40, ReorderLevel: 25, Discontinued: 0, UnitsShipped:  [0--&gt;] 2  row: 0x1207d64e0  session: 0x1207d6f30  ins_upd_dlt: upd - 2024-08-31 21:14:54,651 - logic_logger - INF\nLogic Phase:        COMMIT LOGIC        (session=0x1207d6f30)                                            - 2024-08-31 21:14:54,651 - logic_logger - INF\n..Order[None] {Commit Event} Id: None, CustomerId: ALFKI, EmployeeId: 1, OrderDate: 2024-08-31 21:14:54.637311, RequiredDate: None, ShippedDate: None, ShipVia: None, Freight: 11, ShipName: None, ShipAddress: None, ShipCity: None, ShipRegion: None, ShipZip: None, ShipCountry: None, AmountTotal: 56.0000000000, Country: None, City: None, Ready: True, OrderDetailCount: 2, CloneFromOrder: None  row: 0x1207d7ce0  session: 0x1207d6f30  ins_upd_dlt: ins - 2024-08-31 21:14:54,652 - logic_logger - INF\n..Order[None] {Hi, Andrew - Congratulate Nancy on their new order} Id: None, CustomerId: ALFKI, EmployeeId: 1, OrderDate: 2024-08-31 21:14:54.637311, RequiredDate: None, ShippedDate: None, ShipVia: None, Freight: 11, ShipName: None, ShipAddress: None, ShipCity: None, ShipRegion: None, ShipZip: None, ShipCountry: None, AmountTotal: 56.0000000000, Country: None, City: None, Ready: True, OrderDetailCount: 2, CloneFromOrder: None  row: 0x1207d7ce0  session: 0x1207d6f30  ins_upd_dlt: ins - 2024-08-31 21:14:54,656 - logic_logger - INF\n..Order[None] {Illustrate database access} Id: None, CustomerId: ALFKI, EmployeeId: 1, OrderDate: 2024-08-31 21:14:54.637311, RequiredDate: None, ShippedDate: None, ShipVia: None, Freight: 11, ShipName: None, ShipAddress: None, ShipCity: None, ShipRegion: None, ShipZip: None, ShipCountry: None, AmountTotal: 56.0000000000, Country: None, City: None, Ready: True, OrderDetailCount: 2, CloneFromOrder: None  row: 0x1207d7ce0  session: 0x1207d6f30  ins_upd_dlt: ins - 2024-08-31 21:14:54,657 - logic_logger - INF\n..Order[None] {Commit Event} Id: None, CustomerId: ALFKI, EmployeeId: 1, OrderDate: 2024-08-31 21:14:54.637311, RequiredDate: None, ShippedDate: None, ShipVia: None, Freight: 11, ShipName: None, ShipAddress: None, ShipCity: None, ShipRegion: None, ShipZip: None, ShipCountry: None, AmountTotal: 56.0000000000, Country: None, City: None, Ready: True, OrderDetailCount: 2, CloneFromOrder: None  row: 0x1207d7ce0  session: 0x1207d6f30  ins_upd_dlt: ins - 2024-08-31 21:14:54,658 - logic_logger - INF\nLogic Phase:        AFTER_FLUSH LOGIC   (session=0x1207d6f30)                                            - 2024-08-31 21:14:54,670 - logic_logger - INF\n..Order[11078] {AfterFlush Event} Id: 11078, CustomerId: ALFKI, EmployeeId: 1, OrderDate: 2024-08-31 21:14:54.637311, RequiredDate: None, ShippedDate: None, ShipVia: None, Freight: 11, ShipName: None, ShipAddress: None, ShipCity: None, ShipRegion: None, ShipZip: None, ShipCountry: None, AmountTotal: 56.0000000000, Country: None, City: None, Ready: True, OrderDetailCount: 2, CloneFromOrder: None  row: 0x1207d7ce0  session: 0x1207d6f30  ins_upd_dlt: ins - 2024-08-31 21:14:54,670 - logic_logger - INF\n..Order[11078] {Sending Order to Shipping &lt;&lt; not activated &gt;&gt;} Id: 11078, CustomerId: ALFKI, EmployeeId: 1, OrderDate: 2024-08-31 21:14:54.637311, RequiredDate: None, ShippedDate: None, ShipVia: None, Freight: 11, ShipName: None, ShipAddress: None, ShipCity: None, ShipRegion: None, ShipZip: None, ShipCountry: None, AmountTotal: 56.0000000000, Country: None, City: None, Ready: True, OrderDetailCount: 2, CloneFromOrder: None  row: 0x1207d7ce0  session: 0x1207d6f30  ins_upd_dlt: ins - 2024-08-31 21:14:54,674 - logic_logger - INF\n</code></pre></p> <p> </p>"},{"location":"Behave-Logic-Report/#scenario-bad-ship-of-empty-order","title":"Scenario: Bad Ship of Empty Order","text":"<p>\u2003  Scenario: Bad Ship of Empty Order \u2003\u2003    Given Customer Account: ALFKI \u2003\u2003    When Order Shipped with no Items \u2003\u2003    Then Rejected per Do Not Ship Empty Orders  </p> Tests - and their logic - are transparent.. click to see Logic <p> </p> <p>Logic Doc for scenario: Bad Ship of Empty Order</p> <p>Reuse the rules for Good Order...</p> <p>Familiar logic patterns:</p> <ul> <li>Constrain a derived result</li> <li>Counts as existence checks</li> </ul> <p>Logic Design (\"Cocktail Napkin Design\")</p> <ul> <li>Constraint: do_not_ship_empty_orders()</li> <li>Order.OrderDetailCount = count(OrderDetail)</li> </ul> <p> </p> <p>Rules Used in Scenario: Bad Ship of Empty Order  Logic Log in Scenario: Bad Ship of Empty Order <pre><code>Logic Phase:        ROW LOGIC       (session=0x121069d60) (sqlalchemy before_flush)          - 2024-08-31 21:14:55,264 - logic_logger - INF\n..Order[None] {Insert - client} Id: None, CustomerId: ALFKI, EmployeeId: 1, OrderDate: None, RequiredDate: None, ShippedDate: 2013-10-13, ShipVia: None, Freight: 10, ShipName: None, ShipAddress: None, ShipCity: None, ShipRegion: None, ShipZip: None, ShipCountry: None, AmountTotal: None, Country: None, City: None, Ready: True, OrderDetailCount: None, CloneFromOrder: None  row: 0x12106a090  session: 0x121069d60  ins_upd_dlt: ins - 2024-08-31 21:14:55,265 - logic_logger - INF\n..Order[None] {server_defaults: OrderDetailCount -- skipped: Ready[BOOLEAN (not handled)] } Id: None, CustomerId: ALFKI, EmployeeId: 1, OrderDate: None, RequiredDate: None, ShippedDate: 2013-10-13, ShipVia: None, Freight: 10, ShipName: None, ShipAddress: None, ShipCity: None, ShipRegion: None, ShipZip: None, ShipCountry: None, AmountTotal: None, Country: None, City: None, Ready: True, OrderDetailCount: 0, CloneFromOrder: None  row: 0x12106a090  session: 0x121069d60  ins_upd_dlt: ins - 2024-08-31 21:14:55,266 - logic_logger - INF\n..Order[None] {Formula OrderDate} Id: None, CustomerId: ALFKI, EmployeeId: 1, OrderDate: 2024-08-31 21:14:55.270516, RequiredDate: None, ShippedDate: 2013-10-13, ShipVia: None, Freight: 10, ShipName: None, ShipAddress: None, ShipCity: None, ShipRegion: None, ShipZip: None, ShipCountry: None, AmountTotal: 0, Country: None, City: None, Ready: True, OrderDetailCount: 0, CloneFromOrder: None  row: 0x12106a090  session: 0x121069d60  ins_upd_dlt: ins - 2024-08-31 21:14:55,270 - logic_logger - INF\n....Customer[ALFKI] {Update - Adjusting Customer: OrderCount} Id: ALFKI, CompanyName: Alfreds Futterkiste, ContactName: Maria Anders, ContactTitle: Sales Representative, Address: Obere Str. 57A, City: Berlin, Region: Western Europe, PostalCode: 12209, Country: Germany, Phone: 030-0074321, Fax: 030-0076545, Balance: 2102.0000000000, CreditLimit: 2300.0000000000, OrderCount:  [15--&gt;] 16, UnpaidOrderCount: 10, Client_id: 1  row: 0x12106b260  session: 0x121069d60  ins_upd_dlt: upd - 2024-08-31 21:14:55,271 - logic_logger - INF\nLogic Phase:        COMMIT LOGIC        (session=0x121069d60)                                            - 2024-08-31 21:14:55,274 - logic_logger - INF\n..Order[None] {Commit Event} Id: None, CustomerId: ALFKI, EmployeeId: 1, OrderDate: 2024-08-31 21:14:55.270516, RequiredDate: None, ShippedDate: 2013-10-13, ShipVia: None, Freight: 10, ShipName: None, ShipAddress: None, ShipCity: None, ShipRegion: None, ShipZip: None, ShipCountry: None, AmountTotal: 0, Country: None, City: None, Ready: True, OrderDetailCount: 0, CloneFromOrder: None  row: 0x12106a090  session: 0x121069d60  ins_upd_dlt: ins - 2024-08-31 21:14:55,274 - logic_logger - INF\n..Order[None] {Hi, Andrew - Congratulate Nancy on their new order} Id: None, CustomerId: ALFKI, EmployeeId: 1, OrderDate: 2024-08-31 21:14:55.270516, RequiredDate: None, ShippedDate: 2013-10-13, ShipVia: None, Freight: 10, ShipName: None, ShipAddress: None, ShipCity: None, ShipRegion: None, ShipZip: None, ShipCountry: None, AmountTotal: 0, Country: None, City: None, Ready: True, OrderDetailCount: 0, CloneFromOrder: None  row: 0x12106a090  session: 0x121069d60  ins_upd_dlt: ins - 2024-08-31 21:14:55,276 - logic_logger - INF\n..Order[None] {Illustrate database access} Id: None, CustomerId: ALFKI, EmployeeId: 1, OrderDate: 2024-08-31 21:14:55.270516, RequiredDate: None, ShippedDate: 2013-10-13, ShipVia: None, Freight: 10, ShipName: None, ShipAddress: None, ShipCity: None, ShipRegion: None, ShipZip: None, ShipCountry: None, AmountTotal: 0, Country: None, City: None, Ready: True, OrderDetailCount: 0, CloneFromOrder: None  row: 0x12106a090  session: 0x121069d60  ins_upd_dlt: ins - 2024-08-31 21:14:55,277 - logic_logger - INF\n..Order[None] {Commit Event} Id: None, CustomerId: ALFKI, EmployeeId: 1, OrderDate: 2024-08-31 21:14:55.270516, RequiredDate: None, ShippedDate: 2013-10-13, ShipVia: None, Freight: 10, ShipName: None, ShipAddress: None, ShipCity: None, ShipRegion: None, ShipZip: None, ShipCountry: None, AmountTotal: 0, Country: None, City: None, Ready: True, OrderDetailCount: 0, CloneFromOrder: None  row: 0x12106a090  session: 0x121069d60  ins_upd_dlt: ins - 2024-08-31 21:14:55,277 - logic_logger - INF\n</code></pre></p> <p> </p>"},{"location":"Behave-Logic-Report/#scenario-bad-order-custom-service","title":"Scenario: Bad Order Custom Service","text":"<p>\u2003  Scenario: Bad Order Custom Service \u2003\u2003    Given Customer Account: ALFKI \u2003\u2003    When Order Placed with excessive quantity \u2003\u2003    Then Rejected per Check Credit  </p> Tests - and their logic - are transparent.. click to see Logic <p> </p> <p>Logic Doc for scenario: Bad Order Custom Service</p> <p>Reuse the rules for Good Order...</p> <p>Familiar logic patterns:</p> <ul> <li>Constrain a derived result</li> <li>Chain up, to adjust parent sum/count aggregates</li> </ul> <p>Logic Design (\"Cocktail Napkin Design\")</p> <ul> <li>Customer.Balance &lt;= CreditLimit</li> <li>Customer.Balance = Sum(Order.AmountTotal where unshipped)</li> <li>Order.AmountTotal = Sum(OrderDetail.Amount)</li> <li>OrderDetail.Amount = Quantity * UnitPrice</li> <li>OrderDetail.UnitPrice = copy from Product</li> </ul> <p> </p> <p>Rules Used in Scenario: Bad Order Custom Service <pre><code>  Customer  \n    1. Derive Customer.UnpaidOrderCount as Count(&lt;class 'database.models.Order'&gt; Where &lt;function declare_logic.&lt;locals&gt;.&lt;lambda&gt; at 0x105744ea0&gt;)  \n    2. Constraint Function: None   \n    3. Derive Customer.Balance as Sum(Order.AmountTotal Where &lt;function declare_logic.&lt;locals&gt;.&lt;lambda&gt; at 0x105623740&gt;)  \n    4. RowEvent Customer.customer_defaults()   \n    5. Derive Customer.OrderCount as Count(&lt;class 'database.models.Order'&gt; Where None)  \n  Order  \n    6. RowEvent Order.order_defaults()   \n    7. Derive Order.OrderDate as Formula (1): as_expression=lambda row: datetime.datetime.now())  \n    8. Derive Order.AmountTotal as Sum(OrderDetail.Amount Where None)  \n    9. Derive Order.OrderDetailCount as Count(&lt;class 'database.models.OrderDetail'&gt; Where None)  \n  OrderDetail  \n    10. RowEvent OrderDetail.order_detail_defaults()   \n    11. Derive OrderDetail.UnitPrice as Copy(Product.UnitPrice)  \n    12. Derive OrderDetail.Amount as Formula (1): as_expression=lambda row: row.UnitPrice * row.Qua [...]  \n    13. Derive OrderDetail.ShippedDate as Formula (2): row.Order.ShippedDate  \n  Product  \n    14. Derive Product.UnitsShipped as Sum(OrderDetail.Quantity Where &lt;function declare_logic.&lt;locals&gt;.&lt;lambda&gt; at 0x105744d60&gt;)  \n    15. Derive Product.UnitsInStock as Formula (1): &lt;function&gt;  \n</code></pre> Logic Log in Scenario: Bad Order Custom Service <pre><code>Logic Phase:        ROW LOGIC       (session=0x121069880) (sqlalchemy before_flush)          - 2024-08-31 21:14:55,444 - logic_logger - INF\n..OrderDetail[None] {Insert - client} Id: None, OrderId: None, ProductId: 1, UnitPrice: None, Quantity: 1111, Discount: 0, Amount: None, ShippedDate: None  row: 0x121069250  session: 0x121069880  ins_upd_dlt: ins - 2024-08-31 21:14:55,445 - logic_logger - INF\n..OrderDetail[None] {copy_rules for role: Product - UnitPrice} Id: None, OrderId: None, ProductId: 1, UnitPrice: 18.0000000000, Quantity: 1111, Discount: 0, Amount: None, ShippedDate: None  row: 0x121069250  session: 0x121069880  ins_upd_dlt: ins - 2024-08-31 21:14:55,457 - logic_logger - INF\n..OrderDetail[None] {Formula Amount} Id: None, OrderId: None, ProductId: 1, UnitPrice: 18.0000000000, Quantity: 1111, Discount: 0, Amount: 19998.0000000000, ShippedDate: None  row: 0x121069250  session: 0x121069880  ins_upd_dlt: ins - 2024-08-31 21:14:55,460 - logic_logger - INF\n....Order[None] {Adjustment logic chaining deferred for this parent parent do_defer_adjustment: True, is_parent_submitted: True, is_parent_row_processed: False, Order} Id: None, CustomerId: ALFKI, EmployeeId: 1, OrderDate: None, RequiredDate: None, ShippedDate: None, ShipVia: None, Freight: 10, ShipName: None, ShipAddress: None, ShipCity: None, ShipRegion: None, ShipZip: None, ShipCountry: None, AmountTotal:  [None--&gt;] 19998.0000000000, Country: None, City: None, Ready: True, OrderDetailCount:  [None--&gt;] 1, CloneFromOrder: None  row: 0x1210695e0  session: 0x121069880  ins_upd_dlt: * - 2024-08-31 21:14:55,465 - logic_logger - INF\n....Product[1] {Update - Adjusting Product: UnitsShipped} Id: 1, ProductName: Chai, SupplierId: 1, CategoryId: 1, QuantityPerUnit: 10 boxes x 20 bags, UnitPrice: 18.0000000000, UnitsInStock: 39, UnitsOnOrder: 0, ReorderLevel: 10, Discontinued: 0, UnitsShipped:  [0--&gt;] 1111  row: 0x121069670  session: 0x121069880  ins_upd_dlt: upd - 2024-08-31 21:14:55,466 - logic_logger - INF\n....Product[1] {Formula UnitsInStock} Id: 1, ProductName: Chai, SupplierId: 1, CategoryId: 1, QuantityPerUnit: 10 boxes x 20 bags, UnitPrice: 18.0000000000, UnitsInStock:  [39--&gt;] -1072, UnitsOnOrder: 0, ReorderLevel: 10, Discontinued: 0, UnitsShipped:  [0--&gt;] 1111  row: 0x121069670  session: 0x121069880  ins_upd_dlt: upd - 2024-08-31 21:14:55,466 - logic_logger - INF\n..Order[None] {Insert - client} Id: None, CustomerId: ALFKI, EmployeeId: 1, OrderDate: None, RequiredDate: None, ShippedDate: None, ShipVia: None, Freight: 10, ShipName: None, ShipAddress: None, ShipCity: None, ShipRegion: None, ShipZip: None, ShipCountry: None, AmountTotal: 19998.0000000000, Country: None, City: None, Ready: True, OrderDetailCount: 1, CloneFromOrder: None  row: 0x1210695e0  session: 0x121069880  ins_upd_dlt: ins - 2024-08-31 21:14:55,468 - logic_logger - INF\n..Order[None] {server_defaults: -- skipped: Ready[BOOLEAN (not handled)] } Id: None, CustomerId: ALFKI, EmployeeId: 1, OrderDate: None, RequiredDate: None, ShippedDate: None, ShipVia: None, Freight: 10, ShipName: None, ShipAddress: None, ShipCity: None, ShipRegion: None, ShipZip: None, ShipCountry: None, AmountTotal: 19998.0000000000, Country: None, City: None, Ready: True, OrderDetailCount: 1, CloneFromOrder: None  row: 0x1210695e0  session: 0x121069880  ins_upd_dlt: ins - 2024-08-31 21:14:55,468 - logic_logger - INF\n..Order[None] {Formula OrderDate} Id: None, CustomerId: ALFKI, EmployeeId: 1, OrderDate: 2024-08-31 21:14:55.472505, RequiredDate: None, ShippedDate: None, ShipVia: None, Freight: 10, ShipName: None, ShipAddress: None, ShipCity: None, ShipRegion: None, ShipZip: None, ShipCountry: None, AmountTotal: 19998.0000000000, Country: None, City: None, Ready: True, OrderDetailCount: 1, CloneFromOrder: None  row: 0x1210695e0  session: 0x121069880  ins_upd_dlt: ins - 2024-08-31 21:14:55,472 - logic_logger - INF\n....Customer[ALFKI] {Update - Adjusting Customer: Balance, UnpaidOrderCount, OrderCount} Id: ALFKI, CompanyName: Alfreds Futterkiste, ContactName: Maria Anders, ContactTitle: Sales Representative, Address: Obere Str. 57A, City: Berlin, Region: Western Europe, PostalCode: 12209, Country: Germany, Phone: 030-0074321, Fax: 030-0076545, Balance:  [2102.0000000000--&gt;] 22100.0000000000, CreditLimit: 2300.0000000000, OrderCount:  [15--&gt;] 16, UnpaidOrderCount:  [10--&gt;] 11, Client_id: 1  row: 0x12106a540  session: 0x121069880  ins_upd_dlt: upd - 2024-08-31 21:14:55,473 - logic_logger - INF\n....Customer[ALFKI] {Constraint Failure: balance (22100.00) exceeds credit (2300.00)} Id: ALFKI, CompanyName: Alfreds Futterkiste, ContactName: Maria Anders, ContactTitle: Sales Representative, Address: Obere Str. 57A, City: Berlin, Region: Western Europe, PostalCode: 12209, Country: Germany, Phone: 030-0074321, Fax: 030-0076545, Balance:  [2102.0000000000--&gt;] 22100.0000000000, CreditLimit: 2300.0000000000, OrderCount:  [15--&gt;] 16, UnpaidOrderCount:  [10--&gt;] 11, Client_id: 1  row: 0x12106a540  session: 0x121069880  ins_upd_dlt: upd - 2024-08-31 21:14:55,474 - logic_logger - INF\n</code></pre></p> <p> </p>"},{"location":"Behave-Logic-Report/#scenario-alter-item-qty-to-exceed-credit","title":"Scenario: Alter Item Qty to exceed credit","text":"<p>\u2003  Scenario: Alter Item Qty to exceed credit \u2003\u2003    Given Customer Account: ALFKI \u2003\u2003    When Order Detail Quantity altered very high \u2003\u2003    Then Rejected per Check Credit  </p> Tests - and their logic - are transparent.. click to see Logic <p> </p> <p>Logic Doc for scenario: Alter Item Qty to exceed credit</p> <p>Same constraint as above.</p> <p>Key Takeaway: Automatic Reuse (design one, solve many)</p> <p> </p> <p>Rules Used in Scenario: Alter Item Qty to exceed credit <pre><code>  Customer  \n    1. Derive Customer.UnpaidOrderCount as Count(&lt;class 'database.models.Order'&gt; Where &lt;function declare_logic.&lt;locals&gt;.&lt;lambda&gt; at 0x105744ea0&gt;)  \n    2. Constraint Function: None   \n    3. Derive Customer.Balance as Sum(Order.AmountTotal Where &lt;function declare_logic.&lt;locals&gt;.&lt;lambda&gt; at 0x105623740&gt;)  \n    4. RowEvent Customer.customer_defaults()   \n    5. Derive Customer.OrderCount as Count(&lt;class 'database.models.Order'&gt; Where None)  \n  Order  \n    6. RowEvent Order.order_defaults()   \n    7. Derive Order.AmountTotal as Sum(OrderDetail.Amount Where None)  \n    8. Derive Order.OrderDetailCount as Count(&lt;class 'database.models.OrderDetail'&gt; Where None)  \n  OrderDetail  \n    9. RowEvent OrderDetail.order_detail_defaults()   \n    10. Derive OrderDetail.Amount as Formula (1): as_expression=lambda row: row.UnitPrice * row.Qua [...]  \n</code></pre> Logic Log in Scenario: Alter Item Qty to exceed credit <pre><code>Logic Phase:        ROW LOGIC       (session=0x1207568a0) (sqlalchemy before_flush)          - 2024-08-31 21:14:55,656 - logic_logger - INF\n..OrderDetail[1040] {Update - client} Id: 1040, OrderId: 10643, ProductId: 28, UnitPrice: 45.6000000000, Quantity:  [15--&gt;] 1110, Discount: 0.25, Amount: 684.0000000000, ShippedDate: None  row: 0x121069130  session: 0x1207568a0  ins_upd_dlt: upd - 2024-08-31 21:14:55,657 - logic_logger - INF\n..OrderDetail[1040] {Formula Amount} Id: 1040, OrderId: 10643, ProductId: 28, UnitPrice: 45.6000000000, Quantity:  [15--&gt;] 1110, Discount: 0.25, Amount:  [684.0000000000--&gt;] 50616.0000000000, ShippedDate: None  row: 0x121069130  session: 0x1207568a0  ins_upd_dlt: upd - 2024-08-31 21:14:55,658 - logic_logger - INF\n..OrderDetail[1040] {Prune Formula: ShippedDate [['Order.ShippedDate']]} Id: 1040, OrderId: 10643, ProductId: 28, UnitPrice: 45.6000000000, Quantity:  [15--&gt;] 1110, Discount: 0.25, Amount:  [684.0000000000--&gt;] 50616.0000000000, ShippedDate: None  row: 0x121069130  session: 0x1207568a0  ins_upd_dlt: upd - 2024-08-31 21:14:55,659 - logic_logger - INF\n....Order[10643] {Update - Adjusting Order: AmountTotal} Id: 10643, CustomerId: ALFKI, EmployeeId: 6, OrderDate: 2013-08-25, RequiredDate: 2013-09-22, ShippedDate: None, ShipVia: 1, Freight: 29.4600000000, ShipName: Alfreds Futterkiste, ShipAddress: Obere Str. 57, ShipCity: Berlin, ShipRegion: Western Europe, ShipZip: 12209, ShipCountry: Germany, AmountTotal:  [1086.00--&gt;] 51018.0000000000, Country: None, City: None, Ready: True, OrderDetailCount: 3, CloneFromOrder: None  row: 0x1207d7020  session: 0x1207568a0  ins_upd_dlt: upd - 2024-08-31 21:14:55,662 - logic_logger - INF\n....Order[10643] {Prune Formula: OrderDate [[]]} Id: 10643, CustomerId: ALFKI, EmployeeId: 6, OrderDate: 2013-08-25, RequiredDate: 2013-09-22, ShippedDate: None, ShipVia: 1, Freight: 29.4600000000, ShipName: Alfreds Futterkiste, ShipAddress: Obere Str. 57, ShipCity: Berlin, ShipRegion: Western Europe, ShipZip: 12209, ShipCountry: Germany, AmountTotal:  [1086.00--&gt;] 51018.0000000000, Country: None, City: None, Ready: True, OrderDetailCount: 3, CloneFromOrder: None  row: 0x1207d7020  session: 0x1207568a0  ins_upd_dlt: upd - 2024-08-31 21:14:55,663 - logic_logger - INF\n......Customer[ALFKI] {Update - Adjusting Customer: Balance} Id: ALFKI, CompanyName: Alfreds Futterkiste, ContactName: Maria Anders, ContactTitle: Sales Representative, Address: Obere Str. 57A, City: Berlin, Region: Western Europe, PostalCode: 12209, Country: Germany, Phone: 030-0074321, Fax: 030-0076545, Balance:  [2102.0000000000--&gt;] 52034.0000000000, CreditLimit: 2300.0000000000, OrderCount: 15, UnpaidOrderCount: 10, Client_id: 1  row: 0x12106acf0  session: 0x1207568a0  ins_upd_dlt: upd - 2024-08-31 21:14:55,665 - logic_logger - INF\n......Customer[ALFKI] {Constraint Failure: balance (52034.00) exceeds credit (2300.00)} Id: ALFKI, CompanyName: Alfreds Futterkiste, ContactName: Maria Anders, ContactTitle: Sales Representative, Address: Obere Str. 57A, City: Berlin, Region: Western Europe, PostalCode: 12209, Country: Germany, Phone: 030-0074321, Fax: 030-0076545, Balance:  [2102.0000000000--&gt;] 52034.0000000000, CreditLimit: 2300.0000000000, OrderCount: 15, UnpaidOrderCount: 10, Client_id: 1  row: 0x12106acf0  session: 0x1207568a0  ins_upd_dlt: upd - 2024-08-31 21:14:55,666 - logic_logger - INF\n</code></pre></p> <p> </p>"},{"location":"Behave-Logic-Report/#scenario-alter-required-date-adjust-logic-pruned","title":"Scenario: Alter Required Date - adjust logic pruned","text":"<p>\u2003  Scenario: Alter Required Date - adjust logic pruned \u2003\u2003    Given Customer Account: ALFKI \u2003\u2003    When Order RequiredDate altered (2013-10-13) \u2003\u2003    Then Balance not adjusted  </p> Tests - and their logic - are transparent.. click to see Logic <p> </p> <p>Logic Doc for scenario: Alter Required Date - adjust logic pruned</p> <p>We set <code>Order.RequiredDate</code>.</p> <p>This is a normal update.  Nothing depends on the columns altered, so this has no effect on the related Customer, Order Details or Products.  Contrast this to the Cascade Update Test and the Custom Service test, where logic chaining affects related rows.  Only the commit event fires.</p> <p>Key Takeaway: rule pruning automatically avoids unnecessary SQL overhead.</p> <p> </p> <p>Rules Used in Scenario: Alter Required Date - adjust logic pruned <pre><code>  Customer  \n    1. Derive Customer.UnpaidOrderCount as Count(&lt;class 'database.models.Order'&gt; Where &lt;function declare_logic.&lt;locals&gt;.&lt;lambda&gt; at 0x105744ea0&gt;)  \n    2. Derive Customer.Balance as Sum(Order.AmountTotal Where &lt;function declare_logic.&lt;locals&gt;.&lt;lambda&gt; at 0x105623740&gt;)  \n    3. Derive Customer.OrderCount as Count(&lt;class 'database.models.Order'&gt; Where None)  \n  Order  \n    4. RowEvent Order.order_defaults()   \n    5. RowEvent Order.clone_order()   \n    6. RowEvent Order.congratulate_sales_rep()   \n    7. RowEvent Order.do_not_ship_empty_orders()   \n    8. RowEvent Order.send_order_to_shipping()   \n</code></pre> Logic Log in Scenario: Alter Required Date - adjust logic pruned <pre><code>Logic Phase:        ROW LOGIC       (session=0x1210402c0) (sqlalchemy before_flush)          - 2024-08-31 21:14:55,849 - logic_logger - INF\n..Order[10643] {Update - client} Id: 10643, CustomerId: ALFKI, EmployeeId: 6, OrderDate: 2013-08-25, RequiredDate:  [2013-09-22--&gt;] 2013-10-13 00:00:00, ShippedDate: None, ShipVia: 1, Freight: 29.4600000000, ShipName: Alfreds Futterkiste, ShipAddress: Obere Str. 57, ShipCity: Berlin, ShipRegion: Western Europe, ShipZip: 12209, ShipCountry: Germany, AmountTotal: 1086.00, Country: None, City: None, Ready: True, OrderDetailCount: 3, CloneFromOrder: None  row: 0x12106bb30  session: 0x1210402c0  ins_upd_dlt: upd - 2024-08-31 21:14:55,850 - logic_logger - INF\n..Order[10643] {Prune Formula: OrderDate [[]]} Id: 10643, CustomerId: ALFKI, EmployeeId: 6, OrderDate: 2013-08-25, RequiredDate:  [2013-09-22--&gt;] 2013-10-13 00:00:00, ShippedDate: None, ShipVia: 1, Freight: 29.4600000000, ShipName: Alfreds Futterkiste, ShipAddress: Obere Str. 57, ShipCity: Berlin, ShipRegion: Western Europe, ShipZip: 12209, ShipCountry: Germany, AmountTotal: 1086.00, Country: None, City: None, Ready: True, OrderDetailCount: 3, CloneFromOrder: None  row: 0x12106bb30  session: 0x1210402c0  ins_upd_dlt: upd - 2024-08-31 21:14:55,852 - logic_logger - INF\nLogic Phase:        COMMIT LOGIC        (session=0x1210402c0)                                            - 2024-08-31 21:14:55,854 - logic_logger - INF\n..Order[10643] {Commit Event} Id: 10643, CustomerId: ALFKI, EmployeeId: 6, OrderDate: 2013-08-25, RequiredDate:  [2013-09-22--&gt;] 2013-10-13 00:00:00, ShippedDate: None, ShipVia: 1, Freight: 29.4600000000, ShipName: Alfreds Futterkiste, ShipAddress: Obere Str. 57, ShipCity: Berlin, ShipRegion: Western Europe, ShipZip: 12209, ShipCountry: Germany, AmountTotal: 1086.00, Country: None, City: None, Ready: True, OrderDetailCount: 3, CloneFromOrder: None  row: 0x12106bb30  session: 0x1210402c0  ins_upd_dlt: upd - 2024-08-31 21:14:55,854 - logic_logger - INF\n..Order[10643] {Commit Event} Id: 10643, CustomerId: ALFKI, EmployeeId: 6, OrderDate: 2013-08-25, RequiredDate:  [2013-09-22--&gt;] 2013-10-13 00:00:00, ShippedDate: None, ShipVia: 1, Freight: 29.4600000000, ShipName: Alfreds Futterkiste, ShipAddress: Obere Str. 57, ShipCity: Berlin, ShipRegion: Western Europe, ShipZip: 12209, ShipCountry: Germany, AmountTotal: 1086.00, Country: None, City: None, Ready: True, OrderDetailCount: 3, CloneFromOrder: None  row: 0x12106bb30  session: 0x1210402c0  ins_upd_dlt: upd - 2024-08-31 21:14:55,854 - logic_logger - INF\nLogic Phase:        AFTER_FLUSH LOGIC   (session=0x1210402c0)                                            - 2024-08-31 21:14:55,857 - logic_logger - INF\n..Order[10643] {AfterFlush Event} Id: 10643, CustomerId: ALFKI, EmployeeId: 6, OrderDate: 2013-08-25, RequiredDate:  [2013-09-22--&gt;] 2013-10-13 00:00:00, ShippedDate: None, ShipVia: 1, Freight: 29.4600000000, ShipName: Alfreds Futterkiste, ShipAddress: Obere Str. 57, ShipCity: Berlin, ShipRegion: Western Europe, ShipZip: 12209, ShipCountry: Germany, AmountTotal: 1086.00, Country: None, City: None, Ready: True, OrderDetailCount: 3, CloneFromOrder: None  row: 0x12106bb30  session: 0x1210402c0  ins_upd_dlt: upd - 2024-08-31 21:14:55,857 - logic_logger - INF\n</code></pre></p> <p> </p>"},{"location":"Behave-Logic-Report/#scenario-set-shipped-adjust-logic-reuse","title":"Scenario: Set Shipped - adjust logic reuse","text":"<p>\u2003  Scenario: Set Shipped - adjust logic reuse \u2003\u2003    Given Customer Account: ALFKI \u2003\u2003    When Order ShippedDate altered (2013-10-13) \u2003\u2003    Then Balance reduced 1086 \u2003\u2003    Then Product[46] UnitsInStock adjusted  </p> Tests - and their logic - are transparent.. click to see Logic <p> </p> <p>Logic Doc for scenario: Set Shipped - adjust logic reuse</p> <p>Logic Patterns:</p> <ul> <li>Chain Down</li> </ul> <p>Logic Design (\"Cocktail Napkin Design\")</p> <ul> <li>Formula: OrderDetail.ShippedDate = Order.ShippedDate</li> </ul> <p>We set <code>Order.ShippedDate</code>.</p> <p>This cascades to the Order Details, per the <code>derive=models.OrderDetail.ShippedDate</code> rule.</p> <p>This chains to adjust the <code>Product.UnitsShipped</code> and recomputes <code>UnitsInStock</code>, as above</p> <p>Key Takeaway: parent references (e.g., <code>OrderDetail.ShippedDate</code>) automate chain-down multi-table transactions.</p> <p>Key Takeaway: Automatic Reuse (design one, solve many)</p> <p> </p> <p>Rules Used in Scenario: Set Shipped - adjust logic reuse <pre><code>  Customer  \n    1. Derive Customer.UnpaidOrderCount as Count(&lt;class 'database.models.Order'&gt; Where &lt;function declare_logic.&lt;locals&gt;.&lt;lambda&gt; at 0x105744ea0&gt;)  \n    2. Derive Customer.Balance as Sum(Order.AmountTotal Where &lt;function declare_logic.&lt;locals&gt;.&lt;lambda&gt; at 0x105623740&gt;)  \n    3. RowEvent Customer.customer_defaults()   \n    4. Derive Customer.OrderCount as Count(&lt;class 'database.models.Order'&gt; Where None)  \n  Order  \n    5. RowEvent Order.order_defaults()   \n    6. RowEvent Order.do_not_ship_empty_orders()   \n    7. Derive Order.AmountTotal as Sum(OrderDetail.Amount Where None)  \n    8. RowEvent Order.clone_order()   \n    9. RowEvent Order.congratulate_sales_rep()   \n    10. Derive Order.OrderDetailCount as Count(&lt;class 'database.models.OrderDetail'&gt; Where None)  \n    11. RowEvent Order.send_order_to_shipping()   \n  OrderDetail  \n    12. RowEvent OrderDetail.order_detail_defaults()   \n    13. Derive OrderDetail.ShippedDate as Formula (2): row.Order.ShippedDate  \n  Product  \n    14. Derive Product.UnitsShipped as Sum(OrderDetail.Quantity Where &lt;function declare_logic.&lt;locals&gt;.&lt;lambda&gt; at 0x105744d60&gt;)  \n    15. Derive Product.UnitsInStock as Formula (1): &lt;function&gt;  \n</code></pre> Logic Log in Scenario: Set Shipped - adjust logic reuse <pre><code>Logic Phase:        ROW LOGIC       (session=0x121109430) (sqlalchemy before_flush)          - 2024-08-31 21:14:56,232 - logic_logger - INF\n..Order[10643] {Update - client} Id: 10643, CustomerId: ALFKI, EmployeeId: 6, OrderDate: 2013-08-25, RequiredDate: 2013-10-13, ShippedDate:  [None--&gt;] 2013-10-13, ShipVia: 1, Freight: 29.4600000000, ShipName: Alfreds Futterkiste, ShipAddress: Obere Str. 57, ShipCity: Berlin, ShipRegion: Western Europe, ShipZip: 12209, ShipCountry: Germany, AmountTotal: 1086.00, Country: None, City: None, Ready: True, OrderDetailCount: 3, CloneFromOrder: None  row: 0x1210f98b0  session: 0x121109430  ins_upd_dlt: upd - 2024-08-31 21:14:56,233 - logic_logger - INF\n..Order[10643] {Prune Formula: OrderDate [[]]} Id: 10643, CustomerId: ALFKI, EmployeeId: 6, OrderDate: 2013-08-25, RequiredDate: 2013-10-13, ShippedDate:  [None--&gt;] 2013-10-13, ShipVia: 1, Freight: 29.4600000000, ShipName: Alfreds Futterkiste, ShipAddress: Obere Str. 57, ShipCity: Berlin, ShipRegion: Western Europe, ShipZip: 12209, ShipCountry: Germany, AmountTotal: 1086.00, Country: None, City: None, Ready: True, OrderDetailCount: 3, CloneFromOrder: None  row: 0x1210f98b0  session: 0x121109430  ins_upd_dlt: upd - 2024-08-31 21:14:56,234 - logic_logger - INF\n....Customer[ALFKI] {Update - Adjusting Customer: Balance, UnpaidOrderCount} Id: ALFKI, CompanyName: Alfreds Futterkiste, ContactName: Maria Anders, ContactTitle: Sales Representative, Address: Obere Str. 57A, City: Berlin, Region: Western Europe, PostalCode: 12209, Country: Germany, Phone: 030-0074321, Fax: 030-0076545, Balance:  [2102.0000000000--&gt;] 1016.0000000000, CreditLimit: 2300.0000000000, OrderCount: 15, UnpaidOrderCount:  [10--&gt;] 9, Client_id: 1  row: 0x12110a3c0  session: 0x121109430  ins_upd_dlt: upd - 2024-08-31 21:14:56,236 - logic_logger - INF\n....OrderDetail[1040] {Update - Cascading Order.ShippedDate (,...)} Id: 1040, OrderId: 10643, ProductId: 28, UnitPrice: 45.6000000000, Quantity: 15, Discount: 0.25, Amount: 684.0000000000, ShippedDate: None  row: 0x1211094c0  session: 0x121109430  ins_upd_dlt: upd - 2024-08-31 21:14:56,241 - logic_logger - INF\n....OrderDetail[1040] {Prune Formula: Amount [['UnitPrice', 'Quantity']]} Id: 1040, OrderId: 10643, ProductId: 28, UnitPrice: 45.6000000000, Quantity: 15, Discount: 0.25, Amount: 684.0000000000, ShippedDate: None  row: 0x1211094c0  session: 0x121109430  ins_upd_dlt: upd - 2024-08-31 21:14:56,241 - logic_logger - INF\n....OrderDetail[1040] {Formula ShippedDate} Id: 1040, OrderId: 10643, ProductId: 28, UnitPrice: 45.6000000000, Quantity: 15, Discount: 0.25, Amount: 684.0000000000, ShippedDate:  [None--&gt;] 2013-10-13  row: 0x1211094c0  session: 0x121109430  ins_upd_dlt: upd - 2024-08-31 21:14:56,242 - logic_logger - INF\n......Product[28] {Update - Adjusting Product: UnitsShipped} Id: 28, ProductName: R\u00f6ssle Sauerkraut, SupplierId: 12, CategoryId: 7, QuantityPerUnit: 25 - 825 g cans, UnitPrice: 45.6000000000, UnitsInStock: 26, UnitsOnOrder: 0, ReorderLevel: 0, Discontinued: 1, UnitsShipped:  [0--&gt;] -15  row: 0x12110b1a0  session: 0x121109430  ins_upd_dlt: upd - 2024-08-31 21:14:56,244 - logic_logger - INF\n......Product[28] {Formula UnitsInStock} Id: 28, ProductName: R\u00f6ssle Sauerkraut, SupplierId: 12, CategoryId: 7, QuantityPerUnit: 25 - 825 g cans, UnitPrice: 45.6000000000, UnitsInStock:  [26--&gt;] 41, UnitsOnOrder: 0, ReorderLevel: 0, Discontinued: 1, UnitsShipped:  [0--&gt;] -15  row: 0x12110b1a0  session: 0x121109430  ins_upd_dlt: upd - 2024-08-31 21:14:56,244 - logic_logger - INF\n....OrderDetail[1041] {Update - Cascading Order.ShippedDate (,...)} Id: 1041, OrderId: 10643, ProductId: 39, UnitPrice: 18.0000000000, Quantity: 21, Discount: 0.25, Amount: 378.0000000000, ShippedDate: None  row: 0x12110a330  session: 0x121109430  ins_upd_dlt: upd - 2024-08-31 21:14:56,246 - logic_logger - INF\n....OrderDetail[1041] {Prune Formula: Amount [['UnitPrice', 'Quantity']]} Id: 1041, OrderId: 10643, ProductId: 39, UnitPrice: 18.0000000000, Quantity: 21, Discount: 0.25, Amount: 378.0000000000, ShippedDate: None  row: 0x12110a330  session: 0x121109430  ins_upd_dlt: upd - 2024-08-31 21:14:56,246 - logic_logger - INF\n....OrderDetail[1041] {Formula ShippedDate} Id: 1041, OrderId: 10643, ProductId: 39, UnitPrice: 18.0000000000, Quantity: 21, Discount: 0.25, Amount: 378.0000000000, ShippedDate:  [None--&gt;] 2013-10-13  row: 0x12110a330  session: 0x121109430  ins_upd_dlt: upd - 2024-08-31 21:14:56,247 - logic_logger - INF\n......Product[39] {Update - Adjusting Product: UnitsShipped} Id: 39, ProductName: Chartreuse verte, SupplierId: 18, CategoryId: 1, QuantityPerUnit: 750 cc per bottle, UnitPrice: 18.0000000000, UnitsInStock: 69, UnitsOnOrder: 0, ReorderLevel: 5, Discontinued: 0, UnitsShipped:  [0--&gt;] -21  row: 0x121108fb0  session: 0x121109430  ins_upd_dlt: upd - 2024-08-31 21:14:56,248 - logic_logger - INF\n......Product[39] {Formula UnitsInStock} Id: 39, ProductName: Chartreuse verte, SupplierId: 18, CategoryId: 1, QuantityPerUnit: 750 cc per bottle, UnitPrice: 18.0000000000, UnitsInStock:  [69--&gt;] 90, UnitsOnOrder: 0, ReorderLevel: 5, Discontinued: 0, UnitsShipped:  [0--&gt;] -21  row: 0x121108fb0  session: 0x121109430  ins_upd_dlt: upd - 2024-08-31 21:14:56,249 - logic_logger - INF\n....OrderDetail[1042] {Update - Cascading Order.ShippedDate (,...)} Id: 1042, OrderId: 10643, ProductId: 46, UnitPrice: 12.0000000000, Quantity: 2, Discount: 0.25, Amount: 24.0000000000, ShippedDate: None  row: 0x121109fd0  session: 0x121109430  ins_upd_dlt: upd - 2024-08-31 21:14:56,250 - logic_logger - INF\n....OrderDetail[1042] {Prune Formula: Amount [['UnitPrice', 'Quantity']]} Id: 1042, OrderId: 10643, ProductId: 46, UnitPrice: 12.0000000000, Quantity: 2, Discount: 0.25, Amount: 24.0000000000, ShippedDate: None  row: 0x121109fd0  session: 0x121109430  ins_upd_dlt: upd - 2024-08-31 21:14:56,251 - logic_logger - INF\n....OrderDetail[1042] {Formula ShippedDate} Id: 1042, OrderId: 10643, ProductId: 46, UnitPrice: 12.0000000000, Quantity: 2, Discount: 0.25, Amount: 24.0000000000, ShippedDate:  [None--&gt;] 2013-10-13  row: 0x121109fd0  session: 0x121109430  ins_upd_dlt: upd - 2024-08-31 21:14:56,251 - logic_logger - INF\n......Product[46] {Update - Adjusting Product: UnitsShipped} Id: 46, ProductName: Spegesild, SupplierId: 21, CategoryId: 8, QuantityPerUnit: 4 - 450 g glasses, UnitPrice: 12.0000000000, UnitsInStock: 95, UnitsOnOrder: 0, ReorderLevel: 0, Discontinued: 0, UnitsShipped:  [0--&gt;] -2  row: 0x12110ad20  session: 0x121109430  ins_upd_dlt: upd - 2024-08-31 21:14:56,253 - logic_logger - INF\n......Product[46] {Formula UnitsInStock} Id: 46, ProductName: Spegesild, SupplierId: 21, CategoryId: 8, QuantityPerUnit: 4 - 450 g glasses, UnitPrice: 12.0000000000, UnitsInStock:  [95--&gt;] 97, UnitsOnOrder: 0, ReorderLevel: 0, Discontinued: 0, UnitsShipped:  [0--&gt;] -2  row: 0x12110ad20  session: 0x121109430  ins_upd_dlt: upd - 2024-08-31 21:14:56,253 - logic_logger - INF\nLogic Phase:        COMMIT LOGIC        (session=0x121109430)                                            - 2024-08-31 21:14:56,254 - logic_logger - INF\n..Order[10643] {Commit Event} Id: 10643, CustomerId: ALFKI, EmployeeId: 6, OrderDate: 2013-08-25, RequiredDate: 2013-10-13, ShippedDate:  [None--&gt;] 2013-10-13, ShipVia: 1, Freight: 29.4600000000, ShipName: Alfreds Futterkiste, ShipAddress: Obere Str. 57, ShipCity: Berlin, ShipRegion: Western Europe, ShipZip: 12209, ShipCountry: Germany, AmountTotal: 1086.00, Country: None, City: None, Ready: True, OrderDetailCount: 3, CloneFromOrder: None  row: 0x1210f98b0  session: 0x121109430  ins_upd_dlt: upd - 2024-08-31 21:14:56,256 - logic_logger - INF\n..Order[10643] {Commit Event} Id: 10643, CustomerId: ALFKI, EmployeeId: 6, OrderDate: 2013-08-25, RequiredDate: 2013-10-13, ShippedDate:  [None--&gt;] 2013-10-13, ShipVia: 1, Freight: 29.4600000000, ShipName: Alfreds Futterkiste, ShipAddress: Obere Str. 57, ShipCity: Berlin, ShipRegion: Western Europe, ShipZip: 12209, ShipCountry: Germany, AmountTotal: 1086.00, Country: None, City: None, Ready: True, OrderDetailCount: 3, CloneFromOrder: None  row: 0x1210f98b0  session: 0x121109430  ins_upd_dlt: upd - 2024-08-31 21:14:56,256 - logic_logger - INF\nLogic Phase:        AFTER_FLUSH LOGIC   (session=0x121109430)                                            - 2024-08-31 21:14:56,262 - logic_logger - INF\n..Order[10643] {AfterFlush Event} Id: 10643, CustomerId: ALFKI, EmployeeId: 6, OrderDate: 2013-08-25, RequiredDate: 2013-10-13, ShippedDate:  [None--&gt;] 2013-10-13, ShipVia: 1, Freight: 29.4600000000, ShipName: Alfreds Futterkiste, ShipAddress: Obere Str. 57, ShipCity: Berlin, ShipRegion: Western Europe, ShipZip: 12209, ShipCountry: Germany, AmountTotal: 1086.00, Country: None, City: None, Ready: True, OrderDetailCount: 3, CloneFromOrder: None  row: 0x1210f98b0  session: 0x121109430  ins_upd_dlt: upd - 2024-08-31 21:14:56,263 - logic_logger - INF\n</code></pre></p> <p> </p>"},{"location":"Behave-Logic-Report/#scenario-reset-shipped-adjust-logic-reuse","title":"Scenario: Reset Shipped - adjust logic reuse","text":"<p>\u2003  Scenario: Reset Shipped - adjust logic reuse \u2003\u2003    Given Shipped Order \u2003\u2003    When Order ShippedDate set to None \u2003\u2003    Then Logic adjusts Balance by -1086  </p> Tests - and their logic - are transparent.. click to see Logic <p> </p> <p>Logic Doc for scenario: Reset Shipped - adjust logic reuse</p> <p>Same logic as above.</p> <p>Key Takeaway: Automatic Reuse (design one, solve many)</p> <p> </p> <p>Rules Used in Scenario: Reset Shipped - adjust logic reuse <pre><code>  Customer  \n    1. Derive Customer.UnpaidOrderCount as Count(&lt;class 'database.models.Order'&gt; Where &lt;function declare_logic.&lt;locals&gt;.&lt;lambda&gt; at 0x105744ea0&gt;)  \n    2. Derive Customer.Balance as Sum(Order.AmountTotal Where &lt;function declare_logic.&lt;locals&gt;.&lt;lambda&gt; at 0x105623740&gt;)  \n    3. RowEvent Customer.customer_defaults()   \n    4. Derive Customer.OrderCount as Count(&lt;class 'database.models.Order'&gt; Where None)  \n  Order  \n    5. RowEvent Order.order_defaults()   \n    6. RowEvent Order.do_not_ship_empty_orders()   \n    7. Derive Order.AmountTotal as Sum(OrderDetail.Amount Where None)  \n    8. RowEvent Order.clone_order()   \n    9. RowEvent Order.congratulate_sales_rep()   \n    10. Derive Order.OrderDetailCount as Count(&lt;class 'database.models.OrderDetail'&gt; Where None)  \n    11. RowEvent Order.send_order_to_shipping()   \n  OrderDetail  \n    12. RowEvent OrderDetail.order_detail_defaults()   \n    13. Derive OrderDetail.ShippedDate as Formula (2): row.Order.ShippedDate  \n  Product  \n    14. Derive Product.UnitsShipped as Sum(OrderDetail.Quantity Where &lt;function declare_logic.&lt;locals&gt;.&lt;lambda&gt; at 0x105744d60&gt;)  \n    15. Derive Product.UnitsInStock as Formula (1): &lt;function&gt;  \n</code></pre> Logic Log in Scenario: Reset Shipped - adjust logic reuse <pre><code>Logic Phase:        ROW LOGIC       (session=0x121042900) (sqlalchemy before_flush)          - 2024-08-31 21:14:56,658 - logic_logger - INF\n..Order[10643] {Update - client} Id: 10643, CustomerId: ALFKI, EmployeeId: 6, OrderDate: 2013-08-25, RequiredDate: 2013-10-13, ShippedDate:  [2013-10-13--&gt;] None, ShipVia: 1, Freight: 29.4600000000, ShipName: Alfreds Futterkiste, ShipAddress: Obere Str. 57, ShipCity: Berlin, ShipRegion: Western Europe, ShipZip: 12209, ShipCountry: Germany, AmountTotal: 1086.00, Country: None, City: None, Ready: True, OrderDetailCount: 3, CloneFromOrder: None  row: 0x1210fa4e0  session: 0x121042900  ins_upd_dlt: upd - 2024-08-31 21:14:56,659 - logic_logger - INF\n..Order[10643] {Prune Formula: OrderDate [[]]} Id: 10643, CustomerId: ALFKI, EmployeeId: 6, OrderDate: 2013-08-25, RequiredDate: 2013-10-13, ShippedDate:  [2013-10-13--&gt;] None, ShipVia: 1, Freight: 29.4600000000, ShipName: Alfreds Futterkiste, ShipAddress: Obere Str. 57, ShipCity: Berlin, ShipRegion: Western Europe, ShipZip: 12209, ShipCountry: Germany, AmountTotal: 1086.00, Country: None, City: None, Ready: True, OrderDetailCount: 3, CloneFromOrder: None  row: 0x1210fa4e0  session: 0x121042900  ins_upd_dlt: upd - 2024-08-31 21:14:56,660 - logic_logger - INF\n....Customer[ALFKI] {Update - Adjusting Customer: Balance, UnpaidOrderCount} Id: ALFKI, CompanyName: Alfreds Futterkiste, ContactName: Maria Anders, ContactTitle: Sales Representative, Address: Obere Str. 57A, City: Berlin, Region: Western Europe, PostalCode: 12209, Country: Germany, Phone: 030-0074321, Fax: 030-0076545, Balance:  [1016.0000000000--&gt;] 2102.0000000000, CreditLimit: 2300.0000000000, OrderCount: 15, UnpaidOrderCount:  [9--&gt;] 10, Client_id: 1  row: 0x12106a570  session: 0x121042900  ins_upd_dlt: upd - 2024-08-31 21:14:56,662 - logic_logger - INF\n....OrderDetail[1040] {Update - Cascading Order.ShippedDate (,...)} Id: 1040, OrderId: 10643, ProductId: 28, UnitPrice: 45.6000000000, Quantity: 15, Discount: 0.25, Amount: 684.0000000000, ShippedDate: 2013-10-13  row: 0x12106ac60  session: 0x121042900  ins_upd_dlt: upd - 2024-08-31 21:14:56,666 - logic_logger - INF\n....OrderDetail[1040] {Prune Formula: Amount [['UnitPrice', 'Quantity']]} Id: 1040, OrderId: 10643, ProductId: 28, UnitPrice: 45.6000000000, Quantity: 15, Discount: 0.25, Amount: 684.0000000000, ShippedDate: 2013-10-13  row: 0x12106ac60  session: 0x121042900  ins_upd_dlt: upd - 2024-08-31 21:14:56,667 - logic_logger - INF\n....OrderDetail[1040] {Formula ShippedDate} Id: 1040, OrderId: 10643, ProductId: 28, UnitPrice: 45.6000000000, Quantity: 15, Discount: 0.25, Amount: 684.0000000000, ShippedDate:  [2013-10-13--&gt;] None  row: 0x12106ac60  session: 0x121042900  ins_upd_dlt: upd - 2024-08-31 21:14:56,667 - logic_logger - INF\n......Product[28] {Update - Adjusting Product: UnitsShipped} Id: 28, ProductName: R\u00f6ssle Sauerkraut, SupplierId: 12, CategoryId: 7, QuantityPerUnit: 25 - 825 g cans, UnitPrice: 45.6000000000, UnitsInStock: 41, UnitsOnOrder: 0, ReorderLevel: 0, Discontinued: 1, UnitsShipped:  [-15--&gt;] 0  row: 0x1211097c0  session: 0x121042900  ins_upd_dlt: upd - 2024-08-31 21:14:56,669 - logic_logger - INF\n......Product[28] {Formula UnitsInStock} Id: 28, ProductName: R\u00f6ssle Sauerkraut, SupplierId: 12, CategoryId: 7, QuantityPerUnit: 25 - 825 g cans, UnitPrice: 45.6000000000, UnitsInStock:  [41--&gt;] 26, UnitsOnOrder: 0, ReorderLevel: 0, Discontinued: 1, UnitsShipped:  [-15--&gt;] 0  row: 0x1211097c0  session: 0x121042900  ins_upd_dlt: upd - 2024-08-31 21:14:56,670 - logic_logger - INF\n....OrderDetail[1041] {Update - Cascading Order.ShippedDate (,...)} Id: 1041, OrderId: 10643, ProductId: 39, UnitPrice: 18.0000000000, Quantity: 21, Discount: 0.25, Amount: 378.0000000000, ShippedDate: 2013-10-13  row: 0x12106a960  session: 0x121042900  ins_upd_dlt: upd - 2024-08-31 21:14:56,671 - logic_logger - INF\n....OrderDetail[1041] {Prune Formula: Amount [['UnitPrice', 'Quantity']]} Id: 1041, OrderId: 10643, ProductId: 39, UnitPrice: 18.0000000000, Quantity: 21, Discount: 0.25, Amount: 378.0000000000, ShippedDate: 2013-10-13  row: 0x12106a960  session: 0x121042900  ins_upd_dlt: upd - 2024-08-31 21:14:56,672 - logic_logger - INF\n....OrderDetail[1041] {Formula ShippedDate} Id: 1041, OrderId: 10643, ProductId: 39, UnitPrice: 18.0000000000, Quantity: 21, Discount: 0.25, Amount: 378.0000000000, ShippedDate:  [2013-10-13--&gt;] None  row: 0x12106a960  session: 0x121042900  ins_upd_dlt: upd - 2024-08-31 21:14:56,672 - logic_logger - INF\n......Product[39] {Update - Adjusting Product: UnitsShipped} Id: 39, ProductName: Chartreuse verte, SupplierId: 18, CategoryId: 1, QuantityPerUnit: 750 cc per bottle, UnitPrice: 18.0000000000, UnitsInStock: 90, UnitsOnOrder: 0, ReorderLevel: 5, Discontinued: 0, UnitsShipped:  [-21--&gt;] 0  row: 0x12110aa50  session: 0x121042900  ins_upd_dlt: upd - 2024-08-31 21:14:56,673 - logic_logger - INF\n......Product[39] {Formula UnitsInStock} Id: 39, ProductName: Chartreuse verte, SupplierId: 18, CategoryId: 1, QuantityPerUnit: 750 cc per bottle, UnitPrice: 18.0000000000, UnitsInStock:  [90--&gt;] 69, UnitsOnOrder: 0, ReorderLevel: 5, Discontinued: 0, UnitsShipped:  [-21--&gt;] 0  row: 0x12110aa50  session: 0x121042900  ins_upd_dlt: upd - 2024-08-31 21:14:56,674 - logic_logger - INF\n....OrderDetail[1042] {Update - Cascading Order.ShippedDate (,...)} Id: 1042, OrderId: 10643, ProductId: 46, UnitPrice: 12.0000000000, Quantity: 2, Discount: 0.25, Amount: 24.0000000000, ShippedDate: 2013-10-13  row: 0x12106ba40  session: 0x121042900  ins_upd_dlt: upd - 2024-08-31 21:14:56,675 - logic_logger - INF\n....OrderDetail[1042] {Prune Formula: Amount [['UnitPrice', 'Quantity']]} Id: 1042, OrderId: 10643, ProductId: 46, UnitPrice: 12.0000000000, Quantity: 2, Discount: 0.25, Amount: 24.0000000000, ShippedDate: 2013-10-13  row: 0x12106ba40  session: 0x121042900  ins_upd_dlt: upd - 2024-08-31 21:14:56,675 - logic_logger - INF\n....OrderDetail[1042] {Formula ShippedDate} Id: 1042, OrderId: 10643, ProductId: 46, UnitPrice: 12.0000000000, Quantity: 2, Discount: 0.25, Amount: 24.0000000000, ShippedDate:  [2013-10-13--&gt;] None  row: 0x12106ba40  session: 0x121042900  ins_upd_dlt: upd - 2024-08-31 21:14:56,676 - logic_logger - INF\n......Product[46] {Update - Adjusting Product: UnitsShipped} Id: 46, ProductName: Spegesild, SupplierId: 21, CategoryId: 8, QuantityPerUnit: 4 - 450 g glasses, UnitPrice: 12.0000000000, UnitsInStock: 97, UnitsOnOrder: 0, ReorderLevel: 0, Discontinued: 0, UnitsShipped:  [-2--&gt;] 0  row: 0x12110ae70  session: 0x121042900  ins_upd_dlt: upd - 2024-08-31 21:14:56,677 - logic_logger - INF\n......Product[46] {Formula UnitsInStock} Id: 46, ProductName: Spegesild, SupplierId: 21, CategoryId: 8, QuantityPerUnit: 4 - 450 g glasses, UnitPrice: 12.0000000000, UnitsInStock:  [97--&gt;] 95, UnitsOnOrder: 0, ReorderLevel: 0, Discontinued: 0, UnitsShipped:  [-2--&gt;] 0  row: 0x12110ae70  session: 0x121042900  ins_upd_dlt: upd - 2024-08-31 21:14:56,678 - logic_logger - INF\nLogic Phase:        COMMIT LOGIC        (session=0x121042900)                                            - 2024-08-31 21:14:56,679 - logic_logger - INF\n..Order[10643] {Commit Event} Id: 10643, CustomerId: ALFKI, EmployeeId: 6, OrderDate: 2013-08-25, RequiredDate: 2013-10-13, ShippedDate:  [2013-10-13--&gt;] None, ShipVia: 1, Freight: 29.4600000000, ShipName: Alfreds Futterkiste, ShipAddress: Obere Str. 57, ShipCity: Berlin, ShipRegion: Western Europe, ShipZip: 12209, ShipCountry: Germany, AmountTotal: 1086.00, Country: None, City: None, Ready: True, OrderDetailCount: 3, CloneFromOrder: None  row: 0x1210fa4e0  session: 0x121042900  ins_upd_dlt: upd - 2024-08-31 21:14:56,680 - logic_logger - INF\n..Order[10643] {Commit Event} Id: 10643, CustomerId: ALFKI, EmployeeId: 6, OrderDate: 2013-08-25, RequiredDate: 2013-10-13, ShippedDate:  [2013-10-13--&gt;] None, ShipVia: 1, Freight: 29.4600000000, ShipName: Alfreds Futterkiste, ShipAddress: Obere Str. 57, ShipCity: Berlin, ShipRegion: Western Europe, ShipZip: 12209, ShipCountry: Germany, AmountTotal: 1086.00, Country: None, City: None, Ready: True, OrderDetailCount: 3, CloneFromOrder: None  row: 0x1210fa4e0  session: 0x121042900  ins_upd_dlt: upd - 2024-08-31 21:14:56,681 - logic_logger - INF\nLogic Phase:        AFTER_FLUSH LOGIC   (session=0x121042900)                                            - 2024-08-31 21:14:56,685 - logic_logger - INF\n..Order[10643] {AfterFlush Event} Id: 10643, CustomerId: ALFKI, EmployeeId: 6, OrderDate: 2013-08-25, RequiredDate: 2013-10-13, ShippedDate:  [2013-10-13--&gt;] None, ShipVia: 1, Freight: 29.4600000000, ShipName: Alfreds Futterkiste, ShipAddress: Obere Str. 57, ShipCity: Berlin, ShipRegion: Western Europe, ShipZip: 12209, ShipCountry: Germany, AmountTotal: 1086.00, Country: None, City: None, Ready: True, OrderDetailCount: 3, CloneFromOrder: None  row: 0x1210fa4e0  session: 0x121042900  ins_upd_dlt: upd - 2024-08-31 21:14:56,687 - logic_logger - INF\n</code></pre></p> <p> </p>"},{"location":"Behave-Logic-Report/#scenario-clone-existing-order","title":"Scenario: Clone Existing Order","text":"<p>\u2003  Scenario: Clone Existing Order \u2003\u2003    Given Shipped Order \u2003\u2003    When Cloning Existing Order \u2003\u2003    Then Logic Copies ClonedFrom OrderDetails  </p> Tests - and their logic - are transparent.. click to see Logic <p> </p> <p>Logic Doc for scenario: Clone Existing Order</p> <p>We create an order, setting CloneFromOrder.</p> <p>This copies the CloneFromOrder OrderDetails to our new Order.</p> <p>The copy operation is automated using <code>logic_row.copy_children()</code>:</p> <ol> <li> <p><code>place_order.feature</code> defines the test</p> </li> <li> <p><code>place_order.py</code> implements the test.  It uses the API to Post an Order, setting <code>CloneFromOrder</code> to trigger the copy logic</p> </li> <li> <p><code>declare_logic.py</code> implements the logic, by invoking <code>logic_row.copy_children()</code>.  <code>which</code> defines which children to copy, here just <code>OrderDetailList</code></p> </li> </ol> <p><code>CopyChildren</code> For more information, see here</p> <pre><code>Useful in row event handlers to copy multiple children types to self from copy_from children.\n\nchild-spec := &lt; \u2018child-list-name\u2019 | &lt; \u2018child-list-name = parent-list-name\u2019 &gt;\nchild-list-spec := [child-spec | (child-spec, child-list-spec)]\n\nEg. RowEvent on Order\n    which = [\"OrderDetailList\"]\n    logic_row.copy_children(copy_from=row.parent, which_children=which)\n\nEg, test/copy_children:\n    child_list_spec = [\n        (\"MileStoneList\",\n            [\"DeliverableList\"]  # for each Milestone, get the Deliverables\n        ),\n        \"StaffList\"\n    ]\n</code></pre> <p>Key Takeaway: copy_children provides a deep-copy service.</p> <p> </p> <p>Rules Used in Scenario: Clone Existing Order <pre><code>  Customer  \n    1. Derive Customer.UnpaidOrderCount as Count(&lt;class 'database.models.Order'&gt; Where &lt;function declare_logic.&lt;locals&gt;.&lt;lambda&gt; at 0x105744ea0&gt;)  \n    2. Constraint Function: None   \n    3. Derive Customer.Balance as Sum(Order.AmountTotal Where &lt;function declare_logic.&lt;locals&gt;.&lt;lambda&gt; at 0x105623740&gt;)  \n    4. RowEvent Customer.customer_defaults()   \n    5. Derive Customer.OrderCount as Count(&lt;class 'database.models.Order'&gt; Where None)  \n  Order  \n    6. RowEvent Order.order_defaults()   \n    7. Derive Order.OrderDate as Formula (1): as_expression=lambda row: datetime.datetime.now())  \n    8. RowEvent Order.clone_order()   \n    9. Derive Order.AmountTotal as Sum(OrderDetail.Amount Where None)  \n    10. Derive Order.OrderDetailCount as Count(&lt;class 'database.models.OrderDetail'&gt; Where None)  \n  OrderDetail  \n    11. RowEvent OrderDetail.order_detail_defaults()   \n    12. Derive OrderDetail.UnitPrice as Copy(Product.UnitPrice)  \n    13. Derive OrderDetail.Amount as Formula (1): as_expression=lambda row: row.UnitPrice * row.Qua [...]  \n    14. Derive OrderDetail.ShippedDate as Formula (2): row.Order.ShippedDate  \n</code></pre> Logic Log in Scenario: Clone Existing Order <pre><code>Logic Phase:        ROW LOGIC       (session=0x121146a50) (sqlalchemy before_flush)          - 2024-08-31 21:14:57,021 - logic_logger - INF\n..Order[None] {Insert - client} Id: None, CustomerId: ALFKI, EmployeeId: 1, OrderDate: None, RequiredDate: None, ShippedDate: None, ShipVia: None, Freight: 11, ShipName: None, ShipAddress: None, ShipCity: None, ShipRegion: None, ShipZip: None, ShipCountry: None, AmountTotal: None, Country: None, City: None, Ready: True, OrderDetailCount: None, CloneFromOrder: 10643  row: 0x121146ed0  session: 0x121146a50  ins_upd_dlt: ins - 2024-08-31 21:14:57,022 - logic_logger - INF\n..Order[None] {server_defaults: OrderDetailCount -- skipped: Ready[BOOLEAN (not handled)] } Id: None, CustomerId: ALFKI, EmployeeId: 1, OrderDate: None, RequiredDate: None, ShippedDate: None, ShipVia: None, Freight: 11, ShipName: None, ShipAddress: None, ShipCity: None, ShipRegion: None, ShipZip: None, ShipCountry: None, AmountTotal: None, Country: None, City: None, Ready: True, OrderDetailCount: 0, CloneFromOrder: 10643  row: 0x121146ed0  session: 0x121146a50  ins_upd_dlt: ins - 2024-08-31 21:14:57,022 - logic_logger - INF\n..Order[None] {Formula OrderDate} Id: None, CustomerId: ALFKI, EmployeeId: 1, OrderDate: 2024-08-31 21:14:57.029015, RequiredDate: None, ShippedDate: None, ShipVia: None, Freight: 11, ShipName: None, ShipAddress: None, ShipCity: None, ShipRegion: None, ShipZip: None, ShipCountry: None, AmountTotal: 0, Country: None, City: None, Ready: True, OrderDetailCount: 0, CloneFromOrder: 10643  row: 0x121146ed0  session: 0x121146a50  ins_upd_dlt: ins - 2024-08-31 21:14:57,029 - logic_logger - INF\n....Customer[ALFKI] {Update - Adjusting Customer: UnpaidOrderCount, OrderCount} Id: ALFKI, CompanyName: Alfreds Futterkiste, ContactName: Maria Anders, ContactTitle: Sales Representative, Address: Obere Str. 57A, City: Berlin, Region: Western Europe, PostalCode: 12209, Country: Germany, Phone: 030-0074321, Fax: 030-0076545, Balance: 2102.0000000000, CreditLimit: 2300.0000000000, OrderCount:  [15--&gt;] 16, UnpaidOrderCount:  [10--&gt;] 11, Client_id: 1  row: 0x1210fa6f0  session: 0x121146a50  ins_upd_dlt: upd - 2024-08-31 21:14:57,030 - logic_logger - INF\n..Order[None] {Begin copy_children} Id: None, CustomerId: ALFKI, EmployeeId: 1, OrderDate: 2024-08-31 21:14:57.029015, RequiredDate: None, ShippedDate: None, ShipVia: None, Freight: 11, ShipName: None, ShipAddress: None, ShipCity: None, ShipRegion: None, ShipZip: None, ShipCountry: None, AmountTotal: 0, Country: None, City: None, Ready: True, OrderDetailCount: 0, CloneFromOrder: 10643  row: 0x121146ed0  session: 0x121146a50  ins_upd_dlt: ins - 2024-08-31 21:14:57,033 - logic_logger - INF\n....OrderDetail[None] {Insert - Copy Children OrderDetailList} Id: None, OrderId: None, ProductId:  [None--&gt;] 28, UnitPrice: None, Quantity:  [None--&gt;] 15, Discount:  [None--&gt;] 0.25, Amount: None, ShippedDate: None  row: 0x12110af90  session: 0x121146a50  ins_upd_dlt: ins - 2024-08-31 21:14:57,035 - logic_logger - INF\n....OrderDetail[None] {copy_rules for role: Product - UnitPrice} Id: None, OrderId: None, ProductId:  [None--&gt;] 28, UnitPrice:  [None--&gt;] 45.6000000000, Quantity:  [None--&gt;] 15, Discount:  [None--&gt;] 0.25, Amount: None, ShippedDate: None  row: 0x12110af90  session: 0x121146a50  ins_upd_dlt: ins - 2024-08-31 21:14:57,037 - logic_logger - INF\n....OrderDetail[None] {Formula Amount} Id: None, OrderId: None, ProductId:  [None--&gt;] 28, UnitPrice:  [None--&gt;] 45.6000000000, Quantity:  [None--&gt;] 15, Discount:  [None--&gt;] 0.25, Amount:  [None--&gt;] 684.0000000000, ShippedDate: None  row: 0x12110af90  session: 0x121146a50  ins_upd_dlt: ins - 2024-08-31 21:14:57,037 - logic_logger - INF\n......Order[None] {Update - Adjusting Order: AmountTotal, OrderDetailCount} Id: None, CustomerId: ALFKI, EmployeeId: 1, OrderDate: 2024-08-31 21:14:57.029015, RequiredDate: None, ShippedDate: None, ShipVia: None, Freight: 11, ShipName: None, ShipAddress: None, ShipCity: None, ShipRegion: None, ShipZip: None, ShipCountry: None, AmountTotal:  [0--&gt;] 684.0000000000, Country: None, City: None, Ready: True, OrderDetailCount:  [0--&gt;] 1, CloneFromOrder: 10643  row: 0x121146ed0  session: 0x121146a50  ins_upd_dlt: upd - 2024-08-31 21:14:57,038 - logic_logger - INF\n......Order[None] {Prune Formula: OrderDate [[]]} Id: None, CustomerId: ALFKI, EmployeeId: 1, OrderDate: 2024-08-31 21:14:57.029015, RequiredDate: None, ShippedDate: None, ShipVia: None, Freight: 11, ShipName: None, ShipAddress: None, ShipCity: None, ShipRegion: None, ShipZip: None, ShipCountry: None, AmountTotal:  [0--&gt;] 684.0000000000, Country: None, City: None, Ready: True, OrderDetailCount:  [0--&gt;] 1, CloneFromOrder: 10643  row: 0x121146ed0  session: 0x121146a50  ins_upd_dlt: upd - 2024-08-31 21:14:57,039 - logic_logger - INF\n........Customer[ALFKI] {Update - Adjusting Customer: Balance} Id: ALFKI, CompanyName: Alfreds Futterkiste, ContactName: Maria Anders, ContactTitle: Sales Representative, Address: Obere Str. 57A, City: Berlin, Region: Western Europe, PostalCode: 12209, Country: Germany, Phone: 030-0074321, Fax: 030-0076545, Balance:  [2102.0000000000--&gt;] 2786.0000000000, CreditLimit: 2300.0000000000, OrderCount: 16, UnpaidOrderCount: 11, Client_id: 1  row: 0x1210fa6f0  session: 0x121146a50  ins_upd_dlt: upd - 2024-08-31 21:14:57,040 - logic_logger - INF\n........Customer[ALFKI] {Constraint Failure: balance (2786.00) exceeds credit (2300.00)} Id: ALFKI, CompanyName: Alfreds Futterkiste, ContactName: Maria Anders, ContactTitle: Sales Representative, Address: Obere Str. 57A, City: Berlin, Region: Western Europe, PostalCode: 12209, Country: Germany, Phone: 030-0074321, Fax: 030-0076545, Balance:  [2102.0000000000--&gt;] 2786.0000000000, CreditLimit: 2300.0000000000, OrderCount: 16, UnpaidOrderCount: 11, Client_id: 1  row: 0x1210fa6f0  session: 0x121146a50  ins_upd_dlt: upd - 2024-08-31 21:14:57,041 - logic_logger - INF\n</code></pre></p> <p> </p>"},{"location":"Behave-Logic-Report/#feature-salary-change","title":"Feature: Salary Change","text":""},{"location":"Behave-Logic-Report/#scenario-audit-salary-change","title":"Scenario: Audit Salary Change","text":"<p>\u2003  Scenario: Audit Salary Change \u2003\u2003    Given Employee 5 (Buchanan) - Salary 95k \u2003\u2003    When Patch Salary to 200k \u2003\u2003    Then Salary_audit row created  </p> Tests - and their logic - are transparent.. click to see Logic <p> </p> <p>Logic Doc for scenario: Audit Salary Change</p> <p>Logic Patterns:</p> <ul> <li>Auditing</li> </ul> <p>Logic Design (\"Cocktail Napkin Design\")</p> <ul> <li>copy_row(copy_to=models.EmployeeAudit...)</li> </ul> <p>Observe the logic log to see that it creates audit rows:</p> <ol> <li>Discouraged: you can implement auditing with events.  But auditing is a common pattern, and this can lead to repetitive, tedious code</li> <li>Preferred: approaches use extensible rules.</li> </ol> <p>Generic event handlers can also reduce redundant code, illustrated in the time/date stamping <code>handle_all</code> logic.</p> <p>This is due to the <code>copy_row</code> rule.  Contrast this to the tedious <code>audit_by_event</code> alternative:</p> <p>Key Takeaway: use extensible own rule types to automate pattern you identify; events can result in tedious amounts of code.</p> <p> </p> <p>Rules Used in Scenario: Audit Salary Change <pre><code>\n</code></pre> Logic Log in Scenario: Audit Salary Change <pre><code>Logic Phase:        ROW LOGIC       (session=0x10dfbbdd0) (sqlalchemy before_flush)          - 2024-07-12 14:57:09,599 - logic_logger - INF\n..Employee[5] {Update - client} Id: 5, LastName: Buchanan, FirstName: Steven, Title: Sales Manager, TitleOfCourtesy: Mr., BirthDate: 1987-03-04, HireDate: 2025-10-17, Address: 14 Garrett Hill, City: London, Region: British Isles, PostalCode: SW1 8JR, Country: UK, HomePhone: (71) 555-4848, Extension: 3453, Notes: Steven Buchanan graduated from St. Andrews University, Scotland, with a BSC degree in 1976.  Upon joining the company as a sales representative in 1992, he spent 6 months in an orientation program at the Seattle office and then returned to his permanent post in London.  He was promoted to sales manager in March 1993.  Mr. Buchanan has completed the courses 'Successful Telemarketing' and 'International Sales Management.'  He is fluent in French., ReportsTo: 2, PhotoPath: http://localhost:5656/ui/images/Employee/buchanan.jpg, EmployeeType: Commissioned, Salary:  [95000.0000000000--&gt;] 200000, WorksForDepartmentId: 3, OnLoanDepartmentId: None, UnionId: None, Dues: None  row: 0x10dfbb710  session: 0x10dfbbdd0  ins_upd_dlt: upd - 2024-07-12 14:57:09,600 - logic_logger - INF\n..Employee[5] {BEGIN Copy to: EmployeeAudit} Id: 5, LastName: Buchanan, FirstName: Steven, Title: Sales Manager, TitleOfCourtesy: Mr., BirthDate: 1987-03-04, HireDate: 2025-10-17, Address: 14 Garrett Hill, City: London, Region: British Isles, PostalCode: SW1 8JR, Country: UK, HomePhone: (71) 555-4848, Extension: 3453, Notes: Steven Buchanan graduated from St. Andrews University, Scotland, with a BSC degree in 1976.  Upon joining the company as a sales representative in 1992, he spent 6 months in an orientation program at the Seattle office and then returned to his permanent post in London.  He was promoted to sales manager in March 1993.  Mr. Buchanan has completed the courses 'Successful Telemarketing' and 'International Sales Management.'  He is fluent in French., ReportsTo: 2, PhotoPath: http://localhost:5656/ui/images/Employee/buchanan.jpg, EmployeeType: Commissioned, Salary:  [95000.0000000000--&gt;] 200000, WorksForDepartmentId: 3, OnLoanDepartmentId: None, UnionId: None, Dues: None  row: 0x10dfbb710  session: 0x10dfbbdd0  ins_upd_dlt: upd - 2024-07-12 14:57:09,604 - logic_logger - INF\n....EmployeeAudit[None] {Insert - Copy EmployeeAudit} Id: None, Title: Sales Manager, Salary: 200000, LastName: Buchanan, FirstName: Steven, EmployeeId: None, CreatedOn: None, UpdatedOn: None, CreatedBy: None, UpdatedBy: None  row: 0x10dfba1b0  session: 0x10dfbbdd0  ins_upd_dlt: ins - 2024-07-12 14:57:09,605 - logic_logger - INF\n....EmployeeAudit[None] {early_row_event_all_classes - handle_all did stamping} Id: None, Title: Sales Manager, Salary: 200000, LastName: Buchanan, FirstName: Steven, EmployeeId: None, CreatedOn: 2024-07-12 14:57:09.606065, UpdatedOn: None, CreatedBy: aneu, UpdatedBy: None  row: 0x10dfba1b0  session: 0x10dfbbdd0  ins_upd_dlt: ins - 2024-07-12 14:57:09,606 - logic_logger - INF\nLogic Phase:        COMMIT LOGIC        (session=0x10dfbbdd0)                                            - 2024-07-12 14:57:09,607 - logic_logger - INF\nLogic Phase:        AFTER_FLUSH LOGIC   (session=0x10dfbbdd0)                                            - 2024-07-12 14:57:09,612 - logic_logger - INF\n</code></pre></p> <p> </p>"},{"location":"Behave-Logic-Report/#scenario-manage-propersalary","title":"Scenario: Manage ProperSalary","text":"<p>\u2003  Scenario: Manage ProperSalary \u2003\u2003    Given Employee 5 (Buchanan) - Salary 95k \u2003\u2003    When Retrieve Employee Row \u2003\u2003    Then Verify Contains ProperSalary  </p> Tests - and their logic - are transparent.. click to see Logic <p> </p> <p>Logic Doc for scenario: Manage ProperSalary</p> <p>Observe the use of <code>old_row</code></p> <p>Key Takeaway: State Transition Logic enabled per <code>old_row</code></p> <p> </p> <p>Rules Used in Scenario: Manage ProperSalary <pre><code>\n</code></pre> Logic Log in Scenario: Manage ProperSalary <pre><code>\n</code></pre></p> <p> </p>"},{"location":"Behave-Logic-Report/#scenario-raise-must-be-meaningful","title":"Scenario: Raise Must be Meaningful","text":"<p>\u2003  Scenario: Raise Must be Meaningful \u2003\u2003    Given Employee 5 (Buchanan) - Salary 95k \u2003\u2003    When Patch Salary to 96k \u2003\u2003    Then Reject - Raise too small  </p> Tests - and their logic - are transparent.. click to see Logic <p> </p> <p>Logic Doc for scenario: Raise Must be Meaningful</p> <p>Logic Patterns:</p> <ul> <li>State Transition Logic</li> </ul> <p>Logic Design (\"Cocktail Napkin Design\")</p> <ul> <li>Rule.constraint(validate=Employee, calling=raise_over_20_percent...)</li> </ul> <p>Observe the use of <code>old_row</code></p> <p>Key Takeaway: State Transition Logic enabled per <code>old_row</code></p> <p> </p> <p>Rules Used in Scenario: Raise Must be Meaningful <pre><code>  Employee  \n    1. Constraint Function: &lt;function declare_logic.&lt;locals&gt;.raise_over_20_percent at 0x10b959940&gt;   \n</code></pre> Logic Log in Scenario: Raise Must be Meaningful <pre><code>Logic Phase:        ROW LOGIC       (session=0x10dfd4b60) (sqlalchemy before_flush)          - 2024-07-12 14:57:09,907 - logic_logger - INF\n..Employee[5] {Update - client} Id: 5, LastName: Buchanan, FirstName: Steven, Title: Sales Manager, TitleOfCourtesy: Mr., BirthDate: 1987-03-04, HireDate: 2025-10-17, Address: 14 Garrett Hill, City: London, Region: British Isles, PostalCode: SW1 8JR, Country: UK, HomePhone: (71) 555-4848, Extension: 3453, Notes: Steven Buchanan graduated from St. Andrews University, Scotland, with a BSC degree in 1976.  Upon joining the company as a sales representative in 1992, he spent 6 months in an orientation program at the Seattle office and then returned to his permanent post in London.  He was promoted to sales manager in March 1993.  Mr. Buchanan has completed the courses 'Successful Telemarketing' and 'International Sales Management.'  He is fluent in French., ReportsTo: 2, PhotoPath: http://localhost:5656/ui/images/Employee/buchanan.jpg, EmployeeType: Commissioned, Salary:  [95000.0000000000--&gt;] 96000, WorksForDepartmentId: 3, OnLoanDepartmentId: None, UnionId: None, Dues: None  row: 0x10dd75790  session: 0x10dfd4b60  ins_upd_dlt: upd - 2024-07-12 14:57:09,908 - logic_logger - INF\n..Employee[5] {Constraint Failure: Buchanan needs a more meaningful raise} Id: 5, LastName: Buchanan, FirstName: Steven, Title: Sales Manager, TitleOfCourtesy: Mr., BirthDate: 1987-03-04, HireDate: 2025-10-17, Address: 14 Garrett Hill, City: London, Region: British Isles, PostalCode: SW1 8JR, Country: UK, HomePhone: (71) 555-4848, Extension: 3453, Notes: Steven Buchanan graduated from St. Andrews University, Scotland, with a BSC degree in 1976.  Upon joining the company as a sales representative in 1992, he spent 6 months in an orientation program at the Seattle office and then returned to his permanent post in London.  He was promoted to sales manager in March 1993.  Mr. Buchanan has completed the courses 'Successful Telemarketing' and 'International Sales Management.'  He is fluent in French., ReportsTo: 2, PhotoPath: http://localhost:5656/ui/images/Employee/buchanan.jpg, EmployeeType: Commissioned, Salary:  [95000.0000000000--&gt;] 96000, WorksForDepartmentId: 3, OnLoanDepartmentId: None, UnionId: None, Dues: None  row: 0x10dd75790  session: 0x10dfd4b60  ins_upd_dlt: upd - 2024-07-12 14:57:09,909 - logic_logger - INF\n</code></pre></p> <p> </p>"},{"location":"Behave-Logic-Report/#feature-tests-successful","title":"Feature: Tests Successful","text":""},{"location":"Behave-Logic-Report/#scenario-run-tests","title":"Scenario: Run Tests","text":"<p>\u2003  Scenario: Run Tests \u2003\u2003    Given Database and Set of Tests \u2003\u2003    When Run Configuration: Behave Tests \u2003\u2003    Then No Errors  </p> <p>  Completed at July 12, 2024 14:57:0  </p>"},{"location":"Behave/","title":"Agility With Behave","text":"<p> TL;DR - Executable Test Suite, Documentation</p> <p>You can optionally use the Behave test framework to:</p> <ol> <li> <p>Capture Requirements as Tests: Use Behave in your IDE to capture requirements as executable tests. Behave is based on Behavior Driven Design, so your requirements are phrased as tests that can be understood by both technical and business users.</p> </li> <li> <p>Run Automated Test Suite: Create Python code to execute tests. You can then execute your entire test suite with a single command.</p> </li> <li> <p>Generate Requirements and Test Documentation: Create wiki reports that document your requirements and the tests (Scenarios) that confirm their proper operation.</p> <ul> <li>Integrated Logic Documentation: Reports integrate your declarative logic, showing rules and their execution traces. This makes logic transparent to business users and supports Agile Collaboration.</li> </ul> </li> </ol> <p>For an Agile approach to using Behave, see Logic Tutorial.</p> <p> </p>"},{"location":"Behave/#why-testing-matters","title":"Why Testing Matters","text":"<p>Experienced professionals advocate comprehensive test suites for answering critical questions:</p> Key Question Best Practice What is the formal definition of the system's functionality? The test suite defines the functionality Is the system ready to go-live? The test suite passes Did my maintenance change break something? Run the test suite How do the declarative rules actually execute? Logic logs show execution traces"},{"location":"Behave/#testing-frameworks","title":"Testing Frameworks","text":"<p>API Logic Server does not dictate any particular framework. You can use popular frameworks such as:</p> <ul> <li><code>pytest</code> - Modern, feature-rich testing framework (recommended)</li> <li><code>unittest</code> - Python's built-in testing framework</li> <li><code>behave</code> - BDD framework with built-in documentation generation (described here)</li> </ul> <p>We use all three internally for different purposes.</p> <p> </p>"},{"location":"Behave/#the-behave-framework","title":"The Behave Framework","text":"<p>Behave is particularly useful because it:</p> <ol> <li>Uses natural language (Gherkin) for test definitions - readable by business users</li> <li>Automatically generates documentation from tests</li> <li>Integrates logic execution traces into reports</li> <li>Supports Behavior Driven Development (BDD) workflows</li> </ol> <p></p> <p>Behave is a framework for defining and executing tests based on BDD (Behavior Driven Development), an Agile approach for defining system requirements as executable tests.</p> <p> </p>"},{"location":"Behave/#using-behave-quick-start","title":"Using Behave - Quick Start","text":"<p>Behave is pre-installed with API Logic Server. The typical workflow:</p> <ol> <li> <p>Create <code>.feature</code> files - Define test Scenarios (tests) for Features (stories) in natural language</p> </li> <li> <p>Code <code>.py</code> files - Implement the scenario steps in Python</p> </li> <li> <p>Run Test Suite - Execute all scenarios with Launch Configuration <code>Behave Run</code></p> </li> <li> <p>Generate Report - Create documentation with Launch Configuration <code>Behave Report</code></p> </li> </ol> <p>The following sections provide detailed guidance for each step.</p> <p> </p>"},{"location":"Behave/#1-create-feature-files-to-define-scenarios","title":"1. Create <code>.feature</code> Files to Define Scenarios","text":"<p>Feature files use Gherkin syntax - a business-readable, domain-specific language that lets you describe software behavior without detailing implementation.</p> <p>Example: <pre><code>Feature: Order Processing with Business Logic\n\n  Scenario: Good Order Placed\n    Given Customer \"Alice\" with balance 0 and credit limit 1000\n    When B2B order placed for \"Alice\" with 5 Widget\n    Then Customer \"Alice\" balance should be 450\n    And Order amount_total should be 450\n    And Item amount should be 450\n</code></pre></p> <p>Best Practices:</p> <ul> <li>Use Given for setup/preconditions</li> <li>Use When for the action being tested  </li> <li>Use Then/And for assertions</li> <li>Write scenarios that business users can understand</li> <li>Keep scenarios focused on one behavior</li> </ul> <p>Feature files are stored in <code>features/</code> directory with <code>.feature</code> extension.</p> <p> </p>"},{"location":"Behave/#2-implement-test-steps-in-python","title":"2. Implement Test Steps in Python","text":"<p>Each scenario step maps to a Python function using decorators like <code>@given</code>, <code>@when</code>, <code>@then</code>.</p> <p>Example Implementation: <pre><code>from behave import given, when, then\nimport requests\n\n@given('Customer \"{name}\" with balance {balance:d} and credit limit {limit:d}')\ndef step_impl(context, name, balance, limit):\n    # Create test customer via API\n    unique_name = f\"{name} {int(time.time() * 1000)}\"  # Unique for repeatability\n    response = requests.post(\n        f'{BASE_URL}/api/Customer/',\n        json={\"data\": {\"attributes\": {\n            \"name\": unique_name,\n            \"balance\": balance,\n            \"credit_limit\": limit\n        }}}\n    )\n    context.customer_id = int(response.json()['data']['id'])\n    context.customer_map = {name: {'id': context.customer_id, 'unique_name': unique_name}}\n</code></pre></p> <p>Key Implementation Points:</p> <ol> <li> <p>Link scenarios with <code>@when/@given/@then</code> decorators - Behave matches scenario text to these patterns</p> </li> <li> <p>Use <code>test_utils.prt()</code> for logic logging: <pre><code>scenario_name = context.scenario.name\ntest_utils.prt(f'\\n{scenario_name}\\n', scenario_name)  # 2nd arg drives log filename\n</code></pre></p> </li> <li> <p>Add docstrings for documentation (optional but recommended):    <pre><code>@when('B2B order placed for \"{customer}\" with {qty:d} {product}')\ndef step_impl(context, customer, qty, product):\n    \"\"\"\n    Phase 2 test: Uses OrderB2B custom API.\n    Creates complete order with items in single transaction.\n    \"\"\"\n    scenario_name = context.scenario.name\n    test_utils.prt(f'\\n{scenario_name}\\n', scenario_name)\n    # ... implementation\n</code></pre></p> </li> <li> <p>Store context for later steps: <pre><code>context.order_id = order_id\ncontext.customer_map[customer_name] = {'id': customer_id}\n</code></pre></p> </li> <li> <p>Use unique test data (see Rule #0 in <code>docs/training/testing.md</code>):    <pre><code>unique_name = f\"TestCustomer {int(time.time() * 1000)}\"\n</code></pre></p> </li> </ol> <p>Step implementations are stored in <code>features/steps/</code> directory with <code>*_steps.py</code> naming pattern.</p> <p> </p>"},{"location":"Behave/#3-run-test-suite","title":"3. Run Test Suite","text":""},{"location":"Behave/#prerequisites","title":"Prerequisites","text":"<p>The server must be running! Start it first:</p> <pre><code># Option 1: Run with debugger\n# Use Launch Configuration \"ApiLogicServer\"\n\n# Option 2: Run without debugger (faster, doesn't restart on code changes)\npython api_logic_server_run.py\n</code></pre>"},{"location":"Behave/#running-tests","title":"Running Tests","text":"<pre><code># Run all scenarios\npython test/api_logic_server_behave/behave_run.py --outfile=logs/behave.log\n\n# Or use Launch Configuration: \"Behave Run\"\n</code></pre> <p>Test Execution Options:</p> <ul> <li>Run all tests: <code>Behave Run</code> Launch Configuration</li> <li>Run single scenario: <code>Behave Scenario</code> Launch Configuration  </li> <li>Windows users: Use <code>Windows Behave Run</code> if needed</li> <li>Debugging: Set breakpoints in your step implementations</li> </ul> <p>Output Files:</p> <ul> <li><code>logs/behave.log</code> - Test results summary</li> <li><code>logs/scenario_logic_logs/*.log</code> - Logic execution traces per scenario</li> </ul> <p> </p>"},{"location":"Behave/#4-generate-documentation-report","title":"4. Generate Documentation Report","text":"<p>After running tests, generate the wiki-style report:</p> <pre><code>cd test/api_logic_server_behave\npython behave_logic_report.py run\n\n# Or use Launch Configuration: \"Behave Report\"\n</code></pre> <p>Generated Report Includes:</p> <ul> <li>\u2705 All features and scenarios  </li> <li>\u2705 Test results (pass/fail)</li> <li>\u2705 Logic execution traces - Shows exactly which rules fired</li> <li>\u2705 Rules used - Summary of rules involved</li> <li>\u2705 Expandable logic detail sections</li> <li>\u2705 Docstring documentation (if provided in steps)</li> </ul> <p>The report is generated at: <code>reports/Behave Logic Report.md</code></p> <p> </p>"},{"location":"Behave/#5-testing-best-practices","title":"5. Testing Best Practices","text":""},{"location":"Behave/#test-repeatability-rule-0","title":"Test Repeatability (Rule #0)","text":"<p>CRITICAL: Tests modify the database. Always create fresh test data with timestamps:</p> <pre><code># \u274c WRONG - Reuses contaminated data\ncustomer = requests.get(f'/api/Customer/?filter[name]=Bob').json()['data'][0]\n\n# \u2705 CORRECT - Always creates fresh data\nunique_name = f\"Bob {int(time.time() * 1000)}\"\nresponse = requests.post(f'/api/Customer/', json={...})\n</code></pre> <p>See <code>docs/training/testing.md</code> for comprehensive testing patterns and common pitfalls.</p>"},{"location":"Behave/#optimistic-locking-considerations","title":"Optimistic Locking Considerations","text":"<p>When testing with optimistic locking enabled, set <code>PYTHONHASHSEED=0</code> for repeatable test execution.</p> <p>See API Optimistic Locking Testing for details.</p>"},{"location":"Behave/#step-ordering-rule-05","title":"Step Ordering (Rule #0.5)","text":"<p>Behave matches steps by FIRST pattern that fits. Always order from most specific \u2192 most general:</p> <pre><code># \u2705 CORRECT ORDER\n@when('Order for \"{customer}\" with {qty:d} carbon neutral {product}')  # Most specific\n@when('Order for \"{customer}\" with {q1:d} {p1} and {q2:d} {p2}')     # More specific\n@when('Order for \"{customer}\" with {qty:d} {product}')                # General\n\n# \u274c WRONG - General pattern matches everything first!\n</code></pre> <p>Use <code>python check_step_order.py</code> to verify correct ordering.</p> <p> </p>"},{"location":"Behave/#troubleshooting","title":"Troubleshooting","text":""},{"location":"Behave/#tests-not-showing-in-report","title":"Tests Not Showing in Report","text":"<p>Problem: Scenarios appear in report but without logic traces.</p> <p>Solution: Ensure <code>test_utils.prt(scenario_name, scenario_name)</code> is called in your <code>@when</code> step implementation.</p>"},{"location":"Behave/#logic-logs-empty","title":"Logic Logs Empty","text":"<p>Problem: <code>logs/scenario_logic_logs/</code> files are empty or missing.</p> <p>Solution:  1. Verify server is running before tests 2. Check that <code>test_utils.prt()</code> second argument matches scenario name exactly 3. Ensure scenario names don't exceed 26 characters (gets truncated)</p>"},{"location":"Behave/#test-repeatability-issues","title":"Test Repeatability Issues","text":"<p>Problem: Tests pass first run, fail on second run.</p> <p>Solution: Use timestamps in test data names: <code>f\"Customer {int(time.time() * 1000)}\"</code></p> <p>See Rule #0 in <code>docs/training/testing.md</code> for comprehensive guidance.</p> <p> </p>"},{"location":"Behave/#advanced-topics","title":"Advanced Topics","text":""},{"location":"Behave/#phase-1-vs-phase-2-testing","title":"Phase 1 vs Phase 2 Testing","text":"<ul> <li>Phase 1 (CRUD): Test individual operations (POST, PATCH, DELETE) for granular rule testing</li> <li>Phase 2 (Custom APIs): Test complete business transactions using custom API endpoints</li> </ul> <p>See <code>docs/training/testing.md</code> for the complete decision tree.</p>"},{"location":"Behave/#custom-api-testing","title":"Custom API Testing","text":"<p>When testing custom business APIs (e.g., OrderB2B), remember to include both <code>\"method\"</code> and <code>\"args\"</code> in the meta object:</p> <pre><code>{\n    \"meta\": {\n        \"method\": \"OrderB2B\",  # \u2190 REQUIRED!\n        \"args\": {\n            \"data\": { ... }\n        }\n    }\n}\n</code></pre>"},{"location":"Behave/#debugging-tests","title":"Debugging Tests","text":"<ol> <li>Set breakpoints in step implementations</li> <li>Use <code>Behave Scenario</code> to run single test</li> <li>Check <code>logs/behave.log</code> for test execution details</li> <li>Review <code>logs/scenario_logic_logs/*.log</code> for logic traces</li> </ol>"},{"location":"Behave/#additional-resources","title":"Additional Resources","text":"<ul> <li>Complete Testing Guide: <code>docs/training/testing.md</code> (1755 lines of AI training material)</li> <li>Behave Official Docs: behave.readthedocs.io</li> <li>BDD Introduction: Introducing BDD</li> <li>API Logic Server Docs: apilogicserver.github.io/Docs</li> </ul> <ol> <li> <p>Run Test Suite: Launch Configuration <code>Behave Run</code>.  This runs all your Scenarios, and produces a summary report of your Features and the test results.</p> </li> <li> <p>Report: Launch Configuration <code>Behave Report</code> to create the wiki file shown here.</p> </li> </ol> <p>These steps are further defined, below.  Explore the samples in the sample project.</p> <p> </p>"},{"location":"Behave/#1-create-feature-file-to-define-scenario","title":"1. Create <code>.feature</code> file to define Scenario","text":"<p>Feature (aka Story) files are designed to promote IT / business user collaboration.  </p> <p> </p>"},{"location":"Behave/#2-code-py-file-to-implement-test","title":"2. Code <code>.py</code> file to implement test","text":"<p>Implement your tests in Python.  Here, the tests are largely 1. read existing data, 2. run transaction, and 3. test results, using the API.  You can obtain the URLs for reading/updatind data from the swagger.</p> <p>Key points (see items 2.1, 2.2 etc in the diagram above):</p> <ol> <li> <p>Link your scenario / implementations with <code>@when</code> annotations, as shown for Order Placed with excessive quantity.</p> </li> <li> <p>Optionally, include a Python docstring on your <code>@when</code> implementation as shown above, delimited by <code>\"\"\"</code> strings (see \"Familiar logic pattern\" in the screen shot, above). If provided, this will be written into the wiki report.</p> </li> <li> <p>Important: the system assumes the line following the docstring identifies the <code>scenario_name</code>; be sure to include it.</p> </li> <li> <p>Include the <code>test_utils.prt()</code> call; be sure to use specify the scenario name as the 2nd argument.  This is what drives the name of the Logic Log file, discussed below.</p> </li> </ol> <p> </p>"},{"location":"Behave/#3-run-test-suite-launch-configuration-behave-run","title":"3. Run Test Suite: Launch Configuration <code>Behave Run</code>","text":"<p>You can now execute your Test Suite.  Run the <code>Behave Run</code> Launch Configuration, and Behave will run all of the tests, producing the outputs (<code>behave.log</code> and <code>&lt;scenario.logs&gt;</code> shown above.</p> <ul> <li> <p>Windows users may need to run <code>Windows Behave Run</code></p> </li> <li> <p>You can run just 1 scenario using <code>Behave Scenario</code></p> </li> <li> <p>You can set breakpoints in your tests</p> </li> </ul> <p>The server must be running for these tests.  Use the Launch Configuration <code>ApiLogicServer</code>, or <code>python api_logic_server_run.py</code>.  The latter does not run the debugger, which you may find more convenient since changes to your test code won't restart the server.</p> <p> </p>"},{"location":"Behave/#4-report-launch-configuration-behave-report","title":"4. Report: Launch Configuration `Behave Report'","text":"<p>Run this to create the wiki reports from the logs in step 3.</p>"},{"location":"Behave/#5-testing-considerations","title":"5. Testing considerations","text":"<p>Please see here for important considerations on optimistic locking and testing.</p>"},{"location":"Create-ApiLogicProject/","title":"Create an API Logic Project","text":"<p>Create projects by establishing your Python environment, then issuing <code>ApiLogicServer create ...</code>.  The process differs slighly on whether you are using Docker, or a local install.</p> <p>The procedures here will create the Tutorial, the recommended starting point.  You will then want to create a project with your own database.  For that, you will require a SQLAlchemy URI.  You can see some examples with the command <code>ApiLogicServer examples</code>.</p> Local InstallDocker Install <p>If necessary, re-establish your Python environment:</p> Re-establish Python environment (already estaslished if you just installed)<pre><code>cd ApiLogicServer          # your install folder\nsource venv/bin/activate   # windows venv\\Scripts\\activate\nApiLogicServer create      # accept default project name, db\n</code></pre> <p>Then, create your project: Create API Logic Project<pre><code>ApiLogicServer create      # accept default project name, db (sample tutorial)\n</code></pre></p> <p>If necessary, re-establish your Python environment:</p> Re-establish Python environment (already estaslished if you just installed)<pre><code>cd ApiLogicServer  # directory of API Logic Server projects on local host\n\n# Start (install if required) the API Logic Server docker container\n\ndocker run -it --name api_logic_server --rm -p 5656:5656 -p 5002:5002 -v ${PWD}:/localhost apilogicserver/api_logic_server\n</code></pre> <p>Then, create your project: Create API Logic Project<pre><code>$ ApiLogicServer create --project_name=/localhost/ApiLogicProject --db_url=\n</code></pre></p>"},{"location":"Create-ApiLogicProject/#_1","title":"","text":""},{"location":"Create-ApiLogicProject/#project-directory-created","title":"Project Directory Created","text":"<p>In either case, the <code>create</code> command builds an <code>ApiLogicProject</code> - a directory, shown here in VSCode:</p> <p></p>"},{"location":"Data-Model-Classes/","title":"Data Model Classes","text":"<p>Most of API Logic Server functionality derives from the data model classes created from your schema when you create your project with <code>ApiLogicServer create</code>.  </p> <p>It operates as described below.</p>"},{"location":"Data-Model-Classes/#create-modelspy-from-schema","title":"Create <code>models.py</code> from schema","text":"<p><code>ApiLogicServer create</code> builds the <code>database/models.py</code> file, with a class for each table: </p> <pre><code>class Category(SAFRSBase, Base):             #  &lt;--- singular/capitalized tablename\n    __tablename__ = 'CategoryTableNameTest'  #  &lt;--- from schema\n    _s_collection_name = 'Category'          #  &lt;--- defaults from class name - endpoint, admin reference\n    Id = Column(Integer, primary_key=True)\n    CategoryName = Column(String(8000))\n    Description = Column(String(8000))\n\n\n\nclass Order(SAFRSBase, Base):\n    __tablename__ = 'Order'\n    _s_collection_name = 'Order'\n    __table_args__ = (\n        ForeignKeyConstraint(['Country', 'City'], ['Location.country', 'Location.city']),\n    )\n\n    Id = Column(Integer, primary_key=True)\n    CustomerId = Column(ForeignKey('Customer.Id'), nullable=False, index=True)\n    EmployeeId = Column(ForeignKey('Employee.Id'), nullable=False, index=True)\n    # etc\n    AmountTotal = Column(DECIMAL(10, 2))\n    Country = Column(String(50))\n    City = Column(String(50))\n    Ready = Column(Boolean, server_default=text(\"TRUE\"))\n    OrderDetailCount = Column(Integer, server_default=text(\"0\"))\n    CloneFromOrder = Column(ForeignKey('Order.Id'))\n\n    # see backref on parent: parent = relationship('Order', remote_side=[Id], cascade_backrefs=True, backref='OrderList')\n    # see backref on parent: Location = relationship('Location', cascade_backrefs=True, backref='OrderList')\n    # see backref on parent: Customer = relationship('Customer', cascade_backrefs=True, backref='OrderList')\n    # see backref on parent: Employee = relationship('Employee', cascade_backrefs=True, backref='OrderList')\n\n    parent = relationship('Order', remote_side=[Id], cascade_backrefs=True, backref='OrderList')  # special handling for self-relationships\n    OrderDetailList = relationship('OrderDetail', cascade='all, delete', cascade_backrefs=True, backref='Order')  # manual fix\n</code></pre> <p>This was derived from sqlacodgen -- many thanks!  (It is not necessary to <code>pip</code> this into your project - it's part of API Logic Server).</p> <p> </p>"},{"location":"Data-Model-Classes/#class-end-point-for-each-table","title":"Class (end point) for each table","text":"<p>A class is created for each table.  The name (e.g. <code>Order</code>) is derived from the table name: capitalized and singlularized.</p> <p> </p>"},{"location":"Data-Model-Classes/#end-point-name-from-class","title":"End point name from Class","text":"<p>These class names are used as the default API endpoint name.  Override them as described below.</p> <p> </p>"},{"location":"Data-Model-Classes/#overriding-the-class-name","title":"Overriding the Class Name","text":"<p>Developers often want to control endpoint names.  To do so, edit the value of <code>_s_collection_name</code> as shown above. </p> <p> </p>"},{"location":"Data-Model-Classes/#relationship-names","title":"Relationship Names","text":"<p>Your class model includes accessors for related data:</p> <ol> <li> <p>Relationships are created on the one side of one-to-many relationships.  The relationship name is the target class + \"List\", and is available in Python (<code>items = anOrder.OrderDetailList</code>).  These names are used in your UI admin apps, and your API</p> </li> <li> <p>Relationships have 2 names; the backref name is how the many side refers to the one side (e.g., <code>anOrder = anOrderDetail.order</code>)</p> </li> </ol> <p>Relationship names are also part of your API:</p> <p></p> <p>Each database has extensions which can introduce issues in model generation, so facilities are described in Troubleshooting to edit models and rebuild.</p> <p>Relationship names are derived from database foreign keys, as described here.  As described in the link, you can add missing foreign keys in your data model classes.</p> <p> </p>"},{"location":"Data-Model-Classes/#multi-reln","title":"Multi-reln","text":"<p>In the sample database, there are 2 relationships between <code>Department</code> and <code>Employee</code>.  The default names described above would clearly create name collisions.  These are avoided with 2 strategies:</p> <ul> <li> <p>basic: the first relationship is named as above; subsequent accessor names are appended with a number (1, 2)</p> </li> <li> <p>advanced: if the foreign key is single-field, and ends with <code>id</code> or <code>_id</code> (also spellings such as <code>Id</code> and <code>ID</code>), the foreign key names is used:</p> </li> </ul> advanced relationship names<pre><code>    # parent relationships (access parent) -- example: self-referential\n    # .. https://docs.sqlalchemy.org/en/20/orm/self_referential.html\n    Department : Mapped[\"Department\"] = relationship(remote_side=[Id], back_populates=(\"DepartmentList\"))\n\n    # child relationships (access children)\n    DepartmentList : Mapped[List[\"Department\"]] = relationship(back_populates=\"Department\")\n    EmployeeList : Mapped[List[\"Employee\"]] = relationship(foreign_keys='[Employee.OnLoanDepartmentId]', back_populates=\"OnLoanDepartment\")\n    WorksForEmployeeList : Mapped[List[\"Employee\"]] = relationship(foreign_keys='[Employee.WorksForDepartmentId]', back_populates=\"WorksForDepartment\")\n</code></pre> <p> </p>"},{"location":"Data-Model-Classes/#model-linkages","title":"Model Linkages","text":"<p>The diagram below illustrates how the class aspects and the admin app tie together:</p> <p></p>"},{"location":"Data-Model-Classes/#override-s_count-performance","title":"Override s_count: performance","text":"<p>If you see performance issues in loading the API, explore overriding s_count:</p> <p></p>"},{"location":"Data-Model-Classes/#view-support","title":"View Support","text":"<p>Views are supported with the following restrictions:</p> <ul> <li>They are created in <code>models.py</code> as tables, not classes</li> <li>They are not part of API automation<ul> <li>You can expose views with custom APIs, as shown here -- search for *view</li> </ul> </li> </ul> <p> </p>"},{"location":"Data-Model-Classes/#appendix-pre-910-sqlalchemy-2-typing","title":"Appendix: Pre 9.1.0 (SQLAlchemy 2 typing)","text":"<p>Release 9.1.0 enhanced data model attribute / relationship typing, based on SQLAlchemy 2.  Prior to that release, classes were created like this: </p> <pre><code>class Category(SAFRSBase, Base):                #  &lt;--- singular/capitalized tablename\n    __tablename__ = 'CategoryTableNameTest'     #  &lt;--- from schema\n    _s_collection_name = 'Category'             #  &lt;--- defaults from class name - endpoint, admin \n    __bind_key__ = 'None'\n\n    Id = Column(Integer, primary_key=True)\n    CategoryName = Column('CategoryName_ColumnName', String(8000))  # manual fix - alias\n    Description = Column(String(8000))\n    Client_id = Column(Integer)\n\n    @jsonapi_attr\n    def _check_sum_(self):                      # &lt;--- optimistic locking\n        return None if isinstance(self, flask_sqlalchemy.model.DefaultMeta) \\\n            else self._check_sum_property if hasattr(self,\"_check_sum_property\") \\\n                else None  # property does not exist during initialization\n\n    @_check_sum_.setter\n    def _check_sum_(self, value):  # type: ignore [no-redef]\n        self._check_sum_property = value\n\n    S_CheckSum = _check_sum_\n\n\n\nclass Order(SAFRSBase, Base):\n    __tablename__ = 'Order'\n    _s_collection_name = 'Order'  # type: ignore\n    __bind_key__ = 'None'\n    __table_args__ = (\n        ForeignKeyConstraint(['Country', 'City'], ['Location.country', 'Location.city']),\n    )\n\n    Id = Column(Integer, primary_key=True)\n    CustomerId = Column(ForeignKey('Customer.Id'), nullable=False, index=True)\n    EmployeeId = Column(ForeignKey('Employee.Id'), nullable=False, index=True)\n    OrderDate = Column(String(8000))\n    RequiredDate = Column(Date)\n    # etd\n    AmountTotal : DECIMAL = Column(DECIMAL(10, 2))  # &lt;--- Observe typing\n    Country = Column(String(50))\n    City = Column(String(50))\n    Ready = Column(Boolean, server_default=text(\"TRUE\"))\n    OrderDetailCount = Column(Integer, server_default=text(\"0\"))\n    CloneFromOrder = Column(ForeignKey('Order.Id'))\n\n    # parent relationships (access parent)\n    Order : Mapped[\"Order\"] = relationship(remote_side=[Id], back_populates=(\"OrderList\"))\n    Location : Mapped[\"Location\"] = relationship(back_populates=(\"OrderList\"))\n    Customer : Mapped[\"Customer\"] = relationship(back_populates=(\"OrderList\"))\n    Employee : Mapped[\"Employee\"] = relationship(back_populates=(\"OrderList\"))\n\n    # child relationships (access children)\n    OrderList : Mapped[List[\"Order\"]] = relationship(back_populates=\"Order\")\n    OrderDetailList : Mapped[List[\"OrderDetail\"]] = relationship(cascade=\"all, delete\", back_populates=\"Order\")  # manual fix\n</code></pre> <p> </p>"},{"location":"Data-Model-Classes/#appendix-pre-650-end-point-names-from-table-names","title":"Appendix: Pre 6.5.0 (End Point names from table names)","text":"<p>This functionality was altered in version 6.4.6.  In prior versions, it operated as shown in the example below:</p> <ul> <li>On the right are the created data model classes</li> <li>On the left are references to it from the Admin Web App <code>admin.yaml</code> model file that defines how the app behaves:</li> </ul> <p></p> <p>Observe that:</p> <ol> <li> <p>A class is created for each table.  The name (e.g. <code>OrderDetail</code>) is derived from the table name, but is capitalized and singlularized</p> </li> <li> <p>The table name is from your schema, this corresponds to a resource collection in the API</p> </li> <li> <p>Relationships are created on the one side of one-to-many relationships.  The relationship name is the target class + \"List\", and is available in Python (<code>items = anOrder.OrderDetailList</code>).  These names are used in your UI admin apps, and your API</p> </li> <li> <p>Relationships have 2 names; the backref name is now the many side refers to the _one\" side (e.g., anOrder = anOrderDetail.order`)</p> </li> </ol> <p>Relationship names are also part of your API:</p> <p></p> <p>Each database has extensions which can introduce issues in model generation, so facilities are described in Troubleshooting to edit models and rebuild.</p>"},{"location":"Data-Model-Customization/","title":"Data Model Customization","text":""},{"location":"Data-Model-Customization/#customize-the-model-add-relationships-derived-attributes","title":"Customize the Model: add relationships, derived attributes","text":"<p>Model files describe your database tables.  You can extend these, e.g. to add relationships, and add derived attributes.</p> <p>Note: relationships are a particularly critical aspect of the model.  While they normally come from your schema and are discovered during <code>ApiLogicServer create</code>, they are often missing from the database.  You can add them as shown below.</p> <p> </p>"},{"location":"Data-Model-Customization/#edit-modelspy-referential-integrity-eg-sqlite","title":"Edit <code>models.py</code>: referential integrity (e.g., sqlite)","text":"<p>Rebuild support enables you to rebuild your project, preserving customizations you have made to the api, logic and app.  You can rebuild from the database, or from the model.</p> <p>This enables you to edit the model to specify aspects not captured in creating the model from your schema.  For example, sqlite often is not configured to enforce referential integrity.  SQLAlchemy provides  support to fill such gaps.</p> <p>For example, try to delete the last order for the first customer.  You will encounter an error since the default is to nullify foreign keys, which in this case is not allowed.</p> <p>You can fix this by altering your <code>models.py:</code></p> <pre><code>    OrderDetailList = relationship('OrderDetail', cascade='all, delete', cascade_backrefs=True, backref='Order')\n</code></pre> <p>Your api, logic and ui are not (directly) dependent on this setting, so there is no need to rebuild; just restart the server, and the system will properly cascade the <code>Order</code> delete to the <code>OrderDetail</code> rows.  Note further that logic will automatically adjust any data dependent on these deletions (e.g. adjust sums and counts).</p> <p> </p>"},{"location":"Data-Model-Customization/#edit-customize_modelspy-add-relationships-derived-attributes","title":"Edit <code>customize_models.py</code>: add relationships, derived attributes","text":"<p>In addition, you may wish to edit <code>customize_models.py</code>, for example:</p> <ul> <li> <p>to define relationships, critical for multi-table logic, APIs, and web apps</p> <ul> <li>See this example.</li> </ul> </li> <li> <p>to describe derived attributes, so that your API, logic and apps are not limited to the physical data model</p> </li> </ul>"},{"location":"Data-Model-Design/","title":"Database Design","text":"<p>Consider the database design guidelines below.</p> <p> </p>"},{"location":"Data-Model-Design/#use-foreign-keys","title":"Use Foreign Keys","text":"<p>These are required for multi-table rules (sum, count, copy etc), and for multi-table pages.</p> <p>If these are not in your database, you can add them in to the created data model class.  For example, find <code>Employee.Manager</code> in <code>customize_models</code>, here.</p> <p> </p>"},{"location":"Data-Model-Design/#foreign-key-indices","title":"Foreign Key Indices","text":"<p>In general, add indices for your Foreign Keys.  Note performance may be fine in dev, but degrade when product data volumes are encountered (e.g., pre-production testing).</p> <p> </p>"},{"location":"Data-Model-Design/#initialize-stored-derivations","title":"Initialize Stored Derivations","text":"<p>Recall that the logic engine uses adjustments to maintain aggregates, instead of expensive (possibly nested) aggregate queries.  This can result in order-of-magnitude performance advantage.</p> <p>It does, however, rely currently stored values being accurate.  Logic will ensure remains true, but you must ensure it's initially true.  Introducing stored aggregates in an existing database with existing rows requires you initialize new sums and counts.</p> <p>For example, let's assume you introduced the <code>Customer.Balance</code> as a new column in the northwind sample database.  You'd need to initialize the Balance like this:</p> <pre><code>update Customer set Balance = (select AmountTotal from \"Order\" where Customer.Id = CustomerId and ShippedDate is null);\n\n# Then, verify with:\nselect CompanyName, Balance from Customer where Id=\"ALFKI\";\n</code></pre>"},{"location":"Data-Model-Examples/","title":"Sample Systems","text":"<p>To make experimenting easier, several sqlite databases are included in the install.  Use them as described below.</p>"},{"location":"Data-Model-Examples/#db_url-abbreviations","title":"<code>db_url</code> Abbreviations","text":"<p>SQLAlchemy URIs can be fiddly.  For example, the sample database is specified like this:</p> <pre><code>ApiLogicServer create --project_name=Allocation --db_url=sqlite:////Users/val/Desktop/database.sqlite\n</code></pre> <p>So, API Logic Server supports the following <code>db_url</code> shortcuts for these pre-installed sqlite sample databases:</p> <ul> <li> <p>nw - same as the sample (customers and orders; you can also use an empty <code>db_url</code>)</p> <ul> <li>With no customizations, the default nw example illustrates the level of automation you should expect for your own projects</li> </ul> </li> <li> <p>nw- - same as nw</p> </li> <li> <p>nw+ - same as nw, but with customizations</p> <ul> <li>This includes many examples of customization, so it's an excellent idea to create and explore it</li> </ul> </li> <li> <p>basic_demo - a similar, simpler example </p> </li> <li>allocation - a rule to allocate a payment to a set of outstanding orders</li> <li>BudgetApp - illustrates automatic creation of parent rows for rollups</li> <li>auth - sqlite authentication database</li> </ul> <p>In addition to the pre-installed sqlite samples, there are also abbreviations for a few docker databases:</p> <ul> <li>chinook - albums and artists</li> <li>classicmodels - customers and orders</li> <li>todo - a simple 1 table database</li> </ul> <p> </p>"},{"location":"Data-Model-Examples/#creating-databases","title":"Creating databases","text":"<p>If you don't have a database, but have an idea, you can use AI tools to create them, or use WebGenAI to create databases - and logic - from Natural Language.  To explore WebGenAI, click here.</p> <p> </p>"},{"location":"Data-Model-Examples/#creating-sample-projects","title":"Creating Sample Projects","text":"<p>You can use the abbreviations to create projects.  For example, create the sample project without customizations to see how API Logic Server would support your own databases:</p> <pre><code>ApiLogicServer create --project_name=nw_no_customizations --db_url=nw-\n</code></pre> <p>Notes:</p> <ol> <li> <p>Docker users would typically precede the <code>project_name</code> with <code>localhost/</code></p> </li> <li> <p>Codespaces users should specify <code>project_name</code> as <code>./</code></p> </li> </ol>"},{"location":"Data-Model-Filters/","title":"Table Filters","text":"<p>For databases with many tables, it may be desirable to filter these when creating your model. </p> <p>As of release 8.1.11, <code>ApiLogicServer create</code> provides a <code>--include_tables</code> option.  You can include or exclude tables based on regex expressions.</p> <p>You designate a yaml file of regex expressions, such as:</p> <pre><code>---\ninclude:\n  - I.*\n  - J\n  - X.*\nexclude:\n  - X1.*\n</code></pre> <p>For example, you can exclude the Region:</p> <pre><code>ApiLogicServer create --project_name=nw_filtered --db_url=nw --include_tables=nw_filter.yml\n</code></pre> <p>where nw_filter contains: <pre><code>---\ninclude:\n  - .*\nexclude:\n  - Region\n</code></pre></p> <p>Heads up - exact match syntax ^Region$</p> <p>Regex infers implicit leading/trailing wildcards.  For exact match, use ^Region$ in the example above</p> <p>As of release 8.1.12, you can omit the include/extend tag, and/or the values under them.  Prior releases require these tags to be present, and populated (e.g., use 'a^' to exclude nothing)</p>"},{"location":"Data-Model-Keys/","title":"Data Model Keys","text":"<p>A critical part of enabling API Logic Server automation is providing for Primary and Foreign Keys.  </p>"},{"location":"Data-Model-Keys/#primary-keys","title":"Primary Keys","text":"<p>These are expected to defined in the database.  They are required for updates, and for the Admin App.</p> <p> </p>"},{"location":"Data-Model-Keys/#-infer_unique_keys","title":"<code>--infer_unique_keys</code>","text":"<p>In some (discouraged) cases, your schema might not declare a primary key, but </p> <ul> <li>designate a specific column as <code>unique</code>, or</li> <li>declare a unique constraint or index</li> </ul> <p>The <code>--infer_unique_keys</code> option is provided to address such cases.  It will presume the unique column/constraint/index is a primary key, and class creation will proceed normally.</p> <p> </p>"},{"location":"Data-Model-Keys/#table-vs-class","title":"Table vs. Class","text":"<p>If your table has no primary key, and <code>infer_unique_keys</code> does not apply, the system will create a table instead of a class.  This significantly reduces functionality: no api, no rules, no admin app, etc.</p> <p>Such situations are flagged on creation as follows for the <code>EmployeeSkills</code> table in a ChatGPT-created Employee Skills database:</p> <pre><code>Welcome to API Logic Server, 09.02.24\n\n                 .. .. .. ..Create EmployeeSkills as table, because no Unique Constraint   \n\n\nCustomizable project ../../../servers/employee_skills created from database mysql+pymysql://root:p@localhost:3306/employee_skills.  Next steps:\n\n\nRun API Logic Server:\n  cd ../../../servers/employee_skills;  python api_logic_server_run.py\n\nCustomize using your IDE:\n  code ../../../servers/employee_skills  # e.g., open VSCode on created project\n  Establish your Python environment - see https://apilogicserver.github.io/Docs/IDE-Execute/#execute-prebuilt-launch-configurations\n</code></pre>"},{"location":"Data-Model-Keys/#foreign-keys","title":"Foreign Keys","text":"<p>These are also expected to be defined in the database.  They are required for a large set of automation, including:</p> <ul> <li> <p>Multi-table APIs</p> </li> <li> <p>Multi-table forms, including Automatic Joins</p> </li> <li> <p>Multi-Table logic (such as sums, counts, parent references, and copy)</p> </li> </ul> <p>If these are missing in the schema, you can provide them in the SQLAlchemy models, as illustrated in the sample project.</p>"},{"location":"Data-Model-Multi/","title":"Multiple Databases","text":"<p>API Logic Server enables you to create projects that support multiple databases, as follows:</p> <ol> <li> <p>Create the project, specifying your \"main\" database</p> </li> <li> <p>Use the <code>ApiLogicServer add-db</code> command for each additional database</p> <ul> <li>See the example below</li> </ul> </li> </ol> <p> </p>"},{"location":"Data-Model-Multi/#example","title":"Example","text":"<p>SQLAlchemy supports multiple databases by using the <code>bind_key</code> which is supported by Flask.  It is leveraged in creating Api Logic Projects when you add databases like this:</p> <pre><code>cd YourApiLogicProject\nApiLogicServer add-db --db_url=todo --bind_key=Todo\n</code></pre> <p> </p> <p></p> <p>Observe:</p> <ol> <li>Model files are created (prefixed by your <code>bind-key</code>) for each table in your <code>db-url</code>.  Note:<ul> <li>The <code>bind-key</code> is inserted into the table class.</li> <li>Sqlite databases are copied to your database folder, simplifying source control.</li> <li>This example uses the shorthand for sqlite databases: <code>todo</code>, <code>classicmodels</code>, <code>chinook</code> and <code>nw</code>.  These are included in the install, so you can experiment with them.</li> </ul> </li> <li>The <code>conf/config.py</code> file is altered per your <code>db-url</code><ul> <li>You can use environment variables to override these assignments, to avoid placing passwords in projects.</li> </ul> </li> <li>The <code>bind_databases.py</code> file is created to bind the <code>bind_key</code> to the database url.   This enables SQLAlchemy to access the proper database.</li> </ol> <p> </p>"},{"location":"Data-Model-Multi/#internals","title":"Internals","text":"<p>The example above will result in the following log:</p> <pre><code>ApiLogicServer 6.90.08 Creation Log:\n1. Not Deleting Existing Project\n2. Using Existing Project\n.. ..Adding Database [Todo] to existing project\n.. .. ..Copying sqlite database to: database/Todo_db.sqlite\n.. .. ..From /Users/val/dev/ApiLogicServer/api_logic_server_cli/database/todos.sqlite\n.. ..Updating config.py file with SQLALCHEMY_DATABASE_URI_TODO...\n.. ..Updating database/bind_databases.py with SQLALCHEMY_DATABASE_URI_TODO...\n3. Create/verify database/Todo_models.py, then use that to create api/ and ui/ models\n a.  Create Models - create database/Todo_models.py, using sqlcodegen\n.. .. ..For database:  sqlite:////Users/val/dev/servers/ApiLogicProject/database/Todo_db.sqlite\n.. .. ..Setting bind_key = Todo\n.. .. ..Create resource_list - dynamic import database/Todo_models.py, inspect 2 classes in &lt;project&gt;/database\n b.  Create api/expose_api_models.py from models\n c.  Create ui/admin/admin.yaml from models\n.. .. ..WARNING - no relationships detected - add them to your database or model\n.. .. ..  See https://github.com/valhuber/LogicBank/wiki/Managing-Rules#database-design\n.. .. ..Write /Users/val/dev/servers/ApiLogicProject/ui/admin/Todo_admin.yaml\n d.  Create ui/basic_web_app -- declined\n4. Final project fixup\n b.   Update api_logic_server_run.py with project_name=/Users/val/dev/servers/ApiLogicProject and api_name, host, port\n c.   Fixing api/expose_services - port, host\n d.   Updated customize_api_py with port=5656 and host=localhost\n e.   Updated python_anywhere_wsgi.py with /Users/val/dev/servers/ApiLogicProject\n</code></pre> <p>Notes:</p> <ol> <li>In step 2:<ol> <li>Updating <code>conf/config.py</code> file with the location of the new database</li> <li>Updating <code>database/bind_databases.py</code> to open this database for SQLAlchemy access</li> </ol> </li> <li>In Step 3:<ol> <li>Creating a <code>models.py</code> file; note:<ul> <li>The additional superclasses,</li> <li>Inclusion of your designated <code>bind_key</code>, for step 1.2</li> </ul> </li> </ol> </li> <li>Note the shorthand for sqlite versions of <code>todo</code>, <code>classicmodels</code>, <code>chinook</code>.  These are included in the install.</li> </ol> <p> </p>"},{"location":"Data-Model-Multi/#runtime-support","title":"Runtime Support","text":""},{"location":"Data-Model-Multi/#api-support","title":"API support","text":"<p>Tables in your new databases are available through swagger.</p> <p> </p>"},{"location":"Data-Model-Multi/#admin-support","title":"Admin support","text":"<p>An admin app is built for the table in your new database.  Access it via a url that prefixes the <code>bind-key</code>, such as <code>http://localhost:5656/admin/Todo_admin/</code> (note the trailing slash).</p>"},{"location":"Data-Model-Postgresql/","title":"Using Postgresql","text":"<p>This page outlines considerations using postgresql.</p>"},{"location":"Data-Model-Postgresql/#creating","title":"Creating","text":"<p>Our tests create the database like this:</p> <pre><code>--\n-- Revised for als from  https://github.com/pthom/northwind_psql/blob/master/northwind.sql\n--\nDROP DATABASE IF EXISTS northwind;\nCREATE DATABASE northwind;\n\\c northwind;\n\n-- in docker container/terminal\n-- psql--username=postgres\n\n\nCREATE TABLE employees (\n    employee_id SERIAL,\n    last_name character varying(20) NOT NULL,\n    first_name character varying(10) NOT NULL...\n\nALTER TABLE ONLY employees\n    ADD CONSTRAINT pk_employees PRIMARY KEY (employee_id);\n\nSELECT setval('employees_employee_id_seq', (SELECT MAX(employee_id) FROM employees));\n</code></pre> <p> </p>"},{"location":"Data-Model-Postgresql/#connecting","title":"Connecting","text":"<p>We refer to it like this:</p> <pre><code>        {\n            \"name\": \"5 - Create Postgres (servers)\",\n            \"type\": \"debugpy\",\n            \"request\": \"launch\",\n            \"cwd\": \"${workspaceFolder}/api_logic_server_cli\",\n            \"justMyCode\": false,\n            \"program\": \"cli.py\",\n            \"redirectOutput\": true,\n            \"args\": [\"create\",\"--project_name=../../../servers/postgres-nw\",\n                \"--db_url=postgresql://postgres:p@localhost/northwind\"],\n            \"console\": \"integratedTerminal\"\n        },\n</code></pre> <p> </p>"},{"location":"Data-Model-Postgresql/#auto-generated-keys","title":"Auto-generated keys","text":"<p>As you can see above, using <code>SERIAL</code> works, creating models that look like this:</p> <pre><code>class Employee(SAFRSBase, Base):\n    __tablename__ = 'employees'\n    _s_collection_name = 'Employee'  # type: ignore\n    __bind_key__ = 'None'\n\n    employee_id = Column(Integer, server_default=text(\"nextval('employees_employee_id_seq'::regclass)\"), primary_key=True)\n    last_name = Column(String(20), nullable=False)\n    first_name = Column(String(10), nullable=False)\n</code></pre> <p> </p>"},{"location":"Data-Model-Postgresql/#loading-test-data","title":"Loading Test Data","text":"<p>The example above illustrates how we create test databases, and load data.  To make subequent inserts work, note you need to initialize sequences, e.g.:</p> <pre><code>SELECT setval('employees_employee_id_seq', (SELECT MAX(employee_id) FROM employees));\n</code></pre>"},{"location":"Data-Model-Quotes/","title":"Data Model Quoted Columns","text":"<p> TL;DR - use --quote for quotedn or accented column names</p> <p>If your database was created with quoted column names, you must specify use the <code>--quote</code> option on <code>ApiLogicServer create</code>.</p>"},{"location":"Data-Model-Quotes/#quoted-column-names","title":"Quoted Column Names","text":"<p>You need to use the <code>--quote</code> option for databases declared like this: Note: ALS will alias the column name by removing non-roman8 accented chars.</p> <pre><code>create table \"STRESS_IDENTITY_BY_DEFAULT\" (  \"id\" int generated by default as identity (increment by 1 start with 1 nocache) ,\"some_text\" varchar(40));\n\nOR\n\nCREATE TABLE MyTable (SerieN\u00famero varchar(11) ...\n</code></pre> <p> </p>"},{"location":"Data-Model-Quotes/#apilogicserver-create-quote","title":"ApiLogicServer create --quote","text":"<p>In such cases, include the <code>--quote</code> option:</p> <pre><code>ApiLogicServer create --project_name=oracle_stress --quote --db_url='oracle+oracledb://stress:tiger@localhost:1521/?service_name=ORCL'\n</code></pre>"},{"location":"Data-Model-Sqlite/","title":"Sqlite","text":"<p>Sqlite requires special considerations for cascade delete.  For more information, click here.</p>"},{"location":"Database-Changes/","title":"Database Design Changes","text":"<p> TL;DR - Executable Test Suite, Documentation</p> <p>You can change your database schema and rebuild your project (\"schema migration\"), preserving customizations to your logic, api and admin app.  You can drive changes from either:</p> <ul> <li> <p>Your database, using your database tools</p> </li> <li> <p>Your <code>database/models.py</code> file, using alembic to drive those changes into the database</p> </li> </ul> <p>To reconcile your api and admin app, you then issue <code>als rebuild-from-model</code> or 'rebuild-from-database`</p> <p> </p>"},{"location":"Database-Changes/#project-creation-models","title":"Project Creation: Models","text":"<p>When you intially create your project:</p> <ul> <li> <p>the system reads the database schema to create <code>models.py</code></p> </li> <li> <p><code>models.py</code> drives the creation process of APIs, Apps etc.</p> </li> <li> <p>you customize the created project, mainly by altering the files on the far right shown in the diagram below</p> </li> </ul>"},{"location":"Database-Changes/#model-customization","title":"Model Customization","text":"<p>As shown in the diagram, creation is always driven from <code>models.py.</code>  Models differ from physical schemas in important ways:</p> <ul> <li> <p>the system ensures that class names are capitalized and singular</p> </li> <li> <p>there are good reasons to customize <code>models.py</code>:</p> <ul> <li>to add foreign keys missing in the database - these are critical for multi-table apis and applications</li> <li>to provide better naming, e.g. alias column names as shown below from the northwind sample</li> </ul> </li> </ul> alias column names<pre><code>class Category(SAFRSBaseX, Base):\n    __tablename__ = 'CategoryTableNameTest'\n    _s_collection_name = 'Category'  # type: ignore\n    __bind_key__ = 'None'\n\n    Id = Column(Integer, primary_key=True)\n    CategoryName = Column('CategoryName_ColumnName', String(8000))  # manual fix - alias\n    Description = Column(String(8000))\n    Client_id = Column(Integer)\n</code></pre>"},{"location":"Database-Changes/#rebuild-from-model-or-database","title":"Rebuild from Model or Database","text":"<p>It is highly likely you will need to alter your database design.  This poses the question: do I alter the schema (using a database tool), or <code>models.py</code>?  As shown below, the system supports both, so you can decide what strategy works best for you:</p> <p></p> <p>You can rebuild your project, preserving customizations (including any additional files you have created).  You have 2 alternatives, depending on where you choose the \"source of truth\" for your database:</p> Source of Truth Means Use <code>rebuild</code> option Database The schema is the source of truthIt includes all the foreign keys <code>rebuild-from-datatabase:</code> rebuilds the files shown in blue and purple. Model Model is the source of truthUse SQLAlchemy services to drive changes into the database <code>rebuild-from-model:</code> rebuilds the files shown in blue <p>Note that <code>ui/admin/admin.yaml</code> is never overwritten (the dotted line  means it is written on only on <code>create</code> commands).  After rebuilds, merge the new <code>ui/admin/admin-created.yaml</code> into your customized <code>admin.yaml.</code></p> <p>For more information, see Alembic.</p> <p> </p>"},{"location":"Database-Changes/#api-and-admin-app-merge-updates","title":"API and Admin App merge updates","text":"<p>As of release 5.02.03, <code>rebuild</code> services provide support for updating customized API and Admin:</p> System Object Support API <code>api/expose_api_models_created.py</code> created with new <code>database/models.py</code> classes Admn App <code>ui/admin/admin-merge.yaml</code> is the merge of <code>ui/admin/admin.yaml</code> and new <code>database/models.py</code> classes <p>Review the altered files, edit (if required), and merge, or copy them over the original files.</p> <p> </p>"},{"location":"Database-Changes/#use-alembic-to-update-database-schema-from-model","title":"Use Alembic to update database schema from model","text":"<p>As of release 5.02.03, created API Logic Projects integrate Alembic to perform database migrations.</p> <ul> <li>Autogenerate: alter your <code>database/models.py</code>, and have alembic create the migration scripts for you</li> <li>Manual: create migration scripts by hand, or</li> </ul> <p>Preconfiguration includes:</p> <ul> <li>initialized <code>database/alembic</code> directory</li> <li>configured <code>database/alembic/env.py</code> for autogenerations</li> <li>configured <code>database/alembic.ini</code> for directory structure</li> </ul> <p>You can Alembic in a more-automated Autogenerate mode, or Manual, as described below.  Then, use <code>rebuild-from-model</code> as described above.</p>"},{"location":"Database-Changes/#autogenerate","title":"Autogenerate","text":"<p>The diagram below illustrates a simple path for enacting changes to the data model, and using alembic to automate the database changes:</p> <ol> <li>Update <code>database/models.py</code> (e.g., add columns, tables)</li> <li>Use alembic to compute the revisions <pre><code>cd database\nalembic revision --autogenerate -m \"Added Tables and Columns\"\n</code></pre></li> <li>Edit the revision file to signify your understanding</li> <li>Activate the change <pre><code>alembic upgrade head \n</code></pre></li> </ol> <p></p>"},{"location":"Database-Changes/#manual","title":"Manual","text":"<p>As described in the Tutorial: <pre><code>cd database\nalembic revision -m \"my revision\"\n</code></pre> This will create <code>database/alembic/versions/xxx_my_revision.py</code>. * edit the <code>upgrade()</code> and <code>downgrade()</code> functions as shown in the Tutorial</p> <p>Then, to run the script <pre><code>alembic upgrade head\n</code></pre></p> <p></p>"},{"location":"Database-Changes/#use-ai-assistant","title":"Use AI Assistant","text":"<p>You can also use your AI assistant to add columns, tables, and relationships.  It will choreograph changes to database models, and use alembic to for the database.</p>"},{"location":"Database-Connectivity/","title":"Connection Examples, Debug","text":"<p> TL;DR - Project Creation: Identify Database (SQLAlchemy URI)</p> <p>You create API Logic Projects with the CLI, providing the <code>db_url</code> parameter -- a SQLAlchemy URI.</p> <ul> <li> <p>See below for several examples</p> </li> <li> <p>Or use the abbrevations to explore pre-supplied test databases - see here.</p> </li> </ul> <p>This page provides background on connecting, including database tools and debugging connections.</p> <p> </p>"},{"location":"Database-Connectivity/#examples","title":"Examples","text":"<p>Recall the <code>db_url</code> parameter is a SQLAlchemy URI.  To see some examples, see below, and use</p> <pre><code>ApiLogicServer examples\n</code></pre> <p>This produces a console log like:</p> <pre><code># local sqlite\ngenai-logic create --db_url=sqlite:///c:\\genai-logic\\nw.sqlite --project_name=nw\ngenai-logic create --db_url=sqlite:///samples/dbs/todos.sqlite --project_name=todo\ngenai-logic create --db_url=sqlite:////Users/val/dev/ApiLogicServer/ApiLogicServer-dev/clean/ApiLogicServer/samples/dbs/todos.sqlite --project_name=todo\n\n# from localhost to mysql container\ngenai-logic create --db_url=mysql+pymysql://root:p@localhost:3306/classicmodels --project_name=docker_classicmodels\ngenai-logic create --db_url=mysql+pymysql://root:p@localhost:3306/Chinook --project_name=docker_chinook\n\n# from container to mysql container  replace localhost with....\ngenai-logic create --db_url=mysql+pymysql://root:p@mysql-container:3306/Chinook --project_name=/localhost/docker_chinook\n\n# microsoft sql server (setup: https://apilogicserver.github.io/Docs/Install-pyodbc/)\ngenai-logic create --db_url='mssql+pyodbc://sa:Posey3861@localhost:1433/NORTHWND?driver=ODBC+Driver+18+for+SQL+Server&amp;trusted_connection=no&amp;Encrypt=no' --project-name=NORTHWND\n\n# oracle\ngenai-logic create --project_name=oracle_hr --db_url='oracle+oracledb://hr:tiger@localhost:1521/?service_name=ORCL'\n\n# postgres\ngenai-logic create --db_url=postgresql://postgres:p@localhost/northwind --project-name=nw-postgres\ngenai-logic create --db_url=postgresql://postgres:p@10.0.0.234/postgres\ngenai-logic create --project_name=my_schema --db_url=postgresql://postgres:p@localhost/my_schema\ngenai-logic create --db_url=postgresql://postgres:password@localhost:5432/postgres?options=-csearch_path%3Dmy_db_schema\n\n# pythonanywhere\ngenai-logic create --project_name=Chinook \\\n  --host=ApiLogicServer.pythonanywhere.com --port= \\\n  --db_url=mysql+pymysql://ApiLogicServer:@ApiLogicServer.mysql.pythonanywhere-services.com/ApiLogicServer\\$Chinook\n\n\nWhere --db_url is one of...\n   &lt;default&gt;                     Sample DB                    - https://apilogicserver.github.io/Docs/Sample-Database/\n   &lt;db_url abbreviation&gt;         Other Samples                - https://apilogicserver.github.io/Docs/Data-Model-Examples/\n   &lt;SQLAlchemy Database URI&gt;     Your own database            - https://docs.sqlalchemy.org/en/14/core/engines.html\n                                 Other URI examples:          - https://apilogicserver.github.io/Docs/Database-Connectivity//\n\nDocs: https://apilogicserver.github.io/Docs/Database-Connectivity/\n</code></pre> <p>Important notes:</p> <ul> <li>tables without primary keys are not imported as classes, and do not appear in your API or Admin application</li> </ul> <p> </p>"},{"location":"Database-Connectivity/#verify-database-connectivity","title":"Verify Database Connectivity","text":"<p>Database connectivity can be... trying.  We recommend, if possible, that you verify local machine operation before trying docker.</p> <p>Before attempting the SQLAlchemy connectivity discussed here, it's a best practice to make sure your computer can connect to the database server.  One possible approach is a command line utility called <code>telnet</code>.</p> <p>First, ensure your machine has telnet installed.  Consult the documentation for your OS type.  Note that Windows 11 requires this command (use Powershell, and run as adminstrator):</p> <pre><code>Enable-WindowsOptionalFeature -Online -FeatureName TelnetClient\n</code></pre> <p>Then, you can issue a command such as:</p> <p><pre><code>telnet 10.0.0.77 3306  # where you subsitute IP address)\n</code></pre> If you are prompted for your database password, you have established connectivity.</p> <p> </p>"},{"location":"Database-Connectivity/#explore-sqlalchemy","title":"Explore SQLAlchemy","text":"<p>To facilitate exploring SQLAlchemy, each project contains a <code>database/db_debug/db_debug.py</code>.</p> <p>Alter it to explore SQLAlchemy features and IDE support, as illustrated in the sample project.</p> <p> </p>"},{"location":"Database-Connectivity/#oracle-debug","title":"Oracle debug","text":"<p>For Oracle connections, <code>ApiLogicServer create</code> creates <code>database/db_debug/sa-pydb.py</code>.  You can use this to explore Oracle connections.</p> <p> </p>"},{"location":"Database-Connectivity/#sqlite","title":"Sqlite","text":"<p>You can use an existing sqlite database like this: <pre><code>ApiLogicServer create --project_name=Allocation --db_url=sqlite:////Users/val/Desktop/database.sqlite\n</code></pre></p> <p>Other important notes:</p> <ul> <li>As shown above, use the full path</li> <li>So that such databases are included in your project, they are copied to the <code>database</code> folder, and renamed to <code>db.sqlite'</code></li> <li>The project URL in <code>conf/config.py</code> is made relative to this location (<code>sqlite:///../database/db.sqlite</code>).  This keeps your projects portable, e.g., colleagues can pull your project from <code>GitHub</code> and run.</li> </ul> <p> </p>"},{"location":"Database-Connectivity/#cli-installation","title":"CLI Installation","text":"<p>The sqlite runtime is installed with API Logic Server.  You might, however, wish to install the command line tools (CLI).</p> <p>These are typically already installed on Mac computers.</p> <p>For windows, download and unzip this file:</p> <p></p> <p>And copy the 3 exe files to a place where they can be run, such as <code>~/AppData/Local/Microsoft/WindowsApps</code>:</p> <p></p> <p> </p>"},{"location":"Database-Connectivity/#northwind-sqlite-default-sample","title":"Northwind - sqlite (default sample)","text":"<p>See Sample Database.</p> <p>This is a sqlite database, packaged with API Logic Server, so you can explore without any installs.  It is obtained from Northwind, and altered to include several columns to demonstrate rules.</p> <p>Run under API Logic Server docker: <pre><code>ApiLogicServer run --project_name=/localhost/docker_project\n</code></pre></p>"},{"location":"Database-Connectivity/#chinook-albums-and-artists","title":"Chinook - Albums and Artists","text":"<p>Designate this as follows: <code>--db_url={install}/Chinook_Sqlite.sqlite</code>, e.g.:</p> <pre><code>~/ApiLogicServer/api_logic_server_cli/database/Chinook_Sqlite.sqlite\n</code></pre> <p> </p>"},{"location":"Database-Connectivity/#sqlite-database-abbreviations","title":"SQLite Database Abbreviations","text":"<p>To make experimenting easier, you can specify a <code>db_url</code> shortcut.</p> <p> </p>"},{"location":"Database-Connectivity/#docker-databases","title":"Docker Databases","text":"<p>See Docker Test Databases.</p> <p> </p>"},{"location":"Database-Connectivity/#managing-database-in-your-ide","title":"Managing Database in your IDE","text":"<p>Various IDEs provide tools for managing databases.</p> <p> </p>"},{"location":"Database-Connectivity/#dbvis","title":"dbvis","text":"<p>dbvis is a very popular tool, with support for exporting tables and data.</p> <p>For local connections, consider resetting <code>trustServerCertificate</code>:</p> <p></p> <p> </p>"},{"location":"Database-Connectivity/#adminer","title":"adminer","text":"<p>You can find it here.</p> <p>Try: <pre><code>docker run --name adminer --link some_database:db -p 8080:8080 --net dev-network adminer\n</code></pre></p> <p>Then you can hit http://localhost:8080 or http://host-ip:8080 in your browser:</p> <p></p> <p>You will need to install plug-ins for sqlite3, to address logging in without a password</p> <p> </p>"},{"location":"Database-Connectivity/#pycharm-database-tools","title":"PyCharm Database Tools","text":"<p>Pycharm provides excellent database tools, as shown below:</p> <p></p> <p> </p>"},{"location":"Database-Connectivity/#vscode-database-tools","title":"VSCode Database Tools","text":"<p>I also use SQLTools.  To use it, you must first install drivers:</p> <p></p> <p>You may want to install extensions for MySQL and Postgres.</p> <p>Then, you can explore the sample:</p> <p></p> <p> </p>"},{"location":"Database-Connectivity/#docker-pgadmin","title":"Docker pgadmin","text":"<p>See discussion above.</p> <p> </p>"},{"location":"Database-Connectivity/#azure-data-studio","title":"Azure Data Studio","text":"<p>See discussion above.</p> <p> </p>"},{"location":"Database-Connectivity/#db-browser-for-sqlite","title":"DB Browser for SQLite","text":"<p>Quite a nice tool for sqlite.</p> <p> </p>"},{"location":"Database-Connectivity/#pythonanywhere","title":"PythonAnywhere","text":"<p>PythonAnyWhere provides the ability to create and connect to databases.  For example, create a project like this from within PythonAnyWhere:</p> Create database for mysql/Chinook<pre><code>  ApiLogicServer create --project_name=Chinook \\\n      --host=ApiLogicServer.pythonanywhere.com --port= \\\n      --db_url=mysql+pymysql://ApiLogicServer:Your-DB-Password@ApiLogicServer.mysql.pythonanywhere-services.com/ApiLogicServer\\$Chinook\n</code></pre> <p>Notes:</p> <ul> <li>Be aware of connectivity and firewall issues.</li> </ul> <p> </p>"},{"location":"Database-Diagram/","title":"Database Diagram","text":"<p> TL;DR - Database Diagram Creation</p> <p>Created projects include a <code>docs</code> folder with a <code>db.dbml</code> file.  This can be rendered</p> <ul> <li>on the Web, or </li> <li> <p>in your IDE</p> <ul> <li>Requires IDE extension.  For example, in VSCode,  DBML Live Preview. </li> </ul> </li> </ul> <p> </p> <p></p>"},{"location":"Database-Docker/","title":"Docker Test Databases","text":"<p>Docker is a wonderful way to get known databases for your project, and eliminate often-messy database installs.  The docker databases below were created for use with API Logic Server, but you may find them generally useful. </p> <p>General notes:</p> <ul> <li> <p>Images include data: the databases below contain data, so they are easier to install for dev.  In production, you would almost certainly separate storage from the database server.</p> </li> <li> <p>Authdb: in addition to the database noted below, the MySQL and Postgres versions contain <code>authdb</code>, so you can begin exploring / testing security.  You may wish to alter these to introduce additional data you can use in Grant declarations.</p> </li> </ul> <p> </p>"},{"location":"Database-Docker/#quick-start","title":"Quick Start","text":"<p>You probably don't need all these, but here's how you start the docker databases (schema details below):</p> <pre><code>docker network create dev-network  # only required once\n\ndocker run --name mysql-container --net dev-network -p 3306:3306 -d -e MYSQL_ROOT_PASSWORD=p apilogicserver/mysql8.0:latest\n\ndocker run -d --name postgresql-container --net dev-network -p 5432:5432 -e PGDATA=/pgdata -e POSTGRES_PASSWORD=p apilogicserver/postgres:latest\n\ndocker run --name sqlsvr-container --net dev-network -p 1433:1433 -d apilogicserver/sqlsvr:latest\n\ndocker run --name sqlsvr-container --net dev-network -p 1433:1433 -d apilogicserver/sqlsvr-m1:latest  # Mac M1\n</code></pre> <p></p> <p> </p>"},{"location":"Database-Docker/#managing-docker-dbs","title":"Managing Docker DBs","text":"<p>For some internal notes on using Docker command line tools with Docker databases, click here.</p> <p> </p>"},{"location":"Database-Docker/#connecting-to-docker-dbs","title":"Connecting to Docker DBs","text":"<p>The examples below illustrate connecting to dockerized databases.  You can connect from <code>pip</code> installs, or from API Logic Server containers, as described below.</p> <p> </p>"},{"location":"Database-Docker/#locally-from-pip-install","title":"Locally, From <code>pip</code> Install","text":"<p>If you are using <code>pip install</code> version of API Logic Server.  Differences to note:</p> <ul> <li>the <code>/localhost</code> path is typically not required</li> <li>the server host address is <code>localhost</code></li> <li>Note related in install procedure, the SqlServer example illustrates you can single-quote the url, instead of using the <code>\\</code> escapes</li> </ul> <pre><code>ApiLogicServer create --project_name=sqlserver --db_url='mssql+pyodbc://sa:Posey3861@localhost:1433/SampleDB?driver=ODBC+Driver+18+for+SQL+Server&amp;trusted_connection=no&amp;Encrypt=no'\n\nApiLogicServer create --project_name=classicmodels --db_url='mysql+pymysql://root:p@localhost:3306/classicmodels'\n\nApiLogicServer create --project_name=postgres --db_url=postgresql://postgres:p@localhost/postgres\n</code></pre> <p> </p>"},{"location":"Database-Docker/#from-container","title":"From Container","text":"<p>To connect from docker containers, you must to enable connectivity from your API Logic Server container to your database container.  See the instructions below.</p> <p> </p>"},{"location":"Database-Docker/#create-docker-network","title":"Create Docker network","text":"<p>Start the docker machine like this (Windows users - use Powershell) to enable connectivity from your API Logic Server container to your database container:</p> <pre><code>cd ~/dev/servers  # project directories will be created here\ndocker network create dev-network  # only required once\ndocker run -it --name api_logic_server --rm -p 5656:5656 -p 5002:5002 --net dev-network -v ${PWD}:/ApiLogicServer apilogicserver/api_logic_server\n</code></pre> <p>And then, you can refer to the container names (<code>sqlsvr-container</code> instead of an IP name) for your database uri, e.g.:</p> <pre><code>mssql+pyodbc://sa:Posey3861@sqlsvr-container:1433/NORTHWND?driver=ODBC+Driver+18+for+SQL+Server&amp;trusted_connection=no&amp;Encrypt=no\"\n</code></pre> <p> </p>"},{"location":"Database-Docker/#vscode-enable-network","title":"VSCode - enable network","text":"<p>If you are running API Logic Server in a container, and accessing dockerized databases, you will need to enable connectivity by uncommenting the indicated line in the diagram below:</p> <p>]</p> <p>The diagram above, and the examples below, presume you have created a docker network called <code>dev-network</code>, as shown at the top of this page.</p> <p> </p>"},{"location":"Database-Docker/#sqlserver-sqlalchemy-uris","title":"SqlServer SQLAlchemy URIs","text":"<p>Important considerations for SQLAlchemy URIs:</p> <ul> <li> <p>The example above runs on a mac</p> </li> <li> <p>It depends on the version of ODBC Driver; for example, a more recent version is:</p> </li> </ul> <pre><code>  mssql+pyodbc://sa:Posey3861@localhost:1433/NORTHWND?driver=ODBC+Driver+18+for+SQL+Server&amp;trusted_connection=no&amp;Encrypt=no\n</code></pre> <ul> <li> <p>Observe the additional parameter for encryption (see here)</p> </li> <li> <p>On Linux (and inside docker), the URI is:</p> </li> </ul> <pre><code>--db_url='mssql+pyodbc://sa:Posey3861@sqlsvr-container:1433/NORTHWND?driver=ODBC+Driver+18+for+SQL+Server&amp;trusted_connection=no&amp;Encrypt=no'\n</code></pre> <ul> <li>In VSCode launch configurations, the <code>db_url</code> fails, a situation I have resolved and would welcome help on...</li> </ul> <p> </p>"},{"location":"Database-Docker/#sample-dbs-apilogicserver","title":"Sample DBs: <code>apilogicserver</code>","text":""},{"location":"Database-Docker/#mysql","title":"MySQL","text":""},{"location":"Database-Docker/#classicmodels","title":"classicmodels","text":"<p>Docker below built from MySQL Tutorials - Customers, Orders...</p> <pre><code>docker run --name mysql-container --net dev-network -p 3306:3306 -d -e MYSQL_ROOT_PASSWORD=p apilogicserver/mysql8.0:version1.0.7\n</code></pre> <p>Then access using Docker: <pre><code>ApiLogicServer create --project_name=/localhost/classicmodels --db_url=mysql+pymysql://root:p@mysql-container:3306/classicmodels\n</code></pre></p> <p> </p>"},{"location":"Database-Docker/#mysql-native-user","title":"MySQL Native user","text":"<p>If you are using VSCode, you may wish to use tools to manage and query your database.  A useful resource is this video, which illustrates using SQLTools, a VSCode extension.  Connecting to Docker databases has proven difficult for many, but this video shows that the solution is to create a native user: <pre><code>Create new MySQL user with old authentication method:\nCREATE USER 'sqluser'@'%' IDENTIFIED WITH mysql_native_password BY 'password';\nGRANT ALL PRIVILEGES ON *.* TO 'sqluser'@'%';\nFLUSH PRIVILEGES;\n</code></pre></p> <p> </p>"},{"location":"Database-Docker/#sakila","title":"Sakila","text":"<p>Obtained from Sakila - Actors and Films.</p> <p>Installed in Docker per these instructions.</p> <pre><code>ApiLogicServer create --project_name=/localhost/sakila --db_url=mysql+pymysql://root:p@mysql-container/sakila\n</code></pre> <p> </p>"},{"location":"Database-Docker/#chinook","title":"Chinook","text":"<p>Obtained from Chinooks.</p> <pre><code>ApiLogicServer create --project_name=/localhost/chinook --db_url=mysql+pymysql://root:p@mysql-container/Chinook\n</code></pre> <p> </p>"},{"location":"Database-Docker/#postgres","title":"Postgres","text":""},{"location":"Database-Docker/#northwind","title":"Northwind","text":"<p>Obtained from pthom at git - many thanks!</p> <p>Installed in Docker per these instructions.</p> <pre><code>docker run -d --name postgresql-container --net dev-network -p 5432:5432 -e PGDATA=/pgdata -e POSTGRES_PASSWORD=p apilogicserver/postgres:latest\n</code></pre> <p>Run under API Logic Server docker: <pre><code>ApiLogicServer create --project_name=/localhost/postgres --db_url=postgresql://postgres:p@postgresql-container/postgres\n</code></pre></p> <p>It may be necessary to replace the docker container name with your IP address, e.g., --db_url=postgresql://postgres:p@10.0.0.236/postgres</p> <p>Docker pgadmin: <pre><code>docker run --name pgadmin -p 5050:5050 thajeztah/pgadmin4\n</code></pre></p> <p>JDBC (for tools): <code>postgresql://postgres:p@10.0.0.234/postgres</code></p>"},{"location":"Database-Docker/#version-update-200","title":"Version Update: 2.0.0","text":"<p>In prior versions, note the datatype <code>bpchar</code> (blank-padded char) results in several evidently benign messages like: <pre><code>packages/sqlalchemy/dialects/postgresql/base.py:3185: SAWarning: Did not recognize type 'bpchar' of column 'customer_id'\n</code></pre></p> <p>The current version uses <code>character varying(5)</code>, and should not exhibit issues such as Element does not exist.</p>"},{"location":"Database-Docker/#bpchar","title":"bpchar","text":"<p>This was researched.  </p> <p>This database used `bpchar`` (an old datatype), with no length (a logical error - blank pad to unspecified length??).  So, the maintainers corrected the bogus example to eliminate the use of bpchar. </p> <p>Here is the revised standard, which we are using as our test example.</p> <p> </p>"},{"location":"Database-Docker/#sqlserver","title":"SqlServer","text":""},{"location":"Database-Docker/#northwind_1","title":"Northwind","text":"<p>Start SQL Server:</p> <pre><code>docker run --name sqlsvr-container --net dev-network -p 1433:1433 -d apilogicserver/sqlsvr:version2.0.1\n</code></pre> <p>Then, under API Logic Server, Docker installed: <pre><code>ApiLogicServer create --project_name=/localhost/sqlserver --db_url=mssql+pyodbc://sa:Posey3861@sqlsvr-container:1433/NORTHWND?driver=ODBC+Driver+17+for+SQL+Server\\&amp;trusted_connection=no\n</code></pre></p> <p>You will probably also want to get Azure Data Studio, and configure a connection like this (password: posey3861):</p> <p></p> <p>It also supports connecting to Azure-based databases:</p> <p></p>"},{"location":"Database-Docker/#oracle","title":"Oracle","text":"<p>This procedure explores accessing oracle 19c via SQLAlchemy, using oracledb.  Many thanks to the following:</p> <ul> <li> <p>This article.</p> </li> <li> <p>The following sample code.</p> </li> <li> <p>This docker image</p> </li> </ul> <p>This Project contains short programs you can use to explore Oracle and SQLAlchemy.</p> <p> </p>"},{"location":"Database-Docker/#obtain-the-docker-image","title":"Obtain the Docker Image","text":"<p>Set up Oracle Volume</p> <pre><code>cd ~/dev/ApiLogicServer/oracle\nmkdir oracle-19c\nchmod -R 755 oracle-19c\n</code></pre> <p>Start the Oracle Database</p> <p>For amd architectures, this will install Oracle 19 and SqlPlus (command line SQL):</p> <pre><code>docker run --name oracle-19c -p 1521:1521 -e ORACLE_SID=ORCL -e ORACLE_PWD=tiger -v ~/dev/ApiLogicServer/oracle/oracle-19c/oradata/:/opt/oracle/oradata doctorkirk/oracle-19c \n</code></pre> <p>Note: Start takes several minutes (initially) once docker is downloaded/started.  It's large: over 5GB (smaller images are available).</p> <p>Note: This fails under M-series Macs.  There are several web articles that discuss how to make this work, but we have not tried them.</p> <p>Verify SqlPlus Works</p> <p>Use Docker desktop &gt; terminal to login to <code>sqlplus</code> with system/tiger.  Some commands you might want:</p> <pre><code>-- list schemas\n\nselect * from all_users;\n\nselect USERNAME from all_users;\n\nalter session set current_schema = HR;\n\nSELECT table_name FROM all_tables WHERE owner = 'HR';\n\n-- determine service name\n\nselect value from v$parameter where name like '%service_name%';\n</code></pre> <p> </p>"},{"location":"Database-Docker/#hr","title":"HR","text":"<p>To explore Oracle using the Oracle HR database...</p>"},{"location":"Database-Docker/#deploy-the-hr-example","title":"Deploy the HR Example","text":"<p>Use this documentation.</p> <p>The installer will ask several questions; we used the following responses:</p> <p>args: 1 = tiger, 2 = users, 3 = temp, 4 = tiger, 5 = $ORACLE_HOME/demo/schema/log/</p> <p>Here, for example, is the create sql.</p> <p> </p>"},{"location":"Database-Docker/#create-api-logic-project","title":"Create API Logic Project","text":"<pre><code>ApiLogicServer create --project_name=oracle_hr --db_url='oracle+oracledb://hr:tiger@localhost:1521/?service_name=ORCL'\n</code></pre> <p>Notes:</p> <ol> <li> <p><code>oracle+oracledb</code> designates the database type.  ApiLogicServer includes this driver, so you don't need to pip-install it.</p> </li> <li> <p>Observe the login is <code>hr</code> (not <code>system</code>).  The previous step defines the <code>hr</code> user as having the default schema as <code>hr</code>.  This is one approach for filtering the tables for a specific schema.  </p> </li> <li> <p>Note the <code>service_name=ORCL</code> corresponds to <code>ORACLE_SID=ORCL</code> on the docker start command above.</p> </li> </ol> <p> </p>"},{"location":"Database-Docker/#new-userdatabase","title":"New user/database","text":"<p>Some basic SqlPlus commands for creating a user / schema:</p> <pre><code>create user STRESS identified by tiger;\n\nGRANT CONNECT, RESOURCE, DBA TO STRESS;\n\nconnect STRESS;\n\nSELECT table_name FROM all_tables WHERE owner = 'STRESS';\n</code></pre> <p>You can create tables now (note user prefix not required per <code>connect</code>).</p>"},{"location":"Database-Docker/#create-your-own-db-image","title":"Create Your Own DB Image","text":"<p>The API Logic Server project provides several docker databasesas described above.  A simple approach is to build on one of these, to add your own data, and to create your own database container for your team.  This provides a valuable \"common starting place\" for test database structure and test data.</p> <p> </p>"},{"location":"Database-Docker/#1-add-databases-test-data","title":"1. Add Databases, Test Data","text":"<p>You can access the database cli via Docker Desktop, to add databases, data etc as shown below.</p> <p>Created projects contain \"cheat-sheet\" instructions for logging into your database; click here.</p> <p>See here for another example on how to update / save a docker image.</p> <p></p> <p> </p>"},{"location":"Database-Docker/#2-push-docker-image","title":"2. Push Docker Image","text":"<p>The same created directory contains <code>authdb_mysql.Dockerfile</code>, with instructions to convert a running (database) container to an image, and push it to your own DockerHub account.</p>"},{"location":"DevOps-Automation/","title":"DevOps Automation","text":"<p> TL;DR - Project Creation: DevOp script creation</p> <p>Shell scripts are created to:</p> <ul> <li> <p>containerize your project</p> </li> <li> <p>test the image</p> </li> <li> <p>deploy it to Azure</p> </li> </ul> <p>Note the scripts require modification for your GitHub and Docker accounts.</p> <p> </p> <p></p> <p>This is built when you create your project.</p> <ul> <li> <p>The various names are drawn from your project name, and altered to meet docker standards (lower case, no underbars, etc).</p> </li> <li> <p>Note the construction includes usage of <code>env</code> files and environment variables; for more information, see Container Configuration.</p> </li> </ul> <p>You can create and run the image as shown above.  </p> <p>You can also run the docker compose, which contains services for both your application, and the database.  </p> <p>The pages below illustrate how you can explore database configuration:</p> <ul> <li> <p>You can use cloud-based managed databases (e.g., Azure).</p> </li> <li> <p>Or use dev-oriented database images. You can explore these using our pre-built sample database containers; see Container Database.</p> </li> <li> <p>These examples just get you started; cloud suppliers provide a wealth of options and documentation.</p> </li> </ul>"},{"location":"DevOps-Container-Configuration/","title":"Container Configuration","text":"<p> TL;DR - Configure Containers with env variables</p> <p>Containers are most commonly configured by environment variables, either in docker files, docker compose files, env files, or command line arguments.  The most common configuration parameters govern database / port locations - click here.</p> <p> </p>"},{"location":"DevOps-Container-Configuration/#starting-the-server","title":"Starting the Server","text":""},{"location":"DevOps-Container-Configuration/#via-the-container","title":"Via the Container","text":"<p>Once the container is created, you can start it click here, which contains:</p> <pre><code>docker run --env-file devops/docker-image/env.list -it --name api_logic_project --rm --net dev-network -p 5656:5656 -p 5002:5002 apilogicserver/&lt;your project&gt;\n</code></pre> <p>Note that:</p> <ol> <li> <p>Execution begins automatically (the dockerfile runs <code>python api_logic_server_run.py</code>)</p> </li> <li> <p>Configuration is via <code>env.list</code>; configure as required</p> </li> </ol> <p> </p>"},{"location":"DevOps-Container-Configuration/#via-the-ide","title":"Via the IDE","text":"<p>As described in the Quick Start, Run Configurations are provided to start the server in your IDE.</p> <p> </p>"},{"location":"DevOps-Container-Configuration/#command-line-python","title":"Command Line - Python","text":"<p>Recall that you execute your API Logic Project by starting the server, like this:</p> <p><pre><code>ApiLogicServer (venv)&gt; cd my_new_project\nmy_new_project(venv)&gt; python api_logic_server_run.py\n</code></pre> Note this presumes you have activated your <code>venv</code>.  The system also provides shell scripts you can use: <pre><code>sh run.sh  # windows - use run.ps1\n</code></pre></p> <p>Then, to run the Admin App and Swagger:</p> <p>Run your browser at</p> <pre><code>http://localhost:5656/\n</code></pre> <p> </p>"},{"location":"DevOps-Container-Configuration/#command-line-scripts","title":"Command Line - Scripts","text":"<p>Alternatively, you can start the server using the run script, e.g.:</p> <p></p>"},{"location":"DevOps-Container-Configuration/#stopping-the-server","title":"Stopping the server","text":"<p>You can stop the server by cancelling it, or via an API:</p> <pre><code>http://localhost:5656/stop?msg=API stop - Stop API Logic Server\n</code></pre> <p>This can be useful in testing if you don't have access to the server console.  The <code>msg</code> parameter is optional.</p> <p> </p>"},{"location":"DevOps-Container-Configuration/#configuring-the-server","title":"Configuring the server","text":"<p>Configuration parameters enable you to specify hosts and ports, database locations, debug settings, etc,, as described below.</p> <p> </p>"},{"location":"DevOps-Container-Configuration/#database-locations","title":"Database Locations","text":"<p>SQLAlchemy database URIs are set in your <code>conf/config.py</code> file, from your creation CLI arguments.  They apply to target database(s), and the authentication database.  For example:</p> <pre><code>    SQLALCHEMY_DATABASE_URI : typing.Optional[str] = f\"mysql+pymysql://root:p@localhost:3306/classicmodels\"\n</code></pre> <p>Special handling is provided for sqlite databases, as described here.</p> <p> </p>"},{"location":"DevOps-Container-Configuration/#docker-directories","title":"Docker Directories","text":"<p>Projects are created with a <code>devops/docker-image/build-image/dockerfile</code>, resulting in the following directory structure:  </p> <p></p> <p> </p>"},{"location":"DevOps-Container-Configuration/#hosts-and-ports","title":"Hosts and Ports","text":"<p>ApiLogicServer attempts to avoid port conflicts.  These can arise from:</p> <ul> <li> <p>Common use of 8080</p> </li> <li> <p>Mac use of 5000</p> </li> </ul> <p>To avoid conflicts, ports are defaulted as follows:</p> For Port ApiLogicServer <code>5656</code> <p>Hosts are defaulted as follows:</p> Installed as Host Docker <code>0.0.0.0</code> Local Install <code>localhost</code> <p>These defaults are also stored in the <code>conf/config.py</code> file.</p> <p> </p>"},{"location":"DevOps-Container-Configuration/#defaults-create-time","title":"Defaults: Create Time","text":"<p>You can specify default values for hosts, ports and databases when you create the application.  Specify ApiLogicServer CLI arguments, like this:</p> <pre><code>ApiLogicServer create --project_name=~/dev/servers/api_logic_server \\\n                      --host=myhost --port=myport --swagger_host=mycloud \\\n                      --db_url=mysql+pymysql://root:p@localhost:3306/classicmodels\n</code></pre> <p> </p>"},{"location":"DevOps-Container-Configuration/#overridden-by-configpy","title":"Overridden by: Config.py","text":"<p>As noted above, the defaults are stored in the <code>conf/config.py</code> file.  You can override these values as required.</p> <p> </p>"},{"location":"DevOps-Container-Configuration/#overridden-by-run-args","title":"Overridden by: run args","text":"<p>When you run created applications, you can provide API Logic Project arguments to override the defaults.  Discover the arguments using <code>--help</code>:</p> <p><pre><code>(venv) val@Vals-MBP-16 ApiLogicProject % python api_logic_server_run.py -h\n\nAPI Logic Project Starting: /Users/val/dev/servers/ApiLogicProject/api_logic_server_run.py\nusage: api_logic_server_run.py [-h] [--port PORT] [--flask_host FLASK_HOST] [--swagger_host SWAGGER_HOST]\n                               [--swagger_port SWAGGER_PORT] [--http_type HTTP_TYPE] [--verbose VERBOSE]\n                               [--create_and_run CREATE_AND_RUN]\n                               [flask_host_p] [port_p] [swagger_host_p]\n\npositional arguments:\n  flask_host_p\n  port_p\n  swagger_host_p\n\noptions:\n  -h, --help                       show this help message and exit\n  --port PORT                      port (Flask) (default: 5656)\n  --flask_host FLASK_HOST          ip to which flask will be bound (default: localhost)\n  --swagger_host SWAGGER_HOST      ip clients use to access API (default: localhost)\n  --swagger_port SWAGGER_PORT      swagger port (eg, 443 for codespaces) (default: 5656)\n  --http_type HTTP_TYPE            http or https (default: http)\n  --verbose VERBOSE                for more logging (default: False)\n  --create_and_run CREATE_AND_RUN  system use - log how to open project (default: False)\n(venv) val@Vals-MBP-16 ApiLogicProject % \n</code></pre> These are used for Codespaces support</p> <p> </p> <p>Notes:</p> <ul> <li><code>host</code> is the flask-host, which maps to the IP address of the interface to which flask will be bound (on the machine itself</li> <li><code>swagger_host</code> maps to the ip address as seen by the clients</li> </ul> <p>For example, 127.0.0.1 (localhost) or 0.0.0.0 (any interface) only have meaning on your own computer.</p> <p>Also, it's possible to map hostname-&gt;IP DNS entries manually in /etc/hosts, but users on other computers are not aware of that mapping.</p>"},{"location":"DevOps-Container-Configuration/#overridden-by-env-variables","title":"Overridden by: env variables","text":"<p>A common approach for host, port and database configuration is to use env variables.  These can be set in your OS, or container options such as env files or docker compose.  </p> <p>Best Practice: env variables</p> <p>We recommend the use of environmental variables when running Docker containers.</p> <p>You can see the env variables in the sample <code>env_list</code> file - click here.  </p> <p>The names of the variables are those noted used in the <code>conf/config.py</code> file, preceded by <code>APILOGICPROJECT_</code><sup>1</sup>.  These values override both the <code>conf/config.py</code> values and the Api Logic Project CLI arguments.</p> <p>Here are the most commonly set environment variables:</p> <pre><code>services:\n\n    api-logic-server:\n        image: apilogicserver/classicmodels\n        environment:\n          - APILOGICPROJECT_VERBOSE=true\n          - SECURITY_ENABLED=true\n          - APILOGICPROJECT_CLIENT_URI=//classicmodels.azurewebsites.net\n          - PYTHONPATH=/app/ApiLogicProject \n          ## specify Database uri's:\n          - APILOGICPROJECT_SQLALCHEMY_DATABASE_URI=mysql+pymysql://root:p@mysql-service:3306/classicmodels\n          - APILOGICPROJECT_SQLALCHEMY_DATABASE_URI_AUTHENTICATION=mysql+pymysql://root:p@mysql-service:3306/authdb\n</code></pre> <p>For example, to override the database location on mac:</p> <pre><code>export APILOGICPROJECT_SQLALCHEMY_DATABASE_URI=mysql+pymysql://root:p@localhost:3306/\n</code></pre> <p>To see a list of typical env variables, click here.</p> <p> </p>"},{"location":"DevOps-Container-Configuration/#docker-project-envlist-file","title":"Docker project <code>env.list</code> file","text":"<p>The example below illustrates you can store such variables in a <code>classicmodels/devops/docker-image/env.list</code> file (be sure to edit these - the current values are commented out, intended to confirm settings during initial testing).  Some of the most common settings are noted below:</p> env.list env variables - initially commented out<pre><code># ip to which flask will be bound (default: 0.0.0.0)\n# APILOGICPROJECT_FLASK_HOST=flask-host-e\n\n# port (Flask) (default: 5656)\n# APILOGICPROJECT_PORT=port-e\n\n# ip clients use to access API (default: localhost)\n# APILOGICPROJECT_SWAGGER_HOST=swagger-host-e\n\n# swagger port (eg, 443 for codespaces) (default: 5656)\n# APILOGICPROJECT_SWAGGER_PORT=swagger-port-e\n\n# http or https (default: http)\n# APILOGICPROJECT_HTTP_SCHEME=http-scheme-e\n\n# APILOGICPROJECT_HTTP_SCHEME=http\n\n# for reverse proxy cases where the entire URI must be specified\n# APILOGICPROJECT_CLIENT_URI=httpe://hoste:porte\n</code></pre>  Env variables in the `env.list` file  <p>APILOGICPROJECT_SWAGGER_PORT</p> <p></p>"},{"location":"DevOps-Container-Configuration/#debugging","title":"Debugging","text":"<p>Use the <code>APILOGICPROJECT_VERBOSE</code> to log the values to the console log.</p> <p> </p>"},{"location":"DevOps-Container-Configuration/#production-deployment","title":"Production Deployment","text":"<p>As noted in the gunicorn documentation:</p> <p>While lightweight and easy to use, Flask\u2019s built-in server is not suitable for production as it doesn\u2019t scale well. </p> <p> </p>"},{"location":"DevOps-Container-Configuration/#gunicorn","title":"gunicorn","text":"<p>You can run API Logic Server servers under gunicorn.  To use the default API Logic Server ports:</p> <pre><code>gunicorn api_logic_server_run:flask_app -w 4 -b localhost:5656\n</code></pre> <p>Or, to use the default gunicorn ports:</p> <pre><code>gunicorn api_logic_server_run:flask_app -w 4\n</code></pre> <p>You will also need to:</p> <ol> <li>Update the default server/port settings in <code>api_logic_server_run.py</code></li> <li>Start your browser at http://127.0.0.1:8000</li> </ol> <p> </p>"},{"location":"DevOps-Container-Configuration/#pythonanywhere","title":"PythonAnywhere","text":"<p>Please see the Install Instructions for information on PythonAnywhere.</p> <p> </p>"},{"location":"DevOps-Container-Configuration/#docker","title":"Docker","text":"<p>You can use Docker compose files or env files to configure your project.  There is an example in the default project - click here to see run-image.sh.</p> <ol> <li> <p>Several changes were made as of release 9.01.17.  It is available as preview; click here \u21a9</p> </li> </ol>"},{"location":"DevOps-Containers-Azure-Setup/","title":"Azure Setup","text":""},{"location":"DevOps-Containers-Azure-Setup/#create-azure-account","title":"Create Azure Account","text":"<p>I created a free account, electing the $200 free option.  In the entire exercise, I used less than $2 of my allotment.</p> <p> </p>"},{"location":"DevOps-Containers-Azure-Setup/#resource-groups","title":"Resource Groups","text":"<p>A key concept in all of the steps below is a <code>Resource Group</code>, which manages the multiple containers and resources (databases, storage etc) that comprise your system.  </p> <p>For more information, click here.</p> <p> </p>"},{"location":"DevOps-Containers-Azure-Setup/#managing-your-account","title":"Managing your Account","text":"<p>There are several ways of creating applications.  Key ones are noted below.</p> <p> </p>"},{"location":"DevOps-Containers-Azure-Setup/#portal-cli","title":"Portal CLI","text":"<p>You can log into the Azure Portal, and access the CLI like this:</p> <p></p> <p> </p>"},{"location":"DevOps-Containers-Azure-Setup/#local-az-cli","title":"Local az CLI","text":"<p>You can install the CLI locally, as described here.</p> <p> </p>"},{"location":"DevOps-Containers-Azure-Setup/#azure-ui","title":"Azure UI","text":"<p>The Azure Portal also offers many UI options to create accounts, databases, etc.</p>"},{"location":"DevOps-Containers-Azure-Setup/#sample-scripts","title":"Sample Scripts","text":"<p>You can explore / adapt the automatically created sample scripts:</p> <p></p> <p> </p>"},{"location":"DevOps-Containers-Azure-Setup/#trouble-shooting","title":"Trouble Shooting","text":"<p>Use this command to view Azure logs:</p> <pre><code>az container logs --resource-group myResourceGroup --name mycontainer\n</code></pre> <p>For specific error conditions, see Troubleshooting Azure.</p>"},{"location":"DevOps-Containers-Build/","title":"Build Project Image","text":"<p>Containers are a best practice for deployment, and offer several advantages for development.  This outlines a typical scenario for building images for API Logic Server projects.</p> <p> TL;DR - edit/use the pre-built dockerfile to <code>build</code> and <code>push</code> your project</p> <p><code>devops/docker-image/build-image.dockerfile</code> is pre-built into your project.  Alter it for your organization and project name.  It contains instructions for using it via the command line to <code>build</code> and <code>push</code> your image.</p> <p></p> <p>The diagram above identifies 3 important images you can build, described below.</p> <p> </p>"},{"location":"DevOps-Containers-Build/#myapp-containerize-project","title":"MyApp: containerize project","text":"<p>This is the image you will deploy for production.  It includes Python, API Logic Server, any additional packages your require, and your app (Python and logic).  These are defined by a <code>dockerfile</code>. </p> <p>API Logic Projects<sup>1</sup> include a <code>devops/docker-image/build-image.dockerfile</code> for containerizing your application, shown at right in the diagram below. Click here to see the key files.</p> <p>A key aspect of images is that you can extend an existing image: add new software to build another image.  See the line:</p> <pre><code>FROM --platform=linux/amd64 apilogicserver/api_logic_server\n</code></pre> <p>This builds your projects' image, starting with API Logic Server image, for amd (Intel) platforms.</p> <p></p> <p>To build an image for your ApiLogicProject:</p> <ol> <li>On Docker Hub, create a docker repository under your docker account. </li> <li>Create / customize your project as your normally would</li> <li>Edit <code>build-image.sh</code>: change <code>your_account/your_repository</code> as appropriate<ul> <li>Here is an example</li> </ul> </li> <li>In terminal (not in VSCode docker - docker CLI is not installed there), <code>cd &lt; your-project&gt;</code></li> <li> <p>Run <code>build-image.sh</code>:  <code>sh devops/docker-image/build_image.sh .   # builds the image locally</code></p> <ul> <li>Test the image locally - see Run Container</li> </ul> </li> <li> <p>Deploy to Docker Hub</p> </li> </ol> <pre><code>docker tag your_account/your_repository your_account/your_repository:1.00.00\ndocker login\ndocker push your_account/your_repository:1.00.00\n</code></pre> <p>To run your project container, see the next page.</p> <p> </p>"},{"location":"DevOps-Containers-Build/#mypkgs-containerize-packages","title":"MyPkgs: Containerize Packages","text":"<p>Your project may require additional packages not already included with API Logic Server.  You have 2 choices how to include these:</p> <ul> <li> <p>Standard <code>pip</code> - per Python standards, your project includes a <code>requirements.txt</code> file; update it with your dependencies.</p> </li> <li> <p>If your team is using Dev Containers for development, it is a best practice to establish dependencies in a new image <code>MyPkgs</code>, then build your <code>MyApp</code> container from that.</p> </li> </ul> <p> </p>"},{"location":"DevOps-Containers-Build/#mydb-test-databases","title":"MyDB: Test Databases","text":"<p>One of the great things about Docker is the ability to install popular databases, with no hassle.  Follow the procedures described in Connection Examples.\\</p> <p>You can use this to optionally manage your test databases with containers that can run both locally, or on a cloud / server.</p> <ol> <li> <p>Several changes were made as of release 9.01.17.\u00a0\u21a9</p> </li> </ol>"},{"location":"DevOps-Containers-Deploy-Multi/","title":"Container Database","text":"<p> TL;DR - Dev Deploy: Multi-Container Systems</p> <p>This page shows the simplest way to deploy a dev system to the cloud, to enable collaboration with Business User and fellow developers: </p> <ol> <li> <p>Create a project from a sample dockerized database</p> </li> <li> <p>Containerize your project</p> </li> <li> <p>Deploy to Azure two containers using docker compose:</p> <ol> <li>Your project</li> <li>A database container, with both the DBMS and data</li> </ol> </li> </ol> <p>Containers are a best practice for deployment, and offer several advantages for development.  This outlines a typical scenario for deploying API Logic Server projects to Azure.</p> <p> </p>"},{"location":"DevOps-Containers-Deploy-Multi/#rapid-cloud-preview","title":"Rapid Cloud Preview","text":"<p>This project illustrates using API Logic Server with Docker and docker-compose.  The objective is to provide a simple way to explore using docker with API Logic Server on your local machine.  These are not production procedures - they are designed for simple local machine operation.</p> <p>This doc explains:</p> <ul> <li> <p>I. Create the Project, and Verify Local Operation - run the project</p> </li> <li> <p>II. Add Security</p> </li> <li> <p>III. Run as image - create and run an image</p> </li> <li> <p>IV. Run  as docker-compose - multi-container -- build, deploy and run</p> </li> <li> <p>V. Deploy to Cloud </p> </li> </ul> <p>This presumes you have installed API Logic Server, and docker.  You will need an Azure account.</p> <p> Confirm the Happy Path</p> <p>You will will certainly use different procedures for dev and production deployment.  These introduce variables into a complicated procedure.</p> <p>So, we encourage you to follow this \"Happy Path\" guide closely, to </p> <ol> <li>Confirm you can deploy using a known database / procedure, and</li> <li>Establish a reference example for your procedures</li> </ol> <p> </p> <p> </p>"},{"location":"DevOps-Containers-Deploy-Multi/#i-create-the-project","title":"I. Create the Project","text":"<p>Follow the steps below:</p> <p> </p>"},{"location":"DevOps-Containers-Deploy-Multi/#1-start-the-database-container","title":"1. Start the database container","text":"<pre><code>docker run --name mysql-container --net dev-network -p 3306:3306 -d -e MYSQL_ROOT_PASSWORD=p apilogicserver/mysql8.0:latest\n</code></pre> <p>Verify it looks like this:</p> <p></p> <p>Note: The docker image contains the DBMS and data to simplify this tutorial.  You would almost certainly use volumes in normal practice, but this simplifies the tutorial.</p> <p> </p>"},{"location":"DevOps-Containers-Deploy-Multi/#2-create-the-project","title":"2. Create the Project","text":"<p>Create the project with API Logic Server:</p> <pre><code>ApiLogicServer create --project_name=classicmodels --db_url=mysql+pymysql://root:p@localhost:3306/classicmodels\n</code></pre> <p>The command above uses the pre-supplied docker database, here MySQL.</p> <p>Or, use postgres: <code>ApiLogicServer create --project_name=postgres-nw --db_url=postgresql://postgres:p@localhost/postgres</code>.</p> <p> </p>"},{"location":"DevOps-Containers-Deploy-Multi/#3-start-the-server-test","title":"3. Start the Server, Test","text":"<p>The project should be ready to run without customization:</p> <ol> <li>Open the project in VSCode</li> </ol> <p></p> <ol> <li> <p>Establish your (possibly preview) virtual environment</p> </li> <li> <p>Press F5 to run the server</p> </li> <li> <p>Run the Admin App, and Swagger.  Verify that <code>customers</code> returns data.</p> </li> </ol> <p> </p> <p> </p>"},{"location":"DevOps-Containers-Deploy-Multi/#ii-add-security","title":"II. Add Security","text":"<p>Using the terminal window inside VSCode:</p> <p>Stop the server.</p> <p>Open a new terminal window in VSCode:</p> <p>The current terminal window has an old copy of the project root.  If you try to run, you will see *No such file or directory\".  Just open another terminal window and repeat the command.</p> <pre><code>ApiLogicServer add-auth --project_name=. --db_url=mysql+pymysql://root:p@localhost:3306/authdb\n</code></pre> <p>The system introspects your <code>--db_url</code> database, creates models for it, and configures your project to enable security.</p> <p>Security databases must include certain tables and columns.  Your authdb can optionally provide a superset of these.  Such extensions are useful in declaring role-based authorization.</p> <p>To help you get started, the <code>devops/auth-db</code> directory provides starter kits for creating these databases.  Alter these files for your project, prepare database containers for your team, and use them in the <code>add-auth</code> command above.</p> <p>Re-run the project (F5), observe you need to login (admin, p).</p> <p>Or, use postgres: <code>ApiLogicServer add-auth --project_name=. --db_url=postgresql://postgres:p@localhost/authdb</code></p> <p> </p> <p> </p>"},{"location":"DevOps-Containers-Deploy-Multi/#iii-run-as-image","title":"III. Run as image","text":"<p>These scripts simplify creating and running docker containers for your project.  See details in the sub-sections below.</p> <p>Important Notes:</p> <ol> <li> <p>The docker compose steps (below) use the created image, so you must perform this step first</p> </li> <li> <p>The image must contain the security models created in the step above</p> </li> </ol> <p> </p>"},{"location":"DevOps-Containers-Deploy-Multi/#1-stop-the-server","title":"1. Stop the Server","text":"<p>Stop the API Logic Project, using your IDE.</p> <p> </p>"},{"location":"DevOps-Containers-Deploy-Multi/#2-build-the-image","title":"2. Build the Image","text":"<p>For preview versions, verify <code>devops/docker-image/build_image.dockerfile</code> is using <code>apilogicserver/api_logic_server_x</code> (note the _x).</p> <p> </p> <pre><code>sh devops/docker-image/build_image.sh .\n</code></pre> <p> </p>"},{"location":"DevOps-Containers-Deploy-Multi/#3-observe-database-config","title":"3. Observe database config","text":"<p>When run from a container, the database uri using <code>localhost</code> (from above) does not work.  Confirm the following in <code>devops/docker-image/env.list</code>:</p> <pre><code>APILOGICPROJECT_SQLALCHEMY_DATABASE_URI=mysql+pymysql://root:p@mysql-container:3306/classicmodels\nAPILOGICPROJECT_SQLALCHEMY_DATABASE_URI_AUTHENTICATION=mysql+pymysql://root:p@mysql-container:3306/authdb\n</code></pre> <p> </p>"},{"location":"DevOps-Containers-Deploy-Multi/#4-start-the-server-test","title":"4. Start the Server, Test","text":"<p>1. Start the Server: use the pre-created command line script to run the container from the image:</p> <pre><code>sh devops/docker-image/run_image.sh\n</code></pre> <p>2. Test the App: browse the Admin App, and Swagger</p> <p>You can also run the Authentication Administration App to define users and roles (though not required).</p> <p> </p> <p> </p>"},{"location":"DevOps-Containers-Deploy-Multi/#iv-run-as-docker-compose","title":"IV. Run as docker-compose","text":"<p>Use docker compose to choreograph multiple services (e.g, your application and database) for a multi-container system.</p> <p> </p>"},{"location":"DevOps-Containers-Deploy-Multi/#1-stop-the-system","title":"1. Stop the system","text":"<p>You must now:</p> <ol> <li> <p>Stop the API Logic Project container - press ctl-C</p> </li> <li> <p>Stop the database container (e.g., using Docker Desktop).</p> <ul> <li>The procedure below will spin up another database container.  If the current database container is running, you will see port conflicts.</li> </ul> </li> </ol> <p> </p>"},{"location":"DevOps-Containers-Deploy-Multi/#2-observe-database-service","title":"2. Observe database service","text":"<p>Open <code>devops/docker-compose-dev-local/docker-compose-dev-local.yml</code>, and observe the database service:</p> <pre><code>    mysql-service:\n        image: apilogicserver/mysql8.0:latest\n        restart: always\n        environment:\n            # MYSQL_DATABASE: 'db'\n            # So you don't have to use root, but you can if you like\n            - MYSQL_USER=root\n            # You can use whatever password you like\n            - MYSQL_PASSWORD=p\n            # Password for root access\n            - MYSQL_ROOT_PASSWORD=p\n        ports:\n            # &lt;Port exposed&gt; : &lt;MySQL Port running inside container&gt;\n            - '3306:3306'\n        expose:\n            # Opens port 3306 on the container\n            - '3306'\n</code></pre> <p> </p>"},{"location":"DevOps-Containers-Deploy-Multi/#3-observe-the-app-service","title":"3. Observe the app service","text":"<p>In <code>devops/docker-compose-dev-local/ddocker-compose-dev-local.yml</code>,  observe the database service uses the your application image, and has configured the database URIs to your database service, above:</p> <pre><code>    api-logic-server:\n        image: apilogicserver/classicmodels\n        environment:\n          - APILOGICPROJECT_VERBOSE=true\n          # for testing\n          # - APILOGICPROJECT_CLIENT_URI=//10.0.0.77\n          # HOST_IP set in docker-compose.sh/ps1\n          # - APILOGICPROJECT_CLIENT_URI=//${HOST_IP}\n          - SECURITY_ENABLED=true\n          ## - APILOGICPROJECT_HTTP_SCHEME=https\n          ## - PYTHONPATH=/app/ApiLogicProject \n          ## database uri's:\n          - APILOGICPROJECT_SQLALCHEMY_DATABASE_URI=mysql+pymysql://root:p@mysql-service:3306/classicmodels\n          - APILOGICPROJECT_SQLALCHEMY_DATABASE_URI_AUTHENTICATION=mysql+pymysql://root:p@mysql-service:3306/authdb\n        expose:\n          - 5656\n        ports:\n          - 5656:5656\n</code></pre> <p> </p>"},{"location":"DevOps-Containers-Deploy-Multi/#4-observe-security","title":"4. Observe Security","text":"<p>The database contains <code>authdb</code>.  To see how it was configures, observe <code>devops/docker-compose/docker-compose.yml</code>:</p> <ol> <li> <p>Observe <code>- SECURITY_ENABLED=true</code></p> </li> <li> <p>Under api-logic-server-environment, observe:</p> </li> </ol> <pre><code>  - APILOGICPROJECT_SQLALCHEMY_DATABASE_URI_AUTHENTICATION=mysql+pymysql://root:p@mysql-service:3306/authdb\n</code></pre> <p> </p>"},{"location":"DevOps-Containers-Deploy-Multi/#5-build-deploy-and-run","title":"5. Build, Deploy and Run","text":"<p>The following will build, deploy and start the container stack locally:</p> <pre><code># sh devops/docker-compose-dev-local/docker-compose.sh\n</code></pre> <p>Then, in your browser, open <code>localhost:5656</code>.</p> <p> </p>"},{"location":"DevOps-Containers-Deploy-Multi/#v-deploy-to-cloud","title":"V. Deploy to cloud","text":"<p>This procedure is modeled after this article; it uses this project.  We'll be performing the basic steps:</p> <ul> <li> <p>Create a resource group and service plan</p> </li> <li> <p>Deploy an multi-container application:</p> </li> </ul> <ol> <li> <p>API Logic Project image from DockerHub</p> </li> <li> <p>A Database Container</p> </li> </ol> <p> </p>"},{"location":"DevOps-Containers-Deploy-Multi/#1-acquire-project-files","title":"1. Acquire Project Files","text":"<p>The following setup steps are required.  You will modify these for your own project.  You can use the <code>apilogicserver project/image</code> for this exercise.</p> <p> </p> <p>a) Push Project to github</p> <p>We've already pushed the <code>classicmodels</code> project, so this step is not required in the tutorial.</p> <p> </p> <p>b) Push DB Image to DockerHub</p> <p>We've already pushed the <code>classicmodels</code> image, like this:</p> <pre><code>docker tag apilogicserver/classicmodels apilogicserver/classicmodels:latest\"\ndocker push apilogicserver/classicmodels:latest\"\n</code></pre> <p>As noted above, this database image includes you data, so there is no need to worry about volumes.  If you wish, you can create \"DBMS + Data\" images for your own projects, like this.</p> <p> </p> <p>c) Acquire file in Azure</p> <p>To obtain the project files (docker compose, etc), use the portal:</p> <p></p> <ol> <li> <p>Login to the portal</p> </li> <li> <p>In the Portal CLI:</p> </li> </ol> <pre><code>git clone https://github.com/ApiLogicServer/classicmodels.git\n\ncd classicmodels\n</code></pre>"},{"location":"DevOps-Containers-Deploy-Multi/#1a-automated-deploy","title":"1a. Automated Deploy","text":"<p>Once you have acquired the project, you can perform all of the steps below with the created script:</p> <pre><code>sh devops/docker-compose-dev-azure/azure-deploy.sh\n</code></pre> <p>In the following sections, we'll perform these steps by hand so you can explore the underlying process.</p> <p> </p>"},{"location":"DevOps-Containers-Deploy-Multi/#2-create-container-group","title":"2. Create container group","text":"<pre><code>az group create --name myResourceGroup --location \"westus\"\n</code></pre>"},{"location":"DevOps-Containers-Deploy-Multi/#3-create-service-plan","title":"3. Create service plan","text":"<pre><code>az appservice plan create --name myAppServicePlan --resource-group myResourceGroup --sku S1 --is-linux\n</code></pre>"},{"location":"DevOps-Containers-Deploy-Multi/#4-create-docker-compose-app","title":"4. Create docker compose app","text":"<p>Your create the multi-container system as shown below.  </p> <p>Note the argument <code>--name classicmodels</code>.  Your <code>docker-compose-dev-azure.yml</code> has been pre-configured to use your lower cased project name:</p> <pre><code>          - APILOGICPROJECT_CLIENT_URI=//classicmodels.azurewebsites.net\n</code></pre> <p>This name must match <code>--name classicmodels</code> in the following command:</p> <pre><code>az webapp create --resource-group myResourceGroup --plan myAppServicePlan --name classicmodels --multicontainer-config-type compose --multicontainer-config-file devops/docker-compose-dev-azure/docker-compose-dev-azure.yml\n</code></pre> <p>So, in the postgres example: <pre><code>az webapp create --resource-group pgResourceGroup --plan pgAppServicePlan --name postgres-nw --multicontainer-config-type compose --multicontainer-config-file devops/docker-compose-dev-azure/docker-compose-dev-azure.yml\n</code></pre></p> <p>If you need to update the container:</p> <ol> <li>Update youur project locally</li> <li>Push to git</li> <li>In the Azure portal,    * <code>git pull</code>    * Repeat the <code>az webapp create</code>, above</li> </ol> <p>If you need to recreate the container, you can use the portal, or this command:</p> <pre><code>az container delete --resource-group myResourceGroup --name mycontainer\n</code></pre> <p> </p>"},{"location":"DevOps-Containers-Deploy-Multi/#5-enable-logging","title":"5. Enable logging","text":"<p>Use this procedure; TL;DR:</p> <p>To enable web server logging for Windows apps in the Azure portal, navigate to your app and select App Service logs.  For Web server logging, select Storage to store logs on blob storage, or File System to store logs on the App Service file system.</p> <pre><code>az container logs --resource-group myResourceGroup --name mycontainer\n</code></pre> <p>For specific error conditions, see Troubleshooting Azure.</p> <p> </p>"},{"location":"DevOps-Containers-Deploy-Multi/#6-browse-to-the-app","title":"6. Browse to the app","text":"<p>To run the app, https://classicmodels.azurewebsites..</p> <p>You will need to wait a bit on the first run while the containers are loaded.  Subsequent performance should be fine.</p>"},{"location":"DevOps-Containers-Deploy/","title":"Managed Database","text":"<p> TL;DR - Single (App) Container with Managed Database</p> <p>This page explains how to: </p> <ul> <li> <p>create a resource group</p> </li> <li> <p>create a managed database</p> </li> <li> <p>deploy an API Logic Project image from DockerHub</p> </li> </ul> <p>Containers are a best practice for deployment, and offer several advantages for development.  This outlines a typical scenario for deploying API Logic Server projects to Azure.</p> <p>This tutorial presumes you've already <code>push</code>ed an image, here called <code>apilogicserver/docker_api_logic_project:latest</code>.</p> <p></p> <p> </p>"},{"location":"DevOps-Containers-Deploy/#create-azure-account","title":"Create Azure Account","text":"<p>I created a free account, electing the $200 free option.  In the entire exercise, I used less than $2 of my allotment.</p> <p> </p>"},{"location":"DevOps-Containers-Deploy/#create-managed-database","title":"Create Managed Database","text":"<p>Creating the database was straightforward using Microsoft documentation.  To see it, click here.</p> <p>Note: we used the database name <code>nwlogic</code>.</p> <p>Note this is a managed database, which means that Azure will apply DBMS updates, take backups, etc.  Contrast this to running a database in a bare container, where you'd need to arrange such services yourself.</p> <p> </p>"},{"location":"DevOps-Containers-Deploy/#container-group","title":"Container Group","text":"<p>The database creation wizard requires that you create a container group.</p> <p> </p>"},{"location":"DevOps-Containers-Deploy/#database-nwlogic","title":"database <code>nwlogic</code>","text":"<p>For this tutorial we created the database <code>nwlogic</code>.  It is an exact replica of the sample (nw) sample database), using SqlServer.</p> <p> </p>"},{"location":"DevOps-Containers-Deploy/#load-data-azure-data-tools","title":"Load Data: Azure Data Tools","text":"<p>After creating the database, load the data using tools like PyCharm Data Tools, or DbVis. </p> <p>To find the sql scripts, click here.</p> <p> </p>"},{"location":"DevOps-Containers-Deploy/#portal","title":"Portal","text":""},{"location":"DevOps-Containers-Deploy/#create-container","title":"Create Container","text":"<pre><code>az container create --resource-group myResourceGroup --name mycontainer --image apilogicserver/docker_api_logic_project:latest --dns-name-label val-demo --ports 5656 --environment-variables 'FLASK_HOST'='mssql+pyodbc://valhuber:PWD@mysqlserver-nwlogic.database.windows.net:1433/nwlogic?driver=ODBC+Driver+17+for+SQL+Server&amp;trusted_connection=no' 'VERBOSE'='True'\n</code></pre> <p>Most of the arguments are straight-forward, identifying the Docker Hub repository (<code>apilogicserver/docker_api_logic_project:latest</code>), the container group.  </p> <p>Note the <code>--environment-variables</code> are used to communicate the database and server location: <code>--environment-variables 'FLASK_HOST'='mssql+pyodbc://valhuber:PWD@mysqlserver-nwlogic.database.windows.net:1433/nwlogic?driver=ODBC+Driver+17+for+SQL+Server&amp;trusted_connection=no' 'VERBOSE'='True'</code></p> <p> </p>"},{"location":"DevOps-Containers-Deploy/#recreate-the-container","title":"Recreate the container","text":"<p>If you need to recreate the container, you can use the portal, or this command:</p> <pre><code>az container delete --resource-group myResourceGroup --name mycontainer\n</code></pre> <p> </p>"},{"location":"DevOps-Containers-Deploy/#run-admin-app","title":"Run Admin App","text":"<p>The <code>create</code> command above starts the server.  After that, you can run the admin app: http://val-demo.eastus.azurecontainer.io:5656/.</p> <p> </p>"},{"location":"DevOps-Containers-Deploy/#trouble-shooting","title":"Trouble Shooting","text":"<p>Use this command to view Azure logs:</p> <pre><code>az container logs --resource-group myResourceGroup --name mycontainer\n</code></pre> <p>For specific error conditions, see Troubleshooting Azure.</p>"},{"location":"DevOps-Containers-Preview/","title":"Dev Preview in Cloud","text":"<p> TL;DR - Dev Preview</p> <p>Agile correctly advises getting Working Software as fast as possible, to facilitate Business User Collaboration and Iteration:</p> <ol> <li> <p>Instant Creation: create working software from a database.</p> </li> <li> <p>Publish to GitHub: for dev team collaboration</p> </li> <li> <p>Dev Deploy to the Cloud: use the working software to collaborate with Business Users</p> </li> </ol> <p>Use API Logic Server to create Dev Previews.</p> <p></p>"},{"location":"DevOps-Containers-Preview/#dev-previews","title":"Dev Previews","text":"<p>API Logic Server can create projects with APIs and UIs with a single command.  But to enable collaboration, these need to be available to your colleagues.</p> <p>Such Dev Preview deployments focus on simple and fast, as distinct from Production Deployments that focus on scalability, availability, etc.  As such:</p> <ul> <li> <p>You might use Flask as a Web Server, instead of a production web server such as nginx</p> </li> <li> <p>You might use database containers, with both DBMS software and data, which make it easy to test both locally and in the cloud.</p> </li> </ul> <p> </p>"},{"location":"DevOps-Containers-Preview/#test-databases","title":"Test Databases","text":"<p>The procedures here offer 2 alternatives for test databases:</p> <ol> <li> <p>Managed Databases: use Azure to create databases and add data, and access from an App Server container</p> </li> <li> <p>Container Databases: use docker container databases, and deploy as a docker compose, combining your App Server container and your docker database</p> </li> </ol> <ul> <li>You can create these as shown here</li> </ul> <p>The examples below use pre-supplied MySQL and Postgres databases; for more information, click here.</p>"},{"location":"DevOps-Containers-Run/","title":"Run Container","text":"<p>Containers are a best practice for deployment, and offer several advantages for development.  This outlines a typical scenario for running and testing API Logic Server projects prior to deployment.</p> <p></p>"},{"location":"DevOps-Containers-Run/#running-containers","title":"Running Containers","text":"<p>You can run your container locally, or from DockerHub.  Running locally is clearly a good choice for development.</p> <p> </p>"},{"location":"DevOps-Containers-Run/#local-testing","title":"Local Testing","text":"<p>You will typically want to test your image before pushing it to DockerHub.  Use the run-image, as shown below<sup>1</sup>.</p> <p>For example, to run your project container directly, you can </p> <pre><code>sh devops/docker-image/run_image.sh run_image.sh\n</code></pre> <p> </p>"},{"location":"DevOps-Containers-Run/#environment-variables","title":"<code>environment</code> variables","text":"<p>Note you can use env variables to configure your servers and ports.  For more information, click here.</p> <p> </p>"},{"location":"DevOps-Containers-Run/#arm-machines","title":"Arm machines","text":"<p>The procedures described here presume a team that uses amd (Intel) machines.  Docker has different procedures to deal with arm-based Macs (M1, M2...).</p> <p>If you use the procedures above, Docker will create images for amd.  Such images will run slowly on arm, but in most cases that's fine for dev testing.</p> <p> </p>"},{"location":"DevOps-Containers-Run/#multi-architecture-images","title":"Multi-architecture images","text":"<p>You can build images that operate under either environment.  </p> <p>However, this is not done using the <code>docker build</code> command shown here.  Instead, you use <code>docker buildx</code>, which must be performed in the context of a build environment.  For an excellent article showing how to do this, click here.</p> <p> </p>"},{"location":"DevOps-Containers-Run/#team-testing","title":"Team Testing","text":"<p>Once you have <code>pushed</code> images to DockerHub, your fellow developers can run them in their local environments.</p> <p> </p>"},{"location":"DevOps-Containers-Run/#cloud-testing","title":"Cloud Testing","text":"<p>Cloud container testing is significantly more challenging that in an IDE.  There are some steps we recommend that can make it easier<sup>1</sup>:</p> <ol> <li> <p>Test with <code>env</code> variables - cloud containers pass parameters using <code>env</code> variables, typically not with command line arguments.  These typically identify your database locations etc.</p> <ul> <li>A VSCode Run configuration <code>ApiLogicServer ENV</code> is provided for this, so you can begin testing in your IDE.</li> </ul> </li> <li> <p>Use the <code>VERBOSE</code> env variable to activate logging</p> </li> <li> <p>Then test  by running your container locally, setting env variables per your OS.  See the CLI examples shown above.</p> </li> </ol>"},{"location":"DevOps-Containers-Run/#apilogicserver-container-upgrades","title":"ApiLogicServer Container upgrades","text":"<p>You can update your image to a new version:</p> <pre><code>docker pull apilogicserver/api_logic_server\n</code></pre> <p>If you update your ApiLogicServer container to a new version, your existing VSCode projects may appear to be damaged.  You can fix them easily:</p> <ol> <li>Click the Dev Container button (in the lower left)</li> <li>Choose Rebuild Container</li> </ol> <p> </p>"},{"location":"DevOps-Containers-Run/#start-docker-and-loadrun-api-logic-project-from-github","title":"Start docker and load/run API Logic Project from <code>GitHub</code>","text":"<p>The <code>api_logic_server</code> image supports startup arguments so you can control the <code>api_logic_server</code> container, by running a startup script.  You can run your own script, or use the pre-supplied script (<code>/home/api_logic_server/bin/run-project.sh</code>) to load/run a git project.  For example:</p> <pre><code>docker run -it --name api_logic_server --rm --net dev-network -p 5656:5656 -p 5002:5002 -v ${PWD}:/localhost apilogicserver/api_logic_server sh /home/api_logic_server/bin/run-project.sh https://github.com/valhuber/Tutorial-ApiLogicProject.git /localhost/Project-Fixup.sh\n</code></pre> <p>will load the pre-built sample project from git, and run it.  Prior to execution it runs <code>/localhost/Project-Fixup.sh</code>, which in this case resets ui/admin files, like this:</p> <pre><code>#!/bin/bash\n\necho \" \"\necho \"Project-Fixup script running\"\npwd; ls\necho \" \"\n\ncp ui/admin/admin_custom_nw.yaml ui/admin/admin.yaml\n</code></pre> <p>Instead of using a startup script, you can also use environment variables to achieve the same effect:</p> <pre><code>docker run -it --name api_logic_server --rm --net dev-network -p 5656:5656 -p 5002:5002 -v ${PWD}:/localhost   -e APILOGICSERVER_GIT='https://github.com/valhuber/Tutorial-ApiLogicProject.git' -e APILOGICSERVER_FIXUP='/localhost/Project-Fixup.sh' apilogicserver/api_logic_server\n</code></pre> <ol> <li> <p>Several changes were made as of release 9.01.17.  It is available as preview; click here \u21a9\u21a9</p> </li> </ol>"},{"location":"DevOps-Containers-Use-Standard/","title":"Use Standard Image","text":"<p> TL;DR - Using the standard container</p> <p>You can run your project using the standard container, or build your own container as described on the next page.</p> <p>Containers are a best practice for deployment, and offer several advantages for development.  This outlines a typical scenario for building images for API Logic Server projects.</p> <p><code>devops/docker-image/build-image.dockerfile</code> is pre-built into your project.  Alter it for your organization and project name.  It contains instructions for using it via the command line to <code>build</code> and <code>push</code> your image.</p> <p></p> <p>The diagram above illustrates you can run your project using the pre-created docker image.</p> <p>You may wish to connect your system to others containers, such as databases or keycloak.  Networking requires you configure the hosts' IP address as shown above.</p>"},{"location":"DevOps-Containers/","title":"About Containers","text":"<p> TL;DR - Projects are pre-configured for containers: for both deployment and development</p> <p>Containers are a critical component of DevOps, so API Logic Projects provide pre-configured support:</p> <ul> <li> <p>they contain the <code>.devcontainer</code> directory to enable Dev Container use</p> </li> <li> <p>they contain <code>devops/docker/build-image.dockerfile</code> for building  deployment images</p> </li> </ul> <p>Containers are a best practice for deployment.  They also offer several advantages for development.  This page outlines a typical scenario for API Logic Server projects.</p> <p> </p>"},{"location":"DevOps-Containers/#container-overview","title":"Container Overview","text":""},{"location":"DevOps-Containers/#process","title":"Process","text":"<p>As shown above, you can</p> <ol> <li> <p>Use the Docker CLI (Command Language Interface) to <code>build</code> images.  An image might be an API Logic Server, or a DBMS.  In either case, it is:</p> <ul> <li> <p>self-contained - includes all its dependencies (you identify these in the <code>dockerfile</code> which is input to the <code>build</code> command), and </p> </li> <li> <p>isolated - containers are protected from incoming and outgoing access except through well-defined network and file access</p> </li> </ul> </li> <li> <p>These images can be <code>pushed</code> to Docker Hub as <code>repositories</code>, where they can be shared with other developers, and for production deployment.</p> </li> <li> <p>Developers can <code>run</code> an image, whether on Windows, Macs or Linux systems - a running image is called a <code>container</code>.</p> </li> </ol> <p> </p>"},{"location":"DevOps-Containers/#advantages","title":"Advantages","text":"<p>Containers provide significant well-known advantages for development and deployment:</p> <ul> <li> <p>simplified development by eliminating an otherwise complex install (Python, packages, etc)</p> </li> <li> <p>popular runtime deployment platform, based on a standard Linux base</p> </li> <li> <p>isolation - in both cases, Docker applications encapsulate their environment, eliminating external dependencies.  Likewise, Docker applications will not affect other applications running on the same hardware.</p> <ul> <li>Avoid the install A breaks B problem</li> </ul> </li> <li> <p>performance - containers are very light-weight (e.g., do not contain overhead for Operation System), so start quickly and minimize resource consumption.  For example, my laptop has 3 DBMSs; they start in a second, and consume little overhead.</p> </li> <li> <p>sharing - containers are easy to share between developers (e.g., a test DBMS) via Docker Hub</p> </li> <li> <p>portable - containers can run on Windows, Macs and Unix systems.</p> </li> </ul> <p>ApiLogicServer therefore provides support for building images, and for dev containers.</p> <p> </p>"},{"location":"DevOps-Containers/#terminology-recap","title":"Terminology Recap","text":"<p>Some quick terms:</p> <ul> <li>Your docker account can contain multiple docker repositories<ul> <li>It would be typical to use your project name as the docker repository name</li> <li>Note: repository names must be lower case</li> <li>Repository names are scoped by your account - see the diagram above.  You then refer to your docker repository in the CLI commands as <code>your_account/your_repository</code></li> </ul> </li> <li>A docker repository can can be downloaded (pulled) to create a docker image on your local computer</li> <li>A docker image can be run as a docker container</li> <li>Your system might be comprised of multiple docker containers, e.g. one for your API Logic Project, one for your DBMS, etc.</li> </ul> <p>For more information on containers, see here.</p> <p> </p>"},{"location":"DevOps-Containers/#dev-local-container-cloud","title":"Dev: Local, Container, Cloud","text":"<p>Containers are generally regarded as a deployment technology.  In addition, they offer several advantages for development.</p> <p>API Logic Server supports a variety of development models.  You can install API Logic Server either:</p> <ul> <li>As a Local <code>pip</code> install,</li> <li>Or, use Dev Containers, by running the pre-supplied API Logic Server image<ul> <li>This avoids the sometimes tricky Python install.</li> <li>This image contains Python and all the packages used by API Logic Server.</li> <li>You can use it with VSCode <code>.devcontainer</code> support as described in the install guide.   This provides full IDE support: code editing, debugging, source control, etc.</li> <li>For more information, see Dev Containers.</li> </ul> </li> <li>Or, develop in the cloud using Codespaces - no install at all</li> </ul> <p>In any case, you'll be using a source control system such as <code>git</code>, so it's possible to mix and match these configurations among developers.</p> <p> </p>"},{"location":"DevOps-Containers/#dev-containers-optional","title":"Dev Containers: Optional","text":"<p> Best Practice for deployment, worth considering but optional for dev</p> <p>It's worth re-emphasizing that your decision to use Dev Containers has no effect on using containers for deployment.  Containers for deployment are a best practice.  Dev Containers provide interesting value, and should be considered, but you can create deployment containers no matter what decision you take.</p> <p>As you evalute Dev Containers, be aware API Logic Projects will run either way.  Or both: you can switch back and forth as you determine which approach is best for your team.</p> <p> </p>"},{"location":"DevOps-Containers/#api-logic-server-containers","title":"API Logic Server Containers","text":"<p>API Logic Server pre-supplies several repositories (images available on Docker Hub):</p> <ol> <li> <p>Several DBMSs, so you can explore connectivity and as a quick-start for development</p> </li> <li> <p>API Logic Server itself is <code>apilogicserver/api_logic_server</code> (here is the dockerfile)</p> <ul> <li>as of release 9.01.17<sup>1</sup>, images are both arm and amd compatible.</li> </ul> </li> </ol> <p>You can visualize the API Logic Server Container like this: </p> <p></p> <p>You can use it in 2 ways:</p> <ul> <li> <p>for dev - as described in Dev Containers</p> </li> <li> <p>to build images - as described in Build Image, to share with developers, or deploy to cloud providers (e.g., Microsoft Azure, Amazon AWS, etc).</p> </li> </ul> <p>For more information, see Architecture.</p> <ol> <li> <p>Several changes were made as of release 9.01.17.  It is available as preview; click here \u21a9</p> </li> </ol>"},{"location":"DevOps-Docker/","title":"Dev Containers","text":"<p>As described in Containers, you can develop in a container, including using VSCode.  This is optional, and not required to containerize your project for deployment.</p> <p> TL;DR - <code>.devcontainer</code> configurations are pre-built for API Logic Projects</p> <p>The <code>.devcontainer</code> is pre-built into your project, so it is ready to use with VSCode for code editing, debugging, etc.</p> <p>Recall that devcontainers are valuable, but optional.</p>"},{"location":"DevOps-Docker/#creating-projects","title":"Creating projects","text":"<p>Recall from the Install doc that you create projects like this:</p>"},{"location":"DevOps-Docker/#1-start-docker","title":"1. Start Docker","text":"<p>Start (might install) API Logic Server Docker<pre><code>&gt; docker run -it --name api_logic_server --rm -p 5656:5656 -p 5002:5002 -v ${PWD}:/ApiLogicServer apilogicserver/api_logic_server\n$ # you are now active in the API Logic Server docker container to create projects\n</code></pre> </p> <p>Windows: use Powershell (<code>PWD</code> is not supported in Command Line)</p> <p>To update your container: <code>docker pull apilogicserver/api_logic_server</code></p> <p> </p>"},{"location":"DevOps-Docker/#2-create-a-project","title":"2. Create a Project","text":"<p>Typical project creation identifies the database and target project name: Create Typical project<pre><code>$ cd /ApiLogicServer         # volume mapped to a directory on your local file system for project creation\n$ ApiLogicServer create-and-run --project_name=ApiLogicProject --db_url=\n$ exit                       # return to local host \n</code></pre></p> <p> </p> <p>Note the use of the mapped volume <code>cd /ApiLogicServer</code>.  This creates the projects files on your host computer, so can manage the source locally (e.g., use <code>git</code>).</p> <p> </p>"},{"location":"DevOps-Docker/#2a-using-the-manager","title":"2a. Using the Manager","text":"<p>You can also use the Manager with Docker (\"%\" is a command from your local machine, \"$\" is a command in the docker container):</p> <p>Using the Manager with Docker<pre><code>% cd ~/dev/ApiLogicServer/ApiLogicServer-dev/build_and_test/ApiLogicServer/dockers/ApiLogicServer # your ApiLogicServer dir\n% docker run -it --name api_logic_server --rm --net dev-network -p 5656:5656 -p 5002:5002 -v ${PWD}:/ApiLogicServer apilogicserver/api_logic_server\n$ als start\n$ exit\n% code . (and open container)\n$\n$ chmod a+rwx /workspaces/ApiLogicServer\n$ cd /workspaces/ApiLogicServer\n$\n$ als create --project-name=nw+ --db-url=nw+\n$ #\n$ # to run genai - update your secrets file, and\n$ als genai --using=genai_demo.prompt\n</code></pre> </p> <p>Unlike local installs, the manager does not automatically launch VSCode on created projects.  Proceed as noted in Step 3, below.</p> <p></p> <p> </p>"},{"location":"DevOps-Docker/#3-customize-project","title":"3. Customize project","text":"<p>Once the project is created, open it in VSCode:</p> <ol> <li> <p>Open Folder <code>ApiLogicServer/ApiLogicProject</code> in VSCode</p> <ul> <li>Accept option to \"Reopen in Container\"</li> </ul> <p>If you already skipped this option, no worries.  Use View &gt; Command Palette &gt; Remote-Containers: Reopen in Container</p> </li> </ol> <p>Then, use normal development procedures to edit code, debug it, and manage in under source control.</p> <p>Note: the <code>auto_open</code> option does not work in Docker Project Manager.  You need to manually open a new VSCode instance on your local host.</p> <p> </p>"},{"location":"DevOps-Docker/#project-files-are-local","title":"Project Files are Local","text":"<p>Recall that docker containers are self-contained.  So, we should ask: are the project files in the container, or on the local host?</p> <p>As explained in VSCode docs, project files (and VSCode) are on the local host:</p> <ul> <li>That is why you provided <code>-v ${PWD}:/localhost</code><ul> <li>This gives the container permission to access the current folder</li> </ul> </li> <li>That is why you needed <code>$ exit  # return to local host</code></li> </ul> <p>As shown below, there are typically 2-3 \"machines\" in operation:</p> <ul> <li> <p>Your local host (in grey), where the Customizable Project files (<code>ApiLogicProject</code>) are stored,  and your Dev Tools (IDE etc) operate</p> </li> <li> <p>The ApiLogicServer Docker container (blue), which contains:</p> <ul> <li>The ApiLogicServer, with CLI (Command Language Interface) commands:<ul> <li><code>create</code> to create projects on your local host</li> <li><code>run</code> to execute projects, utilizing the various runtimes (Flask, SQLAlchemy, SAFRS API, Logic, Flask App Builder)</li> </ul> </li> <li>A Python environment to support execution, and development using your IDE</li> </ul> </li> <li> <p>The database (purple) can run as a separate Docker container, in your local host, or (for the demo) within the ApiLogicServer docker container</p> </li> </ul> <p></p> <p>Your docker container (blue) files include Python, Python libraries, and API Logic Server.  The Python project above utilizes IDE <code>remote-container</code> support, which utilizes the docker container (not local host) version of Python.</p> <p>Your docker container looks like this:</p> <p></p> <p></p> <p> </p>"},{"location":"DevOps-Docker/#install-docker-run-arguments","title":"Install - <code>docker run</code> arguments","text":"<p>Once you've installed Docker itself, the <code>docker run</code> command above installs the ApiLogicServer docker (if it's not already there), and starts it, opening a terminal window on the Docker container.  Notes:</p> <ul> <li>the <code>v ${PWD}:/localhost</code> argument is what enables the ApiLogicServer to create / access the project on your local host</li> <li>Windows - Powershell must be used (due to the <code>$(PWD)</code> syntax)</li> <li>if you use Command Prompt, specify the local directory completely </li> </ul> <p>The arguments mean:</p> <ul> <li>-it - launch a terminal window for the Docker container</li> <li>--name api_logic_server - the name of the image on your local host</li> <li>-rm - remove the container once it stops (your project files are not lost - they are on your local host)</li> <li>-p 5656:5656 - maps local (host) part to Docker port </li> <li>-v ${PWD}:/localhost - maps a local directory to a mount name for Docker.  This is where a directory will be created for your new project.  </li> <li><code>${PWD}</code> is your current folder.  <ul> <li>You could also provide a specific folder, e.g., <code>~/dev/servers</code> (Unix), or <code>C:\\Users\\val\\dev\\servers</code> (windows)</li> </ul> </li> <li><code>/localhost</code>is the mounted volume reference from inside the Docker container</li> <li><code>apilogicserver/api_logic_server</code> - the name of the image to pull from Docker Hub.  </li> <li>This will fetch the image first time, and will run it locally on subsequent runs</li> <li>The image is not automatically refreshed -- install ApiLogicServer updates as described below</li> </ul> <p>You may also wish to add a parameter for networking:</p> <ul> <li>--net my-network - attaches to my-network</li> </ul> <p>On your Docker container, you can inspect your environment: <pre><code>python py.py\n</code></pre></p> <p>Open a new terminal window on your local host, and find your docker IP address:</p> <pre><code>docker inspect api_logic_server  # you will find the ip, e.g., 172.17.0.2\n</code></pre>"},{"location":"DevOps-GitHub/","title":"GitHub and Codespaces","text":"<p>API Logic Projects are standard, and so are their GitHb / IDE operations.  A typical flow is illustrated below.</p> <p> TL;DR - Standard file-based projects enable git; Codespaces ready</p> <p>Projects are file-based (including logic), so work with standard <code>git</code> support.</p> <p>Projects are pre-configured for Dev Containers, so work with Codespaces.</p>"},{"location":"DevOps-GitHub/#local-project-creation","title":"Local Project Creation","text":"<p>Create your project, customize as necessary, and use <code>git</code> or your IDE to publish the project to GitHub.  For example, in VSCode, there is a button to <code>Publish</code> your project.</p>"},{"location":"DevOps-GitHub/#codespaces-project-creation","title":"Codespaces Project Creation","text":"<p>This procedure requires your database be accessible from the cloud.</p> <ol> <li>Open the [<code>template</code>]{https://github.com/ApiLogicServer/template)</li> <li>Click the large green Use this template &gt; Open in a Codespace button<ul> <li>The template defines your <code>.devcontainer</code>, including Python and API Logic Server</li> </ul> </li> <li>Create your project in place, e.g.:<ul> <li><code>ApiLogicServer create --project_name=./ --db_url=nw</code></li> </ul> </li> <li>Don't rebuild the Dev Container</li> <li>Publish as a new project (providing your own name):</li> </ol> <p></p>"},{"location":"DevOps-GitHub/#open-existing-github-project-in-codespaces","title":"Open existing GitHub project in Codespaces","text":"<p>However you have created your project, you (and your teammates) can open it in Codespaces:</p> <p></p> <p>You will now see your project - running in VSCode, in the Browser.  But that's just what you see...</p> <p>Behind the scenes, Codespaces has requisitioned a cloud machine, and loaded your project - with a complete development environment - Python, your dependencies, git, etc.  </p> <p>You are attached to this machine in your Browser, running VSCode.</p> <p> Pretty remarkable.</p> <p>1. Start the Server</p> <ul> <li>Use the pre-defined Launch Configuration</li> </ul> <p>2. Start the Browser</p> <p></p>"},{"location":"Doc-Home/","title":"Doc Home","text":"<p>Welcome to GenAI-Logic (aka ApiLogicServer) documentation.  In sufficently large browsers, the pages are shown at left, and the page contents are at right.</p>"},{"location":"Doc-Home/#start-install-samples-training","title":"Start: Install, Samples, Training","text":""},{"location":"Doc-Home/#install-and-verify","title":"Install and Verify","text":"<p>If you have the correct Python (version 3.10-3.13), install is standard (more detailed instructions here):</p> Install API Logic Server in a Virtual Environment<pre><code>mkdir genai-logic                    # aka ApiLogicServer\ncd genai-logic\npython3 -m venv venv                 # windows: python -m venv venv\nsource venv/bin/activate             # windows: venv\\Scripts\\activate\npython -m pip install ApiLogicServer\n\ngenai-logic start                    # start manager, tutorial\n</code></pre> <p>Notes:</p> <ol> <li>This requires you've activated VSCode <code>code</code> CLI (to get it: Open the Command Palette (Cmd+Shift+P) and type <code>shell command</code>).</li> <li>The <code>genai-logic</code> CLI command is the rebranding of <code>ApiLogicServer</code>.  They are synonomous, including aliases such as gail, als.  Use <code>genai-logic --help</code> to discover remaining commands.</li> </ol> Using PyCharm? <p>The Manager defaults to VSCode.  If you are using PyCharm, start the mananager like this:</p> To use Pycharm<pre><code>ApiLogicServer start --open-with=pycharm  # For Mac, you may need use charm, not pycharm\n</code></pre> <p>Verification test - create and run the demo (from the IDE in your Manager CLI, or terminal):</p> Verify - Create and Run Demo<pre><code>genai-logic create --project-name=basic_demo --db-url=sqlite:///sample_ai.sqlite\ncode basic_demo  # not required when running from Manager (IDE starts automatically)\n</code></pre> <p>The resultant project contains a <code>readme</code> which will walk you through the process of exploring the API, app, and customization.</p> <p>The manager also contains a readme that introduces you to several key samples.</p> <p>Finally, explore the demos, samples and tutorials, below.  </p> Demos, Tutorials, Samples <p>Type:</p> <ul> <li>Demo: Small Databases, Introduces Key Features</li> <li>Tutorial: Detailed Walk-throughs</li> <li>Samples: other databases (brief description)</li> <li>Article: shows basic steps without detail (an article reprint)</li> </ul> <p>Recommendation: start with the first 2 items</p> Project Notes Type GenAI Demo 1. Natural language creation of project / database: 1 command 2. Illustrate a very rapid create / customize / iterate cycle3. Introduce Integration Demo Tutorial 1. How to Use the Key Features2. Key code samples for adapting into your project Tutorial App Integration Illustrates running Kafka messaging, self-serve and customized APIs, choreographed with rules and Python Tutorial Deployment Containerize and deploy your applications Tutorial Basic Demo Focused use of API, Admin App and Rules on small customer/orders database Demo AI Demo 1. Use Copilot to create new databases from natural language2. Illustrate a very rapid create / customize / iterate cycle3. Introduce Integration Demo AI Drives Agile Vision Use ChatGPT to create new databases from natural language, to bootstrap an agile create / deploy / collaborate / iterate cycle Article Agile Behavior Driven Design and testing, using Behave Tutorial Allocation Power Rule to allocate a payment to a set of outstanding orders Sample MySQL Docker Create projects from sample databases: chinook (albums and artists), and classicmodels (customers and orders) Sample Sqlite databases Create projects from pre-installed databases via abbreviations:- chinook, classicmodels, todo Sample BudgetApp illustrates automatic creation of parent rows for rollups Sample Banking App Illustrates more complex logic (Funds Transfer) Sample - obtain via <code>git clone</code> <p>Finally, try your own database.</p>  Training  <p>After installing, you can optionally run the first demo, above.  The key training activities are:</p> <ol> <li>Perform the Tutorial<ul> <li><code>ApiLogicServer create --project_name= --db_url=</code></li> <li>Keep this project installed; you can find code samples by searching <code>#als</code> -- see below</li> </ul> </li> <li>Perform Logic Training<ul> <li>Spreadsheet-like rules and Python for integration, and multi-table derivations / constraints</li> </ul> </li> <li>API Customization: explore the code in <code>api/customize_api.py</code><ul> <li>Note this is largely standard Flask, enhanced with logic</li> </ul> </li> </ol> <p></p>  Resources  <p>You might find the following helpful in exploring the project:</p> <ul> <li> <p>Installed Sample Databases - Here are some installed sample databases you can use with simplified abbreviations for <code>db_url</code>.</p> </li> <li> <p>Dockerized Test Databases -  Then, you might like to try out some of our dockerized test databases.</p> </li> <li> <p>auth - sqlite authentication database (you can also use other DBMSs)</p> </li> </ul>  Release Notes  <p>06/11/2024 - 10.04.61: Ontimize Rich Client Tech Preview</p> <p>06/04/2024 - 10.04.43: Improved Ontimize support</p> <p>05/xx/2024 - 10.04.23: API/Logic Discovery</p> <p>05/04/2024 - 10.04.01: GenAI - Generative AI Automation</p> <p>12/21/2023 - 10.00.01: Application Integration (Kafka), Bug Fix</p> <p>10/31/2023 - 09.05.00: Enhanced Security (global filter, permissions), Logic (Insert Parent)</p> <p>09/08/2023 - 09.03.04: AI Driven Automation (preview)</p> <p>09/08/2023 - 09.03.00: Oracle support</p> <p>06/22/2023 - 09.00.00: Optimistic Locking, safrs 310 / SQLAlchemy 2.0.15</p> <p>05/01/2023 - 08.03.06: Allocation sample</p> <p>04/26/2023 - 08.03.00: Virtual attrs (Issue 56), safrs 3.0.2, LogicBank 1.8.4, project readme updates</p> <p>03/23/2023 - 08.01.15: Table filters, cloud debug additions, issue 59, 62-4</p> <p>02/15/2023 - 08.00.01: Declarative Authorization and Authentication</p> <p>01/05/2023 - 07.00.00: Multi-db, sqlite test dbs, tests run, security prototype, env config</p> <p>09/15/2022 - 06.01.00: Multi-app Projects</p> <p>05/04/2022 - 05.02.03: Alembic for database migrations, admin-merge.yaml</p> <p>04/27/2022 - 05.01.02: copy_children, with support for nesting (children and grandchildren, etc.)</p> <p>03/27/2022 - 05.00.06: Introducing Behave test framework, LogicBank bugfix</p> <p>12/26/2021 - 04.00.05: Introducing the Admin app, with Readme Tutorial</p>  Preview Version  <p> </p> <p>This pre-release includes:</p> <ul> <li>Version 15.00.51<ul> <li>Python 3.13</li> </ul> </li> </ul> <p>You can try it at (you may need to use <code>python3</code>):</p> <pre><code>python -m pip install --index-url https://test.pypi.org/simple/ --extra-index-url https://pypi.org/simple ApiLogicServer==15.0.51\n</code></pre> <p>Or use (not available currently):</p> <pre><code>docker run -it --name api_logic_server --rm -p 5656:5656 -p 5002:5002 -v ~/dev/servers:/localhost apilogicserver/api_logic_server_x\n</code></pre> <p>Or, you can use the beta version on codespaces.</p> <p> </p>"},{"location":"Doc-Home/#works-with","title":"Works With","text":"API Logic Server works with key elements of your existing infrastructure Works With Notes AI Use Copilot to create databases, and use API Logic Server to turn these into projects Other Systems APIs and Messages - with logic Databases Tested with MySQL, Sql/Server, Postgres, SQLite and Oracle Client Frameworks Creates instant APIs that factors out business logic, where it is automatically shared for User Interfaces, APIs, and Messages Your IDE Creates standard projects you can customize in your IDE, such as VSCode and PyCharm Messaging Produce and Consume Kafka Messages Deployment Scripts to create container images, and deploy them to the cloud Agile and Test Methodologies Use Behave to capture requirements, rapidly implement them with API Logic Server, collaborate with Business Users, and test with the Behave framework"},{"location":"Doc-Home/#contact-us","title":"Contact Us","text":"<p>We'd love to hear from you:</p> <ol> <li>Email: apilogicserver@gmail.com</li> <li>Issues: github</li> <li>Discord: we use Discord for support - join here.  You should install the Discord app.</li> </ol> <p>It can be tricky to use Discord for screen sharing - here is the procedure for a mac:</p> <ol> <li>Start a call with a contact</li> <li>Share your screen:</li> </ol> <p></p> <p> </p>"},{"location":"Doc-Home/#more-information","title":"More Information","text":"<p>For docs, click here.</p> Acknowledgements <p>Many thanks to</p> <ul> <li>Thomas Pollet, for SAFRS, SAFRS-react-admin, and invaluable design partnership</li> <li>Tyler Band, for leadership on security</li> <li>dbvis, for a complimentary license in support of this open source project</li> <li>Marelab, for react-admin</li> <li>Armin Ronacher, for Flask</li> <li>Mike Bayer, for SQLAlchemy</li> <li>Alex Gr\u00f6nholm, for Sqlacodegen</li> <li>Thomas Peters, for review and testing</li> <li>Meera Datey, for React Admin prototyping</li> <li>Denny McKinney, for Tutorial review</li> <li>Achim G\u00f6tz, for design collaboration and testing</li> <li>Max Tardiveau, for testing and help with Docker</li> <li>Michael Holleran, for design collaboration and testing</li> <li>Nishanth Shyamsundar, for review and testing</li> <li>Gloria Huber and Denny McKinney, for doc revie</li> </ul> Articles <p>There are several articles that provide some orientation to API Logic Server:</p> <ul> <li>Instant APIs With Copilot and API Logic Server</li> <li>Instant App Backends With API and Logic Automation</li> <li>Instant Integrations With API and Logic Automation</li> <li>AI and Rules for Agile Microservices in Minutes</li> </ul> <p>Also:</p> <ul> <li>How Automation Activates Agile</li> <li>How Automation Activates Agile - providing working software rapidly drives agile collaboration to define systems that meet actual needs, reducing requirements risk</li> <li>How to create application systems in moments</li> <li>Stop coding database backends\u2026Declare them with one command.</li> <li>Instant Database Backends</li> <li>Extensible Rules - defining new rule types, using Python</li> <li>Declarative - exploring multi-statement declarative technology</li> <li>Automate Business Logic With Logic Bank - general introduction, discussions of extensibility, manageability and scalability</li> <li>Agile Design Automation With Logic Bank - focuses on automation, design flexibility and agile iterations</li> <li>Instant Web Apps</li> </ul> <p> </p>"},{"location":"Doc-Home/#runtimes-and-cli","title":"Runtimes and CLI","text":"<p>API Logic Server is a Python Application, consisting of:</p> <ol> <li>Runtimes for ApiLogicProject execution (see below)</li> <li>CLI (Command Language Interface - provides <code>ApiLogicServer create</code>\u2026`)</li> </ol> <p>It executes either as a locally install (venv), or a Docker image (which includes Python).  In either case, the contents are the same:</p> <p></p> <p> </p>"},{"location":"Doc-Home/#created-projects","title":"Created Projects","text":"<p>Created projects are designed for Customization.</p> <p></p>"},{"location":"Doc-Home/#key-runtime-components","title":"Key Runtime Components","text":"<p>The following </p> Component Provides Flask enables you to write custom web apps, and custom api end points SQLAlchemy Python-friendly ORM (analogous to Hiberate, JPA) Logic Bank Listens for SQLAlchemy updates, provides Multi-Table Derivations and Constraint RulesPython Events (e.g., send mail, message)Customizable with Python SAFRS JSON:API and swagger, based on SQLAlchemy SAFRS-RA Admin App, using SAFRS <p> </p>"},{"location":"Doc-Home/#execution-3-tiered-architecture","title":"Execution: 3-tiered architecture","text":"<p>The API Logic Server executes as an application server, accessed by an API, in a standard 3-tiered architecture.  </p> <p>Observe that logic plugs into SQLAlchemy.  Logic is thus automatically shared (factored out) of custom services, and web or browser-based apps.</p> <p>In most cases, the API Logic Server executes in a container, so scales horizontally like any other Flask-based server.</p> <p></p>"},{"location":"Execute/","title":"Execute From Terminal","text":"<p>You can execute API Logic Projects in your IDE, or directly in a Terminal window, as described below.</p> <p> </p>"},{"location":"Execute/#most-commonly-in-your-ide","title":"Most commonly - in your IDE","text":"<p>In most cases, you will probably want to run it from your IDE (see IDE &gt; Open and Execute).  </p> <p>If you are following the Tutorial (recommended first step), proceed to the link above.</p> <p> </p>"},{"location":"Execute/#from-the-terminal","title":"From the Terminal","text":""},{"location":"Execute/#1-start-the-server","title":"1. Start the Server","text":"<p>The <code>api_logic_server_run.py</code> file is executable.  The simplest way to run it is:</p> Either from Docker terminal, or from local terminal with `venv` set<pre><code>ApiLogicServer run\n</code></pre> <p>You can also run it directly (see also start args):</p> Either from Docker terminal, or from local terminal with `venv` set<pre><code>python api_logic_server_run.py       # options exist to override URL, port\n</code></pre>"},{"location":"Execute/#2-open-in-your-browser","title":"2. Open in your Browser","text":"<p>The server should start, and suggest the URL for your Browser.  That will open a page like this, where you can explore your data using the automatically created Admin app, and explore the API with automatically generated Swagger:</p> <p></p>"},{"location":"FAQ-AI/","title":"Is this an AI Approach?","text":""},{"location":"FAQ-AI/#tldr-ai-with-business-oriented-models","title":"TL;DR - AI... with business-oriented models","text":"<p> AI has proven to be a powerful tool for automating function-level coding.  However, creating complete sub-systems is less successful, requiring language input for low-level implementation details.  These require substantial skill (e.g., detailed knowledge of a framework), and result in systems that are difficult to maintain.  In short, a failure to communicate.  </p> <p>By introducing high-level business-oriented language, it becomes possible to create complete systems.  API Logic Server uses AI to create complete systems from high-level business logic, without requiring detailed language input.  </p> <p>These systems are then maintained at a high level of abstraction through created executable models.  The resultant systems are easy to maintain, and extend where necessary using standard languages and tools.  This approach is unique in the industry, and has been proven in a wide range of applications.</p> Does GenAI require Microservice Automation? <p>GenAI brings well-known value to app development.  It's great for generating code snippets, including code snippets for driving other sub-systems, such as sql (e.g., \"create a database...\").  API Logic Server leverages both of these strengths.</p> <p>While GenAI is great for driving sub-systems (like sql), it's not appropriate for creating sub-systems.  For example, you would not want to generate a DBMS using GenAI.</p> <p>But what about microservices - APIs, and their logic?  It is like code snippets, or more like a sub-system?  We investigated GenAI API and logic creation, and here's what we found...</p> <p> </p> <p>1. GenAI for APIs</p> <p>It is possible to create rudimentary APIs using GenAI.   However:</p> <ol> <li>Not enterprise-class: the APIs are incomplete or incorrect for required features such as security, fitering, pagination, optimistic locking, etc.  For example, this filtering code only works for the primary key, and pagination is stubbed out:</li> </ol> <pre><code># Endpoint to get customers with filtering and pagination\n@app.route('/customers', methods=['GET'])\ndef get_customers():\n    page = int(request.args.get('page', 1))\n    per_page = int(request.args.get('per_page', 10))\n    query = session.query(Customer)\n    customers = paginate(query, page, per_page).all()\n    return jsonify([{'id': c.id, 'name': c.name, 'email': c.email, 'phone': c.phone} for c in customers])\n</code></pre> <ol> <li>Complex: it requires a great deal of prompt engineering to \"program\" the target framework to get a better result.  That requires detailed knowledge of the target -  failure to communicate - defeats the simplicity objective of using GenAI.</li> </ol> <p> </p> <p>2. GenAI for Logic</p> <p>In most cases, GenAI responses simply ignores the logic requirement.  Attempts to address it fall in 3 categories: triggers, Logic Bank code with no context,  and Logic Bank code with context.</p> <p> </p> <p>2a. Logic: Triggers</p> <p>The trigger solution GenAI response typically looks something like this:</p> <pre><code>-- Note: The enforcement of the Check Credit requirement is complex and might be better handled in application logic.\n-- However, you can create a stored procedure or use triggers to enforce these rules, keeping in mind the performance implications.\n\n-- Example of a trigger to enforce Customer.balance &lt;= credit_limit (simplified version)\nDELIMITER //\nCREATE TRIGGER CheckCreditBeforeCustomerUpdate\nBEFORE UPDATE ON Customers\nFOR EACH ROW\nBEGIN\n    IF NEW.Balance &gt; NEW.Credit_Limit THEN\n        SIGNAL SQLSTATE '45000' SET MESSAGE_TEXT = 'Customer balance exceeds credit limit.';\n    END IF;\nEND;\n//\nDELIMITER ;\n</code></pre> <p>This is simply not a solution: it does not address the triggering event - some change to the order.  By contrast, our logic automates about a dozen Use Cases, including:</p> <ul> <li> <p>The customer balance is adjusted (and credit is checked) when an order is inserted, deleted, shipped, or re-assigned to a different customer.  Importantly, the logic (and its overhead) is pruned on other changes, such as changing the shipping address.</p> </li> <li> <p>This dependency management chains: the order is adjusted when items are inserted, deleted, or updated with new quantities or different products.</p> </li> </ul> <p>Addressing this level of logic is why rules are 40X more concise than code.</p> <p> </p> <p>2b. Logic: Logic Bank, without context</p> <p>If we engineer our prompt to suggest using Logic Bank (a component of API Logic Server), we get a response like this if there is no project context:</p> <pre><code>def declare_logic():\n    LogicBank.activate(session=session, activator=logic_bank_util.register_rules)\n\n    @LogicBank.rule(\"order\", \"before_flush\")\n    def order_amount_total(row: LogicRow):\n        row.amount_total = sum([item.quantity * item.unit_price for item in row.items])\n\n    @LogicBank.rule(\"customer\", \"before_flush\")\n    def customer_balance(row: LogicRow):\n        row.balance = sum([order.amount_total for order in row.orders if order.date_shipped is None])\n\n    @LogicBank.rule(\"item\", \"before_flush\")\n    def item_amount(row: LogicRow):\n        row.amount = row.quantity * row.unit_price\n\n    @LogicBank.rule(\"item\", \"before_flush\")\n    def copy_unit_price_from_product(row: LogicRow):\n        row.unit_price = row.product.unit_price\n\n    @LogicBank.rule(\"customer\", \"before_flush\")\n    def check_credit_limit(row: LogicRow):\n        if row.balance &gt; row.credit_limit:\n            raise Exception(f\"Customer {row.name}'s balance exceeds their credit limit.\")\n</code></pre> <p>There are no existing Logic Bank APIs remotely like those above.  This code does not even compile, much less run.  It is, as they say, an hallucination.</p> <p> </p> <p>2c. Logic: Logic Bank, With Context</p> <p>Excellent results are obtained when the prompt has available context.  Copilot turns our Natural Language requirements into Logic Bank code, requiring only minor adjustments.</p> <p>And this is far preferable to generating logic code -- it's much better to understand and maintain the 5 rules than the 200 lines of generated code.</p> <p> </p> <p>2d. Conclusion: Abstraction Level is Critical</p> <p>As perhaps expected, large scale sub-system creation from GenAI is not practical.  However, it is a great driver for engines, and for creating code snippets.  API Logic Server leverages these strengths, and provides the missing microservice logic automation.</p> <p>Of course, the Logic Bank and SAFRS engines are required for actual execution, just as sql queries require a DBMS.  Watch it in the video below.</p>"},{"location":"FAQ-Frameworks/","title":"Is this a Framework?","text":""},{"location":"FAQ-Frameworks/#tldr-not-a-framework-rather-a-low-code-approach-for-creating-systems","title":"TL;DR - not a framework, rather a low-code approach for creating systems","text":"<p>There are many excellent frameworks for developing web apps.  They provide tools for writing code to handle API and application events.</p> <p>API Logic Server is not a framework - it is built on frameworks (Flask currently, more are possible).  It is a low-code approach for creating customizable microservices - Apps, APIs, and (uniquely) the underlying business logic.</p> <p> </p>"},{"location":"FAQ-Frameworks/#frameworks-code-based-appapi-handlers","title":"Frameworks - code based app/api handlers","text":"<p>Frameworks require extensive background in web app development, and significant amounts of code.  The video at the end provides an excellent summary of Flask, FAST API, and Django.  While flexibile, they are complex and time consuming.</p> <p> </p>"},{"location":"FAQ-Frameworks/#api-logic-server-low-code-declarative-customizable-system-creation","title":"API Logic Server - low-code declarative, customizable system creation","text":"<p>API Logic Server is designed to provide a significantly faster and simpler low-code approach for creating database systems:</p> <ul> <li> <p>Remarkable speed and simplicity: given a database, you get an instant system  - no training, no coding:</p> <ul> <li>an API, including filtering, pagination, sorting, related data and swagger</li> <li>a multi-page, multi-table Admin Web App, and </li> <li>SQLAlchemy model classes</li> </ul> </li> <li> <p>Fully Customizable: you get a customizable project you can use in your IDE to create custom services with all the flexibility and power of Python, Flask and SQLAlchemy</p> </li> <li> <p> Declarative Business Logic: unique spreadsheet-like rules that are 40X more concise than legacy code, extensible with Python</p> </li> </ul> <p> </p>"},{"location":"FAQ-Frameworks/#example-todos-1-command-project-creation","title":"Example: todos  -- 1 command project creation","text":"<p>The video at the top shows how to create a system from a <code>todos</code> database.  You can create this system with API Logic Server like this:</p> <ol> <li> <p>Download the todos database to your desktop</p> </li> <li> <p>Install API Logic Server:</p> </li> </ol> <p>Install API Logic Server  \u00a0\u00a0\u00a0\u00a0\u00a0 (also available for Docker)<pre><code>cd ~/Desktop\nmkdir ApiLogicServer\ncd ApiLogicServer\npython -m venv venv        # may require python3 -m venv venv\nsource venv/bin/activate   # windows venv\\Scripts\\activate\npython -m pip install ApiLogicServer\n</code></pre> 3. Create and run your project Create and Run todos project\u00a0\u00a0\u00a0\u00a0\u00a0 1 command<pre><code>ApiLogicServer create-and-run --project_name=todo \\\n   --db_url=sqlite:////Users/Val/Desktop/todos.db  # explicit path (no ~)\n</code></pre></p> <p>Explore your project in your IDE, using standard services to code, run and debug.</p> <p> </p>"},{"location":"FAQ-Frameworks/#appendix-video-conventional-approach","title":"Appendix - Video Conventional Approach","text":"<p>This video provides an excellent summary of Flask, FAST API, and Django.</p>"},{"location":"FAQ-Live-API-Creator/","title":"Is this like Live API Creator?","text":"<p> TL;DR - Migration from CA/Live API Creator (LAC)</p> <p>CA/Live API Creator was a compelling product that offered instant API creation.  We believe API Logic Server is a superior approach, because:</p> <ol> <li> <p>GenAI: provides order of magnitude more simplicity and speed</p> </li> <li> <p>IDE-driven vs Studio: modern IDEs provide all the services required to maintain ease of use in a standards-based environment</p> </li> <li> <p>Self-serve API: users (for apps, integration, remote access) are not reliant on custom server development for multi-table APIs</p> </li> <li> <p>File-based vs. repository: all artifacts, including rules, are expressed in files that can be managed in GitHub</p> </li> </ol> <p>CA/Live API Creator has reached end-of-life and soon end-of-support.  Customers seeking to migrate have many options for creating APIs.  API Logic Server offers a migration path worth considering:</p> <ul> <li> <p>API Logic Server provides unique support for declarative logic and security</p> </li> <li> <p>We also provide a migration utility for logic and security</p> <ul> <li> <p>Consulting services are available to assess specific applications, and provide migration tools for LAC feature such as custom resources</p> </li> <li> <p>Technology migrations are enabled by declarative models, and represent significant business value in preserving technology investments.</p> </li> </ul> </li> <li> <p>API Logic Server is open source, and offers superior services for:</p> <ul> <li> <p>Development: uses standard IDEs for debugger and source code management</p> <ul> <li>IDE-Driven Development, not via a UI</li> </ul> </li> <li> <p>Deployment: scripts are provided to containerize applications for deployment</p> </li> </ul> </li> <li> <p>API Logic Server is a self-serve API style, well suited for supporting other organizations with ad hoc integrations without requiring central creation of customized APIs</p> <ul> <li> <p>Use standard Flask for custom APIs - still rule-enabled</p> </li> <li> <p>An Extensible ORM enables access to other data sources</p> </li> </ul> </li> </ul> <p> </p>"},{"location":"FAQ-Live-API-Creator/#conceptually-similar","title":"Conceptually Similar","text":"<p>Both products provide:</p> <ul> <li> <p>Instant creation of projects with multi-table APIs.  The APIs both provide filtering, sorting, pagination, and multi-table retrieval</p> </li> <li> <p>Instant creation of multi-page Admin Apps</p> </li> <li> <p>Declarative business logic - rules, extensible with code</p> </li> </ul> <p> </p>"},{"location":"FAQ-Live-API-Creator/#key-difference-summary","title":"Key Difference Summary","text":""},{"location":"FAQ-Live-API-Creator/#lac-only","title":"LAC Only","text":""},{"location":"FAQ-Live-API-Creator/#api-style-custom-resources","title":"API Style: Custom Resources","text":"<p>The styles are different:</p> <ul> <li> <p>LAC APIs are server-defined, with custom Resource definition.</p> <ul> <li>These are suitable for in-house clients whose needs are known in advance</li> </ul> </li> <li> <p>ALS APIs are self-serve, client-defined (see here for more information).  </p> <ul> <li>These are suitable for general clients who can request exactly the data they require, without the performance costs and complexity of integrating several bespoke APIs</li> </ul> </li> </ul> <p> </p>"},{"location":"FAQ-Live-API-Creator/#column-level-security","title":"Column Level Security","text":"<p>Both provide role-based row security.  Additionally, LAC provides role-based column security.</p> <p> </p>"},{"location":"FAQ-Live-API-Creator/#api-logic-server-only","title":"API Logic Server Only","text":""},{"location":"FAQ-Live-API-Creator/#open-source-stability","title":"Open Source Stability","text":"<p>API Logic Server is open source.  Besides obvious pricing advantages, open source is not subject to business cycles and whims of vendors.</p> <p> </p>"},{"location":"FAQ-Live-API-Creator/#leverage-ide-containers","title":"Leverage IDE, Containers","text":"<p>API Logic Server does not provide a \"studio UI\", instead using a Standard IDE using Python as a DSL.  This leverages signficant tooling, such as standard debuggers and source control.</p> <p>API Logic Server leverages containers for Dev and Deploy, for more more standards-based deployment.</p> <p> </p>"},{"location":"FAQ-Live-API-Creator/#python-as-a-dsl","title":"Python (as a DSL)","text":"<p>Both products provide a code-by-exception approach for APIs and logic.  API Logic Server uses Python.  While this may be new to some shops, the general approach is declarative using Python as a DSL and scripting language.  This level of Python is extremely easy to pick up.</p> <p> </p>"},{"location":"FAQ-Live-API-Creator/#migration-evaluation-services","title":"Migration Evaluation Services","text":"<p>The sections above identify the highlights, but the needs of specific projects may differ.  As noted above, we served as lead engineers on both, so we are uniquely positioned to help explore migrating your project.  Please contact us.</p> <p>The Migration Migration Service provides LAC transformation for:</p> <ul> <li> <p>Custom Resources</p> </li> <li> <p>FreeSQL</p> </li> <li> <p>Rules</p> </li> <li> <p>Functions</p> </li> <li> <p>Security</p> </li> <li> <p>Pipelines</p> </li> </ul>"},{"location":"FAQ-Low-Code/","title":"Is this a Low Code approach?","text":""},{"location":"FAQ-Low-Code/#tldr-low-code-for-developers-standards-unique-bus-rules","title":"TL;DR - Low Code For Developers: Standards, Unique Bus Rules","text":"<p>The Low Code promise of business agility has tremendous potential.  To realize it, we must enlist developers by addressing their concerns:</p> <ul> <li>For Business Users, API Logic Server (ALS) provides the fastest and simplest way to create Working Software, directly from an existing database or a GenAI prompt.  <ul> <li>No screen painting is required</li> <li>Database definition -- and the full system -- is automated from GenAI</li> </ul> </li> <li>For Developers, API Logic Server leverages your existing infrastructure, including <ul> <li>Your IDE, existing libraries, and</li> <li>Flexible container-based deployment</li> </ul> </li> <li>API Logic Server provides unique Logic Automation with spreadsheet-like rules - 40X more concise <ul> <li>Such backend logic is half of your system - front-end-only automation falls short</li> </ul> </li> </ul> <p> </p>"},{"location":"FAQ-Low-Code/#current-approaches","title":"Current Approaches","text":""},{"location":"FAQ-Low-Code/#enable-business-users","title":"Enable Business Users","text":"<p>Typical Low Code approaches provide a Studio with designers for databases and screens, so that citizen developers can create systems.  Products are typically cloud based, to enable sharing/collaboration without the complexity of traditional IT deployment.</p> <p> </p>"},{"location":"FAQ-Low-Code/#issues-standards-cost","title":"Issues: Standards, Cost","text":"<p>Developers share the basic business agility objective of reducing time and cost.  Developers have been understandably reluctant to embrace Low Code, because they require:</p> <ul> <li>Proprietary Studio - modern IDEs provide \"must-have\" services for debugging, code management, profiling, using external libraries, etc.</li> <li>Proprietary Deployment - developers expect to create containers that can be deployed anywhere, able to leverage extensive functionality such as Kubernetes</li> <li>A modern and flexible application architecture, for integration (eg., APIs and Messaging), and maximizing re-use (e.g., shared logic between apps and headless services)</li> </ul> <p>And finally, there are issues of cost.</p> <p> </p>"},{"location":"FAQ-Low-Code/#als-developer-low-code","title":"ALS: Developer Low Code","text":"<p>ALS is designed for Developers, to address these challenges.</p> <p> </p>"},{"location":"FAQ-Low-Code/#devs-standards-architecture","title":"Devs: Standards, Architecture","text":"<p>ALS meets the basic requirements for Developers:</p> <ul> <li>Standard IDE: use your debugger, libraries, etc</li> <li>Standard Container-based Deployment: local, cloud, etc, compatible with enterprise options such as Kubernetes for dynamic scaling</li> <li>Architecture: APIs are created automatically, enabling basic application integration and unblocking UI development.  Messaging is also supported, for robust application integration.</li> </ul> <p> </p>"},{"location":"FAQ-Low-Code/#unique-logic","title":"Unique Logic","text":"<p>Backend logic is typically nearly half the effort for systems providing update capabilities.  Procedural approaches - whether code-based or graphical - do not provide meaningful automation.</p> <p>A declarative approach is required.  API Logic Server provides spreadsheet-like rules, leveraging Python as a Domain Specific Language, are 40X more concise for such logic.</p> <p> </p>"},{"location":"FAQ-Low-Code/#business-users-genai","title":"Business Users: GenAI","text":"<p>While API Logic Server is focused on Developers, extreme levels of automation provide important benefits for business users: </p> <ul> <li>Instant Working Software is created directly from an existing database, or a GenAI prompt.  This eliminates tedious database design and screen painting, for earlier collaboration and more rapid iteration.</li> <li>Business Logic is transparent and readable - much like a design document, but executable</li> </ul> <p> </p>"},{"location":"FAQ-Low-Code/#webgenai","title":"Web/GenAI","text":"<p>An important element of collaboration is rapid deployment so colleagues can review screens.  While API Logic Server targets local development, we have working prototypes that can be deployed on your infrastructure or cloud:</p> <p>In your browser, provide a GenAI prompt describing your system.  Press create, and it runs in a few seconds... zero deployment required. Then, Developers can download the project to customize, integrate, etc. </p> <p>Please contact us if you would like to preview this software.</p> <p> </p>"},{"location":"FAQ-Low-Code/#summary","title":"Summary","text":"<p>The following table contrasts traditional \"Current\" Low Code with \"Developer\" Low Code:</p> Aspect Current Low Code Developer Low Code Screen Painter Commonly Provided Not Provided Customizations Proprietary Studio Standard IDE Rich UI Via Screen Painter Declarative App Models Instant Working Softwarefor Agile Collaboration Can be tedious Instant App AutomationNo Screen Painting Required Database Creation Via Forms Can be complicated Gen AI Natural LanguageBreak-through simplicity Business Logic(It's nearly half the system) Proprietary CodeProcedural Unique Spreadsheet-like RulesDeclarative - 40X More Concise Architecture Proprietary - rigid Automated MicroserviceStandard DockerFlexibile: Cloud, Internal"},{"location":"FAQ-Maintenance/","title":"What about Maintenance?","text":"<p>While rapid project creation is valuable and striking, experience has taught us that maintenance costs outweigh initial coding.  Only then is business agility materially improved.</p> <p>So, it's appropriate to ask whether Microservice Automation addresses maintance.</p> <p>It does.</p> <p>Declarative rules play a significant role in iterative development with support for maintenance automation:</p> <ul> <li> <p>Rule are automically invoked, and ordered.  So, unlike code, you can add/alter rules without worrying about where to place them so they run, and in the proper order, with automatic chaining (dependency management).</p> </li> <li> <p>Rules are automatically optimized, reducing SQLs by pruning and adjustment-based aggregates.</p> </li> <li> <p>Debug rules using the IDE debugger, and the logic trace, which shows which rules fire.</p> </li> </ul>"},{"location":"FAQ-RETE/","title":"Is this a RETE Engine?","text":""},{"location":"FAQ-RETE/#tldr-no-optimized-for-transactions","title":"TL;DR: no - optimized for transactions","text":"<p>The API Logic Server engine is not based on the RETE algorithm.  These technolgies are complemetarty:</p> <ul> <li> <p>RETE is appropriate for Decision Logic, where there are no presumptions about a database</p> </li> <li> <p>API Logic Server optimizes performance, often by several orders of magnitude, since it can prune and optimize rule execution based on comparing the proposed / old state of the database.</p> </li> </ul> <p> </p>"},{"location":"FAQ-RETE/#key-differences-in-rules-engines-process-decision-transaction","title":"Key Differences in Rules Engines: Process, Decision, Transaction","text":"<p>Let's consider these rule technologies in the light of the following requirements:</p>"},{"location":"FAQ-RETE/#transaction-logic-requirements","title":"Transaction Logic Requirements","text":"Category Consideration Scalable Rules should minimize SQL overhead, automatically Customizable Developers must be able to extend rule-based logic Manageable Developers must be able to use existing developer tools and procedures for code editing, debugging, code management, etc Integrity The system should ensure that all the rules are consistently enforced, in all cases Architecture Logic should automatically enforced over all apps and APIs"},{"location":"FAQ-RETE/#process-rules","title":"Process Rules","text":"<p>Such rules are typically graphs governing problem areas such as work flow and data flow integration.  These are completely appropriate applications.</p> <p>Process rules are not well suited to highly interdependent transaction logic:</p> <ul> <li>they are user ordered, so logic changes require the diagrams be redesigned</li> <li>they are not concise - a \"flowchart\" of thousands of lines of procedural logic is actually less readable than code.</li> </ul> <p>Transaction and process rules are synergistic:</p> <ul> <li>process diagrams may need to update rows, leveraging transaction logic</li> <li>transaction logic may need to start processes (\"start order process\"), or resume them (\"order is approved - execute next steps\").</li> </ul>"},{"location":"FAQ-RETE/#decision-rules","title":"Decision Rules","text":"<p>Decision rules look virtually identical to transaction rules - a set of chained derivations.  The difference is in the fundamental interface:</p> <ul> <li>logic engine processes rows changed in a transaction</li> <li>logic operation begins by obtaining old values of these rows</li> <li>these enable pruning and optimization (discussed below)</li> <li>old_rows also enable state transition semantics<ul> <li>e.g., all raises must exceed 10%    (one of our favorite rules)</li> </ul> </li> <li>decision logic processes an array of objects (rows), and the name of the RuleSet to run</li> </ul> <p>Decision engines cannot make presumptions about old rows, so when they encounter a rule like <code>balance is sum of order amounts</code>, it has no choice but to read all the Orders (and each of their OrderDetails).</p> <p>This is fine for a single-user \"what-if\" request.  But for multi-user transaction processing, this can reduce performance by multiple orders of magnitude.</p> <p>We also note that decision logic is explicitly called.  That means that you need to audit all of the accessing code to verify the logic is enforced.  Transaction logic, by contrast, ensures that all sqlalchemy access enforces the logic.</p> <p>That said, these technologies are also synergistic:</p> <ul> <li>You can invoke Decision Logic using Python in transaction logic rules</li> </ul>"},{"location":"FAQ-RETE/#transaction-rules","title":"Transaction Rules","text":"<p>This implementation is a Transaction Rules Engine: rule execution is bound into update processing.</p> Category Consideration Transaction Logic Scalable Rules should minimize SQL overhead, automatically Old row access enables pruning and sql optimizations (see below) Customizable Developers must be able to extend rule-based logic Many rules (events, constraints) invoke Python, providing access to all that entails Manageable Developers must be able to use existing developer tools and procedures for code editing, debugging, code management, etc Rules are Python code - use standard editors (with code completion), debuggers, and source code control systems and procedures Integrity The system should ensure that all the rules are consistently enforced, in all cases All ORM access enforces the rules Architecture Logic should automatically enforced over all apps and APIs Logic enforcement is factored out of UI controllers, so shared over all apps and APIs"},{"location":"FAQ-RETE/#multi-table-logic-execution","title":"Multi-Table Logic Execution","text":"<p>Let's look more carefully at how the watch, react and chain logic operates for multi-table transactions. Transactional systems can leverage the presumption that a set of updates is being applied to an existing database:</p> <ul> <li> <p>each updated row has an existing row on disk - the old values</p> </li> <li> <p>the system can compare the old values to the new update values, and</p> </li> </ul> <ol> <li> <p>Prune the rules that do not apply</p> </li> <li> <p>And when the rules must be run, the declarative nature of rules enables the system to execute the rules in any manner that returns the correct result.  In particular, the system can avoid expensive aggregate queries, and use the old/new delta to compute a 1-row adjustment to the parent row.</p> </li> </ol> <p>For example, imagine you need to compute the balance for the credit limit check.  You need to add all the order totals (an expensive SQL <code>sum</code>).  But it\u2019s worse - the order total itself is a summed field, so you need to add all of those too.</p> <p>If a customer has thousands of orders, each with thousands of items, this will be painfully slow.</p> <p>But if the system leverages the old/new to make an adjustment update, an order of $50 simply means \u201dadd 50 to the existing balance\u201d - no need to aggregate the totals.</p>"},{"location":"FAQ-RETE/#adjustments-sum-counts-adjusted-in-1-row-updates-not-expensive-aggregate-sqls","title":"Adjustments - sum / counts adjusted in 1 row updates, not expensive aggregate SQLs","text":"<p>Rollups provoke an important design choice: store the aggregate, or sum things on the fly.  Here, the stored aggregates are <code>Customer.Balance</code>, and <code>Order.AmountTotal</code> (a chained aggregate).  There are good cases to be made for both approaches:</p> <ul> <li> <p>Sum on the fly - use sql <code>select sum</code> queries to aggregate child data as required.    This eliminates consistency risks with storing redundant data    (i.e, the aggregate becomes invalid if an application fails to    adjust it in all of the cases).</p> </li> <li> <p>Stored Aggregates - a good choice when data volumes are large, and / or chain,    since the application can adjust (make a 1 row update) the aggregate based on the    delta of the children.</p> </li> </ul> <p>This design decision can dominate application coding.  It's nefarious, since data volumes may not be known when coding begins.  (Ideally, this can be a \"late binding\" decision, like a sql index.)</p> <p>The logic engine uses the Stored Aggregate approach.  This optimizes multi-table update logic chaining, where updates to 1 row trigger updates to other rows, which further chain to still more rows.</p>"},{"location":"FAQ-RETE/#pruning","title":"Pruning","text":"<p>Pruning was core to changing Order dates:</p> <ul> <li> <p><code>DueDate</code> had no dependencies, so all the logic for adjusting Customers and cascading OrderDetails was pruned.</p> </li> <li> <p>Contrast this to the multiple rows retrieved / update when <code>ShippedDate</code> is changed.</p> </li> </ul>"},{"location":"FAQ-Strategic/","title":"Is this a strategic investment?","text":""},{"location":"FAQ-Strategic/#tldr-a-strategic-approach-to-low-code","title":"TL;DR - a strategic approach to low-code","text":"<p>When you code to a framework, you are coding to a specific set of tools and conventions.  This is a good thing - it provides a common language and approach for developers.  However, it also means that you are locked into that framework, and must code to its conventions.</p> <p>The same applies to Low Code platforms - they provide a common language and approach, but you are locked into their conventions.</p> <p>API Logic Server is different - it is based on business oriented models that are technology independent.  This is the only approach that can future-proof your application investment.</p>"},{"location":"FAQ-Versata/","title":"Is this like Versata?","text":"<p> TL;DR - Is This Like Versata</p> <p>Versata was a major innovator for business rules on J2EE.  We believe GenAI-Logic is a superior approach, because:</p> <ol> <li> <p>IDE as Studio: Pre-IDEs, the Versata Studio presented challenges in debugging, source control, etc.  </p> <ul> <li>GenAI-Logic uses your IDE (debugger, source control), and deploys with standard containers.</li> </ul> </li> <li> <p>Open Client: While rules were effective, some clients found it difficult to achieve the look and feel they desired.  </p> <ul> <li>In addition to an instant automatic client, GenAI-Logic provides open APIs that work with any client.</li> </ul> </li> </ol> <p>Versata provided remarkable value, made compelling by \"riding the J2EE wave\".  Like Versata, GenAI-Logic is riding waves of interest:</p> <ul> <li>GenAI</li> <li>MCP</li> <li>Vibe</li> </ul> <p>For more information, click here.</p>"},{"location":"Home/","title":"API Logic Server","text":"<p> Fastest, Easiest Way to Create Servers for Integration and App Backends</p> <p>For Developers and their organizations seeking to increase business agility,</p> <p>API Logic Server provides instant API creation from a database with one CLI command, customizable with standards: Python, Flask, SQLAlchemy, and tools such as GitHub and your IDE.</p> <p>Weeks-to-months of complex framework-based development is no longer necessary.  API Logic Server provides unique API Automation for instant integrations and app backends, and unique Logic Automation with spreadsheet-like rules that decrease backend logic by 40X.</p> <p> </p>"},{"location":"Home/#quick-tour","title":"Quick Tour","text":"<p>API Logic Server is an open source Python project, consisting of a CLI and set of runtimes (SAFRS API, Flask, SQLAlchemy ORM, business logic engine) for project execution.</p> <p>It runs as a standard pip install, or under Docker. For more on API Logic Server Architecture, see here.</p> <p>Here's a quick tour of using API Logic Server: Create, Run, Customize.</p> <p> </p> <p>1. Create: Microservice Automation Means Create Projects With a Single CLI Command</p> <p>The <code>ApiLogicServer create</code> CLI command creates an executable project by reading the database schema in the <code>db_url</code> argument.  For example, this will create an executable, customizable project from the pre-installed sample database:</p> <pre><code>ApiLogicServer create --project_name=ApiLogicProject --db_url=nw\n</code></pre> <p> </p> <p>2. Run: API Automation and App Automation</p> <p>Microservice Automation has created a project that is executable, with:</p> <ul> <li>API Automation means you have a running JSON:API - filtering, sorting, pagination and optimistic locking</li> <li>App Automation means you have running Admin App - multi-page, multi-table, with automatic joins and lookups</li> </ul> <p>The API unblocks UI Developers from waiting on lengthy API development cycles. The Admin App can be used for instant business user collaboration.</p> See JSON:API and Admin App <p> </p> <p>You can run directly (<code>python api_logic_server_run.py</code>), or open it in your IDE and use the pre-created run configurations:</p> <p></p> <p>Unlike frameworks which require significant time and expertise, the create command builds a complete API for your database, with endpoints for each table, including swagger.  The Admin App provides a link to the Swagger:</p> <p></p> <p> </p> <p>3. Customize: Logic Automation, Python Flexibility</p> <p>Customize created projects in your IDE, with Python and standard libaries.  Significantly, Microservice Automation also includes:.</p> <ul> <li>Logic Automation means you customize logic and security, using Rules and Python in your IDE</li> </ul> <p>Rules are unique and confer significant business agility - 40X more concise than code, for security and multi-table derivations and constraints.</p> See Logic With Rules and Python <p> </p> <p>Rules are 40X more concise than code, and are extensible with Python:</p> <p></p> <p>For more on customization, click here.</p> <p> </p> <p>Customization also provides no-code ad hoc integrations,and enables Instant Business Relationships.</p> See Integration: APIs and Messages <p> </p> <p>The automatically created JSON:API provides no-code ad hoc integrations, enabling organizations to move beyond ETL.  For example, other applications might require a customer record, and their addresses.  The automatically created self-serve JSON:API requires no code, and reduces future custom API development:</p> <ol> <li>Create the JSON:API</li> <li>Declare security, to control access and row level authorization</li> </ol> <p>Integrate with B2B Partners by creating custom endpoints using Python and Flask, with under 10 lines of code.  Instant business relationships.  Observe that:</p> <ol> <li>Update logic is partitioned out of each service - or UI - into shared Logic</li> <li>Mapping between SQLAlchemy rows and requests is automated with the RowDictMapper</li> </ol> <p></p> <p></p> <p>Integrate internal systems with Kafka, using business logic events:</p> <p></p> <p>For more on integration, explore running code in the Application Integration Sample Tutorial.</p> <p> </p>"},{"location":"Home/#scenarios","title":"Scenarios","text":"Application Integration <p>As illustrated below, API Logic Server supports transactions from User Interfaces, and Application Integration - both via custom APIs and Kafka messages.</p> <p></p> <p>JSON:API are a standard for self-serve APIs -- where clients can select the columns and the related data they require.</p> <p>Self-serve APIs reduce the need for ongoing custom API development.  Analogous to GraphQL, they fulfill requirements for UI development and ad hoc integration.</p> <p>You can use Python, Flask and SQLAlchemy to create Custom APIs, e.g. for B2B Partners.  In addition to the underlying logic, API Logic Server provides mapping services as described under Application Integration.</p> <p>Appication Integration support also provides automation for producing and consuming Kafka messages.  Here's an article: click here.  To see these services in a tutorial, click here.</p> Unblock Client App Dev <p> </p> <p>Framework-based API development is time-consuming and complex.  Since client App Dev depends on APIs, front-end dev is often blocked.  This serialized dev process reduces business agility, and increases pressure on the team.</p> <p>API Logic server can change that.  </p> <ol> <li> <p>API Automation means client App Dev can start as soon as you have a database</p> </li> <li> <p>Logic Automation means that</p> <ol> <li>Such logic - a substantial element of the system - is automatically partitioned out of each client into server-based logic.  This reduces client coding, and enables the logic to be shared between user interfaces and services.</li> <li>Logic development can proceed in parallel with client App Dev</li> </ol> </li> </ol> <p>Here's an article, here.  Or, the the Tutorial, here.</p> 1 day projects with AI-Driven Schema Automation <p> </p> <p>API and Logic Automation begins with a database.  But what if it's a new project, and there is no database.</p> <p>You can certainly use your SQL tools.  But we all know that SQL can be... tiresome.</p> <p>AI provides a solution: Schema Automation.  You can use ChatGPT to create the SQL DDL like this:</p> <p>Create database definitions from ChatGPT</p> <p>Create a system with customers, orders, items and products.</p> <p>Include a notes field for orders.</p> <p>Enforce the Check Credit requirement (do not generate check constraints): 1. Customer.balance &lt;= credit_limit 2. Customer.balance = Sum(Order.amount_total where date_shipped is null) 3. Order.amount_total = Sum(Item.amount) 4. Item.amount = quantity * unit_price 5. Store the Item.unit_price as a copy from Product.unit_price</p> <p>Then, employ API Logic Server API and Logic Automation, and use Python and standard frameworks to finish the job.</p> <p>Here's a tutorial you can to explore this: click here,or see this article.</p> <p>\u00a0 For additional Use Cases, click here.</p> <p> </p>"},{"location":"Home/#key-features","title":"Key Features","text":"Feature Notes API Automation Unblock Agile Collaboration, Custom App Dev Logic Automation 40X More Concise than procedural code Application Integration Automation with APIs and Kafka Messages Rule-Base Row Level Security Authorization and Authentication Self-Serve JSON:API UI Developers and Partners don't require API Dev AI-Driven Automation Use ChatGPT to automate database creation Admin Web App Agile Collaboration, Prototyping, Testing, Back Office Data Entry Multiple Databases Application Integration Deployment Automation Automated Container Creation, Azure Deployment"},{"location":"Home/#video-agile-collaboration","title":"Video: Agile Collaboration","text":"<p>Click the image below for a video tutorial, showing complete project creation, execution, customization and debugging (instructions here).  Or, see it using AI: click here.</p> <p></p> <p> </p>"},{"location":"Home/#getting-started-install-tutorial","title":"Getting Started - Install, Tutorial","text":"<p>API Logic Server is designed to make it easy to get started:</p> <ul> <li> <p>Install and run Tutorial -  install, and explore the tutorial for the sample database.</p> </li> <li> <p>Installed Sample Databases - Here are some installed sample databases you can use with simplified abbreviations for <code>db_url</code>.</p> </li> <li> <p>Dockerized Test Databases -  Then, you might like to try out some of our dockerized test databases.</p> </li> <li> <p>Your Database - Finally, try your own database.</p> </li> </ul> <p> </p> <p>In addition to this app dev oriented tutorial, you can also explore:</p> <ul> <li> <p>Messaging: the Application Integration Tutorial illustrates using messaging, self-serve APIs and customized APIs, choreographed with rules and Python.</p> </li> <li> <p>Deployment: the Deployment Tutorial illustrates various ways to containerize and deploy your applications</p> </li> <li> <p>Using AI: the AI-Driven Automation Tutorial shows how you can use ChatGPT to create new databases from english descriptions, to bootstrap a very rapid create / collaborate / iterate Agile cycle.</p> </li> </ul> <p> </p>"},{"location":"Home/#release-notes","title":"Release Notes","text":"<p>To see Release Notes, click here.</p>"},{"location":"Home/#preview-version","title":"Preview Version","text":"Show me how  <p>This pre-release includes:</p> <ul> <li>devops directory has new subdirectory for using Docker w/ std apilogicserver container</li> <li>Manager support for local WebGenAI</li> </ul> <p>You can try it at (you may need to use <code>python3</code>):</p> <pre><code>python -m pip install --index-url https://test.pypi.org/simple/ --extra-index-url https://pypi.org/simple ApiLogicServer==14.03.12\n</code></pre> <p> </p>"},{"location":"Home/#works-with","title":"Works With","text":"<p>API Logic Server works with key elements of your existing infrastructure:</p> Works With Notes AI Use ChatGPT to create databases, and use API Logic Server to turn these into projects Other Systems APIs and Messages - with logic Databases Tested with MySQL, Sql/Server, Postgres, and Oracle Client Frameworks Creates instant APIs that factors out business logic, where it is automatically shared for User Interfaces, APIs, and Messages Your IDE Creates standard projects you can customize in your IDE, such as VSCode and PyCharm Messaging Produce and Consume Kafka Messages Deployment Scripts to create container images, and deploy them to the cloud Agile and Test Methodologies Use Behave to capture requirements, rapidly implement them with API Logic Server, collaborate with Business Users, and test with the Behave framework <p> </p>"},{"location":"Home/#contact-us","title":"Contact Us","text":"<p>We'd love to hear from you:</p> <ol> <li>Email: apilogicserver@gmail.com</li> <li>Slack: https://apilogicserver.slack.com</li> </ol> <p> </p>"},{"location":"Home/#detailed-product-information","title":"Detailed Product Information","text":"<p>For more product information, click here.</p>"},{"location":"IDE-Customize/","title":"Customize Using Your IDE","text":""},{"location":"IDE-Customize/#vibe","title":"Vibe","text":"<p>You can use your IDE as shown below - not only for code, but for Vibe.  With recent IDE updates, the coding assistants look for hints, now available in GenAI-Logic 15.00.41.  You can ask it what to do, create logic, create UIs, etc.  For more information, see this slide show: click here.</p> <p>You will find coding assistants can be helpful, playful, and even empathetic:</p> <p></p> <p></p>"},{"location":"IDE-Customize/#customize-rules-python","title":"Customize: Rules, Python","text":"<p>Customize API Logic Projects using:</p> <ul> <li> <p>Rules and Python, with standard Python packages, such as Flask and SQLAlchemy.</p> </li> <li> <p>In your IDE, using standard IDE features, such as code editors with code completion, source control, debuggers, Natural Language, etc.</p> </li> </ul> <p></p> <ol> <li> <p>You can find customization points by searching your project for <code>Your Code Goes Here</code>.</p> </li> <li> <p>You can find customization examples by creating the Tutorial, and searching for <code>#als</code>.</p> </li> </ol> <p> </p>"},{"location":"IDE-Customize/#discoverability-logic-services","title":"Discoverability - Logic, Services","text":"<p>In addition to altering the files noted above, you can use discovery.  This enables logic and services to be broken up into multiple files, which are auto-discovered.  </p> <p>These can help teams integrate their work, with reduced conflict.</p> <p></p> <p> </p>"},{"location":"IDE-Customize/#run","title":"Run","text":"<p>The <code>ApiLogicServer create</code> command also creates:</p> <ul> <li>Launch configurations to run your project, and run tests.</li> <li>Docker files to open your project, and dockerize your project into a container for DockerHub</li> </ul> <p></p> <p>For more information on opening projects and establishing their Python Execution environment, see Execute an API Logic Project.</p> <p> </p>"},{"location":"IDE-Customize/#debug","title":"Debug","text":"<p>Utilize IDE Debuggers, including for declarative rules, as described in the Tutorial:</p> <p></p> <p> </p>"},{"location":"IDE-Customize/#rebuild","title":"Rebuild","text":"<p>If you change your database / data model, you can rebuild the project, preserving customizations.  For more information, click here.</p> <p> </p>"},{"location":"IDE-Customize/#appendix-ide-notes","title":"Appendix - IDE Notes","text":""},{"location":"IDE-Customize/#virtual-environments","title":"Virtual Environments","text":"<p>Be sure you are clear on how to setup your project venv.</p>"},{"location":"IDE-Customize/#vscode-cli","title":"VSCode CLI","text":"<p>You can launch VSCode from the command line.  It's often pre-installed on Windows; for Mac, you must activate VSCode <code>code</code> CLI:</p> <ol> <li>Open the Command Palette (Cmd+Shift+P) and </li> <li>type <code>shell command</code></li> </ol>"},{"location":"IDE-Execute/","title":"Execute in your IDE","text":"<p>API Logic Projects are simply directories, without restrictions on their location.  You can open them directly in your IDE. (You can also execute them from a Terminal Window). </p> <p>This page describes how to open your project, establish your Python environment, and execute your project.</p>"},{"location":"IDE-Execute/#open-project-and-establish-python-environment","title":"Open Project and Establish Python Environment","text":"<p>IDE instructions depend on whether you are using a local install, or Docker.  Select your desired configuration below, and see how to run, customize and debug your ApiLogicProject.</p> VS Code Local -- Local InstallVS Code -- Docker InstallPyCharm <p>Follow these instructions:</p> <p>1. Open your project with VS Code</p> <p>You can open the IDE yourself, or from the command line:</p> <pre><code>cd ApiLogicServer\n\n# start VS Code either as an application, or via the command line\n#    .. macOS users may require: https://code.visualstudio.com/docs/setup/mac\n\ncode ApiLogicProject  # using command line to open VS Code on project\n</code></pre> <p>2. Remote Container - Decline</p> <p>Decline the option above to use the remote-container.   You can prevent this by deleting the <code>.devcontainer</code> folder.</p> <p>3. Create Virtual Environment</p> <p>You then create your virtual environment, activate it, and install the  ApiLogicServer runtime.  </p> <p>In VS Code: Terminal &gt; New Terminal Window, and...</p> <pre><code>python3 -m venv ./venv                       # windows: python -m venv venv\n# VS Code will recognize your `venv` and ask whether to establish it as your virtual environment.  Say yes.  \nsource venv/bin/activate                     # windows: venv\\Scripts\\activate\npython3 -m pip install -r requirements.txt   # the requirements.txt file was pre-created by ApiLogicServer\n</code></pre> <p>The install sometimes fails due on machines with an older version of <code>pip</code>.  If you see a message suggesting you upgrade  <code>pip</code> , do so.</p> <p>For more information, see Work with Environments, and Project Environment.</p> <p>4. Install Python Extension</p> <p>You may be prompted for this (recent versions of VSCode might auto-detect language support):</p> <p></p> <p>1. Load your docker project</p> <p>You've aleady created your project like this:</p> <pre><code>cd ~/Desktop                # directory of API Logic Server projects on local host\n\n# [Install and] Start the API Logic Server docker container\ndocker run -it --name api_logic_server --rm -p 5656:5656 -p 5002:5002 -v ${PWD}:/localhost apilogicserver/api_logic_server\n\n# (Now inside the container)\nApiLogicServer create   # Return to accept default project name, db\n\nexit  # exit container to localhost\n</code></pre> <p>Container-exit</p> <p>Observe you exit the Docker container.  We'll start VSCode locally below, where it will restart Docker as a Remote Container below.  Local operation means your project files are accessed locally (not via <code>/localhost</code>), which enables local file operations such as git.</p> <p> </p> <p>The project creation above has created a project on your local computer.  You can open it in VSCode like this:</p> Open VSCode on created API Logic Project<pre><code># start VS Code either as an application, or via the command line\n# macOS users may require: https://code.visualstudio.com/docs/setup/mac\ncode ApiLogicProject  # loads VS Code; accept container suggestions, and press F5 to run (described below)\n</code></pre> <p>2. Remote Container - Accept</p> <p>Created projects are pre-configured to support:</p> <ul> <li>launch configurations for running <code>ApiLogicServer</code> and tests</li> <li>Docker-based Python environments, per <code>.devcontainer</code></li> </ul> <p>So, when you open the created project, VS Code recognizes that Docker configuration, and provides an option to Reopen the project in a remote container.  Accept this option.</p> <p>If you already skipped this option, no worries.  Use View &gt; Command Palette &gt; Remote-Containers: Reopen in Container</p> <p></p> <p>Note: when you Execute your application (below), you may need to update your Docker container - see Working with Docker.</p> <p>1. Do not create the <code>venv</code> outside PyCharm</p> <p>2. Open the ApiLogic Project</p> <p>3. Create a new Virtual Environment using PyCharm defaults</p> <p>PyCharm will ask you to configure a Python Interpreter.  Do so as shown below.</p> <p></p> <p>4. <code>pip</code> install</p> <p>Some versions of Pycharm automatically load your dependencies, others do not.  But it's simple to load them using the terminal window:</p> <pre><code>source venv/bin/activate                    # windows: venv\\Scripts\\activate\npython -m pip install -r requirements.txt   # the requirements.txt file was pre-created by ApiLogicServer\n</code></pre> <p>The install sometimes fails due on machines with an older version of <code>pip</code>.  If you see a message suggesting you upgrade  <code>pip</code> , do so.</p> <p>5. Run the pre-configured <code>run</code> launch configuration</p> <p>Some versions of Pycharm may require that you update the Launch Configuration(s) to use your <code>venv</code>.</p> <p> </p>"},{"location":"IDE-Execute/#execute-prebuilt-launch-configurations","title":"Execute - prebuilt Launch Configurations","text":"<p>Once you have established your Python environment, you are ready to run.  The <code>ApiLogicServer create</code> command has built launch configurations, so you can start your server like this:</p>"},{"location":"IDE-Execute/#1-click-run-and-debug","title":"1. Click Run and Debug","text":""},{"location":"IDE-Execute/#2-select-launch-configuation","title":"2. Select Launch Configuation","text":"<p>Select the pre-built <code>ApiLogicServer</code> Launch Configuration (it should be the default).</p> <ul> <li>Use <code>Codespaces</code> if you are running in that environment)</li> </ul>"},{"location":"IDE-Execute/#3-click-green-run-button","title":"3. Click Green Run Button","text":"<p>Press the green run button to start the server.</p> <p>When you run, you may encounter the message below; if so:</p> <ol> <li>Click Extensions (as shown)</li> <li>Ensure Python support is installed and enabled</li> </ol> <p></p>"},{"location":"IDE-Execute/#4-start-the-browser","title":"4. Start the Browser","text":"<ul> <li>If you are running Docker / VS Code, VS Code will suggest opening a Browser, or previewing it in the Editor (i.e., in VSCode).</li> <li>Otherwise open a browser at http://localhost:5656</li> </ul>"},{"location":"IDE-Execute/#5-proceed-to-the-tutorial","title":"5. Proceed to the Tutorial","text":"<p>The Tutorial will walk you through the sample project.</p> <p> </p> <p>Notes:</p> <ul> <li>Be aware that we have seen some issue where the simple browser fails to start; just use your normal browser  </li> <li>We have also seen that some systems are slow to load caches on first execution; browser refresh can often be helpful</li> <li>You may get a message: \"The Python path in your debug configuration is invalid.\"  Open View &gt; Command Pallet, type \u201cPython Select Interpreter\u201d and Select your <code>venv</code>.</li> </ul> <p> </p>"},{"location":"IDE-Execute/#other-launch-configurations","title":"Other Launch Configurations","text":"<p>The <code>ApiLogicServer create</code> command also creates launch configurations for executing tests, and running the Behave Logic Report. </p>"},{"location":"IDE-Fixup-Attrs/","title":"Fixup - missing attributes","text":"<p> TL;DR - Fixup Missing Attributes</p> <p>When adding rules, such as using suggestions, you may introduce new attributes. If these are missing, you will see exceptions when you start your project.</p> <p>The <code>genai-utils</code> fixes such project issues by updating the Data Model and Test Data:</p> <ol> <li>Collects the latest model, rules, and test data from the project. </li> <li>Calls ChatGPT (or similar) to resolve missing columns or data in the project.</li> <li>Saves the fixup request/response under a <code>docs/fixup</code> folder.</li> <li>You then use this to create a new project</li> </ol>"},{"location":"IDE-Fixup-Attrs/#using-fixup","title":"Using Fixup","text":"<p>Fixes project issues by updating the Data Model and Test Data. When adding rules, such as using suggestions, you may introduce new attributes. If these are missing, you will see exceptions when you start your project.</p> <p>The <code>genai-utils --fixup</code> fixes such project issues by updating the Data Model and Test Data:</p> <ol> <li>Collects the latest model, rules, and test data from the project. </li> <li>Calls ChatGPT (or similar) to resolve missing columns or data in the project.</li> <li>Saves the fixup request/response under a 'fixup' folder.</li> <li>You then use this to create a new project</li> </ol> <p>This procedure is available in the Manager README (see Explore Creating Projects &gt; Fixup - update data model with new attributes from rules).</p> <p> </p>"},{"location":"IDE-Fixup-Attrs/#setup","title":"Setup","text":"<p>After starting the Manager: </p> 0. Create Project Requiring Fixup<pre><code># 0. Create a project requiring fixup\nals genai --using=genai_demo.prompt --repaired-response=system/genai/examples/genai_demo/genai_demo_fixup_required.json --project-name=genai_demo_fixup_required\n</code></pre> <p>If you run this project, you will observe that it fails with: <pre><code>Logic Bank Activation Error -- see https://apilogicserver.github.io/Docs/WebGenAI-CLI/#recovery-options\nInvalid Rules:  [AttributeError(\"type object 'Customer' has no attribute 'balance'\")]\nMissing Attrs (try als genai-utils --fixup): ['Customer.balance: constraint']\n</code></pre> </p>"},{"location":"IDE-Fixup-Attrs/#fixup","title":"Fixup","text":"<p>To Fix it: 1. Run FixUp to add missing attributes to the fixup response data model<pre><code># 1. Run FixUp to add missing attributes to the data model\ncd genai_demo_fixup_required\nals genai-utils --fixup\n</code></pre></p> <p>Finally, rebuild the project: 2. Rebuild the project from the fixup response data model<pre><code># 2. Rebuild the project from the fixup response data model\ncd ../\nals genai --using=genai_demo.prompt --repaired-response=genai_demo_fixup_required/docs/fixup/response_fixup.json\n</code></pre></p> <p>Fixup does not update your <code>ui/admin/admin.yaml</code>; you can update it manually.</p> <p> </p>"},{"location":"IDE-Import-WebGenAI/","title":"Import / Merge WebGenai","text":"<p> TL;DR - Import WebGenAI Project</p> <p>You can import WebGenAI projects, merging their data models and rules into a dev project.</p> <p><code>als genai-utils --import-genai --using=&lt;WebGenAI-Project&gt;</code></p> <p>Through experience, you will discover that the IDE maintains full logic automation, albeit using IDE completion instead of Natural Language.  That raises the question: how do I balance work in WebGenAI and the IDE?</p> <p>You will find WebGenAI remains useful, particularly for updating the data model (e.g., as required for logic).  The system provides services described here to sync WebGenAI changes with IDE changes.</p> <p>If you elect to focus on IDE development, analogous services are provided with Rebuild from Model / Database, and Alembic support.</p> <p> </p>"},{"location":"IDE-Import-WebGenAI/#coordinating-parallel-dev-streams-multi-team-development","title":"Coordinating Parallel Dev Streams (Multi-Team Development)","text":"<p>A classic challenge: enable ongoing parallel development with both the LOB and Dev teams.  It's enabled by declarative technology, where the integration is done with software, not manual effort.</p> <p>It works like this:</p> <ol> <li> <p>The project begins with the Kickstart: several iterations to get solid requirements.</p> <ul> <li>Uses Natural Language and Declarative Rules</li> </ul> </li> <li> <p>The project is exported: the Dev Team begin work on the Custom UI, Enterprise Integration, etc</p> <ul> <li>This is not the end of declarative: logic is either or both of Natural Language, and Python DSL</li> </ul> </li> <li> <p>As depicted in the divergent arcs: there are now 2 versions of the project.  Both can, in parallel, introduce new rules and attributes.  This is not just \"Team Development\", it is TeamS Development.</p> <ul> <li>LOB Parallel: (WG_Team): new rules &amp; attributes<ul> <li>Observe: WG is not a day-1-only pilot...</li> <li>They continue to use the Natural Language Web-Based interface (WebGenai)</li> </ul> </li> <li>Dev_Team: their own new rules &amp; attributes, using either genai Natural Language and/or alembic...<ul> <li>In addition, the server team also uses Python (and) and libs as required, e.g. for enterprise integration. <ul> <li>They do this in their favorite IDE, with tools such as GitHub etc.</li> <li>Observe the logic remains at a high lev</li> </ul> </li> <li>The UI team can use familiar tools for Custom UIs.  These <ul> <li>leverage the API (ready day 1, so they are not blocked on API Dev), and</li> <li>are dramatically simplified by automated backend rule-based logic</li> </ul> </li> </ul> </li> </ul> </li> <li> <p>Export 2: illustrates that the LOB WG_Team can export their project.  The dev team can import it using the API Logic Server CLI.</p> <ul> <li>This automatically integrates rules and attributes from both projects, updating the dev project with a new database and models.<ul> <li>This is virtually impossible with procedural code, because developers must manually assess the execution dependencies and order the logic properly.  It time-consuming, complex, and error-prone - just like post deployment maintenance.</li> <li>The integration is automatic and \"safe\" because logic is expressed in a declarative rules/models for which ordering is automatic. </li> </ul> </li> <li>It also rebuilds the test data, per your rules (e.g. sum/count values)</li> <li>The process supports multiple exports.</li> </ul> </li> </ol> <p></p> <p></p> <p></p>"},{"location":"IDE-Import-WebGenAI/#exploring-import","title":"Exploring Import","text":""},{"location":"IDE-Import-WebGenAI/#setup-manager-pre-installs-import-sample","title":"Setup: Manager pre-installs Import Sample","text":"<p>When you create the manager (strongly recommended), the system installs 3 sample projects you can use to explore import.</p> <ol> <li> <p>Base Project is GenAI_no_logic.  No rule-based attributes.  See <code>system/genai/examples/genai_demo/wg_dev_merge/base_genai_demo_no_logic</code>.  It's not really used, just provided as a reference.</p> </li> <li> <p>Dev Project was created with export-1, and has added rules for <code>carbon_neutral</code>.  It is ready for export-2.  See <code>system/genai/examples/genai_demo/wg_dev_merge/dev_demo_no_logic_fixed</code></p> </li> <li> <p>WG project has continued from export-1 to add our standard customer.balance rules.  It is ready for export-2.  See <code>system/genai/examples/genai_demo/wg_dev_merge/wg_demo_no_logic_fixed</code>.</p> <ul> <li>It has an <code>docs/export/export.json</code>, which describes the data model and rules from the WG project.  This is used for import.</li> </ul> </li> </ol> <p>The naming convention is that these started with no rules, had rules added, and were \"fixed\" by Genai-Logic to update the data model.</p> <p></p>"},{"location":"IDE-Import-WebGenAI/#usage","title":"Usage","text":"<p>Imports are performed from with the dev project, using the <code>import-genai</code> CLI command:</p> <p><pre><code>cd system/genai/examples/genai_demo/wg_dev_merge/dev_demo_no_logic_fixed\nals genai-utils --import-genai --using=../wg_demo_no_logic_fixed\n</code></pre> Observe: 1. The data model (<code>system/genai/examples/genai_demo/wg_dev_merge/dev_demo_no_logic_fixed/database</code>) contains <code>Customer.balance</code> and <code>Product.carbon_neutral</code> 2. The test data has been updated to include these attributes, with proper values</p> <p>In this example, <code>als genai-utils --import-genai ...</code> will leave things in this state:</p> <p></p> <p>The <code>import-genai</code> command creates the <code>docs/import</code> directory and the following files, as shown above:</p> <ul> <li><code>request.json</code> is sent to ChatGPT.  It contains both models, and a command to merge them</li> <li><code>response.json</code> is the merged model.  It should reflect the attributes from both sides, as shown</li> <li>The response is translated to <code>system/genai/examples/genai_demo/wg_dev_merge/dev_demo_no_logic_fixed/docs/import/create_db_models.py</code></li> <li>The system creates <code>docs/import/create_db_models.py/create_db_models.sqlite</code> by executing the file above.</li> <li>The system then uses this to update the dev project:<ul> <li>update the dev <code>database/db.sqlite</code> and </li> <li>Runs <code>--rebuild-from-database</code>.  This updates the model, the api, etc from the new database.</li> <li>It's good practice to verify these.  Make sure all the attributes from both sources are reflected in the updated database and models noted above.</li> </ul> </li> </ul> <p></p>"},{"location":"IDE-Import-WebGenAI/#restart-option-for-failure-recovery","title":"Restart option for failure recovery","text":"<p>It may fail, requiring either a re-run or an <code>import-resume</code>:</p> <ul> <li> <p>Re-run is indicated if the data model is missing attributes, incorrect or imcomplete.</p> <ol> <li>make sure to get initial <code>system/genai/examples/genai_demo/wg_dev_merge/dev_demo_no_logic_fixed/database/models.py</code> (eg, update from models_for_resume.py)</li> <li>delete or rename the <code>docs/import</code> directory.</li> </ol> </li> <li> <p><code>import-resume</code> can be used if you can repair the file below, e.g., a minor syntax error.</p> <ol> <li>fix <code>system/genai/examples/genai_demo/wg_dev_merge/dev_demo_no_logic_fixed/docs/import/create_db_models.py</code><ul> <li>Note: you can run this standalone with your IDE to verify it.  It should create <code>create_db_models.sqlite</code> in your <code>docs/import</code> directory.</li> </ul> </li> <li>make sure to get initial system/genai/examples/genai_demo/wg_dev_merge/dev_demo_no_logic_fixed/database/models.py (eg, update from models_for_resume.py)</li> </ol> </li> </ul> <pre><code>cd system/genai/examples/genai_demo/wg_dev_merge/dev_demo_no_logic_fixed\nals genai-utils --import-genai --using=../wg_demo_no_logic_fixed --import-resume\n</code></pre> <p></p>"},{"location":"IDE-Import-WebGenAI/#appendices","title":"Appendices","text":""},{"location":"IDE-Import-WebGenAI/#ground-rules","title":"Ground Rules","text":"<ul> <li>No Dev_Team -&gt; WG_Team integration (just deploy Dev_Team version, and use)<ul> <li>Dev team code cannot be integrated into WG - dependencies, libs, integration, ...</li> </ul> </li> <li>WG_Team - serial dev (as now)</li> <li>WG_Team logic files are separate from Dev_Team (eg, using logic/discovery)</li> <li>sqlite only, for now (presume upgrade to 'some other db' is doable later)<ul> <li>Tyler, what were the issues you mentioned in sqlite that forced you to use PG?</li> </ul> </li> <li>All Dev_Team and logic generations are finished before merge-G</li> </ul>"},{"location":"IDE-Rebuild-Test-Data/","title":"Rebuild Test Data","text":"<p> TL;DR - Rebuild Test Data</p> <p>Proper rule operation requires existing data be correct - see Data Model Design</p> <p>ChatGPT sometimes fails to properly compute the test data.  You can rebuild your test data to match the derivation rules by using <code>genai-utils --rebuild-test-data</code>.</p>"},{"location":"IDE-Rebuild-Test-Data/#overview","title":"Overview","text":"<p>Basic operation:</p> <ol> <li>Builds <code>database/test_data/test_data.py</code> from <code>docs/response.json</code></li> <li>Runs it to create <code>database/test_data/db.sqlite</code></li> <li>Copies <code>database/test_data/db.sqlite</code> to <code>database/db.sqlite</code></li> </ol> <p> </p>"},{"location":"IDE-Rebuild-Test-Data/#example","title":"Example","text":"<p>Fixes project issues by rebuilding the database to conform to the derivation rules:</p> <ol> <li> <p>Create genai_demo:  <pre><code>als genai --using=system/genai/examples/genai_demo/genai_demo.prompt --project-name=genai_demo\n</code></pre></p> </li> <li> <p>Rebuild: <pre><code>cd genai_demo\nals genai-utils --rebuild-test-data\n</code></pre></p> </li> </ol> <p> </p>"},{"location":"Install-Eval/","title":"Express Eval","text":"<p> TL;DR - Using Logic: Understand functions vs. lambda, logic_row</p> <p>The fastest way to explore API Logic Server - with no install - is to run the demo at the Home Page, and then proceed to open the project in GitHub with Codespaces.  </p> <p>The readme of the generated app explains how to launch Codespaces.</p>"},{"location":"Install-Express/","title":"Express Install","text":"<p>In most cases, Python and Python Projects are simple and fast to install, as described below.  If you encounter issues, open the Detailed Install.</p> <p>Follow these instructions to:</p> <ol> <li>Install API Logic Server</li> <li>Create the sample Tutorial API Logic Server Project</li> <li>Open it in your IDE</li> <li>Prepare the projects' Python environment</li> </ol>"},{"location":"Install-Express/#create-an-install-directory","title":"Create an install directory","text":"<p>You can create this anywhere, such as your home folder or Desktop.</p> Create an install directory<pre><code>mkdir ApiLogicServer      # a directory of projects on your local machine\n</code></pre>"},{"location":"Install-Express/#use-local-install-or-docker","title":"Use Local Install, or Docker","text":"<p>You can install API Logic Server locally using <code>pip</code>, or use Docker.  If you already have docker, it can eliminate many of the sometimes-tricky Python install issues.</p> <p>Open the appropriate section below.</p> Local InstallDocker <p>Verify Pre-reqs: Python 3.10+</p> <p>Ensure you have these pre-reqs:</p> Verify 3.10 - 3.13<pre><code>python --version  # on macs, you may need to use Python3\n</code></pre> <p>Note: Python 3.13 is supported as of release 15.0.52.</p> <p>If you need to install Python (it can be tricky), see these notes.</p> <p>Install requires a c compiler.  E.g., MacOS users will require Command Line Tools: <code>&gt; xcode-select --install</code></p> <p>Releases before 15.0.60 may require: <code>brew install librdkafka</code>.</p> <p>Windows VSCode users may require admin privileges for PowerShell: <code>Set-ExecutionPolicy -Scope CurrentUser -ExecutionPolicy RemoteSigned</code></p> <p> </p> <p>Install API Logic Server in a Virtual Environment</p> <p>Then, install API Logic Server in the usual manner (typically you create/cd to a new directory, e.g., <code>ApiLogicServer</code>):</p> Install API Logic Server in a Virtual Environment<pre><code>python -m venv venv                  # may require python3 -m venv venv\nsource venv/bin/activate             # windows: venv\\Scripts\\activate\npython -m pip install ApiLogicServer\n</code></pre> <p>Notes:</p> <ol> <li>Windows users will need to run the terminal in Admin mode, with scripts enabled</li> <li>For <code>genai</code> functions, you will need an OpenAI Key</li> <li>If you are using SqlServer, you also need to install <code>pyodbc</code></li> <li>If you are using VSCode, we strongly recommend you create the VSCode CLI.</li> </ol> <p> </p> <p>Start the ApiLogicServer manager</p> Start Manager<pre><code>ApiLogicServer start\n</code></pre> <p>This will install the samples and open in your IDE; open the readme and follow the directions to create projects.</p> <p> </p> <p>Create the Basic Demo Project</p> <p>This project provides a <code>Readme</code> to walk you through key aspects of API Logic Server.  For more information, click here.</p> <p>The <code>Readme</code> recommends that you start by creating the basic demo app:</p> Create Basic Demo<pre><code>ApiLogicServer create --project_name=basic_demo --db_url=basic_demo\n</code></pre> <p> </p> <p>Open the Project in VSCode</p> <p>The project should open automatically in your IDE with a pre-installed virtual environment (for more information, click here)</p> <p>Start Docker Start (might install) API Logic Server Docker<pre><code>  &gt; docker run -it --name api_logic_server --rm -p 5656:5656 -p 5002:5002 -v ${PWD}:/localhost apilogicserver/api_logic_server\n  $ # you are now active in the API Logic Server docker container to create projects\n</code></pre></p> <p>Mac ARM: if you have an M1 or M2 Mac, change the last parameter to <code>apilogicserver/api_logic_server_arm</code></p> <p>Windows: use Powershell (<code>PWD</code> is not supported in Command Line)</p> <p> </p> <p>Create the Tutorial Project</p> <p>You are now running a terminal window in the Docker machine.  Create the Tutorial project:   Create Tutorial<pre><code>$ cd /localhost/             # a directory on your local file system in which...\n$ ApiLogicServer tutorial    # tutorial directory will be created\n$ exit                       # return to local host \n</code></pre></p> <p> </p> <p>Or, Create a Typical Project</p> <p>Typical project creation identifies the database and target project name:   Create Typical project<pre><code>$ cd /localhost/             # a directory on your local file system for project creation\n$ ApiLogicServer create-and-run --project_name=ApiLogicProject --db_url=\n$ exit                       # return to local host \n</code></pre></p> <p> </p> <p>Open the created Project in VSCode</p> <p>Once the project is created, open it in VSCode on your local host:</p> <ol> <li>Open Folder <code>ApiLogicServer/tutorial</code> in VSCode<ul> <li> <p>Accept option to \"Reopen in Container\"</p> <p>If you already skipped this option, no worries.  Use View &gt; Command Palette &gt; Remote-Containers: Reopen in Container</p> </li> </ul> </li> </ol> <p> </p>"},{"location":"Install-Express/#next-steps-tutorial","title":"Next Steps - Tutorial","text":"<p>You're all set - the Sample is created, installed and ready to run.  Open the readme for a walk-through.</p>"},{"location":"Install-oracle-thick/","title":"Install Oracle Thick","text":"<p>Oracle support depends upon <code>pip install oracledb</code>.  You do not need to do this, since it's already installed with API Logic Server.</p> <p>For more information on oracle-db, click here</p> <p>This driver operates in thin mode and thick mode.  In some tightly regulated corporate environments, thin mode fails to connect with network errors, for example:</p> <pre><code>OSError: [WinError 10038] An operation was attempted on something that is not a socket\n</code></pre> <p>or,</p> <pre><code>Service \"xxx\" is not registered with the listener \n</code></pre> <p>In such cases, you need to use thick mode.  This page shows how.</p> <p> </p>"},{"location":"Install-oracle-thick/#install-thick-client","title":"Install thick client","text":"<p>Install Oracle thick support as described here.  Each os-specific section contains information on installing thick mode, like this for mac.</p> <p>Make a note of the install location.  For example, this might install to the following on a mac: <code>/Users/val/Downloads/instantclient_19_16</code>.</p> <p> </p>"},{"location":"Install-oracle-thick/#activate-thick-client-for-api-logic-server","title":"Activate thick client for API Logic Server","text":"<p>When required, thick client must be activated for both creating and running applications.  It operates by setting the environment variable to the thick client install location noted above.  </p> <pre><code>APILOGICSERVER_ORACLE_THICK=/Users/val/Downloads/instantclient_19_16\n</code></pre> <p>Note: setting environment variables is os-dependent.  Windows, for example, requires you preceed the above with <code>set</code>.</p> <p>To create projects, set the environment variable before you run <code>ApiLogicServer create</code>.</p> <p>You can do the same for running projects.  Or, you can set this in your IDE as shown below.</p> <p></p>"},{"location":"Install-psycopg2/","title":"Install psycopg2: Postgres","text":""},{"location":"Install-psycopg2/#update-psycopg2-pre-installed-as-of-060200","title":"Update - <code>psycopg2</code> pre-installed as of 06.02.00","text":"<p><code>psycopg2</code> was updated at the end of September 2020.  So, as of release 6.2, this is restored into the build of ApiLogicServer.</p> <p> </p>"},{"location":"Install-psycopg2/#postgres-install-psycopg2-release-50333-through-61","title":"Postgres - install <code>psycopg2</code> -- Release 5.03.33 through 6.1","text":"<p>This is included in Docker, but not for local installs.  To install <code>psycopg2</code> (either global to your machine, or within a <code>venv</code>):</p> <pre><code>pip install psycopg2-binary==2.9.3\n</code></pre> <p>Please see the examples on the testing for important considerations in specifying SQLAlchemy URIs.</p>"},{"location":"Install-pyodbc/","title":"Install pyodbc: SqlServer","text":""},{"location":"Install-pyodbc/#sqlserver-install-pyodbc","title":"SqlServer - install <code>pyodbc</code>","text":"<p>This is included in Docker, but not for local installs.  To install <code>pyodbc</code> (either global to your machine, or within a <code>venv</code>):</p> <ul> <li>Linux</li> </ul> <pre><code>apt install unixodbc-dev   # Linux only\npip install pyodbc\n</code></pre> <ul> <li>Mac - using brew:</li> </ul> <p>Install the Microsoft ODBC driver, then:</p> <pre><code># may be required - brew install unixodbc      # Mac only\npip install pyodbc==5.2.0\n</code></pre>"},{"location":"Install-pyodbc/#unix-sql-server-downgrade-to-17-in-docker","title":"Unix SQL Server downgrade to 17 in Docker","text":"<p>Running a SQL Server docker image connecting to a client database may require downgrading to version 17 of the unixodbc driver.  You can test the installed versions by basing into docker and running this command. <pre><code>docker exec -it {container_id} bash\nodbcinst -d -q\n</code></pre></p>"},{"location":"Install-pyodbc/#install-build-and-odbc-unix-driver-dependencies-version-17","title":"Install build and ODBC unix driver dependencies version 17","text":"<p><pre><code># add this to you docker file after the copy command\n# devops/docker-image/build_image.dockerfile\nRUN apt-get update &amp;&amp; \\\n    apt-get install -y curl gnupg apt-transport-https &amp;&amp; \\\n    curl https://packages.microsoft.com/keys/microsoft.asc | apt-key add - &amp;&amp; \\\n    curl https://packages.microsoft.com/config/debian/11/prod.list &gt; /etc/apt/sources.list.d/mssql-release.list &amp;&amp; \\\n    apt-get update &amp;&amp; \\\n    ACCEPT_EULA=Y apt-get install -y msodbcsql17 unixodbc-dev gcc g++ python3-dev &amp;&amp; \\\n    apt-get clean &amp;&amp; \\\n    rm -rf /var/lib/apt/lists/*\n\n\nRUN pip install --upgrade pip &amp;&amp; \\\n    pip install pyodbc==5.2.0\n</code></pre> * Windows - not resolved - this approach is not tested</p> <p>Please see the examples on the testing for important considerations in specifying SQLAlchemy URIs.</p> <p> </p>"},{"location":"Install-pyodbc/#limitations-sqlserver-sort-fields","title":"Limitations - SqlServer Sort fields","text":"<p>Note Sql/Server may not sort on certain fields such as images or long text.  This shows up, for example, in the Docker SqlServer sample database for <code>Category</code>.  So, when testing these in Swagger, modify your Sort fields accordingly.</p> <p> </p>"},{"location":"Install/","title":"Install API Logic Server","text":""},{"location":"Install/#install-in-docker-or-locally","title":"Install in Docker or Locally","text":"<p>You can install API Logic Server locally using <code>pip</code>, using Docker, or pythonanywhere (a cloud service).</p> <p>You can also develop with Docker devcontainers.</p> <p>Create an install directory</p> <p>You can create this anywhere, such as your home folder or Desktop.</p> <p>Create an install directory<pre><code>mkdir ApiLogicServer      # a directory of projects on your local machine\n</code></pre> Then, open the appropriate section below, and see the Installation Notes, below.</p> Local InstallWith DockerPythonAnyWhere <p>API Logic Server requires Python 3.11 or higher.</p> <p>The first section below verifies whether your Python environment is current.  </p> <p>The following section explains how to install a current Python environment.</p> <p>Verify Pre-reqs: Python 3.11+</p> <p>Ensure you have these pre-reqs:</p> Verify 3.11 - 3.12<pre><code>python --version\n\npython -m venv -h  # also verify these work\npython -m pip -h\n</code></pre> <p>Note: on Macs, you may need to use <code>python3</code> instead of <code>python</code>.</p> <p>If you need to install Python (it can be tricky), see these notes.</p> <p> </p> <p>Install API Logic Server in a virtual environment</p> <p>Then, install API Logic Server in the usual manner:</p> Install API Logic Server in a Virtual Environment<pre><code>cd ApiLogicServer                    # directory of your choice\npython -m venv venv                  # may require python3 -m venv venv\nsource venv/bin/activate             # windows venv\\Scripts\\activate\npython -m pip install ApiLogicServer\n</code></pre> <p>If you are using SqlServer, you also need to install <code>pyodbc</code>.</p> Start (might install) API Logic Server Docker<pre><code>cd ApiLogicServer      # a directory of projects on local host\n\n# Start (install if required) the API Logic Server docker container...\n\ndocker run -it --name api_logic_server --rm -p 5656:5656 -p 5002:5002 -v ${PWD}:/localhost apilogicserver/api_logic_server\n</code></pre> <p>This will start a command line in the Docker container at your current directory. You are now able to issue commands like <code>ApiLogicServer create</code> as described in the home page.  These will create API Logic Projects as directories under your current directory.</p> <p>Windows: use Powershell (<code>PWD</code> is not supported in Command Line)</p> <p>API Logic Projects are not restricted to be under the same directory.</p> <p>The <code>api_logic_server</code> image supports startup arguments so you can control the <code>api_logic_server</code> container, by running a startup script or by supplying environment variables.  You might, for example, have automated test procedures that load projects from <code>GitHub</code> and run tests.</p> <p>For more information, see Working With Docker.</p> <p>Already installed?  Upgrade to the latest: <code>docker pull apilogicserver/api_logic_server</code> (you may need to rebuild your container).</p> <p>You can create an ApiLogicServer on PythonAnywhere for any cloud-accessible database. \u00a0Open a bash console, and:</p> <pre><code>python3 -m venv venv  # ensures that Python3 is used  \nsource venv/bin/activate\n\npython3 -m pip install ApiLogicServer\n\nApiLogicServer create --host=ApiLogicServer.pythonanywhere.com --port=   # ApiLogicServer == your account  \n</code></pre> <p>1. Create Application</p> <p>Here is an example using a pythonanywhere-hosted MySQL database (note the escape character for the $ in the database name): <pre><code>ApiLogicServer create --project_name=Chinook \\\n--host=ApiLogicServer.pythonanywhere.com --port= \\\n--db_url=mysql+pymysql://ApiLogicServer:***@ApiLogicServer.mysql.pythonanywhere-services.com/ApiLogicServer\\$Chinook\n</code></pre></p> <p>2. Create and configure a web app</p> <p></p> <p>3. Update the wsgi And copy the contents of <code>/home/ApiLogicServer/api_logic_server/python_anywhere_wsgi.py</code> over the wsgi file created by pythonanywhere.</p> <p>4. Update the Admin App <code>api_root</code> The first few lines of the Admin.yaml and Admin Config page should be (update the last line: <pre><code>about:\n  date: December 26, 2021 09:00:00\n  recent_changes: altered tab captions\n  version: 3.50.51\napi_root: https://apilogicserver.pythonanywhere.com/api\n</code></pre></p> <p>5. Verify <code>admin.yaml</code> Verify that the <code>ui/admin.yaml</code> ends with something like this:</p> <p><pre><code>settings:\n  HomeJS: https://apilogicserver.pythonanywhere.com/admin-app/home.js\n  max_list_columns: 8\n</code></pre> 6. Configure the host and port</p> <p>In <code>api_logic_server_run.py</code>, set these as follows:</p> <p><pre><code>host = \"apilogicserver.pythonanywhere.com\"  # was \"localhost\"\nport = \"\"                                   # was \"5656\"\n</code></pre> 7. Restart the Web App You start ApiLogicServer from the web console, not from the command line</p> <p>8. Run the application</p> <p>You can open the Admin App in your browser http://apilogicserver.pythonanywhere.com/admin-app/index.html.</p> <p>You can use <code>curl</code> from pythonanywhere consoles: <pre><code>curl -X GET \"http://ApiLogicServer.pythonanywhere.com/api/employees/?include=office%2Cparent%2CEmployeeList%2CCustomerList&amp;fields%5BEmployee%5D=employeeNumber%2ClastName%2CfirstName%2Cextension%2Cemail%2CofficeCode%2CreportsTo%2CjobTitle&amp;page%5Boffset%5D=0&amp;page%5Blimit%5D=10&amp;sort=employeeNumber%2ClastName%2CfirstName%2Cextension%2Cemail%2CofficeCode%2CreportsTo%2CjobTitle%2Cid\" -H  \"accept: application/vnd.api+json\" -H  \"Content-Type: application/vnd.api+json\"  \n</code></pre></p> <p> </p>"},{"location":"Install/#installation-notes","title":"Installation Notes","text":""},{"location":"Install/#alert-project-fails-to-start","title":"Alert - Project fails to start","text":"<p>Recent updates to included libs have broken previous versions of API Logic Server.  This is fixed in a new version (5.00.06), and is strongly recommended.  You can also repair broken installations as described in Troubleshooting.</p>"},{"location":"Install/#heads-up-certificate-issues","title":"Heads up - Certificate Issues","text":"<p>We sometimes see Python / Flask AppBuilder Certificate issues - see Troubleshooting.</p>"},{"location":"Install/#default-python-version","title":"Default Python version","text":"<p>In some cases, your computer may have multiple Python versions, such as <code>python3</code>.  <code>ApiLogicServer run</code> relies on the default Python being 3.8 or higher.  You can resolve this by: * making <code>python3</code> the default Python, or * using <code>ApiLogicServer create</code>, and running <code>python3 api_logic_server_run.py</code></p> <p> </p>"},{"location":"Install/#next-steps-create-a-project","title":"Next Steps - Create a Project","text":"<p>Create, start and debug the sample project - see the Creating a Project.</p>"},{"location":"Integration-Kafka/","title":"Kafka Messaging","text":"<p> TL;DR - Kafka Integration: Async Messaging</p> <p>APIs are useful to application integration, but do not deal with the reality that the receiving system might be down.</p> <p>Message Brokers like Kafka address this with guaranteed async delivery of messages.  The Broker stores the message, delivering it (possibly later) when the the receiver is up.</p> <p>Message Brokers also support multi-cast: you publish a message to a \"topic\", and other systems subscribe.  This is often casually described as \"pub/sub\".</p> <p> </p>"},{"location":"Integration-Kafka/#procedure","title":"Procedure","text":"<p>To enable Kafka:</p> <ol> <li> <p>In <code>conf/config.py</code>, find and comment out: <code>KAFKA_PRODUCER = None  # comment out to enable Kafka</code></p> </li> <li> <p>Update your <code>etc/conf</code> to include the lines shown below (e.g., <code>sudo nano /etc/hosts</code>).</p> </li> </ol> <p><pre><code>##\n# Host Database\n#\n# localhost is used to configure the loopback interface\n# when the system is booting.  Do not change this entry.\n##\n\n# for kafka\n127.0.0.1       broker1\n::1             localhost\n255.255.255.255 broadcasthost\n::1             localhost\n\n127.0.0.1       localhost\n# Added by Docker Desktop\n# To allow the same kube context to work on the host and the container:\n127.0.0.1 kubernetes.docker.internal\n# End of section\n</code></pre> 3. If you already created the container, you can</p> <pre><code>1. Start it in the Docker Desktop, and\n2. **Skip the next 2 steps;** otherwise...\n</code></pre> <ol> <li> <p>Start Kafka: in a terminal window: <code>docker compose -f integration/kafka/dockercompose_start_kafka.yml up</code></p> </li> <li> <p>Create topic: in Docker: <code>kafka-topics.sh --create --bootstrap-server localhost:9092 --replication-factor 1 --partitions 3  --topic order_shipping</code></p> </li> </ol> <p>Here some useful Kafka commands:</p> <pre><code># use Docker Desktop &gt; exec, or docker exec -it broker1 bash \n# in docker terminal: set prompt, delete, create, monnitor topic, list all topics\n# to clear topic, delete and create\n\nPS1=\"kafka &gt; \"  # set prompt\n\nkafka-topics.sh --bootstrap-server localhost:9092 --topic order_shipping --delete\n\nkafka-topics.sh --create --bootstrap-server localhost:9092 --replication-factor 1 --partitions 3  --topic order_shipping\n\nkafka-console-consumer.sh --bootstrap-server localhost:9092 --topic order_shipping --from-beginning\n\nkafka-topics.sh --bootstrap-server localhost:9092 --list\n</code></pre>"},{"location":"Integration-MCP/","title":"MCP Integration","text":"<p> TL;DR - MCP: Enable Bus Users to use NL to create multi-step execution flows</p> <p>Developers can use MCP to build MCP Client Executors.  These enable Business Users to use Natural Language to create multi-step execution flows across existing business-rule-enforced APIs.  For example, a Business User might request: </p> <p>Find the overdue orders, and send an email offering a discount.  </p> <p>This is a new request, composed from existing services (find orders, send email).</p> <p>MCP Client Executors use LLMs for Natural Language translation over a wide set of underlying MCP Server Executors (aka tools). MCP enables LLMs to understand these underlying tools - their schema (e.g., Customer, Product), and how they are called (e.g, JSON:API).  </p> <p>MCP Client Executors operate as shown below:</p> <ol> <li>MCP Client Executors first discover servers (tools) - their schema, instructions, etc.</li> <li>MCP Client Executors then call LLMs to translate NL queries into multi-step execution flows called Tool Context Blocks (basically a list of api calls expressed in json). </li> <li> <p>The MCP Client Executors then process the Tool Context Block steps, making calls on the  MCP Server Executors (tools).</p> <ul> <li>MCP Server Executors are commonly provided via logic-enabled APIs.  (Note the logic is critical in maintaining integrity and security.)</li> </ul> </li> </ol> <p>In some cases, you may have a database, but neither the APIs nor the logic.  GenAI-Logic can mcp-ify existing databases by:</p> <ul> <li>Creating JSON:APIs for existing databases with a single CLI command.</li> <li>Creating a MCP Client Executor User Interface, for Business Users to make MCP requests.</li> <li>Enabling you to declare business logic, enforced by the APIs during MCP execution flows.</li> </ul> <p> </p>"},{"location":"Integration-MCP/#architecture","title":"Architecture","text":"<ol> <li> <p>MCP Client Executor Startup calls <code>.well-known</code> endpoint to load training and schema meta data for each configured server</p> </li> <li> <p>MCP Client Executor sends Bus User NL query + training + schema to the external LLM (here we are using ChatGPT - requires API Key).  LLM returns an MCP Tool Context JSON block.</p> <ul> <li> <p>An MCP Client Executor might be similar in concept to installed/Web ChatGPT (etc), but those cannot be used to access MCPs since they cannot issue http calls.  This is a custom client app (or, perhaps an IDE tool)</p> </li> <li> <p>To explore <code>integration/mcp/mcp_client_executor.py</code>, click here</p> </li> <li> <p>Tool definitions are OpenAI specific, so we are sending the schema (in each prompt)</p> <ul> <li>Note this strongly suggests this is a subset of your database - edit <code>docs/mcp_schema.json</code> as required. </li> </ul> </li> </ul> </li> <li> <p>MCP Client Executor iterates through the Tool Context, calling the JSON:API Endpoint that enforces business logic.</p> </li> </ol> <p> </p>"},{"location":"Integration-MCP/#example-pending-order-emails","title":"Example: pending order emails","text":"<p>The basic_demo sample enables you to create orders with business logic: check credit by using rules to roll-up item amount to orders / customers.  Setting the <code>date_shipped</code> indicates payment is received, and the customer balance is reduced.  </p> <p>\ud83d\udca1 The basic_demo project (tutorial here) illustrates basic GenAI-Logic operation: creating projects from new or existing databases, adding logic and security, and customizing your project using your IDE and Python.</p> <p>In this example, we want a new service to:</p> <ol> <li>Find Orders placed over 30 days ago that are not shipped</li> <li>Send an Email encouraging prompt payment</li> </ol> <p>We want to do this without troubling IT.  MCP enables business users to implement new composite services, while maintaining integrity through the existing logic-enabled JSON:APIs.</p> <p> </p>"},{"location":"Integration-MCP/#setup","title":"Setup","text":"<p>Create the basic_demo under the Manager as described in the Manager readme:  </p> <ol> <li>In your IDE: <code>als create --project-name=basic_demo --db-url=basic_demo</code></li> </ol> <p></p> <ol> <li>Run <code>als add-cust</code> to load mcp (and logic)</li> <li> <p>Optionally, define an environment variable: <code>APILOGICSERVER_CHATGPT_APIKEY</code> ChatGPT API Key (obtain one like this).</p> <ul> <li>To make the demo less fiddly, the system loads the tool context from <code>integration/mcp/examples/mcp_tool_context.json</code>.  You can engage the LLM by setting <code>create_tool_context_from_llm</code> to <code>True</code>, which requires an API Key.</li> </ul> </li> <li> <p>Start the Server (F5)</p> </li> <li>Use Run Config: MCP - Model Context Protocol - Client Executor</li> </ol> <p> </p>"},{"location":"Integration-MCP/#prompt","title":"Prompt","text":"<p>Here is a NL prompt using basic_demo coded into <code>mcp_client_executor</code></p> <pre><code>List the orders date_shipped is null and CreatedOn before 2023-07-14, and send a discount email (subject: 'Discount Offer') to the customer for each one.\n</code></pre> <p> </p>"},{"location":"Integration-MCP/#sample-flow","title":"Sample Flow","text":"<p>You can run <code>mcp_client_executor</code> under the debugger, and stop at each of the breakpoints noted in the screenshot below. </p>"},{"location":"Integration-MCP/#0-mcp-client-executor","title":"0 - MCP Client Executor","text":"<p>Here is the basic driver of the <code>mcp_client_executor</code> (see the Architecture diagram above):  </p>"},{"location":"Integration-MCP/#1-discover-servers","title":"1 - Discover Servers","text":"<p>Discovery uses a config file <code>integration/mcp/mcp_server_discovery.json</code> to discover 1 or more servers, and invoke their <code>.well-known</code> endpoint (see <code>api/api_discovery/mcp_discovery.py</code>):   Observe response shown above (for actual content, click here):</p> <ol> <li> <p>The config file is used to discover the servers. </p> <ul> <li>It identifies the <code>.well-known</code> endpoint used to discover server information.   For GenAI-Logic, it is <code>curl -X GET \"http://localhost:5656/.well-known/mcp.json\"</code>.</li> </ul> </li> <li> <p>The server information (see above) includes:</p> <ol> <li><code>base_url</code></li> <li><code>learning</code>: how to call the server</li> <li><code>resources</code>: the exposed endpoints, their attributes and methods</li> </ol> </li> </ol> <p>The resource and learning meta data is created by API Logic Server, but you can control it:</p> <ul> <li> <p>The learning is at  docs/mcp_learning/mcp.prompt.  This is also created by API Logic Server; edit as required to tune / expand training.</p> <ul> <li>For example, the learning describes how to use the request pattern to send email (further described below)</li> </ul> </li> <li> <p>The resources (aka schema) is at at docs/mcp_learning/mcp_schema.json.  </p> <ul> <li>You can edit this as required to control what is discovered, and to minimize the information sent to the LLM.</li> </ul> </li> </ul> <p></p>"},{"location":"Integration-MCP/#2-tool-context-from-llm","title":"2 - Tool Context from LLM","text":"<p>We call the LLM, providing the NL Query and the discovery returned above.  The LLM returns the <code>tool context</code> (to see it, click here) - the set of APIs the MCP Client Executor is to call:</p> <p> </p>"},{"location":"Integration-MCP/#3-invoke-mcp-server","title":"3 - Invoke MCP Server","text":"<p>The calls include GET, and a POST for each returned row.  </p> <p> </p>"},{"location":"Integration-MCP/#3a-fan-out","title":"3a - Fan-out","text":"<p>Fan-out means that we need to create email for each returned Order.  So, in processing step 2, we must iterate over the orders in step 1, and use the <code>customer_id</code> from the Order for the email:</p> <p></p> <p> </p>"},{"location":"Integration-MCP/#3b-logic-request-pattern","title":"3b - Logic (Request Pattern)","text":"<p>MCP is capable of executing email directly, but we have business policies providing for email opt-outs.  We must respect this logic.</p> <p>As shown below, a common logic pattern is a <code>Request Object</code>, which implements the request pattern:</p> <p>Request Pattern: you insert a row, triggering its business logic (a Python event handler)</p> <p>Here, the logic (an after_flush event) checks the opt-out, and sends the mail (stubbed):</p> <p></p>"},{"location":"Integration-MCP/#4-context-results","title":"4 - Context Results","text":"<p>The MCP Client Executor returns and prints the <code>context_results</code>.  These are accrued for each execution step, above.  In this example, it shows the GET, and 4 POST commands (last shown below).  This context would also be passed back to the LLM for Agentic Execution, as shown in the next section.</p> <p></p> <p> </p>"},{"location":"Integration-MCP/#advanced-llm-concepts","title":"Advanced LLM Concepts","text":"<p>The following are implemented but not used in this example or tested.  We encourage participation in designing examples, and testing the implementation.</p> <p> </p>"},{"location":"Integration-MCP/#agentic-execution-llm-call","title":"Agentic Execution (<code>llm-call</code>)","text":"<p>As described in this recommended video, the MCP Client Executor can call the LLM between each MCP Server Executor call.  This enables the LLM to detect intermediate results, and call subsequent tools accordingly.</p> <p>For example, consider this scenario:</p> <p>\u201cGet all orders for Alice. If any are over $500, alert the sales manager.\u201d</p> <p>Here is a sample tool context - note the <code>llm-call/llm-goal</code>:</p> <pre><code>[\n  {\n    \"tool_type\": \"json-api\",\n    \"base_url\": \"https://server-a.com/api\",\n    \"path\": \"Order\",\n    \"method\": \"GET\",\n    \"query_params\": [\n      { \"name\": \"customer\", \"op\": \"eq\", \"val\": \"Alice\" }\n    ],\n    \"body\": [],\n    \"llm_call\": true,  // &lt;-- Indicates to pause and invoke LLM after this step\n    \"llm_goal\": \"Check which orders for Alice are over $500 and generate alert POSTs as needed\"\n  }\n]\n</code></pre> <p> </p>"},{"location":"Integration-MCP/#branching","title":"Branching","text":"<p>An alternative approach would be for the LLM plan to include <code>llm-call</code> and branching.  Consider this scenario:</p> <p>\u201cCheck Alice\u2019s orders. If any are overdue (i.e. date_due &lt; today and not shipped), send a warning email. Otherwise, do nothing.\u201d</p> <p>The LLM might create a tool context like:</p> <pre><code>[\n  {\n    \"tool_type\": \"json-api\",\n    \"base_url\": \"https://server-a.com/api\",\n    \"path\": \"Order\",\n    \"method\": \"GET\",\n    \"query_params\": [\n      { \"name\": \"customer_id\", \"op\": \"eq\", \"val\": \"Alice\" }\n    ],\n    \"body\": [],\n    \"llm_call\": true,\n    \"llm_goal\": \"If any orders are overdue (date_due &lt; today and date_shipped is null), generate an email alert step. Otherwise, no further action.\"\n  }\n]\n</code></pre> <p></p>"},{"location":"Integration-MCP/#mcp-logic-and-security","title":"MCP Logic and Security","text":"<p>Business logic is always critical, particularly when Business Users can make update calls.  A key design goal of the MCP architecture is that updates be made via APIs that enforce logic and security.</p> <p>GenAI-Logic address this as follows:</p> <ol> <li> <p>All domain object updates automatically invoke your declarative business logic.</p> </li> <li> <p>The discussion above noted the use of the request pattern to add business logic to a service, such as email.  </p> </li> <li> <p>MCP also respects your security settings.  For MCP calls made via SysMcp (see next section), API calls are made with the current request header from your login.  In particular, role-based row-access grants are enforced using this auth-token.</p> </li> </ol> <p>For example, you could use the SysMcp in the Admin app (see next section), and enter this request:</p> <pre><code>List customers with credit_limit &gt; 1000.\n</code></pre> <p>Inspect the console log, and observe that 2 rows are returned.</p> <p></p>"},{"location":"Integration-MCP/#mcp-client-executor-ui","title":"MCP Client Executor UI","text":"<p>Invoking the MCP Client Executor via CLI is useful for development, but business users will want a User Interface.  We show here how to use the Automatic Admin App to invoke the same MCP Client Executor code described above.  You can of course use any technology you wish.</p> <p>The screen shot below illustrates using the Admin App to create and execute MCP requests: </p> <p></p> <p>To install the MCP Client Executor User Interface:</p> <ol> <li>Execute the following command. Intall the MCP Client Executor User Interface<pre><code>genai-logic genai-add-mcp-client\n</code></pre></li> <li>It performs the steps in the subsections below.</li> </ol> <p></p>"},{"location":"Integration-MCP/#creates-sqlite-table-sysmcp","title":"Creates sqlite table: <code>SysMCP</code>","text":"<p>We create a separate table because you may wish to use MCP on an existing database that is not alterable.  </p> <p>You can change the definition of this table to fit your needs.  It requires a column called <code>prompt</code>.</p> <p> </p>"},{"location":"Integration-MCP/#adds-sysmcp-logic","title":"Adds <code>SysMcp</code> Logic","text":"<p>The screen shot below shows logic created for the <code>SysMcp</code> table.</p> <ol> <li>This is the same request pattern used for SysEmail.</li> <li>The code invokes the same <code>integration/mcp/mcp_client_executor.py</code> described above.</li> </ol> <p></p>"},{"location":"Integration-MCP/#customizes-the-admin-app","title":"Customizes the Admin App","text":"<p>The system adds the UI in <code>ui/admin/admin.yaml</code>.  For more information, click here.</p> <p></p>"},{"location":"Integration-MCP/#appendix-status","title":"Appendix: Status","text":"<p>MCP support is GA for the MCP Server Executor.  The MCP Client Executor is in Tech Preview.  It is a great way to explore key MCP architecture.</p> <p>We welcome participation in this project. Please contact us via discord.  For example, explore Agentic Execution.</p> <p></p>"},{"location":"Integration-MCP/#appendix-mcp-background","title":"Appendix: MCP Background","text":"<p>Descriptions of MCP often describe them as USB for servers.  That meant little to use, and probably to you.  We hope the more concrete description here might be more useful.</p> <p>Along the same lines, the best video we have found was noted above.</p> <p>Other resources:</p> <ol> <li> <p>see MCP Introduction</p> </li> <li> <p>and here</p> </li> <li> <p>and here</p> </li> <li> <p>and this N8N link</p> </li> <li> <p>and this python sdk</p> </li> <li> <p>and this video</p> </li> </ol> <p> </p>"},{"location":"Integration-MCP/#appendix-key-clarifications","title":"Appendix: Key Clarifications","text":"<p>MCP is a new technology.  In my learning curve, I found much of the information a little bit vague and in some cases, misleading.  The sections below identify key clarifications to incorrect assumptions I had made, so I have listed them below in hopes they can help you.</p> <p> </p>"},{"location":"Integration-MCP/#app-specific-client-executor","title":"App-Specific Client Executor","text":"<p>Several articles described the Client Executor as a \"host such as Claude\".  That lead me to believe that common chat apps could call MCPs.</p> <p>Later, I discovered that most chat apps cannot call http, and so cannot directly call MCPs.  The Client Executor is analogous to a chat, but is written specifically  for MCP use.</p> <p> </p>"},{"location":"Integration-MCP/#client-executor-not-llm-calls-the-mcp","title":"Client Executor (not LLM) calls the MCP","text":"<p>I saw several diagrams with arrows from the LLM to the MCP.  That lead me to believe that the LLM calls the MCP. </p> <p>Later, I realized that the LLM is just preparing the Tool Context.  The Client Executor uses this to invoke the MCP.  I now think of the arrow as \"knows how to include it in the Tool Context\".</p> <p> </p>"},{"location":"Integration-MCP/#server-executor-logic-enabled-apis","title":"Server Executor == logic-enabled APIs","text":"<p>Finally, I presumed that the Client Executor would pass the Tool Context to the LLM.  This was simply a bad guess.  </p> <p>The key idea is that one specific Server Executor would not be aware it is part of an orchestration.  In the case of database APIs, the Server Executor is the set of logic-enabled endpoints identified in the discovery schema.</p> <p>Note the logic here is critical.  The Client Executor can not / should not \"reach in\" and be aware of logic specific to each involved database.</p>"},{"location":"Integration-Map/","title":"Integration Mapping","text":"<p> TL;DR - IntegrationService: Map, Alias, Lookups</p> <p><code>RowDictMapper</code> is a system-supplied class that provides methods to convert between SQLAlchemy <code>rows</code> and <code>Dict</code>.</p> <p>Services include selecting columns / related data joins, providing aliases, and Lookups.  Activate these by extending <code>RowDictMapper</code> and configuring your row / mapping.</p>"},{"location":"Integration-Map/#overview","title":"Overview","text":"<p><code>OrderB2B</code> is an <code>RowDictMapper</code> subclass that defines a <code>dict</code> structure, with the 2 conversion methods shown.</p> <p></p> <p> </p>"},{"location":"Integration-Map/#dict_to_row","title":"<code>dict_to_row</code>","text":"<p>This is the definition of a <code>RowDictMapper</code> called <code>OrderB2B</code>.  It defines the shape of orders received from business partners.  It extends the system-supplied <code>RowDictMapper</code>.</p> <p>Notes:</p> <ol> <li><code>fields</code> designates a subset of the attributes</li> <li>Several attributes are aliased, such as <code>Quantity</code> as <code>QuantityOrdered</code> (around line 27).</li> <li>It also chooses <code>related</code> data, such as the <code>Items</code>, with a nested <code>RowDictMapper</code></li> <li>It defines the subset of attributes used for Lookups<ul> <li>Our data model defines the foreign key as <code>ProductId</code></li> <li>But our partners do not know these; they refer to them as <code>ProductName</code></li> <li>So, a lookup enables them to provide a <code>ProductName</code>; the <code>RowDictMapper</code> converts these into a  <code>ProductId</code></li> </ul> </li> </ol> <p>This custom resource uses <code>dict_to_row</code> to convert the request data into SQLAlchemy objects, and saves them.  This runs the transaction logic (e.g., check credit, reorder Products).</p> <p></p> <p> </p>"},{"location":"Integration-Map/#row_to_dict","title":"<code>row_to_dict</code>","text":"<p>Part of the business logic needs to convert orders into messages, formatted per Shipping specifications.  The <code>after_flush</code> event uses <code>row_to_dict</code> to automate this conversion.</p> <p></p>"},{"location":"Integration-OpenAI-Function/","title":"OpenAI Function Integration","text":"<p>OpenAI functions are tools that extend the capabilities of ChatGPT by allowing it to access real-time data, perform actions, or connect with external services via APIs. .</p> <p>Instead of being limited to its pre-trained knowledge, ChatGPT can use plugins to retrieve up-to-date information (like live weather, stock prices, or databases) or perform tasks (like booking a flight or running a query). </p> <p>The goal is to turn ChatGPT into a more useful, interactive assistant that can bridge AI language understanding with real-world actions and live data.   </p> <p>For example, in large companies, it can be remarkably hard to find corporate systems via an Intranet, and use different user interfaces.  ChatGPT can simplify finding these, and interacting with Natural Language.</p> <p>This is to explore:</p> Explore Status Nat Lang ALS Access using OpenAI Functions Initial Test Running <p>A value prop might be summarized: instantly expose legacy DBs to Natural Language, including critical business logic and security, to simplify user discovery and operation.</p> <p></p>"},{"location":"Integration-OpenAI-Function/#status-technology-exploration","title":"Status: Technology Exploration","text":"<p>This is an initial experiment, without automation.  Many substantive issues need to be addressed, including but not limited to security, update, etc.</p> <p>We welcome participation in this exploration.  Please contact us via discord.</p> <p>This exploration is changing rapidly.  For updates, replace <code>integration/mcp</code> from integration/msp</p> <p></p>"},{"location":"Integration-OpenAI-Function/#nat-lang-als-access-using-openai-plugin","title":"Nat Lang ALS Access using OpenAI Plugin","text":"<p>Requires tunnel to local host such as ngrok, then</p> <pre><code>ngrok config add-authtoken &lt;obtain from https://dashboard.ngrok.com/get-started/setup/macos&gt;\n</code></pre> <p>then start the tunnel</p> <pre><code>ngrok http 5656\n</code></pre> <p>You should see:</p> <p></p> <p>and note the url like: <code>https://42da-2601-644-4900-etc.ngrok-free.app -&gt; http://localhost:5656</code></p> <p>We'll call it <code>tunnel_url</code></p> <p>Enter this into <code>config/default.env</code></p> <p></p>"},{"location":"Integration-OpenAI-Function/#use-genai_demo","title":"Use GenAI_Demo","text":"<p>Create it, and from dev-source, copy:</p> <ul> <li><code>api_logic_server_cli/prototypes/nw_no_cust/integration/openai_function</code></li> <li><code>api_logic_server_cli/prototypes/nw_no_cust/api/api_discovery</code></li> <li><code>api_logic_server_cli/prototypes/nw_no_cust/config/default.env</code></li> </ul> <p></p>"},{"location":"Integration-OpenAI-Function/#obtain-swagger_3","title":"Obtain swagger_3","text":"<p>Obtain swagger 2 from API Logic Server, eg, http://localhost:5656/api/swagger.json) </p> <p>Convert to 3: https://converter.swagger.io or other.</p> <p></p>"},{"location":"Integration-OpenAI-Function/#reduce-to-30-operations","title":"Reduce to 30 Operations","text":"<p>Reduce down to 30 operations (genai_demo has 69).</p> <p>For testing, you can copy <code>integration/openai_plugin/swagger_3_genai_demo.json</code> or <code>integration/openai_plugin/nw-swagger_3.json</code> over <code>integration/openai_plugin/swagger_3.json</code>.</p> <p>This was obtained using ChatGPT with prompts like:</p> <ol> <li>Optionally collapse GET by ID and GET collection into a single endpoint using query params</li> <li>remove POST from relationship endpoints</li> <li>remove delete</li> <li>collapse relationship endpoints further</li> </ol> <p>then fix the result:</p> <ol> <li>ensure servers and paths is retained (got deleted for me), and includes https:</li> <li>version 3.1.0</li> </ol> <p>Still seeing (fix with Chat):</p> <pre><code>In path /Customer, method get is missing operationId; skipping\nIn path /Customer, method post is missing operationId; skipping\nIn path /Order, method get is missing operationId; skipping\nIn path /Order, method post is missing operationId; skipping\nIn path /Item, method get is missing operationId; skipping\nIn path /Item, method post is missing operationId; skipping\nIn path /Product, method get is missing operationId; skipping\nIn path /Product, method post is missing operationId; skipping\n</code></pre> <p></p>"},{"location":"Integration-OpenAI-Function/#custom-endpoint-for-openapi","title":"Custom endpoint for openapi","text":"<p>OpenAI requires a openai document, so observe the custom endpoint - <code>api/api_discovery/openapi</code> - eg, to test locally: <code>http://localhost:5656/api/openai</code></p> <p>Note: the url for use in ChatGPT is the tunnelled version, from the env variable.</p> <p></p>"},{"location":"Integration-OpenAI-Function/#configure-in-chatgpt","title":"Configure in ChatGPT","text":"<p>Then, upload it to the Web version of ChatGPT: </p> <ol> <li>Explore GPTs</li> <li>Create</li> <li>Configure</li> <li>Create New Action</li> </ol> <p>Provide the url of the openai endpoint:</p> <p>https://tunnel_url.ngrok-free.app/api/openapi</p> <p></p>"},{"location":"Integration-OpenAI-Function/#retrieval-worked","title":"Retrieval worked:","text":"<ul> <li>list customers</li> <li>list the items of order 1 with their product names</li> </ul>"},{"location":"Integration-OpenAI-Function/#update-resoved-pending-verification","title":"Update: Resoved, pending verification","text":"<p>We also experimented with update, using <code>integration/openai_plugin/swagger_3.json</code>.</p> <p>It initially failed to load, which we repaired as noted in Appendix 2.</p> <p>It then failed to generate proper update API, evidently due to bad OpenAPI spec as noted in Appendix 3.</p> <p></p>"},{"location":"Integration-OpenAI-Function/#appendices","title":"Appendices","text":""},{"location":"Integration-OpenAI-Function/#appendix-1-create-ai_plug_injson","title":"Appendix 1: Create ai_plug_in.json","text":"<p>We also looked at openai plugins.  These appear to be discontinued.</p> <p>Prepare <code>ai_plug_in.json</code> as shown in this directory.  Observe that it It identifies the url for finding the openapi through the tunnel.</p> <p>Note: both ALS and and <code>ai_plug_in.json</code> presume the swagger and api are consistent:</p> <ul> <li>swagger is at <code>http://localhost:5656/api/swagger.json</code>, </li> <li>typical API at <code>http://localhost:5656/api/Category</code></li> </ul> <p>Not required for function - Settings / Beta / Plugins &gt; Plugin install \u2192 expects the ai-plugin.json manifest URL</p> <p>This appears to be unavailable for ChatGPT 4o</p> <p></p>"},{"location":"Integration-OpenAI-Function/#appendix-2-updateable-openapi","title":"Appendix 2: Updateable openapi","text":"<p>It initially failed to load with</p> <pre><code>In context=('paths', '/Customer/{CustomerId}/', 'patch', 'requestBody', 'content', 'application/json', 'schema'), reference to unknown component Customer_inst; using empty schema\n\nIn path /Customer/{CustomerId}/, method patch, operationId UpdateCustomer_0, request body schema is not an object schema; skipping\n\nIn path /Customer/{CustomerId}/, method patch, operationId UpdateCustomer_0, skipping function due to errors\n</code></pre> <p>We requested a revised jasonapi from ChatGPT to clear these errors, which loaded.  </p> <p></p>"},{"location":"Integration-OpenAI-Function/#appendix-3-invalid-data-object","title":"Appendix 3: Invalid Data Object","text":"<p>This appears to be caused by improper JSON:API openAPI spec, which caused ChatGPT to generate an improper json PATCH payload:</p> <pre><code>            chatgpt_request_json = {\n                        \"credit_limit\": 25000,\n            }\n            standard_request_json = {\n                \"data\": {\n                    \"type\": \"Customer\",\n                    \"id\": \"ALFKI\",\n                    \"attributes\": {\n                        \"name\": \"Alice\",\n                        \"credit_limit\": 25000,\n                        \"balance\": 12345\n                    }\n                }\n            }\n</code></pre>"},{"location":"Integration-chatbot/","title":"ChatBot Integration","text":"<p>ChatBots are extensions to team collaboration systems (Microsoft Teams, Slack, DIscord) that can interface to other systems, such as OpenAI Functions for data inquiry / update.</p> <p>For example, in large companies, users spend significant time in such systems to the point it becomes their central UI.  So, enabling access to key corporate systems, with a Natural Language interface, is a natural way to simpify business.</p> <p>This is to explore:</p> Explore Status ChatBot to Slack -- <p>A value prop might be summarized: instantly expose legacy DBs to Natural Language from collaboration tools, including critical business logic and security, to simplify user discovery and operation.</p> <p></p>"},{"location":"Integration-chatbot/#status-technology-evalution","title":"Status: Technology Evalution","text":"<p>We are solicting reactions to such a capability.</p> <p>We welcome participation in this exploration.  Please contact us via discord.</p> <p></p>"},{"location":"Integration-chatbot/#example","title":"Example","text":"<p>\u2728 Flow example: \u201cCreate order for ALFKI with 2 bottles of Chai\u201d:</p> <ol> <li>User sends message in Slack/Teams</li> <li>Bot passes message to backend</li> <li>Backend sends message to GPT function-calling endpoint</li> <li>GPT returns function call:</li> </ol> <p>\u2192 POST /Order { customer_id: \"ALFKI\", items: [{product_id: \"CHAI\", quantity: 2}] }</p> <ol> <li>Backend sends API request to your OpenAPI endpoint</li> <li>Backend replies in Slack:</li> </ol> <p>\u2192 \u201c\u2705 Created order #1024 for ALFKI with 2 items\u201d</p>"},{"location":"Keycloak-devnotes/","title":"Keycloak DevNotes","text":""},{"location":"Keycloak-devnotes/#integration-apilogicserver-keycloak","title":"Integration: ApiLogicServer + Keycloak","text":"<p>This repo contains a demo for apilogicserver integration with keycloak oidc JWT authentication.  We can now codegen kc-capable apps (though will still required setup as described below).</p> <ul> <li>kci refers to the running KeyCloakIntegration</li> </ul> <p>Status - 3/10:</p> <ol> <li>able to access keycloak for login using modified sra at localhost.</li> <li>kci is running with authentication &amp; authorization (minimal testing)</li> <li>we can now run a generated app, presuming the Iterim Additional Setup</li> </ol> <p> </p>"},{"location":"Keycloak-devnotes/#configuring-security","title":"Configuring Security","text":"<p>With your project open, use the Terminal &gt; New Terminal window:</p> <pre><code>ApiLogicServer add-auth --provider-type=[ keycloak | sql | none ] --db-url=\n</code></pre> <p> </p>"},{"location":"Keycloak-devnotes/#anticipated-usage","title":"Anticipated Usage","text":"<p>We anticipate that developers will probably </p> <ol> <li>start with no auth<ul> <li>just to get running</li> </ul> </li> <li>then configure sqlite (<code>als add-auth --provider-type=sql --db-url=</code>)<ul> <li>simplest way to get started with auth - nothing to install or configure<ul> <li>declare your grants (which is not trivial)</li> </ul> </li> <li>switching to other sql dbms (e.g,. Postgresql) is now more tricky (doc to follow)</li> </ul> </li> <li>then configure keycloak (<code>als add-auth --provider-type=keycloak --db-url=</code>)</li> <li>often switch back and forth during testing, or for different developers<ul> <li>It's important this be fast and easy - in particular, just 1 step to reduce errors</li> </ul> </li> </ol> <p> </p>"},{"location":"Keycloak-devnotes/#system-support","title":"System Support","text":"<p>Therefore, as of 10.04.55, several changes faciliate switching between no / sql / keycloak authentication:</p> <ol> <li> <p>All projects are created sql auth fully configured for sqlite.  This includes the SQLAlchemy models, the api auth endpoints, the database, etc.  </p> <ul> <li>See the screenshot below</li> <li>But, auth is initially disabled<ul> <li>so, user behavior is still no security, just as now</li> <li>they then use the <code>add-auth</code> command to configure, as described above</li> </ul> </li> </ul> </li> <li> <p>The auth setting in <code>ui/admin/admin.yaml</code> is created as <code>authentication: '{system-default}'</code>, and updated on load with the config values (overridden by env settings).</p> <ul> <li>This means you do not have to alter your <code>admin.yanl</code> when you reconfigure auth</li> </ul> </li> <li> <p>You can hard-code authentication, eg,</p> </li> </ol> Hardcoded authentication<pre><code>authentication:\n  keycloak:\n    url: https://kc.hardened.be\n    realm: kcals\n    clientId: alsclient\n</code></pre> <p></p>"},{"location":"Keycloak-devnotes/#iterim-additional-setup","title":"Iterim Additional Setup","text":"<pre><code>ApiLogicServer add-auth --provider-type=keycloak --db-url=  # if not already done\ncp -r devops/keycloak/nginx/admin-app ui/safrs-react-admin\n</code></pre> <p>Or, the entire sequence, using the testpy release (aside - the dev ide has run configs for this under 2. Create servers/ApiLogicProject):</p> <pre><code>ApiLogicServer create --project-name= --db-url=\ncode ApiLogicProject  # then, in VSC terminal...\nApiLogicServer add-cust\nApiLogicServer add-auth --provider-type=keycloak --db-url=\ncp -r devops/keycloak/nginx/admin-app ui/safrs-react-admin\ncd devops/keycloak\ndocker compose up\n# start ApiLogicServer server from the IDE (F5)\n</code></pre> <p> </p>"},{"location":"Keycloak-devnotes/#run","title":"Run:","text":"<pre><code>cd devops/keycloak\ndocker-compose up\n</code></pre> <p>This will run keycloak on the docker host (use admin, password): - keycloak (http://localhost:8080) </p> <p> </p>"},{"location":"Keycloak-devnotes/#define-users-and-roles","title":"Define Users and Roles","text":"<p>This works - you can define users, and they are available (with their roles) at runtime (see the jwt.io screenshot, below):</p> <p></p>"},{"location":"Keycloak-devnotes/#define-attributes","title":"Define Attributes","text":"<p>I can enter User Attributes:</p> <p></p> <p>And, using this, register mappers:</p> <p></p> <p>You must provide the <code>Token Claim Name</code>:</p> <p></p>"},{"location":"Keycloak-devnotes/#authorization-working","title":"Authorization working","text":"<p>Login as u1.   Observe you only get 1 category.</p> <p> </p>"},{"location":"Keycloak-devnotes/#test","title":"Test:","text":""},{"location":"Keycloak-devnotes/#1-keycloak-login-unit-test","title":"1. Keycloak Login Unit Test","text":"<p>Verify keycloak login with demo, demo</p> <pre><code># keycloak realm named \"kcals\"\nKC_BASE=http://localhost:8080/realms/kcals\n\necho \"\\n\\noidc token endpoint\"\nTOKEN_ENDPOINT=$(curl ${KC_BASE}/.well-known/openid-configuration | jq -r .token_endpoint)\necho \"TOKEN_ENDPOINT: ${TOKEN_ENDPOINT} \\n\"\n\necho \"retrieve an access token by logging in \"\nTOKEN=$(curl ${TOKEN_ENDPOINT} -d 'grant_type=password&amp;client_id=alsclient' -d 'username=u1' -d 'password=p' | jq -r .access_token)\necho \"TOKEN: ${TOKEN} \\n\"\n\n# test the authentication\ncurl http://localhost:5656/api/Category -H \"Authorization: Bearer ${TOKEN}\" | jq .\n</code></pre>"},{"location":"Keycloak-devnotes/#2-start-app-logic-server","title":"2. Start APP Logic Server","text":"<p>Use first Run Config.</p> <ul> <li>If possible, I'd like to simplify setup, and make debugging easier, so trying to run the app natively.</li> </ul> <p> </p>"},{"location":"Keycloak-devnotes/#adapted-implementation","title":"Adapted Implementation","text":"<p>Several changes to adapt the original poc to API Logic Server structure:</p> <ol> <li>Updated <code>security/system/authentication.py</code> <ul> <li>Call a new <code>configure_auth</code> function in the Keycloak Provider</li> <li>Pass jwt_data to <code>get_user(identity, jwt_data)</code> (arg 2, instead of password)</li> <li>This removes dependency on this file to provider type.</li> </ul> </li> <li>Introduced <code>security/authentication_provider/keycloak/auth_provider</code><ul> <li>Moved the settings and <code>get_jwt_public_key</code> to there</li> <li>This centralizes all the keycloak elements into its provider</li> <li>There is a <code>config/config.py</code> setting to activate the Keycloak Provider.<ul> <li>This will later be a CLI command.</li> </ul> </li> </ul> </li> <li>Added the docker compose material (including imports) to the <code>devops</code> dir</li> <li>Note interim SRA is included in <code>ui/safrs-react-admin</code></li> <li>To login, see the <code>Auth</code> object in the admin app: demo, demo</li> </ol> <p></p>"},{"location":"Keycloak-devnotes/#inspecting-access-tokens","title":"Inspecting Access Tokens","text":"<p>You can use jwt.io:</p> <p></p>"},{"location":"Keycloak-devnotes/#initial-implementation-for-reference","title":"Initial Implementation (for reference)","text":"<ul> <li>the <code>$PWD/projects</code> was mounted at <code>/projects</code> in the ApiLogicServer container</li> <li>A project named <code>KCALS</code> was created (default nw, with authentication):</li> </ul> <pre><code>mkdir projects\nchmod 777 projects # we need to be able to write to this directory from the container\ndocker run  $PWD/projects:/projects -it apilogicserver/api_logic_server bash -c \"ApiLogicServer create --project_name=/projects/KCALS --db_url= ; ApiLogicServer add-auth --project_name=/projects/KCALS\"\n</code></pre> <p>For users to be able to authenticate with JWTs signed by keycloak, we have to download the JWK signing key from keycloak and use that to validate the JWTs.  JWT validation is implemented in https://github.com/thomaxxl/kcals/security/system/authentication.py. </p> <p>By default, apilogicserver authentication uses a user database. Our users are defined in keycloak however. I had to change auth_provider.py for this to (kinda) work.</p> <p> </p>"},{"location":"Keycloak-devnotes/#react-admin","title":"React-Admin","text":"<p>Nginx is used to host the safrs-react-admin frontend at http://localhost/admin-app .</p> <p> </p>"},{"location":"Keycloak-devnotes/#persisting-keycloak-data","title":"Persisting Keycloak Data","text":"<p>keycloak data is stored inside the keycloak container in /opt/keycloak/data . To make this persistent, you should mount this volume. Currently, only the \"import\" folder is mounted. This import folder contains json files exported by me. These json files are imported when the container starts with the \" --import-realm\" command line switch ( https://www.keycloak.org/server/importExport )</p> <p>You can try this:</p> <pre><code>$ mkdir data\n$ mv import data # the import folder containing the json files\n$ chmod 777 data # make sure the container keycloak user can write to this folder\n</code></pre> <p>Then, change the docker-compose keycloak volumes to:</p> <pre><code>volumes:\n    - $PWD/data:/opt/keycloak/data\n</code></pre> <p>Finally, update the docker-compose file so that the imports don't overwrite the mounted volume settings:</p> <ol> <li>Remove the <code>--import-realm</code></li> <li>Remove <code>- $PWD/import:/opt/keycloak/data/import</code></li> </ol> <p>This way, the /opt/keycloak/data will remain on the docker host mounted directory ($PWD/data).</p> <p>Access data - this does not appear to work (no cli): <pre><code>docker cp keycloak:/opt/keycloak/data ~/Desktop/keycloak\n</code></pre></p> <p>Export the data</p> <p><pre><code>docker exec -it keycloak bash\n$ cd /opt/keycloak\n$ bin/kc.sh export --help\n$ bin/kc.sh export --dir export\n$ exit\ndocker cp keycloak:/opt/keycloak/export ~/Desktop/keycloak-export\n</code></pre> </p>"},{"location":"Keycloak-devnotes/#notes-accessing-the-jwt-at-runtime","title":"Notes: Accessing the jwt at runtime","text":"<p>To retrieve user info from the jwt, you may want to look into these functions: https://flask-jwt-extended.readthedocs.io/en/stable/automatic_user_loading.html as used in security/system/authentication.py</p>"},{"location":"Keycloak-devnotes/#saved-snippet","title":"Saved snippet","text":"<p>Aside - can use this as bearer... jwt.io will decode it</p> <p><pre><code>data = {\n            \"grant_type\": \"password\",\n            \"client_id\": \"alsclient\",\n            \"username\" :f\"{username}\",\n            \"password\": f\"{password}\"\n        }\n        resp = requests.post(f\"{TOKEN_ENDPOINT}\", data)\n        if resp.status_code == 200:\n            resp_data = json.loads(resp.text)\n            access_token = resp_data[\"access_token\"]\n            return jsonify(access_token=access_token)\n</code></pre> </p>"},{"location":"Logic-Allocation-Time-Date/","title":"Time/Date Stamping","text":"<p><code>Rule.early_row_event_all_classes</code> is provided for generic events which apply to all tables. </p> <p>These are intended to support familiar patterns of time, date, and user stamping.  For example:</p> <p></p> <p>Notes:</p> <ol> <li>The initiating event is the insert/update of any row</li> <li>We declare <code>Rule.early_row_event_all_classes</code> to invoke <code>handle_all</code><ul> <li>This is equivalent to an <code>Event</code> rule, but applies to <code>all classes</code></li> </ul> </li> <li>Note the use of <code>LogicRow</code> services, such as <code>nest_level</code><ul> <li>Find other services with code completion</li> </ul> </li> <li>This pattern can be applied to other forms of stamping, such as created_by / updated_by<ul> <li>Alter the code to reflect your own naming conventions</li> </ul> </li> </ol>"},{"location":"Logic-Allocation/","title":"Allocation","text":""},{"location":"Logic-Allocation/#allocate-payment-to-outstanding-orders","title":"Allocate Payment to Outstanding Orders","text":"<p>This project is to illustrate the use of Allcation.</p> <p>Allocation is a pattern where:</p> <p>A <code>Provider</code> allocates items to a list of <code>Recipients</code>, creating <code>Allocation</code> rows.</p> <p>For example, imagine a <code>Customer</code> has a set of outstanding <code>Orders</code>, and pays all/several off with a single <code>Payment</code>.</p> <p>Then, inserting a provider <code>Payment</code> allocates the <code>amount</code> to as set of recipient <code>Orders</code>, creating <code>PaymentAllocation</code> allocation rows.</p> <p> </p>"},{"location":"Logic-Allocation/#data-model","title":"Data Model","text":""},{"location":"Logic-Allocation/#requirements","title":"Requirements","text":"<p>When the <code>Payment</code> is inserted, our system must:</p> <ol> <li>Allocate the <code>Payment</code> to <code>Orders</code> that have <code>AmountOwed</code>, oldest first</li> <li>Keep track of how the <code>Payment</code> is allocated, by creating  a <code>PaymentAllocation</code></li> <li>As the <code>Payment</code> is allocated,</li> <li>Update the <code>Order.AmountOwed</code>, and</li> <li>Adjust the <code>Customer.Balance</code></li> </ol> <p> </p>"},{"location":"Logic-Allocation/#setup","title":"Setup","text":"<p>Create the project:</p> <p><pre><code>ApiLogicServer create --project_name=allocation --db_url=allocation\n</code></pre> After you establish the venv in the usual manner, you can open the project in your IDE and run launch configuration <code>ApiLogicServer</code>.</p>"},{"location":"Logic-Allocation/#test","title":"Test","text":"<p>Use <code>sh test/test.sh</code></p> <p> </p>"},{"location":"Logic-Allocation/#walkthrough","title":"Walkthrough","text":"<p>The test illustrates allocation logic for our inserted payment, which operates as follows:</p> <ol> <li>The initiating event is the insertion of a <code>Payment</code>, which triggers:</li> <li>The <code>allocate</code> rule.  It performs the allocation:</li> <li>Obtains the list of recipient orders by calling the function<code>unpaid_orders</code></li> <li>For each recipient (<code>Order</code>), the system...<ol> <li>Creates a <code>PaymentAllocation</code>, links it to the <code>Order</code> and <code>Payment</code>,</li> <li>Invokes the default <code>while_calling_allocator</code>, which<ol> <li>Reduces <code>Payment.AmountUnAllocated</code></li> <li>Inserts the <code>PaymentAllocation</code>, which runs the following rules:<ul> <li>r1 <code>PaymentAllocation.AmountAllocated</code> is derived ;       this triggers the next rule...</li> <li>r2 <code>Order.AmountPaid</code> is adjusted; that triggers... </li> <li>r3 <code>Order.AmountOwed</code> is derived; that triggers</li> <li>r4 <code>Customer.Balance</code> is adjusted</li> </ul> </li> <li>Returns whether the <code>Payment.AmountUnAllocated</code> has remaining value ( &gt; 0 ).</li> <li>Tests the returned result<ol> <li>If true (allocation remains), the loop continues for the next recipient</li> <li>Otherwise, the allocation loop is terminated</li> </ol> </li> </ol> </li> </ol> </li> </ol>"},{"location":"Logic-Allocation/#log-output","title":"Log Output","text":"<p>Logic operation is visible in the log</p> <pre><code>Logic Phase:        BEFORE COMMIT                                - 2020-12-23 05:56:45,682 - logic_logger - DEBUG\nLogic Phase:        ROW LOGIC (sqlalchemy before_flush)          - 2020-12-23 05:56:45,682 - logic_logger - DEBUG\n..Customer[ALFKI] {Update - client} Id: ALFKI, CompanyName: Alfreds Futterkiste, Balance: 1016.00, CreditLimit: 2000.00  row@: 0x10abbea00 - 2020-12-23 05:56:45,682 - logic_logger - DEBUG\n..Payment[None] {Insert - client} Id: None, Amount: 1000, AmountUnAllocated: None, CustomerId: None, CreatedOn: None  row@: 0x10970f610 - 2020-12-23 05:56:45,682 - logic_logger - DEBUG\n..Payment[None] {BEGIN Allocate Rule, creating: PaymentAllocation} Id: None, Amount: 1000, AmountUnAllocated: None, CustomerId: None, CreatedOn: None  row@: 0x10970f610 - 2020-12-23 05:56:45,683 - logic_logger - DEBUG\n....PaymentAllocation[None] {Insert - Allocate Payment} Id: None, AmountAllocated: None, OrderId: None, PaymentId: None  row@: 0x10abbe700 - 2020-12-23 05:56:45,684 - logic_logger - DEBUG\n....PaymentAllocation[None] {Formula AmountAllocated} Id: None, AmountAllocated: 100.00, OrderId: None, PaymentId: None  row@: 0x10abbe700 - 2020-12-23 05:56:45,684 - logic_logger - DEBUG\n......Order[10692] {Update - Adjusting Order} Id: 10692, CustomerId: ALFKI, OrderDate: 2013-10-03, AmountTotal: 878.00, AmountPaid:  [778.00--&gt;] 878.00, AmountOwed: 100.00  row@: 0x10ac82370 - 2020-12-23 05:56:45,685 - logic_logger - DEBUG\n......Order[10692] {Formula AmountOwed} Id: 10692, CustomerId: ALFKI, OrderDate: 2013-10-03, AmountTotal: 878.00, AmountPaid:  [778.00--&gt;] 878.00, AmountOwed:  [100.00--&gt;] 0.00  row@: 0x10ac82370 - 2020-12-23 05:56:45,685 - logic_logger - DEBUG\n........Customer[ALFKI] {Update - Adjusting Customer} Id: ALFKI, CompanyName: Alfreds Futterkiste, Balance:  [1016.00--&gt;] 916.00, CreditLimit: 2000.00  row@: 0x10abbea00 - 2020-12-23 05:56:45,685 - logic_logger - DEBUG\n....PaymentAllocation[None] {Insert - Allocate Payment} Id: None, AmountAllocated: None, OrderId: None, PaymentId: None  row@: 0x10ac6a850 - 2020-12-23 05:56:45,686 - logic_logger - DEBUG\n....PaymentAllocation[None] {Formula AmountAllocated} Id: None, AmountAllocated: 330.00, OrderId: None, PaymentId: None  row@: 0x10ac6a850 - 2020-12-23 05:56:45,686 - logic_logger - DEBUG\n......Order[10702] {Update - Adjusting Order} Id: 10702, CustomerId: ALFKI, OrderDate: 2013-10-13, AmountTotal: 330.00, AmountPaid:  [0.00--&gt;] 330.00, AmountOwed: 330.00  row@: 0x10ac824f0 - 2020-12-23 05:56:45,686 - logic_logger - DEBUG\n......Order[10702] {Formula AmountOwed} Id: 10702, CustomerId: ALFKI, OrderDate: 2013-10-13, AmountTotal: 330.00, AmountPaid:  [0.00--&gt;] 330.00, AmountOwed:  [330.00--&gt;] 0.00  row@: 0x10ac824f0 - 2020-12-23 05:56:45,686 - logic_logger - DEBUG\n........Customer[ALFKI] {Update - Adjusting Customer} Id: ALFKI, CompanyName: Alfreds Futterkiste, Balance:  [916.00--&gt;] 586.00, CreditLimit: 2000.00  row@: 0x10abbea00 - 2020-12-23 05:56:45,686 - logic_logger - DEBUG\n....PaymentAllocation[None] {Insert - Allocate Payment} Id: None, AmountAllocated: None, OrderId: None, PaymentId: None  row@: 0x10ac6a9d0 - 2020-12-23 05:56:45,687 - logic_logger - DEBUG\n....PaymentAllocation[None] {Formula AmountAllocated} Id: None, AmountAllocated: 570.00, OrderId: None, PaymentId: None  row@: 0x10ac6a9d0 - 2020-12-23 05:56:45,687 - logic_logger - DEBUG\n......Order[10835] {Update - Adjusting Order} Id: 10835, CustomerId: ALFKI, OrderDate: 2014-01-15, AmountTotal: 851.00, AmountPaid:  [0.00--&gt;] 570.00, AmountOwed: 851.00  row@: 0x10ac82550 - 2020-12-23 05:56:45,688 - logic_logger - DEBUG\n......Order[10835] {Formula AmountOwed} Id: 10835, CustomerId: ALFKI, OrderDate: 2014-01-15, AmountTotal: 851.00, AmountPaid:  [0.00--&gt;] 570.00, AmountOwed:  [851.00--&gt;] 281.00  row@: 0x10ac82550 - 2020-12-23 05:56:45,688 - logic_logger - DEBUG\n........Customer[ALFKI] {Update - Adjusting Customer} Id: ALFKI, CompanyName: Alfreds Futterkiste, Balance:  [586.00--&gt;] 16.00, CreditLimit: 2000.00  row@: 0x10abbea00 - 2020-12-23 05:56:45,688 - logic_logger - DEBUG\n..Payment[None] {END Allocate Rule, creating: PaymentAllocation} Id: None, Amount: 1000, AmountUnAllocated: 0.00, CustomerId: None, CreatedOn: None  row@: 0x10970f610 - 2020-12-23 05:56:45,688 - logic_logger - DEBUG\nLogic Phase:        COMMIT                                       - 2020-12-23 05:56:45,689 - logic_logger - DEBUG\nLogic Phase:        FLUSH   (sqlalchemy flush processing         - 2020-12-23 05:56:45,689 - logic_logger - DEBUG\n\nadd_payment, update completed\n</code></pre>"},{"location":"Logic-Allocation/#key-points","title":"Key Points","text":"<p>Allocation illustrates some key points regarding logic.</p>"},{"location":"Logic-Allocation/#extensibility","title":"Extensibility","text":"<p>While Allocation is part of Logic Bank, you could have recognized the pattern yourself, and provided the implementation.  This is enabled since Event rules can invoke Python.  You can make your Python code generic, using meta data (from SQLAlchemy), parameters, etc.  </p> <p>For more information, see Extensibility.</p>"},{"location":"Logic-Allocation/#rule-chaining","title":"Rule Chaining","text":"<p>Note how the created <code>PaymentAllocation</code> row triggered the more standard rules such as sums and formulas.  This required no special machinery: rules watch and react to changes in data - if you change the data, rules will \"notice\" that, and fire.  Automatically.</p>"},{"location":"Logic-Debug/","title":"Debugging Logic","text":"<p> TL;DR - Debugging Logic</p> <p>Debug rules using system-generated logging and your IDE debugger.</p> <p> </p>"},{"location":"Logic-Debug/#using-the-debugger","title":"Using the debugger","text":"<p>Use the debugger as shown below.  Note you can stop in lambda functions.</p> <ul> <li> <p>Key point: rows are instances of your Data Model classes (<code>database/models.py</code>).  These classes define the attributes and relationships; this information powers IDE code completion, the debugger, etc.</p> <ul> <li>Recall the Data Model classes were built by API Logic Server, by introspecing the database</li> </ul> </li> </ul> <p> </p> <p> </p>"},{"location":"Logic-Debug/#logic-log","title":"Logic Log","text":"<p>Logging is performed using standard Python logging, with a logger named <code>logic_logger</code>.  Use <code>info</code> for tracing, and <code>debug</code> for additional information (e.g., all declared rules are logged).</p> <p>In addition, the system logs all rules that fire, to aid in debugging.  Referring the the screen shot above:</p> <ul> <li>Each line represents a rule execution, showing row state (old/new values), and the {reason} that caused the update (e.g., client, sum adjustment)</li> <li>Log indention shows multi-table chaining</li> </ul>"},{"location":"Logic-Debug/#custom-stacktrace","title":"Custom Stacktrace","text":"<p>VSCode stacktraces require several lines, so <code>config/setup_server.py</code> implements a custom stacktrace as shown below.</p> <ol> <li>You can easily disable this if you prefer the standard</li> <li>This applies to all stacktraces, not just for logic</li> </ol> <p></p>"},{"location":"Logic-Operation/","title":"Logic Operation","text":""},{"location":"Logic-Operation/#logic-architecture","title":"Logic Architecture","text":"<p>Logic Bank operates as shown above:</p> <ol> <li> <p>Automatic Configuration</p> <p>a. Declare logic in <code>logic/declare_logic.py</code>.  Here is a summary of the rule types</p> <p>b. The Admin App and JSON:API are already configured to load and execute this logic</p> </li> <li> <p>Admin App and JSON:API operate as usual: makes calls on <code>SQLAlchemy</code> for inserts, updates and deletes     and issues <code>session.commit()</code></p> </li> <li> <p>The Logic Bank engine handles SQLAlchemy <code>before_flush</code> events on <code>Mapped Tables</code>, so executes on this <code>session.commit()</code></p> </li> <li> <p>The logic engine operates in 2 phases:</p> <p>a. Initial Loop - the logic engine operates much like a spreadsheet, executing the following on each inserted, updated or deleted row:</p> <ul> <li>watch for changes -  at the attribute level</li> <li>react by running rules that referenced changed attributes, which can</li> <li>chain to still other attributes that refer to those changes.  Note these might be in different tables, providing automation for multi-table logic</li> </ul> <p>b. Commit Loop after all the rows have been initially processed, the engine executes commit constraints and events for each table that defines them</p> </li> </ol> <p>Logic does not apply to updates outside SQLAlchemy, nor to SQLAlchemy batch updates or unmapped sql updates.</p>"},{"location":"Logic-Operation/#basic-idea-like-a-spreadsheet","title":"Basic Idea - Like a Spreadsheet","text":"<p>Rules are spreadsheet-like expressions for multi-table derivations and constraints.  For example (not actual syntax):</p> <pre><code>The Customer Balance is the sum of the unshipped Order AmountTotals\n</code></pre> <p></p> <p>You can imagine that the spreadsheet watches for changes to referenced cells, reacts by recomputing the cell, which may chain to other cells.</p> <p> </p> <p>Let's see how logic operates on a typical, multi-table transaction.</p>"},{"location":"Logic-Operation/#watch-react-chain","title":"Watch, React, Chain","text":"<p>Let's consider a typical multi-table transaction.  Here is the 5 rule solution for check credit:</p> <p></p> <p>As Order Details are inserted, the rule flow is shown below.</p> <p>The <code>add_order</code> example illustrates how Watch / React / Chain operates to check the Credit Limit as each Order Detail is inserted:</p> <ol> <li> <p>The <code>OrderDetail.UnitPrice</code> (copy, line 78) references Product, so inserts cause it to be copied</p> </li> <li> <p><code>Amount</code> (formula, line 75) watches <code>UnitPrice</code>, so its new value recomputes <code>Amount</code></p> </li> <li> <p><code>AmountTotal</code> (sum, line 72) watches <code>Amount</code>, so <code>AmountTotal</code> is adjusted (more on adjustment, below)</p> </li> <li> <p><code>Balance</code> (sum, line 68) watches <code>AmountTotal</code>, so it is adjusted</p> </li> <li> <p>And the Credit Limit constraint (line 64) is checked (exceptions are raised if constraints are violated, and the transaction is rolled back)</p> </li> </ol> <p>All of the dependency management to see which attributes have changed, logic ordering, the SQL commands to read and adjust rows, and the chaining are fully automated by the engine, based solely on the rules above.</p>"},{"location":"Logic-Operation/#creating-new-rule-types","title":"Creating New Rule Types","text":"<p>Not only can you define Python events, but you can add new rule types.  This is an advanced topic, described here</p> <p> </p>"},{"location":"Logic-Recompute/","title":"Recompute","text":"<p> TL;DR - Update derivations in row on retrieval</p> <p>Intended for dev teams to introduce new derived attributes.</p> <p>Under consideration.</p> <p>Cases:</p> <ul> <li> <p>Get Order -- triggers GetRecompute of...</p> <ul> <li>GetRecompute parent (emp)</li> <li>GetRecompute kids (items, --&gt; Product)</li> </ul> </li> <li> <p>Ins Order (Multi-Table Chaining)</p> <ul> <li>Get parent</li> <li>Not Get Kids</li> </ul> </li> </ul> <p>All Derivations (add recompute to verb, test it in formula as desired) Constraints? </p> <p>Sample-ai, with </p> <ul> <li>Emp has Emp.RepDiscount (which is derived)</li> <li>Item has Product.GreenDiscount</li> </ul>"},{"location":"Logic-Tutorial/","title":"How: Logic and Agile","text":"<p> TL;DR - Collaboration drives Requirements, Tests, Logic Reports</p> <p>Use API Logic Server with Behave: Working Software Now for Agile Collaboration, near instant iteration, and unified requirements capture / traceabilty / test suite development:</p> <ol> <li> <p>Use the created Admin App as Working Software Now, enabling Business User Collaboration to capture logic requirements in Behave.</p> </li> <li> <p>Use these requirements to drive rule declaration, and develop tests that verify the scenarios work.  Iterations are extremely rapid due to automatic logic ordering and optimization.</p> </li> <li> <p>Use the Behave Logic Report for requirements traceability: document the requirements, test results, including the rules that fired for each test.</p> </li> </ol> <p>This page describes an optional approach for using logic in a TDD-based Agile framework.</p> <p> </p>"},{"location":"Logic-Tutorial/#automation-collaboration-fast-right","title":"Automation + Collaboration: Fast, Right","text":"<p>Automated App Creation (Working Software Now) enables Collaboration to uncover Automated Rules.</p> <p></p> <p>This page explains how API Logic Server Automation, coupled with an Agile (TDD - Test Driven Development) Process, can dramatically improve Time to Market and reduce Requirements Risk:</p> <ol> <li> <p>Automated App Creation: API Logic Server creates an API Logic Project with a single command.  The project implements an Admin App and underlying API.</p> </li> <li> <p>Customer Collaboration: the Admin App (Working Software, Now) drives collaboration, resulting in Features (Stories), Scenarios (tests), and Logic Designs that define how data is computed, validated, and processed (e.g., issues email or messages, auditing, etc.).</p> </li> <li> <p>Automated Logic: the Logic Design often translates directly into Executable Rules, which can be entered as customizations into the created API Logic Project.</p> </li> <li> <p>Transparency: the Behave Logic Report documents the functionality of the system: Features (Stories) and Scenarios (tests) that confirm its operation.  The report includes the underlying Rules, extending transparency to the implementation level.</p> </li> </ol> <p> </p> <p>Key Takeaway: automation drives Time to Market by providing working software rapidly; this drives agile collaboration to define systems that meet actual needs, reducing requirements risk.</p> <p>Virtuous Cycle: the collaboration uncovers Logic Designs, which can be declared as spreadsheet-like rules for API Logic Server automation.</p> <p> </p>"},{"location":"Logic-Tutorial/#resources","title":"Resources","text":"<p>After you've reviewed the logic background, use this page to learn how to use logic.  Key resources:</p> <ol> <li>Rule Summary</li> <li>Sample Database</li> <li>Behave is a framework for defining and executing tests.  It is based on TDD (Test Driven Development), an Agile approach for defining system requirements as executable tests.   * Here are some details for using Behave with API Logic Server.</li> </ol> <p> </p>"},{"location":"Logic-Tutorial/#process-overview","title":"Process Overview","text":"<p>The diagram below provides more detail on the development process, further explained in the sections below.</p> <p></p> <p> </p>"},{"location":"Logic-Tutorial/#1-create-api-logic-project","title":"1. Create Api Logic Project","text":"<p>API Logic Server is used once you have a preliminary database design.  Use your existing procedures for database design.  Include at least minimal test data.</p> <p>Then (presuming API Logic Server is installed), create the project with this command, using <code>venv</code> based installs:</p> <pre><code>ApiLogicServer create  --db_url= --project_name=\n</code></pre> <p>or, like this, using docker-based installs: <pre><code>ApiLogicServer create --db_url= --project_name=/localhost/ApiLogicProject\n</code></pre></p> <p> </p>"},{"location":"Logic-Tutorial/#1a-creates-admin-app","title":"1a. Creates Admin App","text":"<p>The Agile objective of collaboration is typically best-served with running screens.  The problem is, it takes quite a long time to create the API and screens to reach this point.  And this work can be wasted if there were misunderstandings.</p> <p>Ideally, User Interface creation would be automatic.</p> <p>So, the API Logic Server <code>create</code> command above builds first-cut screens, automatically from the data model.  </p> <p>The app shown below (more detail here) is suitable for initial business user collaboration (further discussed below), and basic back office data maintenance.</p> <p>You can customize it by editing a simple <code>yaml</code>file (e.g, field captions, ordering etc.)</p> <p></p> <p> </p> <p>Key Takeaway: Admin App Automation enables collaboration, instantly.</p> <p> </p>"},{"location":"Logic-Tutorial/#1b-also-creates-api","title":"1b. Also creates API","text":"<p>It is not difficult to create a single endpoint API.  The problem is that it's quite a bit more work to create an endpoint for each table, with support for related data, pagination, filtering and sorting.</p> <p>Ideally, API creation would be automatic.</p> <p>So, the API Logic Server <code>create</code> command above builds such an API instantly, suitable for application integration, and creating custom User Interfaces.  The API enforces the business logic described below.</p> <p>The created project is customizable, using a standard IDE.</p> <p> </p> <p>Key Takeaway: automatic API creation, with support for related data, pagination, filtering and sorting.</p> <p> </p>"},{"location":"Logic-Tutorial/#2-collaborate-with-admin-app","title":"2. Collaborate with Admin App","text":"<p>As noted above, running screens are an excellent way to engage business user collaboration, and ensure the system meets actual user needs.  Such collaboration typically leads in two important directions, described below.</p> <p> </p>"},{"location":"Logic-Tutorial/#2a-iterate-data-model","title":"2a. Iterate Data Model","text":"<p>You may discover that the data model is incorrect (\"Wait!  Customers have multiple addresses!!\").  </p> <p>In a conventional system, this would mean revising the API and App.  However, since these are created instantly through automation, such iterations are trivial.  Just rebuild.</p> <p> </p>"},{"location":"Logic-Tutorial/#2b-define-behave-scenarios","title":"2b. Define Behave Scenarios","text":"<p>Running screens also spark insight about the Features (\"Place Order\") and Scenarios (\"Check Credit\"): \"When the customer places an order, we need to reject it if it exceeds the credit limit\".  Capture these as described below.</p> <p>Behave is designed for business user collaboration by making Features and Scenarios transparent.  Start using Behave by defining one or more <code>.feature</code> files.</p> <p>For example, see the <code>place_order.feature</code>, as tested by the <code>Bad Order: Custom Service</code> Scenario, below.</p> <p></p> <p> </p>"},{"location":"Logic-Tutorial/#add-custom-service","title":"Add Custom Service","text":"<p>While the automatically-created API is a great start, you may uncover a need for a custom service.  This is easy to add - it's only about 10 lines of Python (<code>api/customize_api.py</code>), since the logic (discussed below) is enforced in the underlying data access.  For details, see here.</p> <p> </p>"},{"location":"Logic-Tutorial/#2c-logic-design","title":"2c. Logic Design","text":"<p>We now choose a scenario (e.g, <code>Bad Order</code>), and engage business users for a clear understanding of check credit.  This follows a familiar step-wise definition of terms:</p> Analyst Question Business User Answer What do you mean by Check Credit? The balance must be less than the credit limit What is the Balance? The sum of the unshipped order amount totals What is the Order AmountTotal? The sum of the Order Detail Amounts What is the Amount? Price * Quantity What is the Price? It's copied from the Product (unaffected by subsequent changes) <p>We capture in text as shown below.</p> <p>Note this \"cocktail napkin spec\" is short, yet clear.  That's because instead of diving unto unnecessary technical detail of how (such as pseudocode), it focuses on what.</p> <p></p> <p> </p>"},{"location":"Logic-Tutorial/#3a-declare-logic-from-design","title":"3a. Declare Logic (from design)","text":"<p>Business Logic is the heart of the system, enforcing our business policies.  Logic consists of multi-table constraints and derivations, and actions such as sending email and messages.  A core Behave objective is to define and test such behavior.</p> <p>It's generally accepted that such domain-specific logic must require domain-specific code.  The problem is that this is:</p> <ul> <li>slow (it's often nearly half the system).</li> <li>opaque to business users.</li> <li>painful to maintain - it's no secret that developers hate maintenance, since it's less coding than \"archaeology\".  A painful amount of time is spent reading the existing code, to understand where to insert the new logic.</li> </ul> <p>Ideally, our logic design is executable. </p> <p>So, API Logic Server provides Logic Automation, where logic is implemented as:</p> <ul> <li> <p>Spreadsheet-like rules for multi-table derivations and constraints, and</p> </li> <li> <p>Python, to implement logic not addressed in rules such as sending email or messages</p> </li> </ul> <p>So, instead of several hundred lines of code, we declare 5 rules (more details here).  </p> <p>Rules are entered in Python, with code completion, as shown below.  Observe how they exactly correspond to our design, and are executable by the API Logic Server rules engine:</p> <p></p> <p>Unlike manual code, logic is declarative:</p> <ul> <li>automatically reused - re-use is usually achieved by careful design; rules make re-use automatic:</li> <li>Since rules are about the data (not a specific transaction), they automate all the transactions that touch the data (add order, delete order, change order shipped date, etc).  Even ones you might have overlooked (move order to different customer).</li> <li>Since rules are enforced as part of the API, they are automatically shared across all screens and services.</li> <li>automatically ordered - maintenance is simply altering the rules; the system computes their execution order by automatically discovering their dependencies.  No more archaeology.</li> <li>transparent - business users can read the spreadsheet-like rules.  We'll exploit this in the Behave Logic Report, described below.</li> </ul> <p> </p> <p>Key Takeaway: spreadsheet-like rules can dramatically reduce the effort for backend logic, and make it transparent</p> <p> </p> <p>Key Takeaway: keep your Logic Design high level (what not how -- think spreadsheet), and your design will often map directly to executable rules. </p> <p> </p>"},{"location":"Logic-Tutorial/#3b-coderun-behave-scenarios","title":"3b. Code/Run Behave Scenarios","text":"<p>Implement the actual scenarios (tests) in Python (<code>place_order.py</code>), using annotations (<code>@when</code>) to match scenarios and implementations.  In this project, the implementation is basically calling APIs to get old data, run transactions, and check results.</p> <p></p> <p>Execute the tests using the pre-supplied Launch Configurations:</p> <ol> <li>Run Launch Configuration <code>API Logic Server</code> </li> <li>Run Launch Configuration <code>Run Behave Logic</code> </li> </ol> <p>The rules fire as transactions are run, and produce Logic Log files later used in Report Behave Logic (described below): </p> <ol> <li><code>test/api_logic_server_behave/behave.log</code> - summarizes test success / failure</li> <li><code>api_logic_server_behave/scenario_logic_logs/Bad_Order_Custom_Service.log</code> - Logic Log output.</li> </ol> <ul> <li>The code on line 161 signals the name of Logic Log</li> <li> <p>Note the Logic Log actually consists of 2 sections:</p> <ul> <li>The first shows each rule firing, including complete old/new row values, with    indentation for <code>multi-table chaining</code></li> <li>The \"Rules Fired\" summarizes which rules actually fired, representing a confirmation of our Logic Design</li> </ul> </li> </ul> <p>You can use the debugger to stop in a test and verify results</p> <p> </p>"},{"location":"Logic-Tutorial/#4-create-behave-logic-report","title":"4. Create Behave Logic Report","text":"<p>The log files are pretty interesting: a record of all our Features and Scenarios, including transparent underlying logic.  The problem is that it's buried in some text files inside our project.</p> <p>Ideally, publishing this in a transparent manner (e.g., a wiki accessible via the Browser) would be a great asset to the team.</p> <p>So, API Logic Server provides <code>report_behave_logic.py</code> to create a Behave Logic Report - including logic - as a wiki file.</p> <p>To run it, use Launch Configuration <code>Behave Logic Report</code>:</p> <ol> <li>Reads your current <code>readme.md</code> file (text like you are reading now), and</li> <li> <p>Appends the Behave Logic Report: by processing the files created in step 3b</p> </li> <li> <p>Reading the <code>behave.log</code>, and</p> </li> <li>Injecting the <code>scenario_logic_logs</code> files</li> <li>Creates the output report as a wiki file named <code>report_behave_logic.md</code></li> </ol> <p> </p> <p>Key Takeaway: Behave makes requirements and tests transparent; rules make your logic transparent; combine them both into the Behave Logic Report.</p> <p> </p>"},{"location":"Logic-Tutorial/#process-summary-automation-collaboration","title":"Process Summary: Automation + Collaboration","text":"<p>We've seen these key points:</p> <ol> <li> <p>API Logic Server kick-starts projects with automated creation of Admin Apps.</p> </li> <li> <p>Working software promotes business user collaboration using Behave, to iterate the data model and create Logic Designs.</p> </li> <li> <p>Logic Designs are automated with spreadsheet-like rules.</p> </li> <li> <p>Behave creates an executable Test Suite.</p> </li> <li> <p>Test Suite execution creates a Behave Logic Report: your Features, Scenarios, Test Results, and the underlying rules-based logic.</p> </li> </ol> <p>Automation enables you to deliver projects faster; the Agile/Behave encourages collaboration to reduce requirements risk.</p> <p></p> <p> </p>"},{"location":"Logic-Tutorial/#appendix-executing-basic-tests","title":"Appendix: Executing Basic Tests","text":"<p>In addition to Behave, you can use manual approaches for testing:</p> Click to see how to run Basic tests <p></p> <p>After you've created the sample project, you can execute pre-defined tests as shown above:</p> <ol> <li>Start the Server (e.g., under VS Code, Launch Configuration ApiLogicServer)</li> <li>Open a terminal window, and <code>cd test/basic; python server_test.py go</code></li> <li>Examine the log in the Debug Console</li> </ol> <p>You can build similar tests for your systems as you would in any project, either in Python (as shown here), in shell scripts (see the supplied example), etc.</p>"},{"location":"Logic-Type-Constraint/","title":"Constraints","text":"<p> TL;DR - Specify expression / function that must be true, else exception</p> <p>Constraints declare an expression (lambda) or function that must be true for a transaction to complete.  You also provide a message that is returned in the exception that is raised if the expression is not true.</p>"},{"location":"Logic-Type-Constraint/#provide-expression-as-lambda","title":"Provide expression as lambda","text":"<p>The simplest contraint is shown below.  The first rule is a constraint using a lambda.  Note the argument is the row, providing access to the attributes.  </p> <p>You can stop in the debuggers and examine values when the lambda is invoked.</p> <p></p>"},{"location":"Logic-Type-Constraint/#provide-function-old_row-verb","title":"Provide function - old_row, verb","text":"<p>For more complex cases, you can provide a function.  Note the arguments include <code>old_row</code> and <code>logic_row</code>.  The latter provides access to the verb, so you can make your logic apply only to the desired verbs.</p> <p></p> <p> </p>"},{"location":"Logic-Type-Constraint/#commit-constraints-aggregate-values","title":"Commit constraints - aggregate values","text":"<p>If your constraint needs to reference derived sums or counts, note these are not derived when the row is initially processed.  You can address such situations using CommitConstraints.</p>"},{"location":"Logic-Type-Copy/","title":"Copy","text":"<p> TL;DR - Derive Attribute from parent -- parent changes do not propagate</p> <p>Copy rules provide parent access, without propagation.   They are declared in the <code>declare_logic()</code> function in <code>logic/declare_logic.py</code>.</p> <p>Constrast this to Formula derivation rules which enable parent references, with propogation.</p> <p> </p>"},{"location":"Logic-Type-Copy/#declare-copy-rule","title":"Declare Copy Rule","text":"<p>In this example, Product UnitPrice changes are not propagated to existing OrderDetails.  So, your Monday purchase is not affected by a Tuesday price change:</p> <pre><code>Rule.copy(derive=models.OrderDetail.UnitPrice,  # get Product Price (e,g., on insert, or ProductId change)\n        from_parent=models.Product.UnitPrice)\n</code></pre>"},{"location":"Logic-Type-Events/","title":"Events","text":"<p> TL;DR - Specify expression / function that must be true, else exception</p> <p>Events are callouts to Python functions, supplying <code>logic_row</code> as a argument.  Events provide extensibility, to address non-database logic (e.g., sending email and messages), and for complex logic that cannot be addressed in rules. </p> <p> </p>"},{"location":"Logic-Type-Events/#defining-events","title":"Defining Events","text":"<p>To define events, you must declare and implement them, as described below.</p> <p> </p>"},{"location":"Logic-Type-Events/#declare-event-rule","title":"Declare Event Rule","text":"<p>Declare the event, identifying the class and function to call:</p> <pre><code>Rule.commit_row_event(on_class=models.Order, calling=congratulate_sales_rep)\n</code></pre> <p> </p>"},{"location":"Logic-Type-Events/#implement-python-function","title":"Implement Python Function","text":"<p>Implement the Python function that handles the event, accepting the supplied arguments:</p> <p></p> <p> </p>"},{"location":"Logic-Type-Events/#event-types","title":"Event Types","text":"<p>There are multiple event types so that you can control how your logic executes within the rule engine.</p> <p> </p>"},{"location":"Logic-Type-Events/#early_row_event","title":"<code>early_row_event</code>","text":"<p>These operate before your derivation / constraint logic executes for each row.  So, for example, derivations have not been performed.</p> <p> </p>"},{"location":"Logic-Type-Events/#early_row_event_all_classes","title":"<code>early_row_event_all_classes</code>","text":"<p>These operate before your logic executes for each row for any class.  It is an excellent way to implement generic logic such as time/date stamping.  It is also used by the system to activate optimistic locking logic, as shown below.</p> <pre><code>def handle_all(logic_row: LogicRow):  # OPTIMISTIC LOCKING, [TIME / DATE STAMPING]\n        \"\"\"\n        This is generic - executed for all classes.\n\n        Invokes optimistic locking.\n\n        You can optionally do time and date stamping here, as shown below.\n\n        Args:\n                logic_row (LogicRow): from LogicBank - old/new row, state\n        \"\"\"\n        if logic_row.is_updated() and logic_row.old_row is not None and logic_row.nest_level == 0:\n                opt_locking.opt_lock_patch(logic_row=logic_row)\n        enable_creation_stamping = True  # CreatedOn time stamping\n        if enable_creation_stamping:\n                row = logic_row.row\n                if logic_row.ins_upd_dlt == \"ins\" and hasattr(row, \"CreatedOn\"):\n                row.CreatedOn = datetime.datetime.now()\n                logic_row.log(\"early_row_event_all_classes - handle_all sets 'Created_on\"'')\n\nRule.early_row_event_all_classes(early_row_event_all_classes=handle_all)\n</code></pre> <p> </p>"},{"location":"Logic-Type-Events/#row_event","title":"<code>row_event</code>","text":"<p>These operate after your derivation / constraint logic executes for each row.  So, for example, derivations have been performed.</p> <p> </p>"},{"location":"Logic-Type-Events/#commit_row_event","title":"<code>commit_row_event</code>","text":"<p>These operate after logic executes for all rows.  So, for example, sums and counts have been computed.  </p> <p></p> <p> </p>"},{"location":"Logic-Type-Formula/","title":"Formula","text":"<p> TL;DR - Derive attribute using other attributes of current/parent class</p> <p>Formula rules are lambda expressions or functions that can reference other attributes of current/parent class.  They are declared in the <code>declare_logic()</code> function in <code>logic/declare_logic.py</code>.</p> <p>Execution order is system-determined based on dependencies.</p> <p>Changes to referenced parent attributes are propagated to all child rows.  Contrast this to the <code>Copy</code> rule, for parent references where you do not want propagation.</p> <p>Formulas may be pruned if there are no changes to the referenced attributes.</p> <p> </p>"},{"location":"Logic-Type-Formula/#provide-expression-as-lamda","title":"Provide expression as lamda","text":"<p>Simple formulas are most easily expressed as lambda functions:</p> <pre><code>Rule.formula(derive=models.OrderDetail.Amount,  # compute price * qty\n        as_expression=lambda row: row.UnitPrice * row.Quantity)\n</code></pre> <p> </p>"},{"location":"Logic-Type-Formula/#provide-expression-as-function","title":"Provide expression as function","text":"<pre><code>   def derive_amount(row: models.Item, old_row: models.Item, logic_row: LogicRow):\n       amount = row.Quantity * row.UnitPrice\n       if row.Product.CarbonNeutral and row.Quantity &gt;= 10:\n           amount = amount * Decimal(0.9)\n       return amount\n\n\n   Rule.formula(derive=models.Item.Amount, calling=derive_amount)\n</code></pre>"},{"location":"Logic-Type-Sum/","title":"Sum","text":"<p> TL;DR - Derive parent-attribute as sum of designated child attribute; optional child qualification</p> <p>Sum derivations enable you to aggregate child data.  They are declared in the <code>declare_logic()</code> function in <code>logic/declare_logic.py</code>.</p> <p>Sums are efficient: child changes result in a 1 row adjustment update, not an expensive <code>select sum</code>.  And, they are pruned entirely if child does not alter the summed field or the qualification condition.</p> <p> </p>"},{"location":"Logic-Type-Sum/#defining-sums","title":"Defining Sums","text":"<p>You declare sums in xxx:</p> <pre><code>Rule.sum(derive=models.Customer.Balance,        # adjust iff AmountTotal or ShippedDate or CustomerID changes\n        as_sum_of=models.Order.AmountTotal,\n        where=lambda row: row.ShippedDate is None)  # adjusts - *not* a sql select sum...\n</code></pre>"},{"location":"Logic-Type-Sum/#insert-parent-option","title":"Insert Parent option","text":"<p>In most cases, the parent must exist or an exception will be thrown.  However, you may wish to create \"group by\" aggregates rows; see the Budget App.</p> <p>You can achieve this effect with the <code>insert_parent</code> parameter:</p> <pre><code>Rule.sum(derive=models.YrTotal.budget_total, as_sum_of=models.CategoryTotal.budget_total,insert_parent=use_parent_insert)\n</code></pre>"},{"location":"Logic-Use/","title":"Using Logic","text":"<p> TL;DR - Using Logic: Understand functions vs. lambda, logic_row</p> <p>For constraints / formulas that require an expression, you can use     lambdas or functions.</p> <p>Functions have a <code>logic_row</code> arguments, providing access to old/new row, verb, etc.</p> <p> </p>"},{"location":"Logic-Use/#declaration-and-activation","title":"Declaration and Activation","text":"<p>Declared rules are automatically activated by <code>api_logic_server_run.py</code> when it starts the server.  For more information, please see Project Operation.</p> <p> </p>"},{"location":"Logic-Use/#function-vs-lambda","title":"Function vs. Lambda","text":"<p>Constraint and Formula rules have arguments for providing an expression.  There are two ways to do this.</p> <p>For simple expressions, provide a lambda (inline) function, e.g.:</p> <pre><code>    Rule.formula(derive=models.OrderDetail.Amount,  # compute price * qty\n        as_expression=lambda row: row.UnitPrice * row.Quantity)\n</code></pre> <p>To get access to <code>old_row</code> and <code>logic_row</code>, specify a function, e.g.:</p> <pre><code>    \"\"\"\n        Demonstrate that logic == Rules + Python (for extensibility)\n    \"\"\"\n    def congratulate_sales_rep(row: models.Order, old_row: models.Order, logic_row: LogicRow):\n        \"\"\" use events for sending email, messages, etc. \"\"\"\n        if logic_row.ins_upd_dlt == \"ins\":  # logic engine fills parents for insert\n            sales_rep = row.Employee        # parent accessor\n            if sales_rep is None:\n                logic_row.log(\"no salesrep for this order\")\n            elif sales_rep.Manager is None:\n                logic_row.log(\"no manager for this order's salesrep\")\n            else:\n                logic_row.log(f'Hi, {sales_rep.Manager.FirstName} - '\n                              f'Congratulate {sales_rep.FirstName} on their new order')\n            category_1 = logic_row.session.query(models.Category).filter(models.Category.Id == 1).one()\n            logic_row.log(\"Illustrate database access (not subject to authorization)\")  # not granted for user: u2\n\n    Rule.commit_row_event(on_class=models.Order, calling=congratulate_sales_rep)\n</code></pre> <p> </p>"},{"location":"Logic-Use/#logicrow-old_row-verb-etc","title":"LogicRow: old_row, verb, etc","text":"<p><code>LogicRow</code> is a system object you can access in declaring rules.  From the online documentation (use code completion):</p> <p> TL;DR - LogicRow provides access to <code>old_row</code>, <code>ins_upd_dlt</code> etc.</p> <p>Wraps <code>row</code> and <code>old_row</code>, plus methods for detecting insert, update and delete</p> <p>Additional instance variables: ins_upd_dlt, nest_level, session, etc.</p> <p>Helper Methods:</p> <ul> <li>are_attributes_changed, set_same_named_attributes, get_parent_logic_row(role_name), get_derived_attributes, log, etc</li> </ul> <p>Here is an example:</p> <pre><code>\"\"\"\n    STATE TRANSITION LOGIC, using old_row\n\"\"\"\ndef raise_over_20_percent(row: models.Employee, old_row: models.Employee, logic_row: LogicRow):\n    if logic_row.ins_upd_dlt == \"upd\" and row.Salary &gt; old_row.Salary:\n        return row.Salary &gt;= Decimal('1.20') * old_row.Salary\n    else:\n        return True\n\nRule.constraint(validate=models.Employee,\n                calling=raise_over_20_percent,\n                error_msg=\"{row.LastName} needs a more meaningful raise\")\n</code></pre> <p>Note the <code>log</code> method, which enables you to write row/old_row into the log with a short message:</p> <pre><code>logic_row.log(\"no manager for this order's salesrep\")\n</code></pre> <p>Use code completion to see the full list of methods and properties:</p> <p></p> <p>You can find examples of these services in the sample <code>ApiLogicProject</code>.</p> <p> </p>"},{"location":"Logic-Use/#inserting-new-rows","title":"Inserting New Rows","text":"<p>Inserting coding depends on whether you are already in the context of a logic_row (\"in logic\"), or not (\"in APIs and Messages\").  These are described below.</p> <p> </p>"},{"location":"Logic-Use/#in-apis-and-messages","title":"In APIs and Messages","text":"<p>In API/Message development, you can submit transaction payloads as shown below:</p> <pre><code>class ServicesEndPoint(safrs.JABase):\n\n    @classmethod\n    @jsonapi_rpc(http_methods=[\"POST\"])\n    def OrderB2B(self, *args, **kwargs):  # yaml comment =&gt; swagger description\n        \"\"\" # yaml creates Swagger description\n            args :\n                order:\n                    AccountId: \"ALFKI\"\n                    Given: \"Steven\"\n                    Surname: \"Buchanan\"\n                    Items :\n                    - ProductName: \"Chai\"\n                      QuantityOrdered: 1\n                    - ProductName: \"Chang\"\n                      QuantityOrdered: 2\n            ---\n\n        Note attribute alias, Lookup automation in OrderB2B\n\n        See: https://apilogicserver.github.io/Docs/Sample-Integration/\n        Test with swagger, or, from command line:\n\n        $(venv) ApiLogicServer login --user=admin --password=p\n        $(venv) ApiLogicServer curl \"'POST' 'http://localhost:5656/api/ServicesEndPoint/OrderB2B'\" --data '\n        {\"meta\": {\"args\": {\"order\": {\n            \"AccountId\": \"ALFKI\",\n            \"Surname\": \"Buchanan\",\n            \"Given\": \"Steven\",\n            \"Items\": [\n                {\n                \"ProductName\": \"Chai\",\n                \"QuantityOrdered\": 1\n                },\n                {\n                \"ProductName\": \"Chang\",\n                \"QuantityOrdered\": 2\n                }\n                ]\n            }\n        }}}'\n\n        \"\"\"\n\n        db = safrs.DB         # Use the safrs.DB, not db!\n        session = db.session  # sqlalchemy.orm.scoping.scoped_session\n\n        order_b2b_def = OrderB2B()\n        request_dict_data = request.json[\"meta\"][\"args\"][\"order\"]\n        sql_alchemy_row = order_b2b_def.dict_to_row(row_dict = request_dict_data, session = session)\n\n        session.add(sql_alchemy_row)\n        return {\"Thankyou For Your OrderB2B\"}  # automatic commit, which executes transaction logic\n</code></pre> <p>Salient points:</p> <ol> <li>Note the process of obtaining a <code>session</code> from safrs (the api engine)</li> <li>Note the use of the <code>OrderB2B</code> \"RowDictMapper\" to transform payload  data into row instances</li> <li>Observe that you add the row to the session; logic execution is automatic</li> </ol> <p> </p>"},{"location":"Logic-Use/#in-logic","title":"In Logic","text":"<p>In logic development, before you save a new row, you will first need to instantiate a new row instance.  Consider the following code from the sample app <code>logic/declare_logic.py</code>:</p> <pre><code>    if preferred_approach:  # #als: AUDITING can be as simple as 1 rule\n        RuleExtension.copy_row(copy_from=models.Employee,\n                            copy_to=models.EmployeeAudit,\n                            copy_when=lambda logic_row: logic_row.ins_upd_dlt == \"upd\" and \n                                    logic_row.are_attributes_changed([models.Employee.Salary, models.Employee.Title]))\n    else:\n        def audit_by_event(row: models.Employee, old_row: models.Employee, logic_row: LogicRow):\n            tedious = False  # tedious code to repeat for every audited class\n            if tedious:      # see instead the RuleExtension.copy_row above (you can create similar rule extensions)\n                if logic_row.ins_upd_dlt == \"upd\" and logic_row.are_attributes_changed([models.Employee.Salary, models.Employee.Title]):\n                    # #als: triggered inserts  \n                    copy_to_logic_row = logic_row.new_logic_row(models.EmployeeAudit)\n                    copy_to_logic_row.link(to_parent=logic_row)\n                    copy_to_logic_row.set_same_named_attributes(logic_row)\n                    copy_to_logic_row.insert(reason=\"Manual Copy \" + copy_to_logic_row.name, row=copy_to_logic_row.row)  # triggers rules...\n\n        Rule.commit_row_event(on_class=models.Employee, calling=audit_by_event)\n</code></pre> <p>If you are doing auditing (a common pattern), we recommend you consider <code>copy_row</code>.  The alternative coding illustrates how do do insert manually, using <code>logic_row.new_logic_row(models.EmployeeAudit)</code>.</p> <p> </p>"},{"location":"Logic-Use/#insert-defaulting","title":"Insert defaulting","text":"<p>In either case, the new logic row is returned with default values.  These are obtained from your database schema, via <code>database/models.py</code>.  For example:</p> <p></p> <p>Observe the <code>server_default</code> property.  This value is used by LogicBank, as follows:</p> <ol> <li> <p>Defaults are applied when instantiating a new row, and for default values when saving an inserted row</p> </li> <li> <p>Only constant values are defaulting, and dates and datetimes with the value <code>CURRENT_TIMESTAMP</code></p> </li> <li> <p>Defaulted values are depicted on the server console</p> </li> </ol> <p> </p>"},{"location":"Logic-Use/#aggregates-defaulted-to-0","title":"Aggregates defaulted to 0","text":"<p>Aggregate derivations (sums and counts) are defaulted to 0.</p> <p> </p>"},{"location":"Logic-Use/#all-defaults","title":"All Defaults","text":"<p>You can set the environment variable <code>ALL_DEFAULTS</code> to force numeric values to 0, and string values to the null string.  This has no effect on dates.</p> <p> </p>"},{"location":"Logic-Use/#updating-and-deleting","title":"Updating and Deleting","text":"<p>These require you first obtain the row, either through a model class accessor (e.g., retrieve a parent row), or a SQLAlchemy call.  In any case, alter the row as required, and issue `logic_row.update()' (or delete).  As for insert, this triggers logic execution.</p> <p> </p>"},{"location":"Logic-Use/#managing-logic","title":"Managing Logic","text":"<p>Declare Rules in your IDE (e.g., VSCode, PyCharm).  Logic is expressed in Python.</p> <p>Use WebGenAI or your IDE with Natural Language, or all the familiar IDE features of code completion and syntax high-lighting.  You have full use of the debugger, and familiar Source Code Control tools such as <code>git</code>.</p> <p> </p>"},{"location":"Logic-Use/#logic-debugging","title":"Logic Debugging","text":"<p>If we use Swagger and run <code>ServicesEndPoint - Post/add_order</code>, we get the following:</p> <p></p>"},{"location":"Logic-Use/#ide-debugger","title":"IDE Debugger","text":"<p>This illustrates that you can stop in your rule logic (the red dot on line 111), and use your IDE debugger (here, VSCode) to see variables, step through execution, etc.</p>"},{"location":"Logic-Use/#logic-logging","title":"Logic Logging","text":"<p>In addition, the system creates a logic log of all rules that fire, to aid in debugging by visualizing rule execution:</p> <ul> <li>Each line represents a rule execution, showing row state (old/new values), and the {reason} that caused the update (e.g., client, sum adjustment)</li> <li>Log indention shows multi-table chaining</li> </ul> <p>Logging is performed using standard Python logging, with a logger named <code>logic_logger</code>.  Use <code>info</code> for tracing, and <code>debug</code> for additional information (e.g., a declared rules are logged).</p>"},{"location":"Logic-Use/#vscode-debugging","title":"VSCode debugging","text":"<p>In VSCode, set <code>\"redirectOutput\": true</code> in your Launch Configuration.  This directs logging output to the Debug Console, where it is not word-wrapped (word-wrap obscures the multi-table chaining).</p> <p></p> <p> </p>"},{"location":"Logic-Use/#logic-management","title":"Logic Management","text":""},{"location":"Logic-Use/#standard-source-control","title":"Standard Source Control","text":"<p>Logic is Python code, so is managed using your existing SCSS approach (e.g., <code>git</code>), with related services for diff, merge, history, versioning, etc.</p> <p> </p>"},{"location":"Logic-Use/#organize-using-logic_discovery","title":"Organize using <code>logic_discovery</code>","text":"<p>You can create logic in <code>logic/declare_logic.py</code>, but in most cases it's better to use <code>logic/logic_discovery</code>.  See the Northwind sample (<code>samples/nw_sample</code> in the manager.)</p> <p>Best Practice: organize logic discovery files by Use Case (eg, check_credit.py)</p> <p> </p>"},{"location":"Logic-Use/#logic-test-suites","title":"Logic Test Suites","text":"<p>It's a best practice to set up identify Use Cases, and create test suites that verify proper logic operation.  You can use the Behave framework; for more information, click here.</p>"},{"location":"Logic-Why/","title":"Logic: Why","text":"<p> TL;DR - n-fold Reduction of Backend Logic With Declarative (Spreadsheet-like) Rules</p> <p>For transaction systems, backend multi-table constraint and derivation logic is often nearly half the system.  API Logic Server automates such logic with unique declarative (spreadsheet-like) rules, which can be extended with Python. </p> <p>Declare in Python, debug with your IDE, extend with Python events as needed.</p> <p>Rules are 40X more concise than code.</p> <p>Rules help automate maintenance, since they are automatically called and ordered.</p> <p>Rules are architected for re-use, automatically applied to all UI Apps, Services, and your custom APIs.</p> <p>Rules are architected for scalable multi-table performance, with automatic pruning and use of adjustment logic to avoid expensive aggregate / multi-row queries.</p> <ul> <li>Such optimizations can easily represent multiple orders of magnitude - contrast to Rete engines, ORM services and <code>iterator</code> verbs</li> </ul> <p>This page describes:</p> <ul> <li>how \"code explosion\" makes logic important to your project</li> <li>how you use rules: delcare, extend, debug</li> <li>how the rules operate: watch, react, chain</li> <li>several key aspects of rules, and</li> <li>how rules compare to similar-looking technologies</li> </ul> <p> </p>"},{"location":"Logic-Why/#problem-code-explosion","title":"Problem: Code Explosion","text":"<p>In conventional approaches, such logic is nearly half the system, due to code explosion.  A typical design specification of 5 lines explodes into 200 lines of legacy code.</p> <p>Let's imagine we have a \"cocktail napkin spec\" for checking credit, shown (in blue) in the diagram below.  How might we enforce such logic?</p> <ul> <li> <p>In UI controllers - this is the most common choice.  It's actually the worst choice, since it offers little re-use between forms, and does not apply to non-UI cases such as API-based application integration.</p> </li> <li> <p>Centralized in the server - in the past, we might have written triggers, but a modern software architecture centralizes such logic in an App Server tier.  If you are using an ORM such as SQLAlchemy, you can ensure sharing with <code>before_flush</code> events as shown below.</p> </li> </ul> <p>After we've determined where to put the code, we then have to write it.  Our simple 5 line cocktail napkin specification explodes into 200 lines of legacy code):</p> <p>It's also incredibly repetitive - you often get the feeling you're doing the same thing over and over.</p> <p>And you're right.  It's because backend logic follows patterns of \"what\" is supposed to happen. And your code is the \"how\". </p> <p>So, API Logic Server provides Declarative Business Rules for multi-table derivations and constraints</p> <p>Rules typically automate over 95% of such logic, and are 40X more concise.  You can think of rules as conceptually similar to spreadsheet cell formulas, applied to your database.  </p> <p>For a procedural / declarative analysis by CoPilot, click here.</p> <p> </p>"},{"location":"Logic-Why/#rules-declare-extend-debug","title":"Rules: Declare, Extend, Debug","text":"<p>Use your IDE to declare rules, extend them with Python, and debug them as described below.</p> <p> </p>"},{"location":"Logic-Why/#declare-python","title":"Declare: Python","text":"<p>For this typical check credit design (in blue), the 5 rules shown below (lines 90-105) represent the same logic as 200 lines of code:</p> <p></p> See the code here <pre><code>\"\"\"\nLogic Design (\"Cocktail Napkin Design\") for User Story Check Credit\n    Customer.Balance &lt;= CreditLimit\n    Customer.Balance = Sum(Order.AmountTotal where unshipped and ready)\n    Order.AmountTotal = Sum(OrderDetail.Amount)\n    OrderDetail.Amount = Quantity * UnitPrice\n    OrderDetail.UnitPrice = copy from Product\n\"\"\"\n\nRule.constraint(validate=models.Customer,       # logic design translates directly into rules\n    as_condition=lambda row: row.Balance &lt;= row.CreditLimit,\n    error_msg=\"balance ({row.Balance}) exceeds credit ({row.CreditLimit})\")\n\nRule.sum(derive=models.Customer.Balance,        # adjust iff AmountTotal or ShippedDate or CustomerID changes\n    as_sum_of=models.Order.AmountTotal,\n    where=lambda row: row.ShippedDate is None and row.Ready == True  # adjusts - *not* a sql select sum...\n\nRule.sum(derive=models.Order.AmountTotal,       # adjust iff Amount or OrderID changes\n    as_sum_of=models.OrderDetail.Amount)\n\nRule.formula(derive=models.OrderDetail.Amount,  # compute price * qty\n    as_expression=lambda row: row.UnitPrice * row.Quantity)\n\nRule.copy(derive=models.OrderDetail.UnitPrice,  # get Product Price (e,g., on insert, or ProductId change)\n    from_parent=models.Product.UnitPrice)\n\n\"\"\"\n    Demonstrate that logic == Rules + Python (for extensibility)\n\"\"\"\ndef congratulate_sales_rep(row: models.Order, old_row: models.Order, logic_row: LogicRow):\n    \"\"\" use events for sending email, messages, etc. \"\"\"\n    if logic_row.ins_upd_dlt == \"ins\":  # logic engine fills parents for insert\n        sales_rep = row.Employee\n        if sales_rep is None:\n            logic_row.log(\"no salesrep for this order\")\n        elif sales_rep.Manager is None:\n            logic_row.log(\"no manager for this order's salesrep\")\n        else:\n            logic_row.log(f'Hi, {sales_rep.Manager.FirstName} - '\n                            f'Congratulate {sales_rep.FirstName} on their new order')\n\nRule.commit_row_event(on_class=models.Order, calling=congratulate_sales_rep)\n</code></pre> <p>Notes:</p> <ol> <li> <p>Rather than learn a new studio, use your IDE code completion services for logic declaration - just type <code>Rule.</code>   Your IDE and Python combine to enable Python as a DSL. </p> </li> <li> <p>See here for the list of rule types, and recommended training for learning to use rules.</p> </li> <li> <p>Unlike procedural code, you neither \"call\" the rules, nor order their execution</p> <ul> <li>The Logic Bank rule engine watches SQLAlchemy updates, and ensures the relevant rules are optimized and executed in the proper order per system-discovered rule dependencies.</li> </ul> </li> </ol> <p> </p>"},{"location":"Logic-Why/#extend-python","title":"Extend: Python","text":"<p>While 95% is certainly remarkable, it's not 100%.  Automating most of the logic is of no value unless there are provisions to address the remainder.</p> <p>That provision is standard Python, provided as standard events:  Logic = Rules + Python.  (See lines 87-100 in the <code>event</code> example, below).  This will be typically be used for non-database oriented logic such as files and messages, and for extremely complex database logic.</p> <p>The system provides <code>logic_row</code> to access the <code>old_row</code>, determine the verb, etc.  For more information, see Logic Row.</p> `event` example <p></p> <p>If code completion isn't working, ensure your <code>venv</code> setup is correct - consult the Trouble Shooting Guide.</p> <p> </p>"},{"location":"Logic-Why/#debug-your-ide","title":"Debug: your IDE","text":"<p>Test your logic by making updates using the Admin App, Swagger API documentation, cURL, etc.</p> <p>As shown in Logic Debugging, you can use your IDE debugger to logic rules.  In addition, logic execution creates a useful Logic Log, showing the rules that execute, the row state, and nesting.</p> <p> </p>"},{"location":"Logic-Why/#iterate-alter-rules","title":"Iterate: alter rules","text":"<p>To iterate (debug cycles and maintenance), simply alter the rules and add new ones - in any order.  The system ensures they will be called, in the proper order.  This helps to ensure correctness, and eliminates the need to determine where to insert new logic.</p> <p> </p>"},{"location":"Logic-Why/#documentation-and-testing","title":"Documentation and Testing","text":"<p>Use any standard test framework for system testing.  One option is to use the Behave framework to capture requirements as tests, and then execute your test suite.  API Logic server can generate a wiki Behave Logic Report, reflecting the requirements, including the rules that execute in each test.</p> <p> </p>"},{"location":"Logic-Why/#watch-react-chain","title":"Watch, React, Chain","text":"<p>The LogicBank rule engine opertes by plugging into SQLAlchemy <code>beforeFLush</code> events, to:</p> <ul> <li>watch for changes -  at the attribute level; for changed attributes...</li> <li>react by running rules that referenced changed attributes, which can...</li> <li> <p>chain to still other attributes that refer to those changes.  </p> <ul> <li>Note these might be in different tables, providing automation for multi-table logic</li> <li>Special optimizations are provided for performance, as described below.</li> </ul> </li> </ul> <p>For more information, see Logic Operation.</p> <p> </p>"},{"location":"Logic-Why/#key-aspects-of-logic","title":"Key Aspects of Logic","text":"<p>While conciseness is the most immediately obvious aspect of logic, rules provide deeper value as summarized below.</p> Concept Rule Automation Why It Matters Re-use Automatic re-use over all resources and actions Velocity / Conciseness: Eliminates logic replication over multiple UI controllers or services. Invocation Automatic logic execution, on referenced data changes Quality: Eliminates the \"code was there but not called\" problem.Rules are active, transforming \u2018dumb\u2019 database objects into smart business objects Execution Order Automatic ordering based on dependencies Maintenance: Eliminates the \"where do I insert this code\" problem - the bulk of maintenance effort. Dependency Management Automatic chaining Conciseness: Eliminates the code that tests \"what's changed\" to invoke relevant logic Multi-Table Chaining Multi-Table Transactions Simplicity: Eliminates and optimizes data access code Persistence Automatic optimization Performance: Unlike Rete engines which have no concept of old values, transaction logic can prune rules for unchanged data, and optimize for adjustment logic based on the difference between old/new values.  This can literally result in sub-second performance instead of multiple minutes, and can be tuned without recoding.. <p>See also the FAQs.</p> <p> </p>"},{"location":"Logic-Why/#concise-dependencies","title":"Concise: Dependencies","text":"<p>Consider the rule <code>Customer.Balance = Sum(Order.AmountTotal where unshipped)</code>.  In a procedural system, you would write dependency mangement code, checking:</p> <ul> <li>Did the <code>Order.AmountTotal</code> change?</li> <li>Did the <code>Order.DateShippedDate</code> change?</li> <li>Was the Order inserted?</li> <li>Was the Order deleted?</li> <li>Did the <code>Order.CustomerId</code> (foreign key) change?</li> </ul> <p>In a declarative system, dependency management is automated, eliminating this effort.  This is a signifcant reason that rulea are n-fold more concise as explained at the top of this page.</p> <p> </p>"},{"location":"Logic-Why/#automatic-ordering","title":"Automatic Ordering","text":"<p>While the conciseness of rules is probably their most striking aspect, automatic ordering provides significant value in automating maintenance.  In a procedural system, introducing a change requires archaeology: read the existing code to determine where to insert the new code.</p> <p>In a declarative system, ordering is automated.  The system parses your derivation rules to determine dependencies, and uses this to order execution.  This occurs once per session on activation, so rule declaration changes automatically determine a new order.  </p> <p>This is significant for iterative development and maintenance, eliminating the archaeology time spent determining where do I insert this new logic.</p> <p> </p>"},{"location":"Logic-Why/#automatic-reuse","title":"Automatic Reuse","text":"<p>In a procedural system, reuse is achieved with careful manual design.  In a declarative system, reuse occurs automatically, at multiple levels:</p> <ul> <li> <p>Architectural Reuse: rules are defined for your data, not a specific page or service.  They therefore to apply to all transaction sources.</p> <ul> <li>Internally, the LogicBank rule engine plugs into SQLAlchemy <code>beforeFlush</code> events.</li> </ul> </li> <li> <p>Use Case Reuse: just as a spreadsheet reacts to inserts, updates and deletes to a summed column, rules automate adding, deleting and updating orders. This results in a \"design one / solve many\" scenario.</p> </li> </ul> <p>Our cocktail napkin spec is conceptually similar to a set of spreadsheet-like rules that govern how to derive and constrain our data. \u00a0And by conceiving of the rules as associated with the data (instead of a UI button), rules conceived for Place Order automatically address these related transactions:</p> <ul> <li>add order</li> <li>Ship Order illustrates cascade, another form of multi-table logic</li> <li>delete order</li> <li>assign order to different customer</li> <li>re-assign an Order Detail to a different Product, with a different quantity</li> <li>add/delete Order Detail</li> </ul> <p> </p>"},{"location":"Logic-Why/#scalability-prune-and-optimize","title":"Scalability: Prune and Optimize","text":"<p>In a procedural system, you write code to read and write rows, optimize such access, and bundle transactions.  In a declarative system, persistence is automated - and optimized. </p> <p>When Performance Matters</p> <p>Modern computers are incredibly fast, and modern architectures can provide clustering.  Productive languages (like Python) should no longer be a concern.</p> <p>That said, it is still important to consider algorithms that can incur substantial database / network overhead.  That is why the issues discussed here are important.  Experience has shown these can result in response times of seconds instead of minutes.</p> <p>For example, the balance rule:</p> <ul> <li>is pruned if only a non-referenced column is altered (e.g., Shipping Address)</li> <li>is optimized into a 1-row adjustment update instead of an expensive SQL aggregate</li> </ul> <p>For more on how logic automates and optimizes multi-table transactions, click here.</p> <p> </p>"},{"location":"Logic-Why/#faq-similar-looking-alternatives","title":"FAQ: Similar Looking Alternatives","text":"<p>At first glance, declarative logic looks quite similar to other familiar approaches.  But while the code may look similar, the differences are quite significant.</p> <p>For example, consider the rule: Customer Balance Rule Example<pre><code>Customer.Balance = Sum(Order.AmountTotal where unshipped and ready)\n</code></pre></p> <p> </p>"},{"location":"Logic-Why/#sql-declarative-read-not-logic","title":"SQL: declarative read, not logic","text":"<p>SQL itself has a <code>select sum()</code> that looks equivalent.  It's a declarative read that you call from your procedural code.</p> <p>So, the difference is not the syntax, it's that the calling code is procedural.  Procedural Logic robs you of all the advantages noted above: not concise, not ordered to facilitate maintenance, and error prone.</p> <p>The <code>sum</code> rule is, in fact, not a \"read\" at all.  It's an end condition, that the system guarantees will be true when the transaction is committed.  Declarative logic is a set of such rules managed by the system - you neither call nor order them.</p> <p> </p>"},{"location":"Logic-Why/#iterator-verb-declarative-logic","title":"Iterator Verb: declarative logic?","text":"<p>Python (and several Low Code scripting languages) provide power verbs like:</p> Iterator Verb (caution: poor practice)<pre><code>balance = sum(order.amount_total for order in customer.orders if order.date_shipped is None)\n</code></pre> <p>The code above implies an expensive multi-row query to read the orders for a customer.  There are several problems:</p> <ul> <li>It's often not declarative - if you must write code that determines when to call this (aka dependency management), your logic is procedural, not declarative.</li> <li>It's expensive if there are many orders</li> <li>It doesn't even work if <code>order.amount_total</code> is not stored.  Adding up all the <code>Item.Amount</code> values - for each of the orders - makes it n times more expensive.</li> </ul> <p> </p>"},{"location":"Logic-Why/#visual-programming","title":"Visual Programming","text":"<p>Flowchart-like diagrams are attractive, and quite approopriate for process logc (a complement to transaction logic).  But it is highly procedural, so the 200 lines of procedural code turns into 200 nodes in a diagram.  Declarative rules are a far more appropriate technology for transaction logic.</p> <p> </p>"},{"location":"Logic-Why/#rete-too-coarse","title":"Rete: too coarse","text":"<p>Rete engines provide similar inference rules.   Experienced developers know they can be useful (e.g., Decision Tables), but should be avoided for multi-table logic.  This is because they do not - cannot - provide adjustment logic.  For more information, see RETE.</p> <p> </p>"},{"location":"Logic-Why/#orm-too-coarse","title":"ORM: too coarse","text":"<p>Some ORMs (Object Relational Managers), such as Hibernate, allow similar verbs.  But again, experienced developers avoid these because they perform poorly:</p> <ol> <li>They are too coarse: a <code>select sum</code> is issued when any order change is made (no pruning)</li> <li>Cost: as above, it's expensive if there are many orders</li> </ol> <p> </p>"},{"location":"Logic-Why/#genai-frankencode","title":"GenAI: Frankencode","text":"<p>You might imagine LLM translating requirements to code.  This approach fails, and even it worked, it would be undesirable to manage a large explosion of frankencode.</p>"},{"location":"Logic/","title":"Logic: Rule Types, Patterns","text":"<p> TL;DR - Logic: multi-table derivations and constraints, using Rules and Python</p> <p>Logic addresses multi-table derivations and constraints, using Rules and Python.  Rules are:</p> <ol> <li>Declared with WebGenAI or IDE and Code Completion - 40X more concise </li> <li>Activated on server start</li> <li>Executed - automatically - on updates (using SQLAlchemy events)</li> <li>Debugged in your IDE, and with the console log</li> </ol> <p>For more on WebGenAI, click here.</p>"},{"location":"Logic/#rule-types","title":"Rule Types","text":"<p>The table shows excerpts only; see the <code>ApiLogicProject</code> (Northwind) sample for full syntax.</p> Rule Summary Example Notes Constraint Boolean function must be Trueelse transaction rolled back <code>row.Balance &lt;= row.CreditLimit</code><code>row.Salary &gt;= Decimal('1.20') * old_row.Salary</code> Multi-field<code>old_row</code> Formula Function computes column value <code>row.UnitPrice * row.Quantity</code><code>row.OrderHeader.ShippedDate</code> lambda, or functionParent <code>(OrderHeader)</code> references Sum Derive parent-attribute as sum of designated child attribute; optional child qualification <code>Rule.sum(derive=Customer.Balance, as_sum_of=Order.AmountTotal,where=lambda row: row.ShippedDate is None)</code> Parent attribute can be hybrid (virtual)scalable: pruning, adjustment Count Derive parent-attribute as count of child rows; optional child qualification <code>Rule.count(derive=Order.OrderDetailCount, as_count_of=OrderDetail)</code> counts are useful as child existence checks Copy Child value set from Parent <code>OrderDetail.ProductPrice = copy(Product.Price)</code> Unlike formula references, parent changes are not propagatede.g, Order totals for Monday are not affected by a Tuesday price increase Event Python Function on insert, call <code>congratulate_sales_rep</code> See Extensibility for a information on early, row and commit events Parent Check Ensure Parent row exists Orders must have a Customer See Referential Integrity Allocation Allocate a provider amount to recipients allocate a payment to outstanding orders See Allocation for an example Copy Row Create child row by copying parent audit Employee Salary changes to EmployeeAudit See Rule Extensibility <p> </p>"},{"location":"Logic/#declaring-rules","title":"Declaring Rules","text":"<p>The table below illustrates that:</p> <ul> <li>You can declare rules in Natural Language (Nat Lang) using your Browser and WebGenAI and/or your IDE.  </li> <li>Rules are stored in your project depending on how they were defined</li> </ul> <p></p> Using Lang Access Using Usage Browser Nat Lang WebGenAI On export, Python rules are stored in <code>logic/wg_rules</code> - details here Your IDE Nat Lang <code>als genai-logic</code> CLI Command Translates Nat Lang <code>docs/logic</code> to <code>logic/logic_discovery</code> - details here Your IDE Nat Lang IDE AI Chat Request Nat Lang logic in AI Chat; paste translated Python result into <code>logic/declare_logic.py</code> or <code>logic/logic_discovery</code> - details here Your IDE Python IDE code completion Rules expressed in Python as a DSLNat Lang rules translated to these <p> </p>"},{"location":"Logic/#genai-natural-language-logic","title":"GenAI: Natural Language Logic","text":"<p>You can use Natural Language to create logic during project creation, or for existing projects.  For example: <code>The Customer's balance is the sum of the Order amount_total where date_shipped is null</code>.</p> <ul> <li>For more information on using Natural Language Logic, see Natural Language Logic.</li> <li>For more information on Managing IDE logic and Natural Language Logic, see WebGenAI Rules and IDE Rules.</li> </ul> <p>Think of Natural Language Logic as a translation process down onto underlying rules -- not a code generator.</p> <p>It is important to learn the rules described here, and to verify proper translation of Natural Language Logic.</p> <p> </p>"},{"location":"Logic/#ide-genai-logic-cli","title":"IDE: GenAI-Logic CLI","text":"<p>You can use Natural Language in your IDE.  See IDE: Natural Language.</p> <p> </p>"},{"location":"Logic/#ide-ai-chat","title":"IDE: AI Chat","text":"<p>The options above use ChatGPT, which requires a paid API key.  You may already have a AI chat enabled in your IDE.  As of release 14.04, projects contain <code>docs/training</code>, which enable some products to translate Natural Language logic into Python rules.</p> <p>For example, the diagram below illustrates the use of VSCode/CoPilot:</p> <ol> <li>Declare your Natural Language in a prompt, and press Enter</li> <li>CoPilot translated Natural Language Logic to Python rules</li> <li>Paste them into your code, in either <code>logic/declare_logic.py</code> or (preferred) a Use-Case specific file such as <code>logic/logic_discovery/check_credit.py</code>:</li> </ol> <p></p> <p> </p>"},{"location":"Logic/#ide-with-code-completion","title":"IDE: With Code Completion","text":"<p>You can also use your IDE with Code Completion to add rules, and their arguments.</p> <p></p> <p> </p>"},{"location":"Logic/#iterative-rules","title":"Iterative Rules","text":"<p>Logic definition is an incremental process.  You can start with a few rules, and add more as needed.  There is no need to define all rules at once, or rebuild the project.</p> <p>Note rules are automatically ordered and invoked, so you can add new ones in any location.</p> <p>Similarly, you can change rules without worrying about the order of execution.</p> <p> </p>"},{"location":"Logic/#learning-rules","title":"Learning Rules","text":"<p>Inside the larger process above, here is the best way to learn how to use rules:</p> <ol> <li> <p>Rule Summary: review the Rule Types table above; there are a small number of rules, since their power lies in chaining</p> <ul> <li>Alert: Logic consists of rules and Python.  You will quickly learn to use logic events; focus on the rules as the preferred approach, using Python (events, etc) as a fallback.</li> </ul> </li> <li> <p>Review the Rule Patterns, below</p> </li> <li> <p>Use the case study approach to learn about using rules, by exploring the examples in the report, below.</p> </li> <li> <p>Be aware of Rule Extensibility.</p> </li> </ol> <p>Pre-req: before learning rules, use the Tutorial to familiarize yourself with basic capabilities and procedures.</p> <p> </p>"},{"location":"Logic/#rule-patterns","title":"Rule Patterns","text":"<p>Rules support chaining: a rule may change a value that triggers other rules, including across tables.  Mastering such multi-table logic is the key to using rules effectively.  The most typical examples are described below.</p> Pattern Notes Example Chain Up parent sums and counts mean that child row changes can adjust parents Derive Balance Constrain a Derived Result constraints may require derived values Balance &lt; creditLimit Chain Down child copy and parent references mean that parent row changes can cascade to children Ship Order State Transition Logic <code>old_row</code> useful comparing old/current values Meaningful Raise Counts as Existence Checks Use counts to check if any children exist Don't Ship Empty Orders Auditing Note the Copy Row rule (and alternatives) Salary Audit Ready Flag Multi-session editing, then , when ready...adjust related data / enforce constraints Make Order Ready Events for Lib Access Events enable Python, use of standard libs (e.g., Kafka) Ship Order Request Pattern Create Row to run service, per logic, e.g. MCP request: \"find overdue orders, and send an email offering a discount\" See MCP Send Mail <p> </p>"},{"location":"Logic/#rules-case-study","title":"Rules Case Study","text":"<p>The best way to learn the rules is by a Case Study approach:</p> <ol> <li> <p>Print this page, for reference</p> </li> <li> <p>Print the Database Diagram</p> <ul> <li>Most of the examples are drawn from this database</li> </ul> </li> <li> <p>For each Rule Pattern, above:</p> <ul> <li> <p>Click the Example link in the table above to open the Behave Logic Report</p> <ul> <li>Aside: later, you can prepare such documentation for your own projects, (like this).</li> </ul> </li> <li> <p>Review the Scenario -- take these as your requirements</p> </li> <li> <p>Spend 5 minutes (perhaps in pairs) and cocktail-napkin design your solution, using</p> <ul> <li>The data model diagram</li> <li>List of Rule Types, and </li> <li>Rule Patterns</li> </ul> </li> <li> <p>Reveal the solution: open the disclosure box: \"Tests - and their logic - are transparent.. click to see Logic\"</p> </li> </ul> </li> </ol> <p> </p>"},{"location":"Logic/#learning-natural-language","title":"Learning Natural Language","text":"<p>As noted above, it is important to be clear on the rules generated for logic.  Use the examples below to test your understanding.</p> <p>WebGenAI provides the Logic Editor so you can see/edit the translation:</p> <p></p>"},{"location":"Logic/#natural-language-patterns","title":"Natural Language Patterns","text":"Pattern Notes Example Formal vs Informal You can: Customer.balance = Sum(Order.amount_total where date_shipped is null) Or, more simply: The Customer's balance is the sum of the Order amount_total where date_shipped is null Integration Logic Kafka Send the Order to Kafka topic 'order_shipping' if the date_shipped is not None Multi-rule Logic See Multi-rule Logic - Generated Rules, below Sum of employee salaries cannot exceed department budget Conditional Derivations See Conditional Derivation - Generated Rules, below Provide a 10% discount when buying more than 10 carbon neutral productsThe Item carbon neutral is copied from the Product carbon neutral Cardinality Patterns- Qualified Any See Cardinality Patterns - Generated Rules, below Products have Notices, with severity 0-5.Raise and error if product is orderable == True and there are any severity 5 Notices, or more than 3 Notices.  Multi-rule Logic - Generated Rules  Logic Recognizes \"conditional derivations\"<pre><code>## Aggregate the total salaries of employees for each department.\nRule.sum(derive=Department.total_salaries, as_sum_of=Employee.salary)\n\n## Ensure the sum of employee salaries does not exceed the department budget\nRule.constraint(validate=Department, as_condition=lambda row: row.total_salaries &lt;= row.budget, error_msg=\"xxx\")\n## End Logic from GenAI\n</code></pre>  Conditional Derivation - Generated Rules  Logic Recognizes \"conditional derivations\"<pre><code>## Provide a 10% discount when buying more than 10 carbon neutral products.\nRule.formula(derive=Item.amount,\n             as_expression=lambda row: 0.9 * row.unit_price * row.quantity \\\n                if row.Product.is_carbon_neutral and row.quantity &gt; 10\n                else row.unit_price * row.quantity)\n## End Logic from GenAI\n</code></pre>  Cardinality Patterns - Generated Rules  Logic Recognizes \"qualified any\"<pre><code>    ## Logic from GenAI: (or, use your IDE w/ code completion)\n\n    ## Derive product notice count from related notices.\n    Rule.count(derive=Product.notice_count, as_count_of=Notice)\n\n    ## Derive count of severity 5 notices for products.\n    Rule.count(derive=Product.class_5_notice_count, as_count_of=Notice, where=lambda row: row.severity == 5)\n\n    ## Ensure product is not orderable if conditions on notices are met.\n    Rule.constraint(validate=Product,\n    as_condition=lambda row: not (row.orderable and (row.class_5_notice_count &gt; 0 or row.notice_count &gt; 3)),\n    error_msg=\"Orderable product contains severity 5 or excessive notices.\")\n\n    ## End Logic from GenAI\n</code></pre>"},{"location":"Logic/#natural-language-examples","title":"Natural Language Examples","text":"<p>WebGenAI was trained to understand the Natural Language Logic problems shown below.  These automate many of the rule patters described above.</p> <p>Please see Natural Language Logic.</p> Example Notes Airport - at least 10 tablesA flight's passengers must be less than its Airplane's seating capacity System for Departments and Employees.Sum of employee salaries cannot exceed department budget Create a system with Employees and their Skills.More than One Employee can have the same Skill.EmployeeSkill.rating = Skill.ratingAn Employee's skill-rating is the sum of the Employee Skills rating, plus 2 * years of service. Students have probations and sick days.Signal an error if a Student's can-graduate is True, and there are more 2 probations, or more than 100 sick days. Applicant have felonies and bankruptcies.Signal error if is-hirable is true and there are more than 3 bankruptcies, or 2 felonies. Students have Grades and belong to Clubs.Copy the name from Club to Student ClubThe student's service activity is the count of Student Clubs where name contains 'service'. Signal error if student is eligible for the honor society == True, and their grade point average is under 3.5, or they have less than 2 service activities Products have Notices, with severity 0-5.Raise and error if product is orderable == True and there are any severity 5 Notices, or more than 3 Notices. Create a system with customers, orders, items and products.Include a notes field for orders.Use Case: enforce the Check Credit for ready orders:1. Customer.balance &lt;= credit_limit2. Customer.balance = Sum(Order.amount_total where date_shipped is null and ready is True)3. Order.amount_total = Sum(Item.amount)4. Item.amount = quantity * unit_price5. Store the Item.unit_price as a copy from Product.unit_priceUse Case: Compute Products ordered1. Item.ready = Order.ready2. Product.total_ordered = sum(Item.quantity) where ready == True3. Product.reorder_required = quantity_on_hand &lt;= total_orderedUse Case: No Empty Orders1. Order.item_count = Count(Items)2. When setting the date_shipped, item_count must be &gt; 0. Ready Flag Teachers, courses which have offerings, and students who have offerings.Use Case: capacityteachers cannot be assigned to more than 5 coursesstudents cannot have more enrollments than 6Use Case: budget controlcourses have a charge, which is copied to enrollments chargea student's total enrollment charges cannot exceed their budget <p> </p>"},{"location":"Manager/","title":"Manager","text":"<p> TL;DR - Manager: genai system files, samples, project organization</p> <p>While the API Logic Server Manager is optional, we strongly recommend it:</p> <ol> <li>GenAI System Files the <code>system</code> folder contains learning files required for GenAI commands </li> <li>Samples to illustrate typical customizations and concepts</li> <li>Project Organization - provides a list of projects (not required, but can be useful)</li> </ol> <p>After 'pip install ApiLogicServer', just <code>als start</code>.</p>"},{"location":"Manager/#overview","title":"Overview","text":"<p>Modern IDEs are remarkably powerful and user-friendly.  Many developers use them as a complement the their OS finder/explorer.</p> <p>As of release 10.03.66, you can use your IDE to create, customize and manage API Logic Projects:</p> Install API Logic Server, Start the API Logic Project Manager<pre><code>mkdir ApiLogicServer\ncd ApiLogicServer\n\npython -m venv venv                  # may require python3 -m venv venv\nsource venv/bin/activate             # windows: venv\\Scripts\\activate\npython -m pip install ApiLogicServer\n\nals start\n</code></pre> <p></p> <p>Created projects will show up here as directories.  You create projects anywhere, and move them; this is just the default.</p> <p><code>als genai</code> commands require projects be located inside the Manager directory.</p> <p> </p>"},{"location":"Manager/#choose-your-ide","title":"Choose your IDE","text":"<p>The default IDE is VSCode.  You can specify your favorite IDE, e.g.</p> Choose IDE<pre><code>als start pycharm   # For Mac, you may need use charm, not pycharm\n</code></pre> <p> </p>"},{"location":"Manager/#pre-created-projects","title":"Pre-created projects","text":"<p>We have pre-created 2 important projects you will want to review at some point:</p> <ul> <li>tutorial - short (&lt; 1 hour) walk-through of using API Logic Server using the northwind (customers, orders...) database</li> <li> <p>sample - the completed tutorial.  It's the same database, but with logic/Python customizations added.  It's a great resource for exploring.  </p> <ul> <li>Hint: use your IDE to search for <code>#als</code></li> </ul> </li> </ul> <p>You can always re-create them as follows:</p> <ol> <li>Open a terminal window (Terminal &gt; New Terminal), and paste the following CLI command:</li> </ol> <pre><code>ApiLogicServer create --project-name=tutorial --db-url=\nApiLogicServer create --project-name=sample --db-url=nw+\n</code></pre> <p> </p>"},{"location":"Manager/#creating-projects-auto_open","title":"Creating Projects: auto_open","text":"<p>By default, the Manager starts with an environment variable <code>APILOGICSERVER_AUTO_OPEN</code>.  It's defaulted to code; you can set it:</p> auto_open<pre><code>export APILOGICSERVER_AUTO_OPEN=charm  # powershell:  $env:APILOGICSERVER_AUTO_OPEN=\"pycharm\"\n</code></pre> <p>Pycharm Notes: your value may be charm or pycharm, depending on your installation.  Also, on windows, the Manager terminal window is tied up when you create a project.</p> <p>Or, use \"\" to disable auto_open.</p> <p>You can set other environment variables here; these defaults are provided:</p> Set Environment Variables<pre><code>export APILOGICSERVER_VERBOSE=true\n</code></pre> <p>Note: your <code>venv</code> is defaulted for VSCode.  It must be configured in PyCharm.</p> <p>Here's a useful link about environment variables.</p> <p> </p>"},{"location":"Manager/#managing-your-projects","title":"Managing Your Projects","text":"<p>Created projects will show up here as directories.  (You create projects anywhere, and move them; this is just the default).</p> <p>If you want to customize/run the project, do so in another instance of VSCode.  You may find it helpful to acquire this extension: <code>Open Folder Context Menus for VS Code</code>.  It will enable you to open the project in another instance of VSCode.</p> <p> </p>"},{"location":"Manager/#manager-using-docker","title":"Manager Using Docker","text":"<p>Please see this page.</p> <p> </p>"},{"location":"Manager/#how-to-run-projects-from-the-manager","title":"How to run projects from the Manager","text":"<p>You typically run projects by opening an IDE on the project folder, using provided Run Configurations.</p> <p>For a quick preview, you can also run from the Manager; there are 2 ways:</p> <ol> <li> <p>Use another instance of VSCode.  You can examine them in this current instance, but run them in their own instance.</p> <ul> <li> <p>To do so, you probably want to acquire this extension: <code>Open Folder Context Menus for VS Code</code>. It will enable you to open the sample, tutorial or your own projects in another instance of VSCode.</p> </li> <li> <p>This option provides more Run/Debug options (e.g., run without security, etc),</p> </li> </ul> </li> <li> <p>Or, use the Run/Debug Entry: <code>API Logic Server Run (run project from manager)</code></p> </li> </ol> <p> </p>"},{"location":"Manager/#using-genai-microservice-automation","title":"Using GenAI Microservice Automation","text":"<p>Use the CLI (Command Language Interface, in your IDE) to create projects from either existing databases, or GenAI prompts.  This creates a project you can open, run and customize in your IDE.</p> <p></p> <p> </p>"},{"location":"Manager/#what-is-api-logic-server","title":"What Is API Logic Server","text":"<p>It's an open source Python project consisting of a CLI to create projects, and runtime libraries to execute them.</p> <p></p> <p> </p>"},{"location":"Manager/#modern-scalable-runtime-architecture","title":"Modern Scalable Runtime Architecture","text":"<p>Created projects use standard Flask and SQLAlchemy; automation is provided by Logic Bank (the rule engine) and SAFRS (JSON:APIs).  Scripts are provided to containerize projects, and deploy to Azure.</p> <p></p> <p> </p>"},{"location":"Optimistic-Locking/","title":"Optimistic Locking","text":"<p>TL;DR - Compute virtual attribute <code>checksum</code> in <code>loaded_as_persistent</code>, verify on save</p> <p>SQLAlchemy provides the <code>loaded_as_persistent</code> event, enabling us to compute the <code>check_sum</code>, store it in the row, and check it on update.</p> <p>Storing it in the row is critical because we do not want to maintain server state between client calls.  For that, we can use <code>@jsonapi_attr</code>.</p> <p>Declaring this virtual attribute is TBD.</p>"},{"location":"Optimistic-Locking/#event-loaded_as_persistent","title":"Event <code>loaded_as_persistent</code>","text":"<p>Looks like this:</p> <pre><code>    @event.listens_for(session, `loaded_as_persistent`)\n    def receive_loaded_as_persistent(session, instance):\n        \"listen for the 'loaded_as_persistent' event\"\n\n        logger.debug(f'{__name__} - compute checksum')\n</code></pre> <p>We can listen for it at server start.</p>"},{"location":"Optimistic-Locking/#safrs-jsonapi_attr","title":"safrs <code>@jsonapi_attr</code>","text":"<p>This provides a mechanism to define attributes as part of the row (so it sent to / returned from the client), and not saved to disk.  It looks like this, for Employee:</p> <pre><code>    from safrs import jsonapi_attr\n    # add derived attribute: https://github.com/thomaxxl/safrs/blob/master/examples/demo_pythonanywhere_com.py\n    @jsonapi_attr\n    def proper_salary(self):  # type: ignore [no-redef]\n        import database.models as models\n        if isinstance(self, models.Employee):\n            import decimal\n            rtn_value = self.Salary\n            rtn_value = decimal.Decimal('1.25') * rtn_value\n            self._proper_salary = int(rtn_value)\n            return self._proper_salary\n        else:\n            print(\"class\")\n            return db.Decimal(10)\n\n    @proper_salary.setter\n    def proper_salary(self, value):  # type: ignore [no-redef]\n        self._proper_salary = value\n        print(f'_proper_salary={self._proper_salary}')\n        pass\n\n    ProperSalary = proper_salary  # signal safrs to recognize this as api-visible property\n</code></pre>"},{"location":"Optimistic-Locking/#open-issue-declaring-jsonapi_attr","title":"Open Issue: declaring <code>@jsonapi_attr</code>","text":"<p>The current (8.02.00) example for <code>proper_salary</code> fails, since the getter/setter must be of the model (here, Employee) class.  The code above works if hand-entered in <code>database.models.py</code>.</p> <p>However, that is not ideal... if <code>models.py</code> is rebuilt-from-model, these changes are lost.  I looked into the following:</p>"},{"location":"Optimistic-Locking/#declare-in-subclass-fails-in-logic","title":"Declare in subclass; fails in logic","text":"<p>It would not be difficult to generate current models with the suffix <code>_base</code>, then sublcass all these models in a customer-alterable file, initially empty.  </p> <p>However, this failed, since LogicBank uses simple mechanisms to find attributes and relationships.  This might be an extensive change.</p>"},{"location":"Optimistic-Locking/#declare-in-mixin-fails-to-recognize-property","title":"Declare in mixin: fails to recognize property","text":"<p>Other approach is to generate models like this:</p> <pre><code>class Employee(SAFRSBase, Base, models_mix.Employee_mix):\n</code></pre> <p>where <code>models_mix.Employee_mix</code> is a user-alterable file that defines virtual attributes.  However, this does not appear to work for <code>@jsonapi_attr</code>s -- it is not called when retrieving rows, and <code>ProperSalary</code> does not appear in swagger.</p> <p>See hand-altered prototype: https://github.com/valhuber/opt_locking_mix.</p>"},{"location":"Product-Detail/","title":"API Logic Server","text":"<p> TL;DR: Instant Creation, Rules, Standard Tooling.  \u00a0 Open Source.</p> <p>Eliminate long dev cycles that delay Agile Collaboration and custom app dev with Working Software, Now.</p> <p>API Logic Server is the fastest and simplest way to create modern, scalable API-based database systems:</p> <ol> <li> <p>Create: <code>ApiLogicServer create</code> builds an executable project from your database, instantly:</p> <ul> <li> <p>Multi-page web app - enable agile collaboration </p> </li> <li> <p>Self-serve API - unblock custom App Dev</p> </li> </ul> </li> <li> <p>Customize: using Python, your IDE and standard libraries such as Flask and SQLAlchemy:</p> <ul> <li> <p>Declare <code>rules</code> that are 40X more concise than code -- unique to API Logic Server \u00a0\u00a0 </p> </li> <li> <p>Extend with standard Python</p> </li> <li> <p>Iterate from revised database designs, preserving customizations</p> </li> </ul> </li> <li> <p>Deploy: automated scripts create standard containers for deployment</p> </li> </ol> <p>Check out the new AI-Driven Tutorial -- article here, or watch the video.  Also, try the Basic Demo.</p> <p> </p> <p>Click to see Created Admin App, Project, Architecture</p> <p> </p> <p>Created Admin App</p> <p>The Admin App is shown below:</p> <p></p> <p> </p> <p>Customize in IDE</p> <p>VSCode and PyCharm users can customize and run/debug within their IDE with these steps.  Created projects include Launch and Docker configurations.  </p> <p></p> <p>Rebuild services are provided to accommodate changes to database structure or ORM classes.</p> <p> </p> <p>Standard, Scalable Modern Architecture</p> <ul> <li>A modern 3-tiered architecture, accessed by APIs</li> <li>Logic is automatically reused, factored out of web apps and custom services</li> <li>Containerized for scalable cloud deployment - the project includes a dockerfile to containerize it to DockerHub.</li> </ul> <p></p> <p> </p>"},{"location":"Product-Detail/#check-it-out","title":"Check it out","text":""},{"location":"Product-Detail/#instant-evaluation-no-install","title":"Instant Evaluation - no install","text":"<p>Run in the cloud: VSCode via your Browser, courtesy Codespaces.  Use your existing GitHub account (no signup is required), and:</p> <ol> <li> <p>Click here to open the Create Codespace page.</p> </li> <li> <p>Configure as desired, and click Create codespace.</p> </li> </ol> <p>This process takes about a minute.  Wait until you see the port created.</p> <p>We think you'll find Codespaces pretty amazing - check it out!</p> <p> </p>"},{"location":"Product-Detail/#self-demo","title":"Self Demo","text":"<p>You can build a sample app from a simple pre-installed database to see the key features:</p> <ol> <li> <p>To install, click here</p> </li> <li> <p>To demo the key features, click here</p> </li> </ol> <p>The navigation menu on the left contains the Tutorial and other samples.  These all use pre-installed databases.</p> <p> </p>"},{"location":"Product-Detail/#instant-cloud-deployment","title":"Instant Cloud Deployment","text":"<p>Follow this procedure to</p> <ol> <li> <p>Create a project from a sample dockerized database</p> </li> <li> <p>Containerize your project</p> </li> <li> <p>Deploy to Azure</p> </li> </ol> <p>Once you are installed, the entire process takes well under an hour.  You will need an Azure account for cloud deployment (but the prior steps are useful to run).</p> <p> </p>"},{"location":"Product-Detail/#in-a-nutshell","title":"In a Nutshell","text":"<p>Here is a quick screen-shot demo of the basic process:</p> 1. Instant App and API2. Flexible Customization3. Declarative Logic \u00a0\u00a0 4. Deployment <p>Create a Flask/SQLAlchemy project from your database:</p> Create Project from database, using API Logic Server CLI<pre><code>ApiLogicServer create --db_url=sqlite:///sample_db.sqlite --project_name=ApiLogicProject\n</code></pre> <p>That command creates a standard project you can open and execute in your IDE.  Here's the Admin App, ready for business user collaboration:</p> <p></p> <p>Expore API, Using Automatically Created Swagger - Custom Add Dev Ready</p> <p> </p> <p>The Admin App provides a link to the Swagger:</p> <p></p> <p>When you're ready, click 2. Flexible Customization, above.</p> <p>Customize and debug with standard dev tools.  Use your IDE (e.g. VSCode, PyCharm), Python, and Flask/SQLAlchemy to create new services.</p> <p></p> <p>When you're ready, click 3. Declarative Logic, above.</p> <p>Declare multi-table constraint/derivation logic, using Python and your IDE.  The 5 spreadsheet-like rules below are declarative, representing the same logic as 200 lines of procedural code (40X more concise):</p> <p></p> <p>Notes:</p> <ol> <li>You can extend rules with Python, as explained in the Eval</li> <li>Similar declarative facilities provide row level security, based on a users roles</li> </ol> <p> </p> <p>When you're ready, click 4. Deployment, above.</p> <p>Projects are container-ready.  The system provides configuration and scripts to containerize your project:</p> <p></p> <p>The container is ready to deploy, on-premise or in the cloud (eg, Azure, AWS, etc):</p> <ul> <li>A modern 3-tiered architecture, accessed by APIs</li> <li>Logic is automatically reused, factored out of web apps and custom services</li> <li>Scale using standard toooling such as Kubernetes</li> </ul> <p></p> <p> </p>"},{"location":"Product-Detail/#video-create-run-customize","title":"Video: Create, Run, Customize","text":"<p>API Logic Server is an open source Python project, consisting of a CLI and set of runtimes (SAFRS API, Flask, SQLAlchemy ORM, business logic engine) for project execution.</p> <p>It runs as a standard pip install, or under Docker. For more on API Logic Server Architecture, see here.</p> <p>Click the image below for a video tutorial, showing complete project creation, execution, customization and debugging (instructions here).  Or, see it using AI: click here.</p> <p></p> <p> </p> <p> </p>"},{"location":"Product-Detail/#why-it-matters","title":"Why It Matters:","text":""},{"location":"Product-Detail/#increased-agility-and-quality-reduced-risk","title":"Increased Agility and Quality, Reduced Risk","text":"<p>Agile wisely advises getting Working Software as fast as possible, to facilitate Business User Collaboration and Iteration.  This reduces requirements risk - substantial effort wasted in misunderstood requirements.</p> <p></p> <ol> <li> <p>Instant Collaboration: with automated creation of an API and an Admin App,  collaboration and UI dev can begin on Day 1.</p> <ul> <li>Tradtionally, API and UI Dev is required before Collaboration.  This might be weeks or months.</li> </ul> </li> <li> <p>Spreadsheet-like Rules, Self-Serve APIs: rules are 40X more concise, and automatically ordered and reused.  Also, APIs are self-serve -- UI developers can use Swagger to formulate requests for filtering, sorting, and multi-table data content.</p> <ul> <li>Tradtionally, Logic Development is by code.  Manual approaches can miss Use Cases, or be coded in UI controllers instead of the server.</li> <li>Tradtionally, Custom APIs are required for each client app.  This can block UI deveopment.</li> </ul> </li> <li> <p>Self-Serve APIs: ongoing API needs can be met by consumers, such as new application integration.</p> <ul> <li>Tradtionally, API Consumers may require new custom APIs, which may result in bottlenecks for server developers.</li> </ul> </li> </ol> <p>In addition to time, risk is also reduced:</p> <ol> <li>Early Collaboration: reduces requirements risk </li> <li>API Automation: reduces technical risk (e.g., pagination, optimistic locking, self-serve design).</li> </ol> <p>Finally, automation drives quality automatic re-use and ordering eliminates an entire class of error.</p> <p> </p>"},{"location":"Product-Detail/#simpler-modern-architecture","title":"Simpler, Modern Architecture","text":"<p>API Logic Server not only increases agility, it can make web app development simpler, and ensure the architectural result:</p> <ul> <li> <p>Automation makes it simpler: this reduces the risk of architectural errors, e.g., no logic reuse between Apps / Services, APIs without pagination, etc.</p> </li> <li> <p>Automation guarantees a modern software architecture: container-ready, API-based, with shared logic between UIs and APIs (no more logic in UI controllers), in a predictable structure for maintenance.</p> </li> </ul> <p> </p>"},{"location":"Product-Detail/#flexibility-of-a-framework-faster-than-low-code","title":"Flexibility of a Framework, Faster than Low Code","text":"<p>Current approaches for building database systems have shortcomings:   </p> <ul> <li>Frameworks: Frameworks like Flask or Django enable you to build a single endpoint or Hello World page, but<ul> <li>Require weeks or more for a multi-endpoint API and multi-page application</li> </ul> </li> <li>Low Code Tools: are great for building custom UIs, but<ul> <li>Slow Admin app creation, requiring layout for each screen</li> <li>Propietary IDEs don't preserve value of traditional IDEs like VSCode, PyCharm, etc</li> <li>No automation for backend business logic (it's nearly half the effort)</li> </ul> </li> </ul> <p>In contrast, API Logic Server provides:</p> <ul> <li> <p>Flexibility of a framework: use your IDE's code editor and debugger to customize the created project, with full access to underlying Flask and SQLAlchemy services</p> </li> <li> <p>Faster than low code for admin apps: you get a full API and Admin app instantly, no screen painting required</p> </li> </ul> <p> </p>"},{"location":"Product-Detail/#use-cases","title":"Use Cases","text":"<p>There are a variety of ways for getting value from API Logic Server:</p> <ul> <li> <p>Create and Customize database web apps - the core target of the project</p> </li> <li> <p>Admin App for your database - the Admin App is a create way to navigate through your database, particularly to explore data relationships</p> </li> <li> <p>Agile Integrations replace cumbersome and inefficent ETL approaches with Agile Integrations</p> </li> <li> <p>Data Repair - using the Admin App with logic to ensure integrity, repair data for which you may not have had time to create custom apps</p> </li> <li> <p>Project Creation - even if you do not intend to use the API, Admin App or logic, you can use API Logic Server to create projects you then edit by hand.  Created projects will include the SQLAlchemy Data Models, and project structure</p> </li> <li> <p>Learning - explore the Learning Center to learn about key concepts of Flask and SQLAlchemy</p> </li> </ul> <p> </p>"},{"location":"Product-Detail/#feature-summary","title":"Feature Summary","text":"Feature Providing Why it Matters Instant 1. Admin App Instant multi-page, multi-table app Business Users engaged earlyBack-office Admin 2. JSON:API and Swagger Endpoint for each table, with... Filtering, pagination, related data Custom UI DevApp Integration 3. Data Model Class Creation Classes for Python-friendly ORM Custom Data AccessUsed by API Customizable 4. Customizable Project Custom Endpoints, Logic Use Python and your IDE Customize and run Re-creation not required Unique Logic 5. Spreadsheet-like Business Rules 40X more concise - compare legacy code Unique backend automation  ... nearly half the system Customizable with Python Familiar Event Model Eg., Send messages, email Testing 6. Behave Test Framework Test Suite AutomationBehave Logic ReportDrive Automation with Agile Optimize Automation to get it fastGet it Right with Agile Collaboration"},{"location":"Product-Detail/#getting-started-install-tutorial","title":"Getting Started - Install, Tutorial","text":"<p>API Logic Server is designed to make it easy to get started:</p> <ul> <li> <p>Install and run Tutorial -  install, and explore the tutorial.  The tutorial creates 2 versions of the sample database</p> <ul> <li>without customizations - so you to see exactly what is automated from the <code>ApiLogicServer create</code> command</li> <li>with customizations - so you can see how to customize </li> </ul> </li> <li> <p>Installed Sample Databases - Here are some installed sample databases you can use with simplified abbreviations for <code>db_url</code>.</p> </li> <li> <p>Dockerized Test Databases -  Then, you might like to try out some of our dockerized test databases.</p> </li> <li> <p>Your Database - Finally, try your own database.</p> </li> </ul> <p> </p> <p>In addition to this app dev oriented tutorial, you can also explore:</p> <ul> <li> <p>Deployment: the Deployment Tutorial illustrates various ways to containerize and deploy your applications</p> </li> <li> <p>Using AI: the AI-Driven Automation Tutorial shows how you can use ChatGPT to create new databases from english descriptions, to bootstrap a very rapid create / collaborate / iterate Agile cycle.</p> </li> </ul> <p> </p>"},{"location":"Product-Detail/#project-information","title":"Project Information","text":""},{"location":"Product-Detail/#making-contributions","title":"Making Contributions","text":"<p>This is an open source project.  We are open to suggestions for enhancements.  Some of our ideas include:</p> Component Provides Consider Adding 1. JSON:API and Swagger API Execution Kubernetes - extend containerization 2. Transactional Logic Rule Enforcement New rule types 3. SAFRS React Admin Admin UI Enhancements Maps, trees, ... 4. This project API Logic Project Creation Support for features described above <p>To get started, please see  the Architecture.</p>"},{"location":"Product-Detail/#preview-version","title":"Preview Version","text":"<p>This pre-release includes:</p> <ul> <li> <p>Running Kafka publish; consume now working.</p> </li> <li> <p>Fix for MySQL CHAR/String import Issue 26</p> </li> </ul> <p>You can try it at (you may need to use <code>python3</code>):</p> <pre><code>python -m pip install --index-url https://test.pypi.org/simple/ --extra-index-url https://pypi.org/simple ApiLogicServer==10.0.0\n</code></pre> <p>Or use (not available currently):</p> <pre><code>docker run -it --name api_logic_server --rm -p 5656:5656 -p 5002:5002 -v ~/dev/servers:/localhost apilogicserver/api_logic_server_x\n</code></pre> <p>Or, you can use the beta version on codespaces.</p> <p> </p>"},{"location":"Product-Detail/#status","title":"Status","text":"<p>We have tested several databases - see status here..</p> <p>We track issues in git (formerly here).</p> <p>We communicate via slack.</p> <p> </p>"},{"location":"Product-Detail/#acknowledgements","title":"Acknowledgements","text":"<p>Many thanks to:</p> <ul> <li>Thomas Pollet, for SAFRS, SAFRS-react-admin, and invaluable design partnership</li> <li>Tyler Band, for major contributions on security, testing, features and much more</li> <li>Nitheish Munusamy, for contributions to Safrs React Admin</li> <li>Marelab, for react-admin</li> <li>Armin Ronacher, for Flask</li> <li>Mike Bayer, for SQLAlchemy</li> <li>Alex Gr\u00f6nholm, for Sqlacodegen</li> <li>Meera Datey, for React Admin prototyping</li> <li>Denny McKinney, for Tutorial review</li> <li>Achim G\u00f6tz, for design collaboration and testing</li> <li>Max Tardiveau, for testing and help with Docker</li> <li>Michael Holleran, for design collaboration and testing</li> <li>Nishanth Shyamsundar, for review and testing</li> <li>Thomas Peters, for review and testing</li> <li>Gloria Huber and Denny McKinney, for doc review</li> </ul> <p> </p>"},{"location":"Product-Detail/#articles","title":"Articles","text":"<p>There are a few articles that provide some orientation to API Logic Server:</p> <ul> <li>How Automation Activates Agile</li> <li>How Automation Activates Agile - providing working software rapidly drives agile collaboration to define systems that meet actual needs, reducing requirements risk</li> <li>How to create application systems in moments</li> <li>Stop coding database backends\u2026Declare them with one command.</li> <li>Instant Database Backends</li> <li>Extensible Rules - defining new rule types, using Python</li> <li>Declarative - exploring multi-statement declarative technology</li> <li>Automate Business Logic With Logic Bank - general introduction, discussions of extensibility, manageability and scalability</li> <li>Agile Design Automation With Logic Bank - focuses on automation, design flexibility and agile iterations</li> <li>Instant Web Apps </li> </ul> <p> </p> <p>A variant of the home page is here.</p> <ol> <li> <p>See the FAQ for Low Code \u21a9</p> </li> </ol>"},{"location":"Product-Overview/","title":"Product Overview","text":""},{"location":"Product-Overview/#instantly-create-and-run-database-apis-flask-sqlalchemy-customize-with-python-and-rules","title":"Instantly Create and Run Database APIs - Flask, SQLAlchemy.  Customize with Python and Rules.","text":"<p>Python, Flask and SQLAlchemy are a great foundation for building servers.  And it's straight-forward to build a single endpoint -- many great courses and articles on building a basic <code>Hello World</code> server.</p> <p>But, it's a long way from <code>Hello World</code> to a running system, with a full API (filtering, pagination, optimistic locking), a usable UI, integration, etc.  And then there's the business logic, often nearly half the effort.  There's got to be a better way.</p> <p>Imagine you could create a running system, instantly. Customize it in standard ways: your IDE, Python, Flask, and SQLAlchemy.  And, declare business logic with spreadsheet-like rules, reducing business logic by 40X?  </p> <p>Well, you've just imagined API Logic Server.  Here's how it works.</p> <p> </p>"},{"location":"Product-Overview/#1-create-automate-project-creation-with-a-single-cli-command","title":"1. Create: Automate Project Creation With a Single CLI Command","text":"<p>The <code>ApiLogicServer create</code> CLI command creates an executable project by reading the database schema in the <code>db_url</code> argument.  For example, this will create an executable, customizable project from the pre-installed sample database:</p> <pre><code>ApiLogicServer create --project_name=ApiLogicProject --db_url=nw\n</code></pre> <p> </p>"},{"location":"Product-Overview/#2-run-automated-jsonapi-admin-app","title":"2. Run: Automated JSON:API, Admin App","text":"<p>The project is executable, providing a JSON:API and an Admin App:</p> <p></p> <p>The Admin App provides a link to the Swagger to explore the JSON:API:</p> <p></p> <p> </p>"},{"location":"Product-Overview/#3-customize-rules-and-python","title":"3. Customize: Rules and Python","text":"<p>The project is customizable in your IDE.  Declare rules in Python for logic and security.  Rules are an executable design, as shown below.</p> <p>Rules are unique and significant - 40X more concise than code, and extensible with Python.</p> <p></p> <p> </p>"},{"location":"Product-Overview/#4-integration-custom-endpoints-kafka-messages","title":"4. Integration: custom endpoints, Kafka messages","text":"<p>For application integration, you can use standard Flask to create new endpoints:</p> <p></p> <p>And, extend logic - with Python - to produce Kafka messages:</p> <p></p> <p> </p>"},{"location":"Product-Overview/#download-and-try","title":"Download and Try","text":"<p>This quick tour has shown how to create and customize a system in days instead of weeks or months.  Not just faster, also much simpler.  </p> <p>It's because the system is declarative: you specify what you want to happen, instead of coding it out each little detail.</p> <p>You can repeat this demo in 15 minutes.  Install API Logic Server, and follow the Tutorial.  </p> <p>Then, try it with one of your own databases (MySql, Sql/Server, Ingres, Oracle, Sqlite).  Join our Slack, and tell us what you think!</p>"},{"location":"Project-AI-Enabled/","title":"AI-Enabled Projects","text":"<p> Every Project Comes Pre-Configured for AI Assistance</p> <p>Every project created by GenAI-Logic includes comprehensive training materials, readme's with code examples, and integration points that work seamlessly with GitHub Copilot, Claude, ChatGPT, and other AI assistants.</p> <p>Your project includes <code>.github/.copilot-instructions.md</code>, AI training documents (<code>docs/training</code>), and working code examples that serve as a \"message in a bottle\" for AI assistants.</p> <p>No more explaining your project structure from scratch - AI assistants can immediately understand your codebase and underlying software to help you build features.</p> <p>AI assistants can help you add business logic rules, customize APIs, create test scenarios, and integrate with external services.</p> <p>They also provide an AI Guided Tour, where an intelligent AI Assistant introduces you to the key concepts of GenAI-Logic.</p> <p> </p> <p>This page describes:</p> <p>\u2022 what makes your project AI-enabled out of the box \u2022 the training materials included as your \"message in a bottle\" \u2022 how to get started with AI assistance \u2022 the AI-friendly workflows built into every project  </p> <p> </p>"},{"location":"Project-AI-Enabled/#ai-enabled-projects","title":"AI-Enabled Projects","text":"<p>When you open a project, activate the AI Assitant:</p> <p></p> <p>When you create a new project with <code>genai-logic create</code>, you're not just getting a basic API and admin interface. Each project is thoughtfully designed to be AI-friendly from day one.</p> <p> </p>"},{"location":"Project-AI-Enabled/#main-capabilities","title":"\ud83d\udee0\ufe0f Main Capabilities","text":"<p>As shown above, your AI-enabled project includes these key capabilities:</p> <p>\u2705 Run the Project - F5 or <code>python api_logic_server_run.py</code> \u2705 Add Business Logic - Declarative rules with 44x code reduction \u2705 Create Custom APIs - B2B integration with natural language \u2705 Customize Data Models - Schema modifications, derived attributes \u2705 Automated Testing - Behave framework with logic traceability \u2705 Security &amp; Authentication - Multiple providers, role-based access \u2705 React App Generation - Complete frontend creation \u2705 MCP Client Integration - Model Context Protocol support \u2705 Admin UI Customization - YAML-driven configuration \u2705 Events &amp; Triggers - Advanced business logic scenarios  </p> <p> </p>"},{"location":"Project-AI-Enabled/#built-in-ai-guidance","title":"\ud83e\udd16 Built-in AI Guidance","text":"<p>Your project includes comprehensive training materials that serve as a \"message in a bottle\" for AI assistants:</p> <ol> <li><code>.github/.copilot-instructions.md</code> - this is the \"message in a bottle\" that enabled your AI Assitant to understand GenAI-Logic projects, and deliver the services above</li> <li><code>docs/training/</code> - AI training documents with detail examples and patterns</li> <li><code>readme.md</code> - Project overview with quick start instructions</li> <li>Code examples - real working examples in the <code>readme's</code> throughout the project</li> </ol> <p> </p>"},{"location":"Project-AI-Enabled/#context-aware-architecture","title":"\ud83e\udde0 Context-Aware Architecture","text":"<p>The project structure itself provides rich context for AI understanding:</p> <p>\u2022 Declarative logic patterns in <code>logic/declare_logic.py</code> \u2022 API endpoint examples with SQLAlchemy models \u2022 Test scenarios that demonstrate business requirements \u2022 Integration templates for common patterns  </p> <p> </p>"},{"location":"Project-AI-Enabled/#ai-friendly-workflows","title":"\ud83d\udca1 AI-Friendly Workflows","text":"<p>Your project supports natural AI-assisted development:</p> <p>\u2022 Natural language to business rules - Describe requirements, get executable logic \u2022 Automated testing - Behave scenarios that serve as living documentation \u2022 Code completion - Rich type hints and patterns for IDE assistance \u2022 Documentation generation - Self-documenting APIs and logic  </p> <p> </p>"},{"location":"Project-AI-Enabled/#training","title":"Training","text":"<p>There are important resources to help you get started.</p> <p> </p>"},{"location":"Project-AI-Enabled/#ai-guided-tour","title":"\ud83c\udf93 AI Guided Tour","text":"<p>It's been clear for quite some time that lab-based training was far superior to death by powerpoint.  But running labs is not simple - it usually requires in-person expertise to deal with inevitable problems.</p> <p>AI enables us to put a \"message in a bottle\" - an AI tutor that can walk you through the tutorial, and, unlike a readme, support you:</p> <ul> <li>answer questions (\"how do I customize this\")</li> <li>get you unstuck (\"ah, you forgot to start the server\")</li> </ul> <p>Key aspects of the tour:</p> <ul> <li>Provocation-based learning (not instruction)</li> <li>Hands-on discovery (doing, not reading)</li> <li>AI as companion during the lab (not before/after)</li> </ul> <p>The tour begins in the manager, which encourages you to create the basic demo.  That creates the <code>basic_demo</code> project, which provides a special readme to start the tour:</p> <p></p> <p> </p> <p>Ed: this was an interesting technical problem - AI prefers to be reactive (not driving a tutorial), and make decisions about 'that seems to be working'.  We needed it to be proactive and not skip steps - to act outside its comfort zone.  To read more, click here.</p> <p> </p>"},{"location":"Project-AI-Enabled/#quick-reference-readmes","title":"\ud83d\ude80 Quick Reference <code>readmes</code>","text":"<p>Each project includes working examples (see various <code>readme</code> files within the project) you can build upon:</p> <p>\u2022 Pre-configured rules demonstrating common business patterns \u2022 Sample API calls with proper request/response formats \u2022 Test data and scenarios for immediate experimentation \u2022 Integration hooks for external services  </p> <p> </p>"},{"location":"Project-AI-Enabled/#next-steps","title":"\ud83c\udfaf Next Steps","text":"<p>To find more:</p> <p>\u2022 Logic Guide - Learn about declarative business rules \u2022 API Documentation - Understand your auto-generated API \u2022 Testing Guide - Write and run business scenarios \u2022 Sample Projects - Explore working examples  </p> <p>Your AI-enabled project is ready to evolve with your needs. Just describe what you want, and let AI help you build it! </p>"},{"location":"Project-Builders/","title":"Builders","text":"<p>The <code>extended_builder</code> option enables you to extend the creation process with user extensible creation. It is intended to accommodate cases where DBMSs provide proprietary features - such as Table Valued Functions (TVFs) - that should be exposed as APIs.</p>"},{"location":"Project-Builders/#overview","title":"Overview","text":"<p>Here is a general overview of creating projects using an extended builder.</p>"},{"location":"Project-Builders/#1-create-your_builderpy","title":"1. Create <code>your_builder.py</code>","text":"<p>This is a Python file that creates <code>&lt;project_directory&gt;/api/your_api_extension.py</code>, with:</p> <pre><code>def extended_builder(db_url, project_directory):\n    \"\"\" called by ApiLogicServer CLI -- scan db_url schema, create your_api_extension.py\n            for each database object:\n                class t_&lt;db-object-name&gt; -- the model\n                class &lt;db-object-name&gt;   -- the service\n        args\n            db_url - use this to open the target database, e.g. for meta data\n            project_directory - the created project... create / alter files here\n\n    \"\"\"\n</code></pre>"},{"location":"Project-Builders/#2-create-project","title":"2. Create Project","text":"<p>Specify the <code>--extended_builder=your_builder.py</code> option.  The system will invoke your builder, which operates as described below.</p>"},{"location":"Project-Builders/#2a-database-introspection","title":"2a. Database Introspection","text":"<p>Use the <code>db_url</code> to open your database, and find database objects you wish to expose</p>"},{"location":"Project-Builders/#2b-project-file-creation","title":"2b. Project File Creation","text":"<p>Create <code>&lt;project_directory&gt;/api/your_api_extension.py</code>.  This executes your api extensions.  It generally contains</p> <ul> <li>SQLAlchemy class definitions for results, e.g.</li> </ul> <pre><code>t_udfEmployeeInLocation = Table(  # define result for udfEmployeeInLocation\n    \"udfEmployeeInLocation\", metadata,\n    Column(\"Id\", Integer),\n    Column(\"Location\", String(50)),\n    Column(\"Name\", String(50)))\n</code></pre> <ul> <li>API Implementations, e.g.</li> </ul> <pre><code>class udfEmployeeInLocation(JABase):\n    \"\"\"\n        description: define service for udfEmployeeInLocation\n    \"\"\"\n\n    _s_type = \"udfEmployeeInLocation\"\n\n    @staticmethod\n    @jsonapi_rpc(http_methods=['POST'], valid_jsonapi=False)\n    def udfEmployeeInLocation(location):\n        \"\"\"\n        description: expose TVF - udfEmployeeInLocation\n        args:\n            location : value\n        \"\"\"\n</code></pre>"},{"location":"Project-Builders/#2c-runtime-activation","title":"2c. Runtime activation","text":"<p>Ensure <code>your_api_extension.py</code> is activated at server startup time, e.g. by updating <code>&lt;project_directory&gt;/api/customize_api.py</code></p>"},{"location":"Project-Builders/#example-tvf","title":"Example - TVF","text":"<p>Install as usual, and create your project using the <code>extended_builder</code> option, e.g:</p> <pre><code>ApiLogicServer run --db_url='mssql+pyodbc://sa:Posey3861@localhost:1433/SampleDB?driver=ODBC+Driver+18+for+SQL+Server&amp;trusted_connection=no&amp;Encrypt=no' \\\n   --extended_builder=extended_builder.py \\\n   --project_name=TVF\n</code></pre> <p>Or, use the default extended_builder:</p> <pre><code>ApiLogicServer create --db_url='mssql+pyodbc://sa:Posey3861@localhost:1433/SampleDB?driver=ODBC+Driver+18+for+SQL+Server&amp;trusted_connection=no&amp;Encrypt=no' \\\n   --extended_builder='*' \\\n   --project_name=TVF\n</code></pre> <p>to designate a file that implements your builder. During the creation process, the system will invoke <code>extended_builder(db_url, project_directory)</code> so you can add / alter files as required.  In this example, the output file <code>&lt;project_directory&gt;/api/your_api_extension.py</code> is named <code>&lt;project_directory&gt;/api/tvf.py</code></p> <p>Full automation for specific DBMS features was considered, but could not conceivably accommodate all the DBMS features that might be desired. We therefore provide this extensible automation approach.</p> <p>Let's illustrate the use of extensible automation with this example.  Create the sample project as follows:</p> <ol> <li>Acquire this sql/server docker database</li> <li>Create the project</li> </ol> <pre><code>docker run -it --name api_logic_server --rm -p 5656:5656 -p 5002:5002 -v ${PWD}:/localhost apilogicserver/api_logic_server\n\nApiLogicServer create --project_name=/localhost/sqlserver-types --extended_builder='*' --db_url=mssql+pyodbc://sa:Posey3861@localhost:1433/SampleDB?driver=ODBC+Driver+17+for+SQL+Server?trusted_connection=no\n</code></pre> <p>This uses an example extended builder can be found here. You can copy this file to a local directory, alter it as required, and specify its location in the CLI argument above. It is loosely based on this example.</p> <p>The interface to ApiLogicServer requires that you provide an <code>extended_builder(db_url, project_directory)</code> function, like this (the rest is up to you):</p> <pre><code>def extended_builder(db_url, project_directory):\n    \"\"\" called by ApiLogicServer CLI -- scan db_url schema for TVFs, create api/tvf.py\n            for each TVF:\n                class t_&lt;TVF_Name&gt; -- the model\n                class &lt;TVF_Name&gt;   -- the service\n        args\n            db_url - use this to open the target database, e.g. for meta data\n            project_directory - the created project... create / alter files here\n\n    \"\"\"\n    print(f'extended_builder.extended_builder(\"{db_url}\", \"{project_directory}\"')\n    tvf_builder = TvfBuilder(db_url, project_directory)\n    tvf_builder.run()\n</code></pre> <p>This particular example creates this tvf file in the api folder.</p> <p>Updates <code>api/customize_api.py</code> to expose it, as shown below:</p> <p></p> <p>This example illustrates the extended builder approach; the resultant services runs as shown below.</p> <p>It does not deal with many data types.</p> <p>It generates Swagger, with arguments:</p> <p></p> <p>You can run it with this cURL:</p> <pre><code>curl -X POST \"http://localhost:5656/udfEmployeeInLocation/api/udfEmployeeInLocation\" -H  \"accept: application/vnd.api+json\" -H  \"Content-Type: application/json\" -d \"{  \\\"location\\\": \\\"Sweden\\\"}\"\n</code></pre> <p>returns the expected data:</p> <pre><code>{\n  \"result\": [\n    2,\n    \"Nikita\",\n    \"Sweden\"\n  ]\n}\n</code></pre>"},{"location":"Project-Create-Copilot/","title":"Create With Copilot","text":"<p>You can use Copilot chat (if extension installed) to create new databases and projects:</p> <ol> <li>Create a model, eg:</li> </ol>  Show Me How to Use Copilot  <p> </p> <p>Paste this into the Copilot prompt:</p> <pre><code>Use SQLAlchemy to create a sqlite database named sample_ai.sqlite, with customers, orders, items and product\n\nHints: use autonum keys, allow nulls, Decimal types, foreign keys, no check constraints.\n\nInclude a notes field for orders.\n\nCreate a few rows of only customer and product data.\n\nEnforce the Check Credit requirement (do not generate check constraints):\n\n1. Customer.Balance &lt;= CreditLimit\n2. Customer.Balance = Sum(Order.AmountTotal where date shipped is null)\n3. Order.AmountTotal = Sum(Items.Amount)\n4. Items.Amount = Quantity * UnitPrice\n5. Store the Items.UnitPrice as a copy from Product.UnitPrice\n</code></pre> <p></p> <p></p> <ol> <li> <p>Paste the copilot response into a new <code>sample_ai.py</code> file</p> </li> <li> <p>Create your project:</p> </li> </ol> <pre><code>als create --project-name=sample_ai --from-model=sample_ai.py --db-url=sqlite\n</code></pre> <ol> <li>This will create your database, create an API Logic Project from it, and launch your IDE.</li> </ol>"},{"location":"Project-Env/","title":"Virtual Environment","text":"<p>This section applies only to <code>pip</code> installs.  Docker based installs eliminate such environment issues, and are therefore worth a look.</p> <p>Important: in addition to Python environment, there are other configuration settings to consider as described in the Quick Start.</p>"},{"location":"Project-Env/#per-project-venv","title":"Per-project <code>venv</code>","text":"<p>You created a virtual environment when you installed ApiLogicServer.  This <code>venv</code> will work for all of your created ApiLogicServer projects, or you can use a per-project <code>venv</code>, as follows.</p> <p>The created project contains a <code>requirements.txt</code> used to create a virtual environment. You can create it in the usual manner:</p> <p><pre><code>cd ApiLogicProject\npython3 -m venv venv       # may require python -m venv venv\nsource venv/bin/activate   # windows venv\\Scripts\\activate\npython3 -m pip install -r requirements.txt\n</code></pre> </p>"},{"location":"Project-Env/#shared-venv","title":"Shared <code>venv</code>","text":"<p>VSCode users may wish to share a <code>venv</code> over multiple projects.  Two altermnatives are described below.</p> <p> </p>"},{"location":"Project-Env/#from-create-default","title":"From Create (default)","text":"<p>Projects created starting with version 10.0.8 (see preview) have a preset <code>python.defaultInterpreterPath</code> in <code>.vscode/settings.json</code>.  The Python interpreter used to create the project (i.e, your ApiLogicServer install location) will be the default interpreter / venv.  Note this only takes effect when you start VSCode; you can override it manually.</p>  Show me how  <p></p> <p> </p>"},{"location":"Project-Env/#from-settings","title":"From Settings","text":"<p>Use Settings &gt; Python: Venv Path, and specify a directory containing <code>venv</code> directories (e.g, where you installed API Logic Server).  This is a convenient way to get started.</p> <p>Recall this does not apply to docker or Codespace environments.  </p> <p> </p> <p>A typical way to install API Logic Server is to create a directory called <code>ApiLogicServer</code>, and create a <code>venv</code> inside it, like this:</p> Install API Logic Server in a Virtual Environment<pre><code>python -m venv venv                  # may require python3 -m venv venv\nvenv\\Scripts\\activate                # mac/linux: source venv/bin/activate\npython -m pip install ApiLogicServer\n</code></pre> <p> </p> <p>The resultant directory structure:</p> <p></p> <p>This <code>venv</code> can be re-used by defining a global path in your <code>Python: venv</code> setting:</p> <p></p> <p>Then, choose this <code>venv</code> with <code>select interpreter</code> (you sometimes have to open a Python file):</p> <p></p>"},{"location":"Project-Env/#from-environmental-variable","title":"From Environmental Variable","text":"<p>You can also set up the default <code>venv</code> for VSCode.  For example, if you installed ApiLogicServer in <code>/dev/ApiLogicServer</code>:</p> <p><pre><code>export VIRTUAL_ENV=~/dev/ApiLogicServer/venv\n</code></pre> Exercise caution - this might affect other projects.</p> <p> </p>"},{"location":"Project-Env/#venv_setup-shortcut-setup-procedures","title":"<code>venv_setup</code> - shortcut setup procedures","text":"<p>Ss of release 5.02.10, projects are created with a <code>venv_setup</code> directory which may be helpful in establishing and verifying your Python environment.  For more information, see the Trouble Shooting Guide.</p> <p> </p>"},{"location":"Project-Env/#venv-troubleshooting","title":"<code>venv</code> Troubleshooting","text":"<p>By far, most of the support calls we get involve <code>venv</code> setup.</p> <p>To find more information, please click here.</p> <p> </p>"},{"location":"Project-Env/#notes","title":"Notes","text":""},{"location":"Project-Env/#issues-with-pip","title":"Issues with <code>pip</code>","text":"<p>The install sometimes fails due on machines with an older version of <code>pip</code>.  If you see a message suggesting you upgrade  <code>pip</code> , do so.</p>"},{"location":"Project-Env/#vscode-may-fail-to-find-your-venv","title":"VSCode may fail to find your <code>venv</code>","text":"<p>If VSCode does not find your <code>venv</code>, you can specify it manually using <code>Python: Select Interpreter</code></p> <p>For more information, see Work with Environments.</p>"},{"location":"Project-Env/#copy-not-recommended","title":"Copy Not Recommended","text":"<p>Recommend re-creating a venv rather than moving/copying; for more information, see here.</p>"},{"location":"Project-Rebuild/","title":"Rebuild","text":"<p>The system is designed to accomodate database schema changes over the course of your project.  Such changes preserve customizations you have made to your api, logic and app.</p> <p>After changing your database, you can issue:</p> <pre><code>ApiLogicServer rebuild-from-database --db_url=sqlite:///basic_demo/database/db.sqlite\n</code></pre> <p>Or, after changing your database model, you can issue:</p> <pre><code>ApiLogicServer rebuild-from-model\n</code></pre> <p>These alternatives depend on whether you drive changes from your model, or from your database using database tools.  For more information, see Database Changes.</p>"},{"location":"Project-Structure/","title":"Create with CLI","text":"<p> TL;DR - ApiLogicServer create</p> <p>The <code>ApiLogicServer create</code> CLI command creates a customizable / executable API Logic Project providing:</p> <ul> <li> <p>A JSON:API - Endpoint for each table, with filtering, sorting, pagination, optimistic locking, including related data access, based on relationships in the models file (typically derived from foreign keys)</p> </li> <li> <p>An Admin App - multi-page, multi-table, with automatic joins</p> </li> </ul> <p>Customize the project in your IDE to add custom endpoints, rules and Python for logic and security.  Projects are fully configured for development (e.g. run configurations) and deployment (e.g., image creation, env variables).</p>"},{"location":"Project-Structure/#apilogicserver-create","title":"ApiLogicServer create","text":"<p>The key <code>ApiLogicServer create</code> options are:</p> <ul> <li> <p><code>--project_name</code> defines the directory created for your project</p> </li> <li> <p><code>--db_url</code> identifies the database.  Specify a SQLAlchemy url, or one of the preloaded sample database abbreviations</p> </li> </ul> <p>Discover other options with <code>ApiLogicServer create --help</code>.</p> <p>Discover other commands with <code>ApiLogicServer --help</code>.</p> <p>The key files that drive execution are described below.  Note they are models - instead of lengthy generated code (what), they are Python declarations of how.</p> <p> </p>"},{"location":"Project-Structure/#1-data-model-classes","title":"1. Data Model Classes","text":"<p>The Data Model Classes enable SQLAlchemy database operations for the system and your custom code.  They are created automatically on project creation.</p> <p>See rebuild for more information.</p> <p>The system also creates a database diagram.</p>"},{"location":"Project-Structure/#2-api","title":"2. API","text":"<p>The JSON:API is driven by the model classes, so is very short.</p>"},{"location":"Project-Structure/#3-admin-app","title":"3. Admin App","text":"<p>The Admin App is also a model (not extensive html and javascript), expressed in yaml.</p> <p> </p>"},{"location":"Project-Structure/#create-from-model","title":"Create From Model","text":"<p>In addition to creating projects from databases, you can also create them from SQLAlchemy models.  For example:</p> <ul> <li>Copilot can produce models</li> <li>Many Python programmers prefer to use SQLAlchemy as their database tool</li> </ul> Create from Model<pre><code>als create --project-name=sample_ai --from-model=sample_ai.py --db-url=sqlite\n</code></pre> <p> </p>"},{"location":"Project-Structure/#project-structure","title":"Project Structure","text":"<p>When you create an ApiLogicProject, the system creates a project like this that you customize in your IDE:</p> <p></p> <p>Explore the Tutorial Project, and observe that the projects are rather small.  That is because the system creates models that define what, not now.  Explore the project and you will find it easy to understand the API, data model, app and logic files.</p> <p>Note the entire project is file-based, which makes it easy to perform typical project functions such as source control, diff, merge, code reviews etc.</p> <p> </p> <p>When you create an ApiLogicProject, the system creates a project like this, pre-configured for Developer Oprations.  See the notes below.</p> <p></p> <p> </p>"},{"location":"Project-Structure/#1-dev-container","title":"1. Dev Container","text":"<p>You can customize projects using a local install, or a container (see the Install Guide).  Container support includes the <code>.devcontainer</code> folder, and the <code>devops/docker/ForVSCode.dockerfile</code>.  You should not need to alter these.</p> <p>In addition to desktop-based development, these enable Codespaces support (see the Express Eval).</p> <p> </p>"},{"location":"Project-Structure/#2-deployment-container","title":"2. Deployment Container","text":"<p>A common approach to deployment is to create a container for your project.  The <code>build-container.dockerfile</code> is created for this purpose.</p> <p>You will need to edit it to reflect your project and Docker account names.</p> <p> </p>"},{"location":"Project-Structure/#3-launch-configurations","title":"3.  Launch Configurations","text":"<p>These are created so you can run the API Logic Server, run tests, etc.  You should not need to modify these, but you may wish to extend them.  </p> <p>Note the file that starts the project is <code>api_logic_server_run.py</code>, which obtains arguments from <code>conf/config.py</code> and environmental variables.</p> <p> </p>"},{"location":"Project-Structure/#4-python-venv","title":"4. Python <code>venv</code>","text":"<p>The creation process builds a standard <code>requirements.txt</code> file.  You can create your <code>venv</code> with this, and (if your IDE does not provide it) the <code>venv.sh/ps1</code> files to initialize your <code>venv</code>.</p> <p> </p>"},{"location":"Project-Structure/#5-github","title":"5. GitHub","text":"<p>Your project includes a suggested <code>.gitignore</code> file (alter as desired).  You can use git in standard ways to push and pull changes.  Some IDEs support the initial GitHub creation (see VSCode publish, or you can use the <code>git_push_new_project.sh</code> file. </p> <p> </p>"},{"location":"Project-Structure/#6-configuration-env-variables","title":"6. Configuration, env variables","text":"<p>Most deployment procedures discourage database names / passwords to be in project files and GitHub, instead preferring to specify these via <code>env</code> variables; click here for more information</p> <p> </p>"},{"location":"Project-Structure/#ide-friendly","title":"IDE Friendly","text":"<p>The project structure above can be loaded into any IDE for code editing, debugging, etc.  For more information on using IDEs, see here.</p> <p> </p>"},{"location":"Project-Structure/#tool-friendly-file-based","title":"Tool-friendly - file-based","text":"<p>All project elements are files - no database or binary objects.  So, you can store objects in source control systems like git, diff/merge them, etc.</p> <p> </p>"},{"location":"Project-Structure/#customizing-apilogicprojects","title":"Customizing ApiLogicProjects","text":"<p>You will typically want to customize and extend the created project.  Edit the files noted ih the diagram at the top of this page.</p> <p>Projects are created from a system-supplied prototype.  You can use your own prototype from git (or a local directory) using the <code>from_git</code> parameter.</p>"},{"location":"Project-Structure/#architecture","title":"Architecture","text":"<p>The resultant projects operates as a (typically containerized) 3-tiered architecture, as described here.</p>"},{"location":"Project-Structure/#apilogicserver-cli","title":"ApiLogicServer CLI","text":"<p>API Logic Server consists of a CLI and various runtimes, as described here.  The commands on this page (<code>ApiLogicServer create</code> etc) are part of the ApiLogicServer CLI.  </p> <p>The CLI operates in a standard way.  Consider the following command:</p> <pre><code>ApiLogicServer create --project-name=my-project --db-url=sqlite3-url\n</code></pre> <ol> <li><code>create</code> is a command; discover the commands with <code>ApiLogicServer</code></li> <li><code>--project-name</code> is an option; discover the options with <code>ApiLogicServer create --help</code></li> </ol> <p>Note: as of release 10.3.45, you can use the abbreviation <code>als</code> instead of <code>ApiLogicServer</code></p>"},{"location":"Sample-AI-ChatGPT/","title":"One Day Projects","text":""},{"location":"Sample-AI-ChatGPT/#ai-sample","title":"AI Sample","text":"<p>Here's how to use AI and API Logic Server to create complete running systems in minutes:</p> <ol> <li>Use ChatGPT for Schema Automation: create a database schema from natural language</li> <li>Use API Logic Server Microservice Automation: create working software with 1 command:<ul> <li>App Automation: a multi-page, multi-table admin app</li> <li>API Automation: a JSON:API - crud for each table, with filtering, sorting, optimistic locking and pagination</li> </ul> </li> <li>Customize the project with your IDE:<ul> <li>Logic Automation using rules: declare spreadsheet-like rules in Python for multi-table derivations and constraints - 40X more concise than code</li> <li>Use Python and standard libraries (Flask, SQLAlchemy), and debug in your IDE</li> </ul> </li> <li>Iterate your project:<ul> <li>Revise your database design and logic</li> <li>Integrate with B2B partners and internal systems</li> </ul> </li> </ol> <p></p> <p>This process leverages your existing IT infrastructure: your IDE, GitHub, the cloud, your database\u2026 open source.  Let's see how.</p> <p> </p>"},{"location":"Sample-AI-ChatGPT/#1-ai-schema-automation","title":"1. AI: Schema Automation","text":"<p>You can use an existing database, or create a new one with ChapGPT or your database tools.</p> <p>Use ChatGPT to generate SQL commands for database creation:</p> <p>Create database schemas from ChatGPT -- provide this prompt</p> <p>Create a sqlite database for customers, orders, items and product</p> <p>Hints: use autonum keys, allow nulls, Decimal types, foreign keys, no check constraints.</p> <p>Include a notes field for orders.</p> <p>Create a few rows of only customer and product data.</p> <p>Use Logic Bank to enforce the Check Credit requirement:</p> <ol> <li>Customer.Balance &lt;= CreditLimit</li> <li>Customer.Balance = Sum(Order.AmountTotal where date shipped is null)</li> <li>Order.AmountTotal = Sum(Items.Amount)</li> <li>Items.Amount = Quantity * UnitPrice</li> <li>Store the Items.UnitPrice as a copy from Product.UnitPrice</li> </ol> <p> </p> <p>This creates standard SQL, like this.  Copy the generated SQL commands into a file, say, <code>sample-ai.sql</code>.  (As always with AI, eyeball the result - for example, you may need to remove a command like \"CREATE DATABASE store.db;\").</p> <p>Then, create the database:</p> <pre><code>sqlite3 sample_ai.sqlite &lt; sample_ai.sql\n</code></pre> <p>You may not have the sqlite cli; you can proceed to step 2 and the system will use a pre-installed database.</p> <p> </p>"},{"location":"Sample-AI-ChatGPT/#2-api-logic-server-create","title":"2. API Logic Server: Create","text":"<p>Given a database, API Logic Server creates an executable, customizable project with the following single command:</p> <pre><code>$ ApiLogicServer create --project_name=sample_ai --db_url=sqlite:///sample_ai.sqlite\n</code></pre> <p>This creates a project you can open with your IDE, such as VSCode (see below).  The project is now ready to run - press F5.  It includes:</p> <ul> <li>a self-serve API ready for UI developers, and</li> <li>an Admin app ready for Business User Collaboration</li> </ul> <p></p> <p> </p>"},{"location":"Sample-AI-ChatGPT/#a-app-automation","title":"a. App Automation","text":"<p>App Automation means that <code>ApiLogicServer create</code> creates a multi-page, multi-table Admin App -- automatically.  This React-Admin app does not consist of hundreds of lines of complex html and javascript - it's a simple yaml file that's easy to customize.</p> <p>Ready for business user collaboration, back-office data maintenance - Day 1.</p> <p></p> <p> </p>"},{"location":"Sample-AI-ChatGPT/#b-api-automation","title":"b. API Automation","text":"<p>API Automation means that <code>ApiLogicServer create</code> creates a JSON:API -- automatically.  Your API supports related data access, pagination, optimistic locking, filtering, and sorting.</p> <p>It would take days to months to create such an API using frameworks.</p> <p>UI App Developers can create custom apps immediately, using swagger to design their API call, and copying the URI into their JavaScript code.  APIs are thus self-serve: no server coding is required.  </p> <p>Custom App Dev is unblocked - Day 1.</p> <p></p> <p> Key Take Away -- Microservice Automation</p> <p>Microservice Automation means that With 1 command, we have a running API and Admin App.</p> <ul> <li>With a framework, you are ready to code</li> <li> <p>With automation, you are ready to run</p> <ul> <li>UI Developers unblocked</li> <li>Ad Hoc Integration</li> </ul> </li> </ul> <p> </p>"},{"location":"Sample-AI-ChatGPT/#3-customize","title":"3. Customize","text":"<p>So, we have working software, in minutes.  It's running, but we really can't deploy it until we have logic and security.  Which brings us to customization.</p> <p>Projects are designed for customization, using standards: Python, frameworks (e.g., Flask, SQLAlchemy), and your IDE for code editing and debugging.  Not only Python code, but also Rules.</p> <p>To explore, let's customize this project.  To speed things up, instead of the normal procedure of declaring rules in your IDE, follow this procedure:</p> <ol> <li> <p>Stop the Server</p> </li> <li> <p>Execute the following in your IDE terminal window:</p> </li> </ol> <pre><code>ApiLogicServer sample-ai\nApiLogicServer add-auth --db_url=auth\n</code></pre> <p>This applies customized logic and security, which we examine below.</p> <p> </p>"},{"location":"Sample-AI-ChatGPT/#a-logic-automation","title":"a. Logic Automation","text":"<p>Logic Automation means that you can declare spreadsheet-like rules using Python.  Such logic maintains database integrity with multi-table derivations and constraints, and security.  Rules are 40X more concise than traditional code, and can be extended with Python.</p> <p>Below we implement the Check Credit requirement - see the comments at top.  Their implementation follows: 5 rules, instead of 200 lines of Python.</p> <ol> <li>Use the Admin App to add an Item for 1000 Widgets, observe how the constraint prevents the transaction</li> </ol> <p>Rules are an executable design.  Note they map exactly to our natural language design:</p> <p></p> <p> </p> <p>1. Debugging</p> <p>The screenshot above shows our logic declarations, and how we debug them:</p> <ol> <li> <p>Execution is paused at a breakpoint in the debugger, where we can examine state, and execute step by step.</p> </li> <li> <p>Note the logging for inserting an <code>Item</code>.  Each line represents a rule firing, and shows the complete state of the row. </p> </li> </ol> <p>2. Chaining - Multi-Table Transaction Automation</p> <p>Note that it's a <code>Multi-Table Transaction</code>, as indicated by the log indentation.  This is because - like a spreadsheet - rules automatically chain, including across tables. </p> <p>3. 40X More Concise</p> <p>The 5 spreadsheet-like rules represent the same logic as 200 lines of code, shown here.  That's a remarkable 40X decrease in the backend half of the system. </p> <p>4. Automatic Re-use</p> <p>The logic above, perhaps conceived for Place order, applies automatically to all transactions: deleting an order, changing items, moving an order to a new customer, etc.  This reduces code, and promotes quality (no missed corner cases). </p> <p>5. Automatic Optimizations</p> <p>SQL overhead is minimized by pruning, and by elimination of expensive aggregate queries.  These can result in orders of magnitude impact.  This is because the rule engine is not a Rete algorithm, but highly optimized for transaction processing, and integrated with the SQLAlchemy ORM (Object Relational Manager). </p> <p>6. Transparent</p> <p>Rules are an executable design.  Note they map exactly to our natural language design (shown in comments) - readable by business users.  </p> <p> </p>"},{"location":"Sample-AI-ChatGPT/#b-security-automation","title":"b. Security Automation","text":"<p>Security Automation means you activate security, and declare grants (using Python) to control row access for user roles.</p> <p>Security requires login to use the Admin App and Swagger.  Security also provide row-level authorization - here, we ensure that less active accounts are hidden if we login as user s1.p:</p> <pre><code>Grant(  on_entity = models.Customer,\n        to_role = Roles.sales,\n        filter = lambda : models.Customer.CreditLimit &gt; 3000,\n        filter_debug = \"CreditLimit &gt; 3000\")\n</code></pre> <p> </p>"},{"location":"Sample-AI-ChatGPT/#4-iterate-rules-python","title":"4. Iterate: Rules + Python","text":"<p>So we have completed our 1 day project.  We can deploy it, as described here, for agile collaboration with business users.</p> <p>Which leads to agile iterations.  Automation helps here too: not only are spreadsheet-like rules 40X more concise, they meaningfully simplify iterations and maintenance.  Let\u2019s explore this with two changes:</p> <p>Green Discounts</p> <p>Give a 10% discount for carbon-neutral products for 10 items or more.</p> <p>\u00a0 And:</p> <p>Application Integration</p> <ol> <li> <p>Provide read access for internal applications.</p> </li> <li> <p>Enable B2B partners to place orders with a custom API.</p> </li> <li> <p>Send new Orders to Shipping using a Kafka message.</p> </li> </ol> <p> </p> <p>As above, we speed things up with the following procedure:</p> <ol> <li> <p>Stop the Server</p> </li> <li> <p>Execute the following in your IDE terminal window:</p> </li> </ol> <pre><code>ApiLogicServer sample-ai-iteration\nApiLogicServer rebuild-from-database --project_name=. --db_url=sqlite:///database/db.sqlite\n</code></pre> <p>This revises your database to add the new Product.CarbonNeutral column, and installs some new code we'll explore below.</p> <p> </p> <p>Iterate Logic - Add Python</p> <p>Here is our revised logic to apply the discount, and send the Kafka message:</p> <p></p> <p>We can also extend our API for our new B2BOrder endpoint, using standard Python and Flask as shown below.  The code includes the swagger example, so we can now test our endpoint:</p> <ol> <li>Use Swagger (ServicesEndPoint &gt; POST /ServicesEndPoint/OrderB2B)</li> </ol> <p></p> <p>Note: Kafka is not activated in this example.  To explore a running Tutorial for application integration with running Kafka, click here.</p> <p>This illustrates some significant aspects of logic.</p> <p> </p>"},{"location":"Sample-AI-ChatGPT/#a-maintenance-automation","title":"a. Maintenance Automation","text":"<p>Along with perhaps documentation, one of the tasks programmers most loathe is maintenance.  That\u2019s because it\u2019s not about writing code, but archaeology - deciphering code someone else wrote, just so you can add 4 or 5 lines that\u2019ll hopefully be called and function correctly.</p> <p>Logic Automation changes that, with Maintenance Automation, which means:</p> <ul> <li>Rules automatically order their execution (and pruning) based on system-discovered dependencies</li> <li>Rules are automatically reused for all relevant transactions</li> </ul> <p>So, to alter logic, you just \u201cdrop a new rule in the bucket\u201d, and the system will ensure it\u2019s called in the proper order, and re-used over all the relevant Use Cases.</p> <p> </p>"},{"location":"Sample-AI-ChatGPT/#b-extensibility-with-python","title":"b. Extensibility: With Python","text":"<p>In the first case, we needed to do some if/else testing, and it was more convenient to add a dash of Python.  While this is pretty simple Python as a 4GL, you have full power of object-oriented Python and its many libraries.</p> <p>For example, our extended API leverages Flask and open source libraries for Kafka messages.</p> <p> </p>"},{"location":"Sample-AI-ChatGPT/#c-rebuild-logic-preserved","title":"c. Rebuild: Logic Preserved","text":"<p>Note we rebuilt the project from our altered database (<code>ApiLogicServer rebuild-from-database</code>), without losing customizations.</p> <p> </p>"},{"location":"Sample-AI-ChatGPT/#summary","title":"Summary","text":"<p>In minutes, you've used ChatGPT and API Logic Server to convert an idea into working software.  It required only 5 rules, and 20 lines of Python.  The process was simple:</p> <ul> <li> <p>Created the Schema with <code>ChatGPT</code></p> </li> <li> <p>Created the Project with <code>ApiLogicServer</code></p> <ul> <li>A Self-Serve API to unblock UI Developers -- Day 1</li> <li>An Admin App for Business User Collaboration -- Day 1</li> </ul> </li> <li> <p>Customized the project</p> <ul> <li>With Rules -- 40X more concise than code</li> </ul> </li> <li> <p>Iterated the project in your IDE to implement new requirements</p> <ul> <li>Rules, with Python for complete flexibility</li> <li>Prior customizations are preserved</li> </ul> </li> </ul> <p>It all works with standard tooling: Python, your IDE, and container-based deployment.</p>"},{"location":"Sample-AI/","title":"AI - Copilot","text":"<p> Instant API Services with Copilot and API Logic Server</p> <p>Creating an API and an admin app using a framework takes too long, and is far too complex. AI and automation can create systems in minutes rather than weeks or months, dramatically simpler, and fully customizable with tools and approaches you already know.</p> <p>In this demo, we'll show how to create a complete system using VS Code, Copilot, and API Logic Server. We'll then add business logic with rules, and use Python to add a custom endpoint and Kafka integration.</p> <p>Note: if you have already created the project, proceed to \"Run the Created Application\".</p> <p> </p>"},{"location":"Sample-AI/#overview","title":"Overview","text":"<p>As shown below, you can submit a Natural Language description of a database to Copilot. This creates a Python data model (SQLAlchemy classes).  </p> <p>You then use API Logic Server CLI to create an executable project from the model. Alternatively, you can create a project by identifying an existing database (pre-installed).</p> <ul> <li> <p>The project is executable, providing an API and an admin app, enabling agile collaboration and unblocking custom app dev.</p> </li> <li> <p>The project is customizable, using rules and Python, in your existing IT infrastructure - your IDE, GitHub, the cloud, your database, etc.  </p> </li> </ul> <p>Let's see how.</p> <p></p> <p> </p> <p>Setup</p> <p>To begin, install Python and VSCode. </p> <p>Optionally, install Copilot: it's moderately priced and you can execute this demo without it. But, it provides the Natural Language services shown here - it's quite a lot of fun to explore, so you might just want to splurge and acquire it.</p> <p>Then, install the API Logic Server and start it:</p> Install and start API Logic Server<pre><code>python3 -m venv venv \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 # windows: python -m venv venv \nsource venv/bin/activate             # windows: venv\\Scripts\\activate \npython -m pip install ApiLogicServer\n\nApiLogicServer start\n</code></pre> <p>This will launch the API Logic Server in VSCode. We've moved the Copilot chat pane to the right.</p> <p></p>"},{"location":"Sample-AI/#1-create-db-model-with-copilot","title":"1. Create DB Model with Copilot","text":"<p>If you are using Copilot..</p> <p>The Sample-AI page includes the Natural Language Text to supply to Copilot; paste it, and press enter. It's shown in the diagram below in dark gray (\"Use SQLAlchemy to...\").</p> <p>Create database model from Copilot -- provide this prompt</p> <p>Use SQLAlchemy to create a sqlite database named sample_ai.sqlite, with customers, orders, items and product</p> <p>Hints: use autonum keys, allow nulls, Decimal types, foreign keys, no check constraints.</p> <p>Include a notes field for orders.</p> <p>Create a few rows of only customer and product data.</p> <p>Enforce the Check Credit requirement (do not generate check constraints):</p> <ol> <li>Customer.Balance &lt;= CreditLimit</li> <li>Customer.Balance = Sum(Order.AmountTotal where date shipped is null)</li> <li>Order.AmountTotal = Sum(Items.Amount)</li> <li>Items.Amount = Quantity * UnitPrice</li> <li>Store the Items.UnitPrice as a copy from Product.UnitPrice</li> </ol> <p>Copilot creates the SQLAlchemy model code.</p> <p>Paste the generated code into a new model file called <code>sample_ai.py</code> (step 2 in the screenshot below):</p> <p></p> <p> </p>"},{"location":"Sample-AI/#2-api-logic-server-create","title":"2. API Logic Server: Create","text":"<p>If you are using Copilot:</p> <p>Create your project (step 3 in the screenshot above) by entering the following into the bottom terminal pane (als is a synonym for ApiLogicServer):</p> Create Project with Copilot<pre><code>$  als create --project-name=sample_ai --from-model=sample_ai.py --db-url=sqlite\n</code></pre> <p> </p> <p>Or, if you are not using Copilot...,</p> <p>Use the pre-installed database to create your project in the terminal window:</p> Create Project from Existing Database<pre><code>$  als create --project-name=sample_ai --db-url=sqlite:///sample_ai.sqlite\n</code></pre> <p> </p>"},{"location":"Sample-AI/#run-the-created-application","title":"Run the Created Application","text":"<p>In either case, this creates a project and opens it in your IDE, such as VSCode (see below).  The project is now ready to run - press F5.  It provides Microservice Automation:</p> <p> a. App Automation: an Admin App, ready for Business User Collaboration, and</p> <p> b. Api Automation: a self-serve JSON:API, ready for UI developers</p> <p></p> <p> </p>"},{"location":"Sample-AI/#a-app-automation","title":"a. App Automation","text":"<p>App Automation means that <code>ApiLogicServer create</code> creates a multi-page, multi-table Admin App -- automatically.  This React-Admin app does not consist of hundreds of lines of complex html and javascript - it's a simple yaml file that's easy to customize.</p> <p>Ready for business user collaboration, back-office data maintenance - Day 1.</p> <p></p> <p> </p>"},{"location":"Sample-AI/#b-api-automation","title":"b. API Automation","text":"<p>API Automation means that <code>ApiLogicServer create</code> creates a JSON:API -- automatically.  Your API supports related data access, pagination, optimistic locking, filtering, and sorting.</p> <p>It would take days to months to create such an API using frameworks.</p> <p>UI App Developers can create custom apps immediately, using swagger to design their API call, and copying the URI into their JavaScript code.  APIs are thus self-serve: no server coding is required.  </p> <p>Custom App Dev is unblocked - Day 1.</p> <p></p> <p> Key Take Away -- Microservice Automation</p> <p>Microservice Automation means that With 1 command, we have a running API and Admin App.</p> <ul> <li>With a framework, you are ready to code</li> <li> <p>With automation, you are ready to run</p> <ul> <li>UI Developers unblocked</li> <li>Ad Hoc Integration</li> </ul> </li> </ul> <p> </p>"},{"location":"Sample-AI/#3-customize","title":"3. Customize","text":"<p>So, we have working software, in minutes.  It's running, but we really can't deploy it until we have logic and security.  Which brings us to customization.</p> <p>API Logic Server contains a rule engine. You can declare rules in Python, using IDE code completion services.  </p> <p>It provides signficant value: spreadsheet-like rules reduce logic code (half the app) by 40X.</p> <p>But, we can have much more fun.  As shown below, we can ask Copilot to create these rules for us, and paste them into a pre-created file:</p> <p></p> <p> </p> <p>Apply Remaining Customizations</p> <p>Projects are designed for customization, using standards: Python, frameworks (e.g., Flask, SQLAlchemy), and your IDE for code editing and debugging.  Not only Python code, but also Rules.</p> <p>To explore, let's customize this project.  To speed things up, instead of the normal procedure of declaring rules and entering Python code in your IDE, follow this procedure:</p> <ol> <li> <p>Stop the Server</p> </li> <li> <p>Execute the following in your IDE terminal window:</p> </li> </ol> <pre><code>ApiLogicServer sample-ai\nApiLogicServer add-auth --db_url=auth\n</code></pre> <p>This applies customized logic and security, which we examine below.</p> <p> </p>"},{"location":"Sample-AI/#a-logic-automation","title":"a. Logic Automation","text":"<p>Logic Automation means that you can declare spreadsheet-like rules using Python.  Such logic maintains database integrity with multi-table derivations and constraints, and security.  Rules are 40X more concise than traditional code, and can be extended with Python.</p> <p>Below we implement the Check Credit requirement - see the comments at top.  Their implementation follows: 5 rules, instead of 200 lines of Python.  It's ready to test:</p> <ol> <li>Restart the Server (F5)</li> <li>Use the Admin App to add an Item for 1000 Widgets, observe how the constraint prevents the transaction</li> </ol> <p>Rules are an executable design.  Note they map exactly to our natural language design:</p> <p></p> <p> </p> <p>1. Debugging</p> <p>The screenshot above shows our logic declarations, and how we debug them:</p> <ol> <li> <p>Execution is paused at a breakpoint in the debugger, where we can examine state, and execute step by step.</p> </li> <li> <p>Note the logging for inserting an <code>Item</code>.  Each line represents a rule firing, and shows the complete state of the row. </p> </li> </ol> <p>2. Chaining - Multi-Table Transaction Automation</p> <p>Note that it's a <code>Multi-Table Transaction</code>, as indicated by the log indentation.  This is because - like a spreadsheet - rules automatically chain, including across tables. </p> <p>3. 40X More Concise</p> <p>The 5 spreadsheet-like rules represent the same logic as 200 lines of code, shown here.  That's a remarkable 40X decrease in the backend half of the system. </p> <p>4. Automatic Re-use</p> <p>The logic above, perhaps conceived for Place order, applies automatically to all transactions: deleting an order, changing items, moving an order to a new customer, etc.  This reduces code, and promotes quality (no missed corner cases). </p> <p>5. Automatic Optimizations</p> <p>SQL overhead is minimized by pruning, and by elimination of expensive aggregate queries.  These can result in orders of magnitude impact.  This is because the rule engine is not a Rete algorithm, but highly optimized for transaction processing, and integrated with the SQLAlchemy ORM (Object Relational Manager). </p> <p>6. Transparent</p> <p>Rules are an executable design.  Note they map exactly to our natural language design (shown in comments) - readable by business users.  </p> <p> </p>"},{"location":"Sample-AI/#b-security-automation","title":"b. Security Automation","text":"<p>Security Automation means you activate security, and declare grants (using Python) to control row access for user roles.</p> <p>Security requires login to use the Admin App and Swagger.  Security also provide row-level authorization - here, we ensure that less active accounts are hidden if we login as user s1.p:</p> <pre><code>Grant(  on_entity = models.Customer,\n        to_role = Roles.sales,\n        filter = lambda : models.Customer.CreditLimit &gt; 3000,\n        filter_debug = \"CreditLimit &gt; 3000\")\n</code></pre> <p> </p>"},{"location":"Sample-AI/#4-iterate-rules-python","title":"4. Iterate: Rules + Python","text":"<p>So we have completed our 1 day project.  We can deploy it, as described here, for agile collaboration with business users.</p> <p>Which leads to agile iterations.  Automation helps here too: not only are spreadsheet-like rules 40X more concise, they meaningfully simplify iterations and maintenance.  Let\u2019s explore this with two changes:</p> <p>Green Discounts</p> <p>Give a 10% discount for carbon-neutral products for 10 items or more.</p> <p>\u00a0 And:</p> <p>Application Integration</p> <ol> <li> <p>Provide read access for internal applications.</p> </li> <li> <p>Enable B2B partners to place orders with a custom API.</p> </li> <li> <p>Send new Orders to Shipping using a Kafka message.</p> </li> </ol> <p> </p> <p>As above, we speed things up with the following procedure:</p> <ol> <li> <p>Stop the Server</p> </li> <li> <p>Execute the following in your IDE terminal window:</p> </li> </ol> <pre><code>ApiLogicServer sample-ai-iteration\nApiLogicServer rebuild-from-database --project_name=. --db_url=sqlite:///database/db.sqlite\n</code></pre> <p>This revises your database to add the new Product.CarbonNeutral column, and installs some new code we'll explore below.</p> <p> </p> <p>Iterate Logic - Add Python</p> <p>Here is our revised logic to apply the discount, and send the Kafka message:</p> <p></p> <p>We can also extend our API for our new B2BOrder endpoint, using standard Python and Flask as shown below.  The code includes the swagger example, so we can now test our endpoint:</p> <ol> <li>Use Swagger (ServicesEndPoint &gt; POST /ServicesEndPoint/OrderB2B)</li> </ol> <p></p> <p>Note: Kafka is not activated in this example.  To explore a running Tutorial for application integration with running Kafka, click here.</p> <p>This illustrates some significant aspects of logic.</p> <p> </p>"},{"location":"Sample-AI/#a-maintenance-automation","title":"a. Maintenance Automation","text":"<p>Along with perhaps documentation, one of the tasks programmers most loathe is maintenance.  That\u2019s because it\u2019s not about writing code, but archaeology - deciphering code someone else wrote, just so you can add 4 or 5 lines that\u2019ll hopefully be called and function correctly.</p> <p>Logic Automation changes that, with Maintenance Automation, which means:</p> <ul> <li>Rules automatically order their execution (and pruning) based on system-discovered dependencies</li> <li>Rules are automatically reused for all relevant transactions</li> </ul> <p>So, to alter logic, you just \u201cdrop a new rule in the bucket\u201d, and the system will ensure it\u2019s called in the proper order, and re-used over all the relevant Use Cases.</p> <p> </p>"},{"location":"Sample-AI/#b-extensibility-with-python","title":"b. Extensibility: With Python","text":"<p>In the first case, we needed to do some if/else testing, and it was more convenient to add a dash of Python.  While this is pretty simple Python as a 4GL, you have full power of object-oriented Python and its many libraries.</p> <p>For example, our extended API leverages Flask and open source libraries for Kafka messages.</p> <p> </p>"},{"location":"Sample-AI/#c-rebuild-logic-preserved","title":"c. Rebuild: Logic Preserved","text":"<p>Note we rebuilt the project from our altered database (<code>ApiLogicServer rebuild-from-database</code>), without losing customizations.</p> <p> </p>"},{"location":"Sample-AI/#5-deploy","title":"5. Deploy","text":"<p>Value is not realized until the system is deployed, whether for final production, or early collaboration with stakeholders. API Logic Server creates scripts to containerize your project, and deploy to Azure with Docker Compose:</p> <p></p> <p> </p>"},{"location":"Sample-AI/#summary","title":"Summary","text":"<p>In minutes, you've used Copilot and API Logic Server to convert an idea into working software.  It required only 5 rules, and 20 lines of Python.  The process was simple:</p> <ul> <li> <p>Created the Schema with <code>Copilot</code></p> </li> <li> <p>Created the Project with <code>ApiLogicServer</code></p> <ul> <li>A Self-Serve API to unblock UI Developers -- Day 1</li> <li>An Admin App for Business User Collaboration -- Day 1</li> </ul> </li> <li> <p>Customized the project</p> <ul> <li>With Rules -- 40X more concise than code, declared with Copilot or IDE code completion</li> </ul> </li> <li> <p>Iterated the project in your IDE to implement new requirements</p> <ul> <li>Rules, with Python for complete flexibility</li> <li>Prior customizations are preserved</li> </ul> </li> </ul> <p>It all works with standard tooling: Python, your IDE, and container-based deployment.</p>"},{"location":"Sample-Basic-Demo-Vibe/","title":"Vibe MCP / Microservice","text":""},{"location":"Sample-Basic-Demo-Vibe/#vibe-an-mcp-microservice","title":"Vibe an MCP Microservice","text":"<p>This illustrates GenAI-Logic automation to create an MCP system using Vibe: </p> <p>1) Natural Language, 2) Declarative (what not now), 3) Trusted error correction with the coding assistant</p> <p></p> \ud83e\udd16 Bootstrap Copilot by pasting the following into the chat<pre><code>Please find and read `.github/.copilot-instructions.md`.\n</code></pre> <p>Important: be sure CoPilot is in \"Agent\" Mode.  \"Ask\" will not work.  Also, we get consistently good results with <code>Claude Sonnet 4.5</code>.</p> <p></p> <p>How to Use This Demo:</p> <p>This demo teaches AI-assisted development patterns. Each step is a natural language prompt you copy/paste into Copilot chat. The prompts are self-documenting - they explain what they do.</p> <p>Vibe Philosophy: AI makes errors. That's expected. When something fails, tell Copilot: \"Error X occurred, fix it\". Copilot is exceptionally good at finding and correcting its own mistakes.</p> <p>Recommended Path: If you're new to GenAI-Logic, start with the Standard Demo (creates <code>basic_demo</code> with guided tutor) to learn platform fundamentals. Then return here to explore AI-assisted development with <code>basic_demo_vibe</code>.</p> <p></p> Demo Overview: Vibe an MCP API, Custom Client and Business Logic; pre-reqs  <p>Here we will use Vibe to:</p> <ol> <li> <p>Create From Existing DB - Provides a MCP-enabled API and an Admin App    - Project Opens: Run - Launch and verify your system</p> </li> <li> <p>Custom UI: GenAI, Vibe - Create a custom (React) client</p> </li> <li> <p>Declare Business Logic - Add rules with natural language</p> </li> <li> <p>Enterprise Connectivity: B2B - Create integration endpoints</p> </li> <li> <p>MCP: Logic, User Interface - Implement Model Context Protocol</p> </li> <li> <p>Iterate: Rules and Python - Advanced customization patterns</p> </li> </ol> <p>Pre-reqs:</p> <ol> <li>Install</li> <li>OpenAI API Key is useful but not required; click here.</li> </ol> <ul> <li>The React App has pre-built apps (<code>ui/my-react-app</code>) you can use; they require <code>npm install; npm start</code></li> <li>The <code>integration/mcp/mcp_client_executor.py</code> has <code>create_tool_context_from_llm</code> set to bypass LLM calls and use saved context; alter as required. 3. NodeJS to run the react app</li> </ul> <p>The entire process takes 20 minutes; usage notes:</p> <ul> <li>Most find it more convenient to view this in your Browser; click here</li> <li>A slide show summary is available on our Web Site</li> <li>Tip: look for readme files in created projects</li> </ul> <p></p> <p></p>"},{"location":"Sample-Basic-Demo-Vibe/#1-create-from-existing-db","title":"1. Create From Existing DB","text":"Create a project from an existing database (open the disclosure box for details)<pre><code>Create a database project named basic_demo_vibe from samples/dbs/basic_demo.sqlite\n</code></pre>  The database is Customer, Orders, Items and Product; you can also create the database <p>Or, create a new database with this prompt: <pre><code>Create a system with customers, orders, items and products.\n\nInclude a notes field for orders.\n\nUse case: Check Credit    \n    1. The Customer's balance is less than the credit limit\n    2. The Customer's balance is the sum of the Order amount_total where date_shipped is null\n    3. The Order's amount_total is the sum of the Item amount\n    4. The Item amount is the quantity * unit_price\n    5. The Item unit_price is copied from the Product unit_price\n\nUse case: App Integration\n    1. Send the Order to Kafka topic 'order_shipping' if the date_shipped is not None.\n</code></pre></p> <p></p> <p>In either case, the database model is customer, orders and items:</p> <p></p> <p> </p>"},{"location":"Sample-Basic-Demo-Vibe/#1a-project-opens-run","title":"1a. Project Opens: Run","text":"<p>The project should automatically open a new window in VSCode. </p> \ud83e\udd16 Again, bootstrap Copilot by pasting the following into the chat<pre><code>Please find and read `.github/.copilot-instructions.md`.\n</code></pre> <p>Run it as follows:</p> <ol> <li>Start the Server: F5 </li> <li>Start the Admin App: browse to http://localhost:5656/.  The Admin App screen shown below should appear in your Browser.</li> <li>Verify as shown below</li> </ol> API: filtering, sorting, pagination, optimistic locking,related data access... see Swagger  <p>Your API is MCP enabled, and ready for custom app dev.  For more information, click here.</p> <p></p> <p></p> Admin App: multi-page, multi-table, automatic joins, lookups, cascade add - collaboration-ready <p>For more information, click here.</p> <p>The Admin App is ready for business user agile collaboration, and back office data maintenance.  This complements custom UIs created with the API.</p> <p>Explore the app - click Customer Alice, and see their Orders, and Items.  </p> <p></p> <p></p>"},{"location":"Sample-Basic-Demo-Vibe/#2-custom-ui-genai-vibe","title":"2. Custom UI: GenAI, Vibe","text":"<p>The app above is suitable for collaborative iteration to nail down the requirements, and back office data maintenance.  It's also easy to make simple customizations, using the yaml file.  For more custom apps, use Vibe:</p> Create a custom react app - customize in your IDE directly or with Vibe<pre><code>Create a new react app using genai-add-app, \nwait for it to complete, \nthen update the Product list to provide users an option to see results in a list or in cards.\n</code></pre> Vibe Automation provides a running start (and can make errors) <ul> <li>Instead of creating data mockups, you have a running API server with real data</li> <li>Instead of starting from scratch, you have a running multi-page app </li> <li>And, you'll have projects that are architecturally correct: shared logic, enforced in the server, available for both User Interfaces and services.</li> <li>Then, use you favorite Vibe tools with your running API:</li> </ul> <p>Note: AI makes errors.  Part of Vibe is to accept that, and insist that AI find and fix them.  CoPilot is generally exceptionally good at this.</p> <p></p> <p>Below is an example from Northwind: click here</p> <p></p> <p></p>"},{"location":"Sample-Basic-Demo-Vibe/#3-declare-business-logic","title":"3. Declare Business Logic","text":"<p>Logic (multi-table derivations and constraints) is a significant portion of a system, typically nearly half.  GenAI-Logic provides spreadsheet-like rules that dramatically simplify and accelerate logic development.</p> <p>Rules are declared in Python, simplified with IDE code completion.  The screen below shows the 5 rules for Check Credit Logic.</p> <p>1. Stop the Server (Red Stop button, or Shift-F5 -- see Appendix)</p> <p>2. Add Business Logic</p> Check Credit Logic (instead of 220 lines of code)<pre><code>Use case: Check Credit    \n    1. The Customer's balance is less than the credit limit\n    2. The Customer's balance is the sum of the Order amount_total where date_shipped is null\n    3. The Order's amount_total is the sum of the Item amount\n    4. The Item amount is the quantity * unit_price\n    5. The Item unit_price is copied from the Product unit_price\n\nUse case: App Integration\n    1. Send the Order to Kafka topic 'order_shipping' if the date_shipped is not None.\n</code></pre> <p></p> <p>To test the logic:</p> <p>1. Use the Admin App to access the first order for <code>Customer Alice</code></p> <p>2. Edit its first item to a very high quantity</p> <p>The update is properly rejected because it exceeds the credit limit.  Observe the rules firing in the console log - see Logic In Action, below.</p> <p></p> Logic is critical - half the effort; Declarative is 40X More Concise, Maintainable  <p>Logic is critical to your system - it represents nearly half the effort.  Instead of procedural code, declare logic with WebGenAI, or in your IDE using code completion or Natural Language as shown above.</p> <p>a. 40X More Concise</p> <p>The 5 spreadsheet-like rules represent the same logic as 200 lines of code, shown here.  That's a remarkable 40X decrease in the backend half of the system.</p> <p>\ud83d\udca1 No FrankenCodeNote the rules look like syntactically correct requirements.  They are not turned into piles of unmanageable \"frankencode\" - see models not frankencode.</p> <p>b. Maintainable: Debugging, Logging</p> <p>The screenshot below shows our logic declarations, and the logging for inserting an <code>Item</code>.  Each line represents a rule firing, and shows the complete state of the row.</p> <p>Note that it's a <code>Multi-Table Transaction</code>, as indicated by the indentation.  This is because - like a spreadsheet - rules automatically chain, including across tables.</p> <p></p> <p></p>"},{"location":"Sample-Basic-Demo-Vibe/#4-enterprise-connectivity-b2b","title":"4. Enterprise Connectivity: B2B","text":"<p>To fit our system into the Value Chain, we need a custom API to accept orders from B2B partners, and forward paid orders to shipping via Kafka.</p> Create the Custom B2B API Endpoint<pre><code>Create a B2B order API called 'OrderB2B' that accepts orders from external partners. \n\nThe external format should map:\n- 'Account' field to find customers by name\n- 'Notes' field to order notes\n- 'Items' array where each item maps 'Name' to find products and 'QuantityOrdered' to item quantity\n\nThe API should create complete orders with automatic lookups and inherit all business logic rules.\n</code></pre> <p>The Kafka logic was created earlier, so we are ready to test.</p> <p>You can use Swagger (note the test data is provided), or use CLI:</p> Test the B2B Endpoint<pre><code>curl -X POST http://localhost:5656/api/OrderB2BEndPoint/OrderB2B -H \"Content-Type: application/json\" -d '{\"meta\":{\"args\":{\"data\":{\"Account\":\"Alice\",\"Notes\":\"RUSH order for Q4 promotion\",\"date_shipped\":\"2025-08-04\",\"Items\":[{\"Name\":\"Widget\",\"QuantityOrdered\":5},{\"Name\":\"Gadget\",\"QuantityOrdered\":3}]}}}}'\n</code></pre> <p>Observe the logic execution in the VSCode debug window.</p> <p></p>"},{"location":"Sample-Basic-Demo-Vibe/#5-mcp-logic-user-interface","title":"5. MCP: Logic, User Interface","text":"<p>The server is automatically mcp-enabled, but we also require a user-interface to enable business users to send email, subject to business logic for customer email opt-outs.  Build it as follows:</p> <p>1. Stop the Server:  click the red stop icon \ud83d\udfe5 or press Shift+F5.</p> <p>2. Create the SysEmail Table to Track Sent Emails</p> <p>Add a Table to Track Sent Emails<pre><code>Create a table SysEmail in `database/db.sqlite` as a child of customer, \nwith columns id, message, subject, customer_id and CreatedOn.\n</code></pre> Follow the suggestions to update the admin app.</p> <p></p> <p>3. Create an MCP Client Executor to process MCP Requests:</p> Create an MCP Client Executor (don't run yet)<pre><code>Create the mcp client executor\n</code></pre> <p>MCP Clients accept MCP Requests, invoke the LLM to obtain a series of API calls to run, and runs them.  For more on MCP, click here.</p> <p></p> <p>4. Create the email service using a Request Table</p> Create the email service using SysEmail as a Request Table<pre><code>Add an after_flush event on SysEmail to produce a log message \"email sent\",\nunless the customer has opted out.\n</code></pre> <p>Inserts into SysEmail will now send mails (stubbed here with a log message).  Request objects are a common rule pattern - for more information, click here.</p> <p></p> Creates logic like this  <p>When sending email, we require business rules to ensure it respects the opt-out policy:</p> <p></p> <p></p> <p>5. Restart the Server - F5</p> <p></p> <p>6. Start the Admin App</p> <p></p> <p>7. Click SysMCP &gt;&gt; Create New, and enter:</p> Test the MCP using the Admin App<pre><code>List the orders date_shipped is null and CreatedOn before 2023-07-14, \nand send a discount email (subject: 'Discount Offer') \nto the customer for each one.\n</code></pre> <p></p> <p></p> More on MCP; Observe the log  <p>For more on MCP, click here.</p> <p></p> <p></p>"},{"location":"Sample-Basic-Demo-Vibe/#6-iterate-rules-and-python","title":"6. Iterate: Rules and Python","text":"<p>This is addressed in the related CLI-based demo - to continue, click here.</p>"},{"location":"Sample-Basic-Demo/","title":"Instant Microservices - with Logic and Security","text":""},{"location":"Sample-Basic-Demo/#product-tour-start-here","title":"Product Tour (Start Here)","text":"<p>This illustrates basic GenAI-Logic operation: </p> <ol> <li>Creating projects from new or existing databases, providing a MCP-enabled API and an Admin App</li> <li>Adding declarative logic and security, and </li> <li>Customizing your project using your IDE and Python</li> </ol> <p>\ud83e\udd16 Bootstrap Copilot by pasting the following into the chat: \ud83e\udd16 Bootstrap Copilot by pasting the following into the chat<pre><code>Please find and read `.github/.copilot-instructions.md`.\n</code></pre></p> <p></p> <p>\ud83e\udd16 Ready to Explore?</p> <p>Recommended: Say to Copilot: \"Guide me through basic_demo\" (30-45 min hands-on tour)</p> <p>Alternative: Follow the sections below at your own pace</p> <p></p> <p>The entire process takes 20 minutes; usage notes:</p> <ul> <li>Important: look for readme files in created projects</li> <li>You may find it more convenient to view this in your Browser</li> <li>A slide show summary is available on our Web Site</li> </ul> <p></p> <p> </p>"},{"location":"Sample-Basic-Demo/#1-create-and-run","title":"1. Create and Run","text":"<p>API Logic Server can create projects from existing databases, or use GenAI to create projects with new databases.  Let's see how.</p> <p> </p>"},{"location":"Sample-Basic-Demo/#from-existing-database","title":"From Existing Database","text":"<p>This is the best way to start:</p> <ol> <li>Open a terminal window: Terminal &gt; New Terminal</li> <li>Create Project from Existing Database: <pre><code>genai-logic create --project_name=basic_demo --db_url=sqlite:///samples/dbs/basic_demo.sqlite\n</code></pre></li> </ol> <p>Note: the <code>db_url</code> value is an abbreviation for a test database provided as part of the installation.  You would normally supply a SQLAlchemy URI to your existing database, e.g. <code>genai-logic create  --project_name=basic_demo --db_url=sqlite:///samples/dbs/basic_demo.sqlite</code>.</p>  The database is Customer, Orders, Items and Product <p></p> <p> </p>"},{"location":"Sample-Basic-Demo/#genai-new-database","title":"GenAI: New Database","text":"<p>Alternatively, you can create a project and a new database from a prompt, using GenAI.</p> <p>Don't do this if you are executing the basic Product Tour.</p> <p>There are 3 ways to use GenAI:</p> <ul> <li>WebGenAI - in the Browser, via pubic website - click here, or</li> <li>GenAI -         in the Browser, via docker - click here, or </li> <li>GenAI CLI - click here </li> </ul> <p>To use the GenAI CLI:</p> <ol> <li>If you have signed up (see Get an OpenAI Key, below), this will create and open a project called <code>genai_demo</code> from <code>genai_demo.prompt</code> (available in left Explorer pane):</li> </ol> <pre><code>genai-logic genai --using=system/genai/examples/genai_demo/genai_demo.prompt --project-name=genai_demo\n</code></pre> <ol> <li>Or, you can simulate the process (no signup) using:</li> </ol> <pre><code>genai-logic genai --repaired-response=system/genai/examples/genai_demo/genai_demo.response_example --project-name=genai_demo\n</code></pre> <p>For background on how it works, click here.</p> <p> </p>"},{"location":"Sample-Basic-Demo/#open-in-your-ide-and-run","title":"Open in your IDE and Run","text":"<p>You can open with VSCode, and run it as follows:</p> <ol> <li> <p>Start the Server: F5 (also described in the Appendix).</p> <ul> <li>Your virtual environment is automatically configured in most cases; see the Appendix (Procedures / Detail Procedures) if that's not working.</li> </ul> </li> <li> <p>Start the Admin App: either use the links provided in the IDE console, or click http://localhost:5656/.  The Admin App screen shown below should appear in your Browser.</p> </li> </ol> <p>The sections below explore the system that has been created (which would be similar for your own database). </p>"},{"location":"Sample-Basic-Demo/#api-with-swagger","title":"API with Swagger","text":"<p>The system creates an API with end points for each table, with filtering, sorting, pagination, optimistic locking and related data access -- self-serve, ready for custom app dev.</p> See the Swagger  <p></p> <p></p>"},{"location":"Sample-Basic-Demo/#admin-app","title":"Admin App","text":"<p>It also creates an Admin App: multi-page, multi-table -- ready for business user agile collaboration, and back office data maintenance.  This complements custom UIs created with the API.</p> <p>You can click Customer Alice, and see their Orders, and Items.</p> See the Admin App  <p></p> <p></p>"},{"location":"Sample-Basic-Demo/#2-custom-ui-genai-vibe","title":"2. Custom UI: GenAI, Vibe","text":"<p>The app above is suitable for collaborative iteration to nail down the requirements, and back office data maintenance.  It's also easy to make simple customizations, using the yaml file.</p> <p>For more custom apps, you get complete control by generating app source code, which you can then customize in your IDE, e.g. using Vibe Natural Language:</p> <pre><code># create react source (requires OpenAI key)\ngenai-logic genai-add-app --vibe\ncd ui/react-app\nnpm install\nnpm start\n</code></pre> <p>And you are ready to Vibe:</p> <ul> <li>Instead of creating data mockups, you have a running API server with real data</li> <li>Instead of starting from scratch, you have a running multi-page app </li> <li>And, you'll have projects that are architecturally correct: shared logic, enforced in the server, available for both User Interfaces and services.</li> <li>Then, use you favorite Vibe tools with your running API:</li> </ul> <p>Customize using Natural Language: Customize using Natural Language<pre><code>In the ui/react app, Update the Product list to provide users an option to see results in a list, or in cards.\n</code></pre> </p> <p>Below is an example from Northwind: click here</p> <p></p> <p></p>"},{"location":"Sample-Basic-Demo/#3-mcp-ready-apis","title":"3. MCP-Ready APIs","text":"<p>Your project is MCP-ready - this will run a simple query List customers with credit_limit &gt; 1000 (we'll explore more interesting examples below, including provisions for user input):</p> <pre><code>Create a table SysEmail in `database/db.sqlite` as a child of customer, \nwith columns id, message, subject, customer_id and CreatedOn.\n</code></pre> <p>Follow the suggestions to update the admin app.</p> <p>TODO: add mcp client  here, and test</p> <p>TODO: test the service</p> <pre><code>List the orders date_shipped is null and CreatedOn before 2023-07-14, and send a discount email (subject: 'Discount Offer') to the customer for each one.\n</code></pre> <p></p> <p></p>"},{"location":"Sample-Basic-Demo/#4-declare-logic-and-security","title":"4. Declare Logic And Security","text":"<p>While API/MCP/UI automation is a great start, it's critical to enforce logic and security.  You do this in your IDE.  Here's how.</p> <p>The following <code>add_customizations</code> process simulates:</p> <ul> <li>Adding security to your project, and</li> <li>Using your IDE to declare logic and security in <code>logic/declare_logic.sh</code> and <code>security/declare_security.py</code>.</li> </ul> <p>Declared security and logic are shown in the screenshots below.It's quite short - 5 rules, 7 security settings.</p> <p>To add customizations, in a terminal window for your project:</p> <p>1. Stop the Server (Red Stop button, or Shift-F5 -- see Appendix)</p> <p>2. Add Customizations</p> <p><pre><code>genai-logic add-cust\ngenai-logic add-auth --db_url=auth\n</code></pre> </p>"},{"location":"Sample-Basic-Demo/#security-role-based-access","title":"Security: Role Based Access","text":"<p>The <code>add_customizations</code> process above has simulated using your IDE to declare security in <code>logic/declare_logic.sh</code>.</p> <p>To see security in action:</p> <p>1. Start the Server  F5</p> <p>2. Start the Admin App: http://localhost:5656/</p> <p>3. Login as <code>s1</code>, password <code>p</code></p> <p>4. Click Customers</p> <p> Observe:</p> <p>1. Login now required</p> <p>2. Role-Based Filtering</p> <p>Observe you now see fewer customers, since user <code>s1</code> has role <code>sales</code>.  This role has a declared filter, as shown in the screenshot below.</p> <p>3. Transparent Logging</p> See Security Declarations  <p>The screenshot below illustrates security declaration and operation:</p> <ul> <li> <p>The declarative Grants in the upper code panel, and</p> </li> <li> <p>The logging in the lower panel, to assist in debugging by showing which Grants (<code>+ Grant:</code>) are applied:</p> </li> </ul> <p></p> <p> </p>"},{"location":"Sample-Basic-Demo/#logic-derivations-constraints","title":"Logic: Derivations, Constraints","text":"<p>Logic (multi-table derivations and constraints) is a significant portion of a system, typically nearly half.  API Logic Server provides spreadsheet-like rules that dramatically simplify and accelerate logic development.</p> <p>Rules are declared in Python, simplified with IDE code completion.  The screen below shows the 5 rules for Check Credit Logic.</p> <p>The <code>add_customizations</code> process above has simulated the process of using your IDE to declare logic in <code>logic/declare_logic.sh</code>.</p> <p>To see logic in action:</p> <p>1. In the admin app, Logout (upper right), and login as admin, p</p> <p>2. Use the Admin App to access the first order for <code>Customer Alice</code></p> <p>3. Edit its first item to a very high quantity</p> <p>The update is properly rejected because it exceeds the credit limit.  Observe the rules firing in the console log - see Logic In Action, below.</p> <p></p> <p>\ud83d\udca1 Logic: Multi-table Derivations and Constraint Declarative Rules. Declarative Rules are 40X More Concise than procedural code.\u2003\u2003For more information, click here.</p> <p></p> See Logic In Action  <p>Declare logic with WebGenAI, or in your IDE using code completion or Natural Language:</p> <p></p> <p>a. Chaining</p> <p>The screenshot below shows our logic declarations, and the logging for inserting an <code>Item</code>.  Each line represents a rule firing, and shows the complete state of the row.</p> <p>Note that it's a <code>Multi-Table Transaction</code>, as indicated by the indentation.  This is because - like a spreadsheet - rules automatically chain, including across tables.</p> <p></p> <p>b. 40X More Concise</p> <p>The 5 spreadsheet-like rules represent the same logic as 200 lines of code, shown here.  That's a remarkable 40X decrease in the backend half of the system.</p> <p>\ud83d\udca1 No FrankenCodeNote the rules look like syntactically correct requirements.  They are not turned into piles of unmanageable \"frankencode\" - see models not frankencode.</p> <p></p> <p>c. Automatic Re-use</p> <p>The logic above, perhaps conceived for Place order, applies automatically to all transactions: deleting an order, changing items, moving an order to a new customer, etc.  This reduces code, and promotes quality (no missed corner cases). </p> <p>d. Automatic Optimizations</p> <p>SQL overhead is minimized by pruning, and by elimination of expensive aggregate queries.  These can result in orders of magnitude impact. </p> <p>e. Transparent</p> <p>Rules are an executable design.  Note they map exactly to our natural language design (shown in comments) - readable by business users.  </p> <p>Optionally, you can use the Behave TDD approach to define tests, and the Rules Report will show the rules that execute for each test.  For more information, click here.</p> <p> </p>"},{"location":"Sample-Basic-Demo/#mcp-logic-user-interface","title":"MCP: Logic, User Interface","text":"<p>Logic is automatically executed in your MCP-enabled API.  For example, consider the following MCP orchestration:</p> <p></p> <p>When sending email, we require business rules to ensure it respects the opt-out policy:</p> <p></p> <p>The server is automatically mcp-enabled, but we might also want an mcp user-interface client:</p> <p>1. Stop the Server</p> <p>2. Create an MCP Client Executor like this:</p> <pre><code>genai-logic genai-add-mcp-client\n</code></pre> <p>3. Restart the Server</p> <p></p> <p>With the server running, test it like this:</p> <ol> <li>Test MCP</li> </ol> <p>You can do this in the command line, or via the admin app.</p> <p>Use the Admin App: (shown above), and follow step 4 on the Home page to see a Business-User-friendly example.</p> <p>Or, use the command line.  </p> <p>Since the CLI does not pass an auth token,  you must first stop the server and disable security.</p> <p>MCP from the command line: MCP from the command line<pre><code>python integration/mcp/mcp_client_executor.py mcp\n</code></pre></p> <p></p> <p>For more on MCP, click here.</p> <p></p>"},{"location":"Sample-Basic-Demo/#5-iterate-with-rules-and-python","title":"5. Iterate with Rules and Python","text":"<p>Not only are spreadsheet-like rules 40X more concise, they meaningfully simplify maintenance.  Let's take an example:</p> <p>Give a 10% discount for carbon-neutral products for 10 items or more. </p> <p>The following <code>add-cust</code> process simulates an iteration:</p> <ul> <li> <p>acquires a new database with <code>Product.CarbonNeutral</code></p> </li> <li> <p>issues the <code>genai-logic rebuild-from-database</code> command that rebuilds your project (the database models, the api), while preserving the customizations we made above.</p> </li> <li> <p>acquires a revised <code>ui/admin/admin.yaml</code> that shows this new column in the admin app</p> </li> <li> <p>acquires this revised logic - in <code>logic/declare_logic.py</code>, we replaced the 2 lines for the <code>models.Item.Amount</code> formula with this (next screenshot shows revised logic executing with breakpoint):</p> </li> </ul> <pre><code>    def derive_amount(row: models.Item, old_row: models.Item, logic_row: LogicRow):\n        amount = row.Quantity * row.UnitPrice\n        if row.Product.CarbonNeutral and row.Quantity &gt;= 10:\n           amount = amount * Decimal(0.9)  # breakpoint here\n        return amount\n\n    Rule.formula(derive=models.Item.Amount, calling=derive_amount)\n</code></pre> <p> </p> <p>To add this iteration, repeat the process above - in a terminal window for your project:</p> <p>1. Stop the Server (Red Stop button, or Shift-F5 -- see Appendix)</p> <p>2. Add Iteration</p> <pre><code>genai-logic add-cust\ngenai-logic rebuild-from-database --db_url=sqlite:///database/db.sqlite\n</code></pre> <ul> <li>You can ignore the warning regarding 'mcp-SysMcp' - not present</li> </ul> <p>3. Set the breakpoint as shown in the screenshot below</p> <p>4. Test: Start the Server, login as Admin</p> <p>5. Use the Admin App to update your Order by adding 12 <code>Green</code> Items</p> <p>At the breakpoint, observe you can use standard debugger services to debug your logic (examine <code>Item</code> attributes, step, etc).</p> <p></p> <p> </p> <p>This simple example illustrates some significant aspects of iteration, described in the sub-sections below.</p> <p></p> <p>\ud83d\udca1 Iteration: Automatic Invocation/Ordering, Extensible, Rebuild Preserves Customizations</p> <p></p> <p>a. Dependency Automation</p> <p>Along with perhaps documentation, one of the tasks programmers most loathe is maintenance.  That's because it's not about writing code, but it's mainly archaeology - deciphering code someone else wrote, just so you can add 4 or 5 lines that will hopefully be called and function correctly.</p> <p>Rules change that, since they self-order their execution (and pruning) based on system-discovered dependencies.  So, to alter logic, you just \"drop a new rule in the bucket\", and the system will ensure it's called in the proper order, and re-used over all the Use Cases to which it applies.  Maintenance is faster, and higher quality. </p> <p>b. Extensibile with Python</p> <p>In this case, we needed to do some if/else testing, and it was convenient to add a pinch of Python. Using \"Python as a 4GL\" is remarkably simple, even if you are new to Python.</p> <p>Of course, you have the full object-oriented power of Python and its many libraries, so there are no automation penalty restrictions. </p> <p>c. Debugging: IDE, Logging</p> <p>The screenshot above illustrates that debugging logic is what you'd expect: use your IDE's debugger.  This \"standard-based\" approach applies to other development activities, such as source code management, and container-based deployment. </p> <p>d. Customizations Retained</p> <p>Note we rebuilt the project from our altered database, illustrating we can iterate, while preserving customizations.</p> <p> </p>"},{"location":"Sample-Basic-Demo/#api-customization-standard","title":"API Customization: Standard","text":"<p>Of course, we all know that all businesses the world over depend on the <code>hello world</code> app.  This is provided in <code>api/customize_api</code>.  Observe that it's:</p> <ul> <li> <p>standard Python</p> </li> <li> <p>using Flask</p> </li> <li> <p>and, for database access, SQLAlchemy.  Note all updates from custom APIs also enforce your logic.</p> </li> </ul> <p>Explore the custom API in <code>api/api_discovery/order_b2b.py</code>, and test it using swagger:</p> <ol> <li>Access the Home page of the Admin App</li> <li>Access the swagger</li> <li>Test the b2b API / Logic, as shown below:</li> </ol> <p></p> <p> </p>"},{"location":"Sample-Basic-Demo/#messaging-with-kafka","title":"Messaging With Kafka","text":"<p>Along with APIs, messaging is another technology commonly employed for application integration.  See the screenshot below; for more information, see Sample Integration.</p> <p> </p>"},{"location":"Sample-Basic-Demo/#6-deploy-containers-no-fees","title":"6. Deploy Containers: No Fees","text":"<p>API Logic Server also creates scripts for deployment.  While these are not required at this demo, this means you can enable collaboration with Business Users:</p> <ol> <li>Create a container from your project -- see <code>devops/docker-image/build_image.sh</code></li> <li>Upload to Docker Hub, and</li> <li>Deploy for agile collaboration.</li> </ol> <p> </p>"},{"location":"Sample-Basic-Tour/","title":"Welcome","text":""},{"location":"Sample-Basic-Tour/#welcome-to-genai-logic","title":"Welcome to GenAI-Logic","text":"<p>What is GenAI-Logic:</p> <ol> <li> <p>Instant mcp-enabled microservices (APIs and Admin Apps), from a database or GenAI prompt -- one command and you are ready for MCP, Vibe and Business User Collaboration.</p> </li> <li> <p>Customize with Declarative Rules and Python in your IDE, standard container deployment</p> </li> </ol> <p>This is the start page for the GenAI-Logic Manager.  The Manager is a good place to manage projects, create notes and resources, etc.  </p> <p>\ud83d\udca1 Tip: Need to install? See the installation guide.</p> <p> </p>"},{"location":"Sample-Basic-Tour/#product-tour-start-here","title":"Product Tour (Start Here)","text":"<p>This illustrates basic GenAI-Logic operation: </p> <ol> <li>Creating projects from new or existing databases, providing a MCP-enabled API and an Admin App</li> <li>Adding declarative logic and security, and </li> <li>Customizing your project using your IDE and Python</li> </ol> <p>\ud83d\ude80 First Time Here? Start with the 20-minute basic_demo tutorial:</p> <ol> <li>Bootstrap Copilot: \ud83e\udd16 Bootstrap Copilot by pasting the following into the chat<pre><code>Please find and read `.github/.copilot-instructions.md`.\n</code></pre></li> </ol> <p>Important: be sure CoPilot is in \"Agent\" Mode.  \"Ask\" will not work.    Also, we get consistently good results with <code>Claude Sonnet 4.5</code>.</p> <ol> <li>Create basic_demo project (auto-opens with guided tour option): <pre><code>genai-logic create --project_name=basic_demo --db_url=sqlite:///samples/dbs/basic_demo.sqlite\n</code></pre></li> </ol> <p></p> <p>The entire process takes 20 minutes; usage notes:</p> <ul> <li>Important: look for readme files in created projects</li> <li>You may find it more convenient to view this in your Browser</li> <li>A slide show summary is available on our Web Site</li> </ul> <p></p> <p> </p>"},{"location":"Sample-Basic-Tour/#1-create-and-run","title":"1. Create and Run","text":"<p>API Logic Server can create projects from existing databases, or use GenAI to create projects with new databases.  Let's see how.</p> <p> </p>"},{"location":"Sample-Basic-Tour/#from-existing-database","title":"From Existing Database","text":"<p>This is the best way to start:</p> <ol> <li>Open a terminal window: Terminal &gt; New Terminal</li> <li>Create Project from Existing Database: <pre><code>genai-logic create --project_name=basic_demo --db_url=sqlite:///samples/dbs/basic_demo.sqlite\n</code></pre></li> </ol>  The database is Customer, Orders, Items and Product <p></p> <p> </p>"},{"location":"Sample-Basic-Tour/#genai-new-database","title":"GenAI: New Database","text":"<p>Alternatively, you can create a project and a new database from a prompt, using GenAI.</p> <p>Don't do this if you are executing the basic Product Tour.</p> <p>There are 3 ways to use GenAI:</p> <ul> <li>WebGenAI - in the Browser, via pubic website - click here, or</li> <li>GenAI -         in the Browser, via docker - click here, or </li> <li>GenAI CLI - click here </li> </ul> <p>To use the GenAI CLI:</p> <ol> <li>If you have signed up (see Get an OpenAI Key, below), this will create and open a project called <code>genai_demo</code> from <code>genai_demo.prompt</code> (available in left Explorer pane):</li> </ol> <pre><code>genai-logic genai --using=system/genai/examples/genai_demo/genai_demo.prompt --project-name=genai_demo\n</code></pre> <ol> <li>Or, you can simulate the process (no signup) using:</li> </ol> <pre><code>genai-logic genai --repaired-response=system/genai/examples/genai_demo/genai_demo.response_example --project-name=genai_demo\n</code></pre> <p>For background on how it works, click here.</p> <p> </p>"},{"location":"Sample-Basic-Tour/#open-in-your-ide-and-run","title":"Open in your IDE and Run","text":"<p>You can open with VSCode, and run it as follows:</p> <ol> <li> <p>Start the Server: F5 (also described in the Appendix).</p> <ul> <li>Your virtual environment is automatically configured in most cases; see the Appendix (Procedures / Detail Procedures) if that's not working.</li> </ul> </li> <li> <p>Start the Admin App: either use the links provided in the IDE console, or click http://localhost:5656/.  The Admin App screen shown below should appear in your Browser.</p> </li> </ol> <p>The sections below explore the system that has been created (which would be similar for your own database). </p>"},{"location":"Sample-Basic-Tour/#api-with-swagger","title":"API with Swagger","text":"<p>The system creates an API with end points for each table, with filtering, sorting, pagination, optimistic locking and related data access -- self-serve, ready for custom app dev.</p> See the Swagger  <p></p> <p></p>"},{"location":"Sample-Basic-Tour/#admin-app","title":"Admin App","text":"<p>It also creates an Admin App: multi-page, multi-table -- ready for business user agile collaboration, and back office data maintenance.  This complements custom UIs created with the API.</p> <p>You can click Customer Alice, and see their Orders, and Items.</p> See the Admin App  <p></p> <p></p>"},{"location":"Sample-Basic-Tour/#2-custom-ui-genai-vibe","title":"2. Custom UI: GenAI, Vibe","text":"<p>The app above is suitable for collaborative iteration to nail down the requirements, and back office data maintenance.  It's also easy to make simple customizations, using the yaml file.</p> <p>For more custom apps, you get complete control by generating app source code, which you can then customize in your IDE, e.g. using Vibe Natural Language:</p> <pre><code># create react source (requires OpenAI key)\ngenai-logic genai-add-app --vibe\ncd ui/react-app\nnpm install\nnpm start\n</code></pre> <p>And you are ready to Vibe:</p> <ul> <li>Instead of creating data mockups, you have a running API server with real data</li> <li>Instead of starting from scratch, you have a running multi-page app </li> <li>And, you'll have projects that are architecturally correct: shared logic, enforced in the server, available for both User Interfaces and services.</li> <li> <p>Then, use you favorite Vibe tools with your running API</p> <ul> <li>Below is an example from Northwind: click here</li> </ul> </li> </ul> <p>Customize using Natural Language: Customize using Natural Language<pre><code>In the ui/react app, Update the Product list to provide users an option to see results in a list, or in cards.\n</code></pre> </p> <p>Below is an example from Northwind: click here</p> <p></p> <p></p>"},{"location":"Sample-Basic-Tour/#3-mcp-ready-apis","title":"3. MCP-Ready APIs","text":"<p>Your project is MCP-ready - this will run a simple query List customers with credit_limit &gt; 1000 (we'll explore more interesting examples below, including provisions for user input):</p> <pre><code>cd basic_demo\npython integration/mcp/mcp_client_executor.py\n</code></pre> <p></p> <p></p>"},{"location":"Sample-Basic-Tour/#4-declare-logic-and-security","title":"4. Declare Logic And Security","text":"<p>While API/MCP/UI automation is a great start, it's critical to enforce logic and security.  You do this in your IDE.  Here's how.</p> <p>The following <code>add_customizations</code> process simulates:</p> <ul> <li>Adding security to your project, and</li> <li>Using your IDE to declare logic and security in <code>logic/declare_logic.sh</code> and <code>security/declare_security.py</code>.</li> </ul> <p>Declared security and logic are shown in the screenshots below.It's quite short - 5 rules, 7 security settings.</p> <p>To add customizations, in a terminal window for your project:</p> <p>1. Stop the Server (Red Stop button, or Shift-F5 -- see Appendix)</p> <p>2. Add Customizations</p> <p><pre><code>genai-logic add-cust\ngenai-logic add-auth --db_url=auth\n</code></pre> </p>"},{"location":"Sample-Basic-Tour/#security-role-based-access","title":"Security: Role Based Access","text":"<p>The <code>add_customizations</code> process above has simulated using your IDE to declare security in <code>logic/declare_logic.sh</code>.</p> <p>To see security in action:</p> <p>1. Start the Server  F5</p> <p>2. Start the Admin App: http://localhost:5656/</p> <p>3. Login as <code>s1</code>, password <code>p</code></p> <p>4. Click Customers</p> <p> Observe:</p> <p>1. Login now required</p> <p>2. Role-Based Filtering</p> <p>Observe you now see fewer customers, since user <code>s1</code> has role <code>sales</code>.  This role has a declared filter, as shown in the screenshot below.</p> <p>3. Transparent Logging</p> See Security Declarations  <p>The screenshot below illustrates security declaration and operation:</p> <ul> <li> <p>The declarative Grants in the upper code panel, and</p> </li> <li> <p>The logging in the lower panel, to assist in debugging by showing which Grants (<code>+ Grant:</code>) are applied:</p> </li> </ul> <p></p> <p> </p>"},{"location":"Sample-Basic-Tour/#logic-derivations-constraints","title":"Logic: Derivations, Constraints","text":"<p>Logic (multi-table derivations and constraints) is a significant portion of a system, typically nearly half.  API Logic Server provides spreadsheet-like rules that dramatically simplify and accelerate logic development.</p> <p>Rules are declared in Python, simplified with IDE code completion.  The screen below shows the 5 rules for Check Credit Logic.</p> <p>The <code>add_customizations</code> process above has simulated the process of using your IDE to declare logic in <code>logic/declare_logic.sh</code>.</p> <p>To see logic in action:</p> <p>1. In the admin app, Logout (upper right), and login as admin, p</p> <p>2. Use the Admin App to access the first order for <code>Customer Alice</code></p> <p>3. Edit its first item to a very high quantity</p> <p>The update is properly rejected because it exceeds the credit limit.  Observe the rules firing in the console log - see Logic In Action, below.</p> <p></p> <p>\ud83d\udca1 Logic: Multi-table Derivations and Constraint Declarative Rules. Declarative Rules are 40X More Concise than procedural code.\u2003\u2003For more information, click here.</p> <p></p> See Logic In Action  <p>Declare logic with WebGenAI, or in your IDE using code completion or Natural Language:</p> <p></p> <p>a. Chaining</p> <p>The screenshot below shows our logic declarations, and the logging for inserting an <code>Item</code>.  Each line represents a rule firing, and shows the complete state of the row.</p> <p>Note that it's a <code>Multi-Table Transaction</code>, as indicated by the indentation.  This is because - like a spreadsheet - rules automatically chain, including across tables.</p> <p></p> <p>b. 40X More Concise</p> <p>The 5 spreadsheet-like rules represent the same logic as 200 lines of code, shown here.  That's a remarkable 40X decrease in the backend half of the system.</p> <p>\ud83d\udca1 No FrankenCodeNote the rules look like syntactically correct requirements.  They are not turned into piles of unmanageable \"frankencode\" - see models not frankencode.</p> <p></p> <p>c. Automatic Re-use</p> <p>The logic above, perhaps conceived for Place order, applies automatically to all transactions: deleting an order, changing items, moving an order to a new customer, etc.  This reduces code, and promotes quality (no missed corner cases). </p> <p>d. Automatic Optimizations</p> <p>SQL overhead is minimized by pruning, and by elimination of expensive aggregate queries.  These can result in orders of magnitude impact. </p> <p>e. Transparent</p> <p>Rules are an executable design.  Note they map exactly to our natural language design (shown in comments) - readable by business users.  </p> <p>Optionally, you can use the Behave TDD approach to define tests, and the Rules Report will show the rules that execute for each test.  For more information, click here.</p> <p> </p>"},{"location":"Sample-Basic-Tour/#mcp-logic-user-interface","title":"MCP: Logic, User Interface","text":"<p>Logic is automatically executed in your MCP-enabled API.  For example, consider the following MCP orchestration:</p> <p></p> <p>When sending email, we require business rules to ensure it respects the opt-out policy:</p> <p></p> <p>The server is automatically mcp-enabled, but we might also want an mcp user-interface client:</p> <p>1. Stop the Server</p> <p>2. Create an MCP Client Executor like this:</p> <pre><code>genai-logic genai-add-mcp-client\n</code></pre> <p>3. Restart the Server</p> <p></p> <p>With the server running, test it like this:</p> <ol> <li>Test MCP</li> </ol> <p>You can do this in the command line, or via the admin app.</p> <p>Use the Admin App: (shown above), and follow step 4 on the Home page to see a Business-User-friendly example.</p> <p>Or, use the command line.  </p> <p>Since the CLI does not pass an auth token,  you must first stop the server and disable security.</p> <p>MCP from the command line: MCP from the command line<pre><code>python integration/mcp/mcp_client_executor.py mcp\n</code></pre></p> <p></p> <p>For more on MCP, click here.</p> <p></p>"},{"location":"Sample-Basic-Tour/#5-iterate-with-rules-and-python","title":"5. Iterate with Rules and Python","text":"<p>Not only are spreadsheet-like rules 40X more concise, they meaningfully simplify maintenance.  Let's take an example:</p> <p>Give a 10% discount for carbon-neutral products for 10 items or more. </p> <p>The following <code>add-cust</code> process simulates an iteration:</p> <ul> <li> <p>acquires a new database with <code>Product.CarbonNeutral</code></p> </li> <li> <p>issues the <code>genai-logic rebuild-from-database</code> command that rebuilds your project (the database models, the api), while preserving the customizations we made above.</p> </li> <li> <p>acquires a revised <code>ui/admin/admin.yaml</code> that shows this new column in the admin app</p> </li> <li> <p>acquires this revised logic - in <code>logic/declare_logic.py</code>, we replaced the 2 lines for the <code>models.Item.Amount</code> formula with this (next screenshot shows revised logic executing with breakpoint):</p> </li> </ul> <pre><code>    def derive_amount(row: models.Item, old_row: models.Item, logic_row: LogicRow):\n        amount = row.Quantity * row.UnitPrice\n        if row.Product.CarbonNeutral and row.Quantity &gt;= 10:\n           amount = amount * Decimal(0.9)  # breakpoint here\n        return amount\n\n    Rule.formula(derive=models.Item.Amount, calling=derive_amount)\n</code></pre> <p> </p> <p>To add this iteration, repeat the process above - in a terminal window for your project:</p> <p>1. Stop the Server (Red Stop button, or Shift-F5 -- see Appendix)</p> <p>2. Add Iteration</p> <pre><code>genai-logic add-cust\ngenai-logic rebuild-from-database --db_url=sqlite:///database/db.sqlite\n</code></pre> <ul> <li>You can ignore the warning regarding 'mcp-SysMcp' - not present</li> </ul> <p>3. Set the breakpoint as shown in the screenshot below</p> <p>4. Test: Start the Server, login as Admin</p> <p>5. Use the Admin App to update your Order by adding 12 <code>Green</code> Items</p> <p>At the breakpoint, observe you can use standard debugger services to debug your logic (examine <code>Item</code> attributes, step, etc).</p> <p></p> <p> </p> <p>This simple example illustrates some significant aspects of iteration, described in the sub-sections below.</p> <p></p> <p>\ud83d\udca1 Iteration: Automatic Invocation/Ordering, Extensible, Rebuild Preserves Customizations</p> <p></p> <p>a. Dependency Automation</p> <p>Along with perhaps documentation, one of the tasks programmers most loathe is maintenance.  That's because it's not about writing code, but it's mainly archaeology - deciphering code someone else wrote, just so you can add 4 or 5 lines that will hopefully be called and function correctly.</p> <p>Rules change that, since they self-order their execution (and pruning) based on system-discovered dependencies.  So, to alter logic, you just \"drop a new rule in the bucket\", and the system will ensure it's called in the proper order, and re-used over all the Use Cases to which it applies.  Maintenance is faster, and higher quality. </p> <p>b. Extensibile with Python</p> <p>In this case, we needed to do some if/else testing, and it was convenient to add a pinch of Python. Using \"Python as a 4GL\" is remarkably simple, even if you are new to Python.</p> <p>Of course, you have the full object-oriented power of Python and its many libraries, so there are no automation penalty restrictions. </p> <p>c. Debugging: IDE, Logging</p> <p>The screenshot above illustrates that debugging logic is what you'd expect: use your IDE's debugger.  This \"standard-based\" approach applies to other development activities, such as source code management, and container-based deployment. </p> <p>d. Customizations Retained</p> <p>Note we rebuilt the project from our altered database, illustrating we can iterate, while preserving customizations.</p> <p> </p>"},{"location":"Sample-Basic-Tour/#api-customization-standard","title":"API Customization: Standard","text":"<p>Of course, we all know that all businesses the world over depend on the <code>hello world</code> app.  This is provided in <code>api/customize_api</code>.  Observe that it's:</p> <ul> <li> <p>standard Python</p> </li> <li> <p>using Flask</p> </li> <li> <p>and, for database access, SQLAlchemy.  Note all updates from custom APIs also enforce your logic.</p> </li> </ul> <p>Explore the custom API in <code>api/api_discovery/order_b2b.py</code>, and test it using swagger:</p> <ol> <li>Access the Home page of the Admin App</li> <li>Access the swagger</li> <li>Test the b2b API / Logic, as shown below:</li> </ol> <p></p> <p> </p>"},{"location":"Sample-Basic-Tour/#messaging-with-kafka","title":"Messaging With Kafka","text":"<p>Along with APIs, messaging is another technology commonly employed for application integration.  See the screenshot below; for more information, see Sample Integration.</p> <p> </p>"},{"location":"Sample-Basic-Tour/#6-deploy-containers-no-fees","title":"6. Deploy Containers: No Fees","text":"<p>API Logic Server also creates scripts for deployment.  While these are not required at this demo, this means you can enable collaboration with Business Users:</p> <ol> <li>Create a container from your project -- see <code>devops/docker-image/build_image.sh</code></li> <li>Upload to Docker Hub, and</li> <li>Deploy for agile collaboration.</li> </ol> <p> </p>"},{"location":"Sample-Basic-Tour/#explore-genai-cli","title":"Explore GenAI CLI","text":"1. New Database - using GenAI Microservice Automation (Experiment with AI - Signup optional) <p>You can do this with or without signup:</p> <ol> <li>If you have signed up (see Get an OpenAI Key, below), this will create a new database and project called <code>genai_demo</code>, and open the project.  It's created using <code>genai_demo.prompt</code>, visible in left Explorer pane:</li> </ol> <pre><code>als genai --using=system/genai/examples/genai_demo/genai_demo.prompt --project-name=genai_demo\n</code></pre> <ol> <li>Or, you can simulate the process (no signup) using:</li> </ol> <pre><code>als genai --repaired-response=system/genai/examples/genai_demo/genai_demo.response_example --project-name=genai_demo\n</code></pre> <p>Verify it's operating properly:</p> <ol> <li>Run Configurations are provided to start the server</li> <li>Verify the logic by navigating to a Customer with an unshipped order, and altering one of the items to have a very large quantity</li> <li>Observe the constraint operating on the rollup of order amount_totals.<ul> <li>View the logic in <code>logic/declare_logic.py</code></li> <li>Put a breakpoint on the <code>as_condition</code>.  Observe the console log to see rule execution for this multi-table transaction.</li> </ul> </li> </ol> <p></p>  What Just Happened? \u00a0\u00a0\u00a0Next Steps... <p><code>genai</code> processing is shown below (internal steps denoted in grey):</p> <ol> <li> <p>You create your.prompt file, and invoke <code>als genai --using=your.prompt</code>.  genai then creates your project as follows:</p> <p>a. Submits your prompt to the <code>ChatGPT API</code></p> <p>b. Writes the response to file, so you can correct and retry if anything goes wrong</p> <p>c. Extracts model.py from the response</p> <p>d. Invokes <code>als create-from-model</code>, which creates the database and your project</p> </li> <li> <p>Your created project is opened in your IDE, ready to execute and customize.  </p> <p>a. Review <code>Tutorial</code>, Explore Customizations.</p> </li> </ol> <p></p> <p></p>  You can iterate the logic and data model <p>The approach for an iteration is to create a new project from an existing one:</p> <ol> <li>add another prompt to an existing projects <code>docs</code> directory, specifying your changes</li> <li>use <code>als genai</code>, specifying <ul> <li><code>--using</code> existing projects <code>docs</code> directory, and </li> <li><code>--project-name</code> as the output project</li> </ul> </li> </ol> <p>Logic iterations are particuarly useful.  For example, here we take the basic check-credit logic, and add:</p> <p>Provide a 10% discount when buying more than 10 carbon neutral products.The Item carbon neutral is copied from the Product carbon neutral</p> <p>Explore genai_demo_iteration_discount.  It's an iteration of basic_demo (see system/genai/examples/genai_demo/genai_demo_iteration_discount/002_create_db_models.prompt).  This will add carbon_neutral to the data model, and update the logic to provide the discount:</p> <p>Iterate Business Logic: Iterate Business Logic<pre><code># Iterate with data model and logic\nals genai --project-name='genai_demo_with_discount' --using=system/genai/examples/genai_demo/genai_demo_iteration_discount\n# open Docs/db.dbml\n</code></pre></p> <p></p> <p>You can perform model iterations: add new columns/tables, while keeping the prior model intact.  First, we create a project with no logic, perhaps just to see the screens (this step is optional, provided just to illustrate that iterations create new projects from existing ones):</p> <p>Iterate Without Logic: Iterate Without Logic<pre><code># Step 1 - create without logic\nals genai --project-name='genai_demo_no_logic' --using=system/genai/examples/genai_demo/genai_demo_no_logic.prompt\n# open Docs/db.dbml\n</code></pre></p> <p>Then, we would create another prompt in the docs directory with our model changes. We've already created these for you in <code>system/genai/examples/genai_demo/genai_demo_iteration</code> - we use that to alter the data model (see <code>system/genai/examples/genai_demo/genai_demo_iteration/004_iteration_renames_logic.prompt</code>):</p> <p>Iterate With Logic: Iterate With Logic<pre><code># Iterate with data model and logic\nals genai --project-name='genai_demo_with_logic' --using=system/genai/examples/genai_demo/genai_demo_iteration\n# open Docs/db.dbml\n</code></pre></p> <p>Explore genai_demo_iteration - observe the <code>--using</code> is a directory of prompts.  These include the prompts from the first example, plus an iteration prompt (<code>004_iteration_renames_logic.prompt</code>) to rename tables and add logic.</p> <p></p>  You can declare informal logic <p>You can declare rules using dot notation, or more informally:</p> <p>Informal Logic (no dot notation): Informal Logic (no dot notation)<pre><code>als genai --using=system/genai/examples/genai_demo/genai_demo_informal.prompt --project-name=genai_demo_informal\n</code></pre></p> <p></p>  Multi-Rule Logic <p>You can add new columns/tables, while keeping the prior model intact:</p> <p>Multi-Rule Logic: Multi-Rule Logic<pre><code>als genai --using=system/genai/examples/emp_depts/emp_dept.prompt\n</code></pre></p> <p></p>  You can ask AI to suggest logic (great way to learn!) <p>You can create a project, and ask GenAI for logic suggestions:</p> <p>1. Create Project, without Rules: 1. Create Project, without Rules<pre><code># 1. Create Project, without Rules\nals genai --project-name='genai_demo_no_logic' --using=system/genai/examples/genai_demo/genai_demo_no_logic.prompt\n</code></pre></p> <p>2. Request Rule Suggestions: 2. Request Rule Suggestions<pre><code># 2. Request Rule Suggestions\ncd genai_demo_no_logic\nals genai-logic --suggest\n</code></pre></p> <p>You can review the resultant logic suggestions in the <code>genai_demo_no_logic</code> project:</p> <ul> <li>See and edit: <code>docs/logic_suggestions/002_logic_suggestions.prompt</code> (used in step 3, below)<ul> <li>This corresponds to the Logic Editor - Logic View in the WebGenAI web app</li> </ul> </li> </ul> <p>3. See the rules for the logic: 3. See the rules for the logic<pre><code># 3. See the rule code for the logic\nals genai-logic --suggest --logic='*'\n</code></pre></p> <p>Important notes about suggestions and generated code: * <code>--suggest --logic='*'</code> is intended to enable you to identify logic that does not translate into proper code * The example above was pretty good, but sometimes the results are downright silly:     * Just run suggest again, or     * Repair <code>docs/logic_suggestions/002_logic_suggestions.prompt</code></p> <p>Also... * It is not advised to paste the code into <code>logic/declare_logic.py</code>     * The suggested logic may result in new data model attributes     * These are created automatically by running <code>als genai</code> (next step)</p> <p>The logic suggestions directory now contains the prompts to create a new project with the suggested logic. When you are ready to proceed: 1. Execute the following to create a new project (iteration), with suggested logic:</p> <p>4. Create a new project with the Rule Suggestions: 4. Create a new project with the Rule Suggestions<pre><code># 4. Create a new project with the Rule Suggestions\ncd ..  # important - back to manager root dir\nals genai --project-name='genai_demo_with_logic' --using=genai_demo_no_logic/docs/logic_suggestions\n</code></pre></p> <p>Observe: 1. The created project has the rule suggestions in <code>logic/declare_logic.py</code> 2. A revised Data Model in <code>database/models.py</code> that includes attributes introduced by the logic suggestions 3. Revised test database, initialized to reflect the derivations in the suggested logic</p> <p>Internal Note: this sequence available in the run configs (s1/s4).</p> <p></p> Fixup - update data model with new attributes from rules <p>Fixes project issues by updating the Data Model and Test Data: when adding rules, such as using suggestions, you may introduce new attributes. If these are missing, you will see exceptions when you start your project.</p> <p>The <code>genai-utils --fixup</code> fixes such project issues by updating the Data Model and Test Data:</p> <ol> <li>Collects the latest model, rules, and test data from the project. </li> <li>Calls ChatGPT (or similar) to resolve missing columns or data in the project.</li> <li>Saves the fixup request/response under a 'fixup' folder.</li> <li>You then use this to create a new project</li> </ol> <p>Setup</p> <p>After starting the Manager: </p> <p>0. Create Project Requiring Fixup: 0. Create Project Requiring Fixup<pre><code># 0. Create a project requiring fixup\nals genai --repaired-response=system/genai/examples/genai_demo/genai_demo_fixup_required.json --project-name=genai_demo_fixup_required\n</code></pre></p> <p>If you run this project, you will observe that it fails with: <pre><code>Logic Bank Activation Error -- see https://apilogicserver.github.io/Docs/WebGenAI-CLI/#recovery-options\nInvalid Rules:  [AttributeError(\"type object 'Customer' has no attribute 'balance'\")]\nMissing Attrs (try als genai-utils --fixup): ['Customer.balance: constraint']\n</code></pre> </p> <p>Fixup</p> <p>To Fix it: 1. Run FixUp to add missing attributes to the fixup response data model: 1. Run FixUp to add missing attributes to the fixup response data model<pre><code># 1. Run FixUp to add missing attributes to the data model\ncd genai_demo_fixup_required\nals genai-utils --fixup\n</code></pre></p> <p>Finally, use the created fixup files to rebuild the project: 2. Rebuild the project from the fixup response data model: 2. Rebuild the project from the fixup response data model<pre><code># 2. Rebuild the project from the fixup response data model\ncd ../\nals genai --repaired-response=genai_demo_fixup_required/docs/fixup/response_fixup.json --project-name=fixed_project\n</code></pre></p> <p>\u00a0 The created project may still report some attributes as missing. (ChatGPT seems to often miss attributes mentioned in sum/count where clauses.)  To fix:</p> <ol> <li>Note the missing attributes(s) from the log</li> <li>Add them to <code>docs/003_suggest.prompt</code></li> <li>Rebuild the project: <code>als genai --project-name='genai_demo_with_logic' --using=genai_demo_no_logic/docs</code></li> </ol> <p>Internal Note: this sequence available in the run configs (f1/f2).</p> <p></p> Create from WebGenAI, and import (merge) subsequent changes <p>You can use WebGenAI to create a project, and export it.  </p> <p>You (or colleagues) can make changes to both the WebGenAI project (on the web), and your downloaded project.  You can import the WebGenAI project, and the system will merge changes to the data model and rules automatically.  </p> <p>This is possible since the logic is declarative, so ordering is automatic.  This eliminates the troublesome merge issues so prevalent in procedural code.  For more on import, click here.</p> <p>The Manager pre-installs a sample project you can use to explore import:</p> <p><pre><code>cd system/genai/examples/genai_demo/wg_dev_merge/dev_demo_no_logic_fixed\nals genai-utils --import-genai --using=../wg_demo_no_logic_fixed\n</code></pre> Observe: 1. The data model contains <code>Customer.balance</code> and <code>Product.carbon_neutral</code> 2. The test data has been updated to include these attributes, with proper values</p> <p></p> Rebuild the test data <p>Fixes project issues by rebuilding the database to conform to the derivation rules:</p> <ol> <li>Create genai_demo:  <pre><code>als genai --using=system/genai/examples/genai_demo/genai_demo.prompt --project-name=genai_demo\n</code></pre></li> <li>Rebuild: <pre><code>cd genai_demo\nals genai-utils --rebuild-test-data\n</code></pre></li> </ol> <p></p>  You can also execute directly, and iterate <p>You can add new columns/tables, while keeping the prior model intact:</p> <p>Iterate: Iterate<pre><code># create project without creating a file...\nals genai-create --project-name='customer_orders' --using='customer orders'\n\nals genai-iterate --using='add Order Details and Products'\n# open Docs/db.dbml\n</code></pre></p> <p></p>  AI somtimes fails - here's how to recover <p>AI results are not consistent, so the model file may need corrections.  You can find it at <code>system/genai/temp/model.py</code>.  You can correct the model file, and then run:</p> <pre><code>als create --project-name=genai_demo --from-model=system/genai/temp/create_db_models.py --db-url=sqlite\n</code></pre> <p>Or, correct the chatgpt response, and</p> <pre><code>als genai --repaired-response=system/genai/examples/genai_demo/genai_demo.response_example --project-name=genai_demo\n</code></pre> <p>We have seen failures such as:</p> <ul> <li>duplicate definition of <code>DECIMAL</code></li> <li>unclosed parentheses</li> <li>data type errors in test data creation</li> <li>wrong engine import: from logic_bank import Engine, constraint</li> <li>bad test data creation: with Engine() as engine...</li> <li>Bad load code (no session)</li> </ul> <p></p>  Postgresql Example  <p>You can test this as follows:</p> <ol> <li>Use our docker image:</li> <li>And try:</li> </ol> <pre><code>als genai --using=system/genai/examples/postgres/genai_demo_pg.prompt --db-url=postgresql://postgres:p@localhost/genai_demo\n</code></pre> <p>Provisos:</p> <ul> <li>You have to create the database first; we are considering automating that: https://stackoverflow.com/questions/76294523/why-cant-create-database-if-not-exists-using-sqlalchemy</li> </ul> <p></p>  2. New Database - using Copilot (Signup optional)  <p>You can use Copilot chat (if extension installed; if not, skip to step 3):</p> <ol> <li>Create a model, eg:</li> </ol>  Show Me How to Use Copilot  <p>&gt;Paste this into the Copilot prompt:</p> <pre><code>Use SQLAlchemy to create a sqlite database named sample_ai.sqlite, with customers, orders, items and product\n\nHints: use autonum keys, allow nulls, Decimal types, foreign keys, no check constraints.\n\nInclude a notes field for orders.\n\nCreate a few rows of only customer and product data.\n\nEnforce the Check Credit requirement (do not generate check constraints):\n\n1. Customer.Balance &lt;= CreditLimit\n2. Customer.Balance = Sum(Order.AmountTotal where date shipped is null)\n3. Order.AmountTotal = Sum(Items.Amount)\n4. Items.Amount = Quantity * UnitPrice\n5. Store the Items.UnitPrice as a copy from Product.UnitPrice\n</code></pre> <p></p> <p></p> <ol> <li> <p>Paste the copilot response into a new <code>sample_ai.py</code> file</p> </li> <li> <p>Create your project:</p> </li> </ol> <pre><code>als create --project-name=sample_ai --from-model=sample_ai.py --db-url=sqlite\n</code></pre> <ol> <li> <p>This will create your database, create an API Logic Project from it, and launch your IDE.</p> </li> <li> <p>Create business logic</p> <ul> <li>You can create logic with either your IDE (and code completion), or Natural Language</li> <li> <p>To use Natural Language:</p> <ol> <li>Use the CoPilot chat,</li> <li>Paste the logic above</li> <li> <p>Copy it to <code>logic/declare_logic.py</code> after <code>discover_logic()</code></p> <ul> <li>Alert:  Table and Column Names may require correction to conform to the model</li> <li>Alert: you may to apply defaulting, and initialize derived attributes in your database</li> </ul> </li> </ol> </li> </ul> </li> </ol> <p></p>  3. New Database - using ChatGPT in the Browser (Signup not required) <p>A final option for GenAI is to use your Browser with ChatGPT.</p> <p>Please see this doc</p> <p></p> <p></p>"},{"location":"Sample-Basic-Tour/#appendices","title":"Appendices","text":""},{"location":"Sample-Basic-Tour/#procedures","title":"Procedures","text":"Quick Basic Demo - Cheat Sheet <p>This demo creates and customizes a project, starting from a database:</p> <p>Quick Basic Demo: Quick Basic Demo<pre><code># Microservice Automation\n# Admin App, API, Project\nals create --project-name=basic_demo --db-url=basic_demo\n\n# Logic and Securityf\n# see logic (logic/declare_logic.py, logic/cocktail-napkin.jpg);  add an Order and Item\n# see security (security/declare_security.py); compare customers, s1 vs. admin\nals add-cust\nals add-auth --db_url=auth\n\n# Python Extensibility, Kafka Integration, Rebuild Iteration\n# see logic/declare_logic.py (breakpoint for Kafka)\n# Swagger: ServicesEndPoint.OrderB2B\nals add-cust\nals rebuild-from-database --db_url=sqlite:///database/db.sqlite\n</code></pre></p> <p></p> Quick GenAI Demo - Cheat Sheet <p>This demo creates and customizes a project, starting from a prompt:</p> <p>Quick GenAI Demo: Quick GenAI Demo<pre><code># Microservice Automation from GenAI Prompt\n# Admin App, API, Project\nals genai --using=system/genai/examples/genai_demo/genai_demo.prompt\n\n# Or, Microservice Automation from Saved Response\n# Admin App, API, Project\nals genai --repaired-response=system/genai/temp/chatgpt_retry.response\n\n# Logic and Security\n#   - see logic (logic/declare_logic.py, logic/cocktail-napkin.jpg);  add an Order and Item\n#   - see security (security/declare_security.py); compare customers, s1 vs. admin\n# Python Extensibility, Kafka Integration, Rebuild Iteration\n#   - see logic/declare_logic.py (breakpoint for Kafka)\n#   - Swagger: ServicesEndPoint.OrderB2B\nals add-cust\n</code></pre></p> <p></p>  Detail Procedures <p>Specific procedures for running the demo are here, so they do not interrupt the conceptual discussion above.</p> <p>You can use either VSCode or Pycharm.</p> <p>1. Establish your Virtual Environment</p> <p>Python employs a virtual environment for project-specific dependencies.  Create one as shown below, depending on your IDE.</p> <p>For VSCode:</p> <p>Establish your <code>venv</code>, and run it via the first pre-built Run Configuration.  To establish your venv:</p> <pre><code>python -m venv venv; venv\\Scripts\\activate     # win\npython3 -m venv venv; . venv/bin/activate      # mac/linux\n\npip install -r requirements.txt\n</code></pre> <p>For PyCharm, you will get a dialog requesting to create the <code>venv</code>; say yes.</p> <p>See here for more information.</p> <p> </p> <p>2. Start and Stop the Server</p> <p>Both IDEs provide Run Configurations to start programs.  These are pre-built by <code>ApiLogicServer create</code>.</p> <p>For VSCode, start the Server with F5, Stop with Shift-F5 or the red stop button.</p> <p>For PyCharm, start the server with CTL-D, Stop with red stop button.</p> <p> </p> <p>3. Entering a new Order</p> <p>To enter a new Order:</p> <ol> <li> <p>Click `Customer 1``</p> </li> <li> <p>Click <code>+ ADD NEW ORDER</code></p> </li> <li> <p>Set <code>Notes</code> to \"hurry\", and press <code>SAVE AND SHOW</code></p> </li> <li> <p>Click <code>+ ADD NEW ITEM</code></p> </li> <li> <p>Enter Quantity 1, lookup \"Product 1\", and click <code>SAVE AND ADD ANOTHER</code></p> </li> <li> <p>Enter Quantity 2000, lookup \"Product 2\", and click <code>SAVE</code></p> </li> <li> <p>Observe the constraint error, triggered by rollups from the <code>Item</code> to the <code>Order</code> and <code>Customer</code></p> </li> <li> <p>Correct the quantity to 2, and click <code>Save</code></p> </li> </ol> <p>4. Update the Order</p> <p>To explore our new logic for green products:</p> <ol> <li> <p>Access the previous order, and <code>ADD NEW ITEM</code></p> </li> <li> <p>Enter quantity 11, lookup product <code>Green</code>, and click <code>Save</code>.</p> </li> </ol> <p> </p>"},{"location":"Sample-Basic-Tour/#setup-codespaces","title":"Setup Codespaces","text":"<p>Codespaces enables you to run in the cloud: VSCode via your Browser, courtesy GitHub.  </p>  Using codespaces on your GenAI project <p>1. Open your project on GitHub</p> <p></p> <p>2. Open it in Codespaces (takes a minute or 2):</p> <p></p> <p>You will now see your project - running in VSCode, in the Browser.  But that's just what you see...</p> <p>Behind the scenes, Codespaces has requisitioned a cloud machine, and loaded your project - with a complete development environment - Python, your dependencies, git, etc.  </p> <p>You are attached to this machine in your Browser, running VSCode.</p> <p> Pretty remarkable.</p> <p>3. Start the Server and open the App in the Browser</p> <ul> <li>Use the pre-defined Launch Configuration</li> </ul> <p></p> <p>We think you'll find Codespaces pretty amazing - check it out!</p> <p> </p>"},{"location":"Sample-Basic-Tour/#get-an-openai-apikey","title":"Get an OpenAI ApiKey","text":"<p>GenAI-Logic uses OpenAI, which requires an OpenAI Key:</p> <ol> <li> <p>Obtain one from here or here</p> </li> <li> <p>Authorize payments here</p> </li> </ol> <p> </p>"},{"location":"Sample-Basic-Tour/#pre-created-samples","title":"Pre-created Samples","text":"Explore Pre-created Samples <p>The <code>samples</code> folder has pre-created important projects you will want to review at some point (Important: look for readme files):</p> <ul> <li> <p>nw_sample_nocust - northwind (customers, orders...) database</p> <ul> <li>This reflects the results you can expect with your own databases</li> </ul> </li> <li> <p>nw_sample - same database, but with with customizations added.  It's a great resource for exploring how to customize your projects.</p> <ul> <li>Hint: use your IDE to search for <code>#als</code></li> </ul> </li> <li> <p>tutorial - short (~30 min) walk-through of using API Logic Server using the northwind (customers, orders...) database</p> </li> </ul> <p></p> You can always re-create the samples <p>Re-create them as follows:</p> <ol> <li>Open a terminal window (Terminal &gt; New Terminal), and paste the following CLI command:</li> </ol> <pre><code>ApiLogicServer create --project-name=samples/tutorial --db-url=\nApiLogicServer create --project-name=samples/nw_sample --db-url=nw+\nApiLogicServer create --project-name=samples/nw_sample_nocust --db-url=nw\n</code></pre>"},{"location":"Sample-Database/","title":"Sample DB, Project","text":"<p>The sample application is created from the pre-installed sample database shown below (tutorial here).  It is an extension to Northwind that includes additional relationships:</p> <ul> <li>multiple relationships between Department / Employee</li> <li>multi-field relationships between Order / Location</li> <li>self-relationships in Department</li> </ul> <p></p> <p>You can create projects for it with or without logic, as described below.</p> <p> </p>"},{"location":"Sample-Database/#northwind-without-logic","title":"Northwind without logic","text":"<p>To install without pre-installed customizations for the API and Logic:</p> <p><pre><code>ApiLogicServer create --project_name=nw_sample_nocust --db_url=nw-\n</code></pre> Open the project in your IDE, and open the <code>readme</code> for a walk-through:</p> <p></p> <p> </p>"},{"location":"Sample-Database/#add-customizations","title":"Add Customizations","text":"<p>The tour begins with a review of the uncustomized project.  </p> <p>This illustrates the level of automation you can expect with your own projects.</p> <p>The tutorial then shows how to add customizations:</p> <pre><code>ApiLogicServer add-cust\n</code></pre> <p></p> <p>This installs:</p> <ol> <li>Logic: The integrity of this database is enforced with this logic</li> <li>Integration: this Kafka logic</li> </ol>"},{"location":"Sample-Database/#add-security","title":"Add Security","text":"<p>Finally, as shown above, add security (defaulting to sqlite-based authorization):</p> <pre><code>ApiLogicServer add-auth\n</code></pre> <p> </p>"},{"location":"Sample-Database/#northwind-with-logic","title":"Northwind with Logic","text":"<p>You can also create the project with the logic pre-installed:</p> <p><pre><code>ApiLogicServer create --project_name=nw_sample --db_url=nw+\n</code></pre> </p>"},{"location":"Sample-Database/#sample-ai","title":"Sample-ai","text":"<p>The ChatGPT-based sample is structured as follows:</p> <p></p> <p> </p>"},{"location":"Sample-Database/#basic-demo","title":"Basic Demo","text":"<p>The ChatGPT-based sample is structured as follows:</p> <p></p>"},{"location":"Sample-Genai/","title":"GenAI Microservice Automation","text":"<p> TL;DR - GenAI leverages AI and Microservice Automation for project creation</p> <p>To create projects (either the WebGenAI web app, or API Logic Server CLI), the system performs the following:</p> <ol> <li> <p>Uses ChatGPT APIs to submit prompts and obtain data model class responses</p> </li> <li> <p>It then uses these to create a database and project</p> </li> </ol> <p>This document presumes you have already created the project, and are using VSCode or GitHub to explore it.  It illustrates how to run and customize the genai_demo project.</p> <p>Note: if you have not already created the project, see the Appendix (\"Creating GenAI Demo\").</p> <p> </p>"},{"location":"Sample-Genai/#setup-codespaces","title":"Setup Codespaces","text":"<p>Codespaces enables you to run in the cloud: VSCode via your Browser, courtesy GitHub.  You can use codespaces on your GenAI project:</p> <p>1. Open your project on GitHub</p> <p></p> <p>2. Open it in Codespaces (takes a minute or 2):</p> <p></p> <p>You will now see your project - running in VSCode, in the Browser.  But that's just what you see...</p> <p>Behind the scenes, Codespaces has requisitioned a cloud machine, and loaded your project - with a complete development environment - Python, your dependencies, git, etc.  </p> <p>You are attached to this machine in your Browser, running VSCode.</p> <p> Pretty remarkable.</p> <p>3. Start the Server and open the App in the Browser</p> <ul> <li>Use the pre-defined Launch Configuration</li> </ul> <p></p> <p>We think you'll find Codespaces pretty amazing - check it out!</p> <p> </p>"},{"location":"Sample-Genai/#how-was-the-project-created","title":"How was the project created?","text":"<p>Your prompt (whether provided in a file to the CLI, or the WebGenAI website)  is sent to ChatGPT to create a schema.  This schema is then processed by als to create  and run a project that provides a JSON:API, a Web App, a database, and business logic that runs in the API.</p> <p>For more information, Appendix (\"how does it work\").  For more information on the architecture, please see: https://www.genai-logic.com/architecture.</p> <p>Let's have a look at the created project.</p> <p> </p>"},{"location":"Sample-Genai/#1-apiapp-automation","title":"1. API/App Automation","text":"<p>API/App Automation means the created project is executable.  To run:</p> <ol> <li>Press F5 to run</li> <li>Start your Browser (use the codespaces button, or locally: http://localhost:5656/) to view:<ul> <li>App Automation: the Admin App, and</li> <li>API Automation: JSON:API, with Swagger</li> </ul> </li> <li>Stop the server when you are done (red box on VSCode Debugger panel)</li> </ol> <p></p> <p>It's a modern, 3-tiered architecture, using standard Python libraries.  For more information, see slide 2: https://www.genai-logic.com/architecture.</p> <p> </p>"},{"location":"Sample-Genai/#2-customize-rules-and-python","title":"2. Customize: Rules and Python","text":"<p>The development environment is also standard: your IDE, standard languages, standard libraries, standard source control, etc.  You customize API Logic Project in two ways, both performed in your IDE:</p> <ul> <li> <p>Logic Automation: declare spreadsheet-like rules to address multi-table derivations and constraints.  These constitute nearly half of a typical database-oriented system.   Declarative rules are 40X more concise than procedural code.</p> </li> <li> <p>Standard Python: e.g, to create a new custom endpoint, and send a Kafka message</p> </li> </ul> <p>Note: projects are model-driven, resulting in a very small amount of code.  This simplifies debugging and customizing your system.</p> <p>Explore rules and Python customization below.</p> <p> </p>"},{"location":"Sample-Genai/#logic-automation","title":"Logic Automation","text":"<p>The project creation provided natural language logic.  This is translated into rules (vs. lots of code) expressed in Python.  To explore rules created from your prompt:</p> <ol> <li> <p>Open <code>logic/declare_logic.py</code></p> </li> <li> <p>View the Python-based rules created by GenAI.  Observe you</p> </li> </ol> <p>You can add more rules, with Python (code completion), and/or GenAI.</p> <p></p> <p> </p>"},{"location":"Sample-Genai/#standard-python-libraries","title":"Standard Python, Libraries","text":"<p>To save time, issue the follow command to simulate changes you might make in your IDE, e.g., to create a new custom endpoint, and send a Kafka message.  </p> Simulate IDE Customization<pre><code>als add-cust\n</code></pre> <p></p> <p>The customization is this code in the diagram above:</p> Send Kafka Message<pre><code>    # Sends the order to Kafka topic 'order_shipping' if the date shipped is not None.\n    Rule.after_flush_row_event(on_class=Order, calling=kafka_producer.send_row_to_kafka, if_condition=lambda row: row.date_shipped is not None, with_args={\"topic\": \"order_shipping\"})\n</code></pre>"},{"location":"Sample-Genai/#try-it-out","title":"Try it out","text":"<p>Set a breakpoint in the code above, and:</p> <ol> <li>Start the Server (F5)</li> <li>Use the Admin app to alter the first Customer, first Order, first Item, and change the quantity to 11111<ul> <li>Observe the error message, from the rules.</li> </ul> </li> <li>To test the new endpoint, use Swagger (ServicesEndPoint &gt; POST /ServicesEndPoint/OrderB2B).<ul> <li>Observe the swagger response - \"Sending Order to Shipping sends:\".</li> </ul> </li> </ol> <p>Note: Kafka is not activated in this example.  To explore a running Tutorial for application integration with running Kafka, see: https://apilogicserver.github.io/Docs/Sample-Integration.</p> <p> </p>"},{"location":"Sample-Genai/#3-deployment-containers-cloud","title":"3. Deployment: Containers, Cloud","text":"<p>One of the best ways to de-risk projects is to verify the sponsors are in sync with what is happening.  This is best addressed with working software, which often occurs late in project development.  Surprises here can result in considerable rework... and frustrations.</p> <p>GenAI Automation produces working software, now, so you can find misunderstandings before investing serious effort (\"fail fast\").  To expose the working software, it's often desirable to deploy to the cloud so business users can run it.</p> <p>API Logic Server creates the <code>devops</code> directory, which scripts to containerize your project, and deploy it to Azure.  For more information, see DevOps Automation: https://apilogicserver.github.io/Docs/DevOps-Automation/.</p> <p> </p>"},{"location":"Sample-Genai/#appendices","title":"Appendices","text":""},{"location":"Sample-Genai/#genai-restart-procedures","title":"GenAI Restart Procedures","text":"<p>AI results are not consistent, so the created model file may need corrections.  You can find it at <code>system/genai/temp/model.py</code>.  You can correct the model file, and then run:</p> <pre><code>als create --project-name=genai_demo --from-model=system/genai/temp/model.py --db-url=sqlite\n</code></pre> <p>Or, correct the chatgpt response in <code>system/genai/temp/genai_demo&lt;your project&gt;response.json</code>, and</p> <pre><code>als genai --repaired-response=system/genai/temp/genai_demo/response.json --project-name=genai_demo\n</code></pre> <p> </p>"},{"location":"Sample-Genai/#diagnosis-tips","title":"Diagnosis Tips","text":"<p>The system saves files used for creation: </p> <p></p> <p>Note there are multiple diagnostic directories.  recall GenAI results are not always predictable, so we make 3 attempts to get a successful result.  This is often enough, but examining the failures can be useful.</p> <p>A good technique is to:</p> <ol> <li>Open the response file in the Manager, and</li> <li>Use your IDE to run the file </li> </ol> <p>It's usage create the sqlite database, but running it in this mode can provide more insight into causes.</p> <p>If you are using Web/GenAI (see: https://apilogicserver.github.io/Docs/WebGenAI/), project files are always under /projects/gen_$ID.</p> <p> </p>"},{"location":"Sample-Genai/#creating-genai_demo","title":"Creating <code>genai_demo</code>","text":""},{"location":"Sample-Genai/#using-webgenai","title":"Using WebGenAI","text":"<p>View the process in this video: https://www.youtube.com/watch?v=7I33Fa9Ulos </p> <p> </p>"},{"location":"Sample-Genai/#using-the-als-cli","title":"Using the ALS CLI","text":"<p>View: https://www.youtube.com/watch?v=LSh7mqGiT0k&amp;t=5s.</p> <p>To create a microservice, identify an existing database, or provide a natural language \"prompt\" description.  </p> <p>You can explore genai_demo using the Manager https://apilogicserver.github.io/Docs/Manager/.  Optionally, you can sign-up for ChatGPT API and Copilot, or simulate the process as described below.</p> <ol> <li>If you have signed up for ChatGPT API and Copilot, this command will create and open a project called <code>genai_demo</code> from <code>system/genai/examples/genai_demo/genai_demo.prompt</code>:</li> </ol> <pre><code>als genai --using=system/genai/examples/genai_demo/genai_demo.prompt\n</code></pre> <ol> <li>Or, if you have not signed up, you can simulate the process using a pre-installed response file:</li> </ol> <pre><code>als genai --using=genai_demo.prompt --gen-using-file=system/genai/temp/chatgpt_retry.txt\n</code></pre> <p>Here is the <code>system/genai/examples/genai_demo/genai_demo.prompt</code> file:</p> <p> TL;DR - GenAI Prompt</p> <p>Create a system with customers, orders, items and products.</p> <p>Include a notes field for orders.</p> <p>Use LogicBank to enforce business logic.</p> <p>Use case: Check Credit     1. The Customer's balance is less than the credit limit     2. The Customer's balance is the sum of the Order amount_total where date_shipped is null     3. The Order's amount_total is the sum of the Item amount     4. The Item amount is the quantity * unit_price     5. The Item unit_price is copied from the Product unit_price</p> <p>Ensure each customer has a unique name.</p> <p>Ensure each Item quantity is not null.</p> <p>Ensure each order has a valid customer_id that exists in the Customer table.</p> <p> </p>"},{"location":"Sample-Genai/#how-does-it-work","title":"How does it work","text":"<p>When you use the WebGenAI website, it captures your prompt, and submits to the als system using its provided CLI (<code>als genai').</code>genai` processing is shown below (internal steps denoted in grey):</p> <ol> <li> <p>You create your.prompt file, and invoke <code>als genai --using=your.prompt</code>.  genai then creates your database and project as follows:</p> <p>a. Submits your prompt to the <code>ChatGPT API</code></p> <p>b. Writes the response to file (<code>system/genai/temp/response.json</code>), so you can correct and retry if anything goes wrong</p> <p>c. Extracts <code>system/genai/temp/create_db_models.py</code> from the response</p> <p>d. Invokes <code>als create-from-model</code>, which creates the database and your project</p> </li> <li> <p>Your created project is opened in your IDE, ready to execute and customize.</p> </li> </ol> <p></p> <p> </p>"},{"location":"Sample-Genai/#genai-using-postgresql","title":"GenAI Using Postgresql","text":"<p>The above examples use sqlite, since it requires no install.  The GenAI process works for other database, such as Postgresql.</p> <p>You can test this as follows:</p> <ol> <li>Use our docker image: https://apilogicserver.github.io/Docs/Database-Docker/</li> <li>And:</li> </ol> <pre><code>als create --project-name=genai_demo_pg.prompt --db-url=postgresql://postgres:p@localhost/genai_demo\n</code></pre> <p>Provisos:</p> <ul> <li>You have to create the database first</li> </ul>"},{"location":"Sample-Integration/","title":"Sample Integration","text":""},{"location":"Sample-Integration/#purpose","title":"Purpose","text":"<p>System Requirements</p> <p>This app illustrates using IntegrationServices for B2B push-style integrations with APIs, and internal integration with messages.  We have the following Use Cases:</p> <ol> <li> <p>Ad Hoc Requests for information (Sales, Accounting) that cannot be anticipated in advance.</p> </li> <li> <p>Two Transaction Sources: A) internal Order Entry UI, and B) B2B partner <code>OrderB2B</code> API</p> </li> </ol> <p>The Northwind API Logic Server provides APIs and logic for both transaction sources:</p> <ol> <li> <p>Self-Serve APIs, to support ad hoc integration and UI dev, providing security (e.g, customers see only their account)</p> </li> <li> <p>Order Logic: enforcing database integrity and application Integration (alert shipping)</p> </li> <li> <p>A Custom API, to match an agreed-upon format for B2B partners</p> </li> </ol> <p>The Shipping API Logic Server listens on kafka, and processes the message.</p> <p></p> <p> </p> <p>Self-serve APIs, Shared Logic</p> <p>This sample illustrates some key architectural considerations:</p> Requirement Poor Practice Good Practice Best Practice Ideal Ad Hoc Integration ETL APIs Self-Serve APIs Automated Self-Serve APIs Logic Logic in UI Reusable Logic Declarative Rules.. Extensible with Python Messages Kafka Kafka Logic Integration <p>We'll further expand of these topics as we build the system, but we note some Best Practices:</p> <ul> <li> <p>APIs should be self-serve: not requiring continuing server development</p> <ul> <li>APIs avoid the overhead of nightly Extract, Transfer and Load (ETL)</li> </ul> </li> <li> <p>Logic should be re-used over the UI and API transaction sources</p> <ul> <li>Logic in UI controls is undesirable, since it cannot be shared with APIs and messages</li> </ul> </li> </ul> <p>This sample was developed with API Logic Server - open source, available here.</p> <p> </p>"},{"location":"Sample-Integration/#development-overview","title":"Development Overview","text":""},{"location":"Sample-Integration/#1-create-instant-project","title":"1. Create: Instant Project","text":"<p>The command below creates an <code>ApiLogicProject</code> by reading your schema.  The database is Northwind (Customer, Orders, Items and Product), as shown in the Appendix.  Note: the <code>db_url</code> value is an abbreviation; you would normally supply a SQLAlchemy URL.  </p> <pre><code>$ ApiLogicServer create --project_name=ApiLogicProject --db_url=nw-    # create ApiLogicProject\n</code></pre> <p>You can then open the project in your IDE, and run it.</p>  Show me how  <p> </p> <p>To run the ApiLogicProject app:</p> <ol> <li> <p>Create Virtual Environment: as shown in the Appendix.</p> </li> <li> <p>Start the Server: F5 (also described in the Appendix).</p> </li> <li> <p>Start the Admin App: either use the links provided in the IDE console, or click http://localhost:5656/.  The screen shown below should appear in your Browser.</p> </li> </ol> <p>One command has created meaningful elements of our system: </p> <p> Instant Self-Serve API - ad hoc integration - and Admin App</p> <p> </p>"},{"location":"Sample-Integration/#api-ad-hoc-integration","title":"API: Ad hoc Integration","text":"<p>The system creates an API with end points for each table, providing filtering, sorting, pagination, optimistic locking and related data access.</p> <p>The API is self-serve: consumers can select their own attributes and related data, eliminating reliance on custom API development.  In this sample, our self-serve API meets our needs for Ad Hoc Integration, and Custom UI Dev.</p> <p></p>"},{"location":"Sample-Integration/#admin-app-order-entry-ui","title":"Admin App: Order Entry UI","text":"<p>The <code>create</code> command also creates an Admin App: multi-page, multi-table with automatic joins -- ready for business user agile collaboration, and back office data maintenance.  This complements custom UIs you can create with the API.</p> <p>You can click the first Customer, and see their Orders, and Items.</p> <p></p> <p> 1 Command: Ad Hoc Integration Complete</p> <p>With 1 command, we have created an executable project that completes our ad hoc integration with a self-serve API.  We have also unblocked custom UI development.</p>"},{"location":"Sample-Integration/#2-customize-in-your-ide","title":"2. Customize: in your IDE","text":"<p>While API/UI automation is a great start, we now require Custom APIs, Logic and Security.</p> <p>You normally apply such customizations using your IDE, leveraging code completion, etc.  To accelerate this sample, you can apply the customizations with <code>ApiLogicServer add-cust</code>.   We'll review the customizations below.</p>  Show me how -- apply customizations, start Kafka  <p> </p> <p>The following <code>add-cust</code> process simulates:</p> <ul> <li>Adding security to your project using a CLI command, and</li> <li> <p>Using your IDE to:</p> <ul> <li>declare logic in <code>logic/declare_logic.sh</code></li> <li>declare security in <code>security/declare_security.py</code></li> <li>implement custom APIs in <code>api/customize_api.py</code>, using <code>OrderShipping</code> declared in <code>integration/row_dict_maps</code></li> </ul> </li> </ul> <p>These customizations are shown in the screenshots below.</p> <p>To apply customizations, in a terminal window for your project:</p> <p>1. Stop the Server (Red Stop button, or Shift-F5 -- see Appendix)</p> <p>2. Apply Customizations:</p> <pre><code>ApiLogicServer add-cust\n</code></pre> <p>3. Enable and Start Kafka</p> Show me how <p> </p> <p>To enable Kafka:</p> <ol> <li> <p>In <code>conf/config.py</code>, find and comment out: <code>KAFKA_PRODUCER = None  # comment out to enable Kafka</code></p> </li> <li> <p>Update your <code>etc/conf</code> to include the lines shown below (e.g., <code>sudo nano /etc/hosts</code>).</p> </li> </ol> <p><pre><code>##\n# Host Database\n#\n# localhost is used to configure the loopback interface\n# when the system is booting.  Do not change this entry.\n##\n\n# for kafka\n127.0.0.1       broker1\n::1             localhost\n255.255.255.255 broadcasthost\n::1             localhost\n\n127.0.0.1       localhost\n# Added by Docker Desktop\n# To allow the same kube context to work on the host and the container:\n127.0.0.1 kubernetes.docker.internal\n# End of section\n</code></pre> 3. If you already created the container, you can</p> <pre><code>1. Start it in the Docker Desktop, and\n2. **Skip the next 2 steps;** otherwise...\n</code></pre> <ol> <li> <p>Start Kafka: in a terminal window: <code>docker compose -f integration/kafka/dockercompose_start_kafka.yml up</code></p> </li> <li> <p>Create topic: in Docker: <code>kafka-topics.sh --create --bootstrap-server localhost:9092 --replication-factor 1 --partitions 3  --topic order_shipping</code></p> </li> </ol> <p>Here some useful Kafka commands:</p> <pre><code># use Docker Desktop &gt; exec, or docker exec -it broker1 bash \n# in docker terminal: set prompt, delete, create, monnitor topic, list all topics\n# to clear topic, delete and create\n\nPS1=\"kafka &gt; \"  # set prompt\n\nkafka-topics.sh --bootstrap-server localhost:9092 --topic order_shipping --delete\n\nkafka-topics.sh --create --bootstrap-server localhost:9092 --replication-factor 1 --partitions 3  --topic order_shipping\n\nkafka-console-consumer.sh --bootstrap-server localhost:9092 --topic order_shipping --from-beginning\n\nkafka-topics.sh --bootstrap-server localhost:9092 --list\n</code></pre> <p> </p> <p>4. Restart the server, login as <code>admin</code></p>"},{"location":"Sample-Integration/#declare-ui-customizations","title":"Declare UI Customizations","text":"<p>The admin app is not built with complex html and javascript.  Instead, it is configured with the ui/admin/admin.yml<code>, automatically created from your data model by</code>ApiLogicServer create`.</p> <p>You can customize this file in your IDE to control which fields are shown (including joins), hide/show conditions, help text etc.  The <code>add-cust</code> process above has simulated such customizations.</p> <p>To see customized Admin app in action, with the restarted server:</p> <p>1. Start the Admin App: http://localhost:5656/</p> <p>2. Login as <code>s1</code>, password <code>p</code></p> <p>3. Click Customers</p> <p> </p> <p>This makes it convenient to use the Admin App to enter an Order and OrderDetails:</p> <p></p> <p>Note the automation for automatic joins (Product Name, not ProductId) and lookups (select from a list of Products to obtain the foreign key).  If we attempt to order too much Chai, the transaction properly fails due to the Check Credit logic, described below.</p> <p> </p>"},{"location":"Sample-Integration/#declare-check-credit-logic","title":"Declare Check Credit Logic","text":"<p>Such logic (multi-table derivations and constraints) is a significant portion of a system, typically nearly half.  API Logic server provides spreadsheet-like rules that dramatically simplify and accelerate logic development.</p> <p> Logic: Multi-table Derivations and Constraint Rules, 40X More Concise</p> <p> </p>"},{"location":"Sample-Integration/#ide-declare-and-debug","title":"IDE: Declare and Debug","text":"<p>The 5 check credit rules are shown below.  </p> <p> Rules are 40X More Concise Than Code</p> <p>Rules are 40X more concise than legacy code, as shown here.</p> <p>Rules are declared in Python, simplified with IDE code completion.  The <code>add-cust</code> process above has simulated the process of using your IDE to declare logic.</p> <p>Observe rules can be debugged using standard logging and the debugger:</p> <p></p> <p>Rules operate by handling SQLAlchemy events, so apply to all ORM access, whether by the api engine, or your custom code.  Once declared, you don't need to remember to call them, which promotes quality.</p> <p>The rules shown above prevented the too-big order with multi-table logic to copy the Product Price, compute the Amount, roll it up to the AmountTotal and Balance, and check the CreditLimit.  </p> <p>These same rules also govern changing orders, deleting them, picking different parts - about 9 transactions, all automated.  Implementing all this by hand would otherwise require about 200 lines of code.</p>"},{"location":"Sample-Integration/#agility-quality","title":"Agility, Quality","text":"<p>Rules are a unique and significant innovation, providing meaningful improvements over procedural logic:</p> CHARACTERISTIC PROCEDURAL DECLARATIVE WHY IT MATTERS Reuse Not Automatic Automatic - all Use Cases 40X Code Reduction Invocation Passive - only if called Active - call not required Quality Ordering Manual Automatic Agile Maintenance Optimizations Manual Automatic Agile Design <p>For more on rules, click here.</p>"},{"location":"Sample-Integration/#declare-security","title":"Declare Security","text":"<p>The <code>add-cust</code> process above has simulated the <code>ApiLogicServer add-auth</code> command, and using your IDE to declare security in <code>logic/declare_security.sh</code>.</p> <p>To see security in action:</p> <p>1. Logout (upper right), and Login as <code>AFLKI</code>, password <code>p</code></p> <p>2. Click Customer</p> <p> </p> <p> Row-Level Security: Customers Filtered</p> <p> </p>"},{"location":"Sample-Integration/#login-row-filtering","title":"Login, Row Filtering","text":"<p>Declarative row-level security ensures that users see only the rows authorized for their roles.  Observe you now see only customer ALFKI, per the security declared below.  Note the console log at the bottom shows how the filter worked.</p> <p></p>"},{"location":"Sample-Integration/#3-integrate-b2b-and-shipping","title":"3. Integrate: B2B and Shipping","text":"<p>We now have a running system - an API, logic, security, and a UI.  Now we must integrate with:</p> <ul> <li>B2B partners -- we'll create a B2B Custom Resource</li> <li>OrderShipping -- we add logic to Send an OrderShipping Message</li> </ul> <p> </p>"},{"location":"Sample-Integration/#b2b-custom-resource","title":"B2B Custom Resource","text":"<p>The self-serve API does not conform to the format required for a B2B partnership.  We need to create a custom resource.</p> <p>You can create custom resources by editing <code>customize_api.py</code>, using standard Python, Flask and SQLAlchemy.  A custom <code>OrderB2B</code> resource is shown below.</p> <p>The main task here is to map a B2B payload onto our logic-enabled SQLAlchemy rows.  API Logic Server provides a declarative <code>ApplicationIntegration</code> service you can use as follows:</p> <ol> <li> <p>Declare the mapping -- see the <code>OrderB2B</code> class in the lower pane</p> <ul> <li>Note the support for lookup, so partners can send ProductNames, not ProductIds</li> </ul> </li> <li> <p>Create the custom API endpoint -- see the upper pane:</p> <ul> <li>Add <code>def OrderB2B</code> to <code>customize_api/py</code> to create a new endpoint</li> <li>Use the <code>OrderB2B</code> class to transform a api request data to SQLAlchemy rows (<code>dict_to_row</code>)</li> <li>The automatic commit initiates the same shared logic described above to check credit and reorder products</li> </ul> </li> </ol> <p></p> <p> Custom Endpoint - 7 lines of code</p> <p>So, our custom endpoint required about 7 lines of code, along with the API specification on the right.  Note the logic is automatically factored out, and re-used for all APIs, both custom and self-serve.</p> <p> </p>"},{"location":"Sample-Integration/#produce-ordershipping-message","title":"Produce <code>OrderShipping</code> Message","text":"<p>Successful orders need to be sent to Shipping, again in a predesignated format.</p> <p>We could certainly POST an API, but Messaging (here, Kafka) provides significant advantages:</p> <ul> <li>Async: Our system will not be impacted if the Shipping system is down.  Kafka will save the message, and deliver it when Shipping is back up.</li> <li>Multi-cast: We can send a message that multiple systems (e.g., Accounting) can consume.</li> </ul> <p>The content of the message is a JSON string, just like an API.</p> <p>Just as you can customize apis, you can complement rule-based logic using Python events:</p> <ol> <li> <p>Declare the mapping -- see the <code>OrderShipping</code> class in the right pane.  This formats our Kafka message content in the format agreed upon with Shipping.</p> </li> <li> <p>Define a Python <code>after_flush</code> event, which invokes <code>send_order_to_shipping</code>.  This is called by the logic engine, which passes the SQLAlchemy `models.Order`` row.</p> </li> <li> <p><code>send_order_to_shipping</code> uses the <code>OrderShipping</code> class, which maps our SQLAlchemy order row to a dict (<code>row_to_dict</code>).</p> </li> </ol> <p></p> <p> Extensible Rules, Kafka Message Produced</p> <p>Rule-based logic is extensible with Python, here producing a Kafka message with 20 lines of code.</p> <p> </p>"},{"location":"Sample-Integration/#4-consuming-messages","title":"4. Consuming Messages","text":"<p>The Shipping system illustrates how to consume messages.  This system was created from AI, here customized to add message consumption.</p> <p> </p>"},{"location":"Sample-Integration/#createstart-shipping","title":"Create/Start Shipping","text":"<p>To explore Shipping:</p> <p>1. Create the Shipping Project:</p> <pre><code>ApiLogicServer create --project_name=shipping --db_url=shipping\n</code></pre> <p>2. Start your IDE (e.g., <code>code shipping</code>) and establish your <code>venv</code></p> <p>3. Start the Shipping Server: F5 (it's configured to use a different port)</p> <p> </p>"},{"location":"Sample-Integration/#consuming-logic","title":"Consuming Logic","text":"<p>To consume messages:</p> <p>1. Enable Consumption</p> <p>Shipping is pre-configured to enable message consumption with a setting in <code>conf/config.py</code>:</p> <pre><code>KAFKA_CONSUMER = '{\"bootstrap.servers\": \"localhost:9092\", \"group.id\": \"als-default-group1\", \"auto.offset.reset\":\"smallest\"}'\n</code></pre> <p>When the server is started in <code>api_logic_server_run.py</code>, it invokes <code>integration/kafka/kafka_consumer.py#flask_consumer</code>.  This calls the pre-supplied <code>FlaskKafka</code>, which takes care of the Kafka listening, thread management, and the <code>handle</code> annotation used below.</p> <p><code>FlaskKafka</code> was inspired by the work of Nimrod (Kevin) Maina, in this project.  Many thanks!</p> <p> </p> <p>2. Configure a mapping</p> <p>As we did for our OrderB2B Custom Resource, we configure an <code>OrderToShip</code> mapping class to map the message onto our SQLAlchemy Order object.</p> <p> </p> <p>3. Provide a Message Handler</p> <p>We provide the <code>order_shipping</code> handler in <code>integration/kafka/kafka_consumer.py</code>:</p> <ol> <li> <p>Annotate the topic handler method, providing the topic name.</p> <ul> <li>This is used by <code>FlaskKafka</code> establish a Kafka listener</li> </ul> </li> <li> <p>Provide the topic handler code, leveraging the mapper noted above.  It is called by <code>Flaskkafka</code> per the method annotations.</p> </li> </ol> <p></p> <p> </p>"},{"location":"Sample-Integration/#test-it","title":"Test it","text":"<p>Use your IDE terminal window to simulate a business partner posting a B2BOrder.  You can set breakpoints in the code described above to explore system operation.</p> <pre><code>ApiLogicServer curl \"'POST' 'http://localhost:5656/api/ServicesEndPoint/OrderB2B'\" --data '\n{\"meta\": {\"args\": {\"order\": {\n    \"AccountId\": \"ALFKI\",\n    \"Surname\": \"Buchanan\",\n    \"Given\": \"Steven\",\n    \"Items\": [\n        {\n        \"ProductName\": \"Chai\",\n        \"QuantityOrdered\": 1\n        },\n        {\n        \"ProductName\": \"Chang\",\n        \"QuantityOrdered\": 2\n        }\n        ]\n    }\n}}}'\n</code></pre> <p> </p>"},{"location":"Sample-Integration/#summary","title":"Summary","text":"<p>These applications have demonstrated several types of application integration:</p> <ul> <li> <p>Ad Hoc Integration via self-serve APIs</p> </li> <li> <p>Custom Integration via custom APIs, to support business agreements with B2B partners</p> </li> <li> <p>Message-Based Integration to decouple internal systems by reducing dependencies that all systems must always be running</p> </li> </ul> <p>We have also illustrated several technologies noted in the Ideal column:</p> Requirement Poor Practice Good Practice Best Practice Ideal Ad Hoc Integration ETL APIs Self-Serve APIs Automated Self-Serve APIs Logic Logic in UI Reusable Logic Declarative Rules.. Extensible with Python Messages Kafka Kafka Logic Integration <p>API Logic Server supports the Ideal Practices noted above: </p> <ol> <li> <p>Automation: instant ad hoc API (and Admin UI) with the <code>ApiLogicServer create</code> command</p> </li> <li> <p>Declarative Rules - security and multi-table logic, providing a 40X code reduction for backend half of these systems</p> </li> <li> <p>Kafka Logic Integration</p> <ul> <li> <p>Send from logic events</p> </li> <li> <p>Consume by extending <code>kafka_consumer</code></p> </li> <li> <p>Services, including:</p> <ul> <li> <p><code>Mapper</code> services to transform rows and dict</p> </li> <li> <p><code>FlaskKafka</code> for Kafka listening, threading, and annotation invocation</p> </li> </ul> </li> </ul> </li> <li> <p>Standards-based Customization:</p> <ul> <li> <p>Standard packages: Python, Flask, SQLAlchemy, Kafka...</p> </li> <li> <p>Using standard IDEs</p> </li> </ul> </li> </ol> <p>As a result, we built 2 non-trivial systems with a remarkably small amount of Python code:</p> Type Code Custom B2B API 10 lines Check Credit Logic 5 rules Row Level Security 1 security declaration Send Order to Shipping 20 lines Process Order in Shipping 30 lines Mapping configurations to transform rows and dicts 45 lines <p>For more information on API Logic Server, click here.</p> <p> </p>"},{"location":"Sample-Integration/#appendix","title":"Appendix","text":""},{"location":"Sample-Integration/#status","title":"Status","text":"<p>Tested on Mac</p>"},{"location":"Sample-Integration/#apendix-customizations","title":"Apendix: Customizations","text":"<p>View them here.</p> <p> </p>"},{"location":"Sample-Integration/#appendix-procedures","title":"Appendix: Procedures","text":"<p>Specific procedures for running the demo are here, so they do not interrupt the conceptual discussion above.</p> <p>You can use either VSCode or Pycharm.</p> <p> </p> <p>1. Establish your Virtual Environment</p> <p>Python employs a virtual environment for project-specific dependencies.  Create one as shown below, depending on your IDE.</p> <p>For VSCode:</p> <p>Establish your <code>venv</code>, and run it via the first pre-built Run Configuration.  To establish your venv:</p> <pre><code>python -m venv venv; venv\\Scripts\\activate     # win\npython3 -m venv venv; . venv/bin/activate      # mac/linux\n\npip install -r requirements.txt\n</code></pre> <p>For PyCharm, you will get a dialog requesting to create the <code>venv</code>; say yes.</p> <p>See here for more information.</p> <p> </p> <p>2. Start and Stop the Server</p> <p>Both IDEs provide Run Configurations to start programs.  These are pre-built by <code>ApiLogicServer create</code>.</p> <p>For VSCode, start the Server with F5, Stop with Shift-F5 or the red stop button.</p> <p>For PyCharm, start the server with CTL-D, Stop with red stop button.</p> <p> </p> <p>3. Entering a new Order</p> <p>To enter a new Order:</p> <ol> <li> <p>Click `ALFKI``</p> </li> <li> <p>Click <code>+ ADD NEW ORDER</code></p> </li> <li> <p>Set <code>Notes</code> to \"hurry\", and press <code>SAVE AND SHOW</code></p> </li> <li> <p>Click <code>+ ADD NEW ITEM</code></p> </li> <li> <p>Enter Quantity 1, lookup \"Chai\", and click <code>SAVE AND ADD ANOTHER</code></p> </li> <li> <p>Enter Quantity 2000, lookup \"Chang\", and click <code>SAVE</code></p> </li> <li> <p>Observe the constraint error, triggered by rollups from the <code>OrderDetail</code> to the <code>Order</code> and <code>Customer</code></p> </li> <li> <p>Correct the quantity to 2, and click <code>Save</code></p> </li> </ol> <p>4. Update the Order</p> <p>To explore our new logic for green products:</p> <ol> <li> <p>Access the previous order, and <code>ADD NEW ITEM</code></p> </li> <li> <p>Enter quantity 11, lookup product <code>Chang</code>, and click <code>Save</code>.</p> </li> </ol>"},{"location":"Security-Activation/","title":"Activation: add-auth","text":"<p> TL;DR - Use add-auth to activate security</p> <p>You activate security by activating authentication using the <code>add-auth</code> CLI command to designate the <code>authentication-type</code> (sql or keycloak), and its database location (<code>db_url</code>).</p> <p> </p>"},{"location":"Security-Activation/#add-auth","title":"add-auth","text":"<p>Use the <code>add-auth</code> command to activate security.  Specify:</p> <ol> <li><code>--provider-type</code>: sql, keycloak, or your custom auth provider</li> <li><code>--db-url</code>: the persistent store to identify valid users and their roles.  These can be stores such as LDAP or Microsoft AD, or a security sql database.</li> </ol> <p> </p>"},{"location":"Security-Activation/#examples","title":"Examples","text":"<p>Use your IDE's terminal window positioned at your project root <sup>1</sup>:</p> Configure Security - Examples<pre><code>gail add-auth --provider-type=sql --db-url=\ngail add-auth --provider-type=sql --db_url=postgresql://postgres:p@localhost/authdb\n\ngail add-auth --provider-type=keycloak --db-url=localhost\ngail add-auth --provider-type=keycloak --db-url=hardened\n\ngail add-auth --provider-type=None # to disable\n</code></pre> <p> </p>"},{"location":"Security-Activation/#add-auth-internal-processing","title":"<code>add-auth</code> Internal Processing","text":""},{"location":"Security-Activation/#updates-configpy","title":"Updates <code>config.py</code>","text":"<p>Internally, this updates <code>conf/config.py</code>:</p> <p></p> <p> </p>"},{"location":"Security-Activation/#creates-auth-models","title":"Creates auth models","text":"<p>See this information for sql authentication.</p> <p> </p>"},{"location":"Security-Activation/#appendix-internals","title":"Appendix: Internals","text":"<p>The Security Manager and sqlite Authentication-Provider are built into created projects from the system's prototype project.</p> <ol> <li> <p><code>gail</code> (or <code>genai-logic</code>) is the rebranded name for <code>als</code> (or <code>apilogicserver</code>). Older installations may require these latter CLI names.\u00a0\u21a9</p> </li> </ol>"},{"location":"Security-Authentication/","title":"Login Authentication","text":"<p>Once you have activated security, the system require you to login to obtain a token, and provide this token on subsequent APIs.  This page describes how to login and provide a token.</p> <p> </p>"},{"location":"Security-Authentication/#obtain-a-token","title":"Obtain a token","text":"<p>The sample test apps obtain a token as shown here (see login()).  This is also illustrated in the swagger section, below.</p> <p> </p>"},{"location":"Security-Authentication/#swagger-authentication","title":"Swagger Authentication","text":"<p>Once you activate, tokens are required, including in Swagger.  You can obtain a token and authenticate as described below for the sqlite authentication-provider:</p> <ol> <li>Access the User Login service</li> <li>Use the Try it now feature as shown below</li> <li>Copy the token value for use in the next step</li> </ol> <p></p> <p>At the top of Swagger, locate the Authenticate button.  Copy the token, precede it with Bearer, and login like this:</p> <p></p> <p> </p>"},{"location":"Security-Authentication/#provide-token-in-header","title":"Provide token in header","text":"<p>The sample test apps use this token on API calls as shown here.</p>"},{"location":"Security-Authentication/#public-role","title":"<code>public</code> role","text":"<p>For each user, you define their roles.  Depending on your authentication provider, this can be in a sql database, keycloak, or your own custom provider (e.g., LDAP, AD).</p> <p>If you define no roles, authenticated users are automatically assigned with the <code>public</code> role.  You must still authorize this role, as illustrated in the nw sample.</p>"},{"location":"Security-Authentication/#password-encryption-with-flask_bcrypt","title":"Password Encryption with flask_bcrypt","text":"<p>It is generally not a good idea to store user passwords in plain text.  The Python package flask_bcrypt is included and can be used to generate encrypted passwords. Note: each time you run the encryption - you will get a different value but the check password hash will return true if the plain text matches.</p> <pre><code>from flask_bcrypt import generate_password_hash, check_password_hash\n\nif __name__ == \"__main__\":\n    pw = input(\"Enter a password to encrypt: \")\n    pw_hash = generate_password_hash(password=pw)\n    print(f'encrypted password = {pw_hash}')\n    print(f'check_password_hash: {pw} = {check_password_hash(pw_hash=pw_hash, password=pw)}')\n\nEnter a password to encrypt: p\nencrypted password = b'$2b$12$7sBO8jrL7nlgd10/yZ6lqeCV9Jr/itMnu0Zx0bFAqzC3kYQbzB8j.'\ncheck_password_hash: p = True\n</code></pre> <p>Once you have the encrypted password - update your 'User' table password_hash value.  SQL for each user: <pre><code>update user set password_hash = '$2b$12$7sBO8jrL7nlgd10/yZ6lqeCV9Jr/itMnu0Zx0bFAqzC3kYQbzB8j.' where user.id = 'admin'\n</code></pre></p> <p>Modify the file database/authentication.py to use the encrypted password_hash. <pre><code>from flask_bcrypt import generate_password_hash, check_password_hash\n\n    # authentication-provider extension - encrypted password check\n    def check_password(self, plaintext=None):\n        # print(password)\n        return check_password_hash(self.password_hash, plaintext)\n</code></pre></p>"},{"location":"Security-Authorization/","title":"Role-based Authorization","text":"<p> TL;DR - Role-based Grants and Permissions, Global Filters</p> <p>Declarative security enables you to control which rows are visible to which users, and their read/update permissions:</p> <p>1. Grants: declare filters for a class/role</p> <p>2. Global Filters: declare filters global to all tables, used for:</p> <ul> <li> <p>Multi-Tenant</p> </li> <li> <p>Common patterns such as hiding rows marked for deletion, rows outside a users' territory, etc</p> </li> </ul> <p>3. Permissions: define whether specific rows are create, read, update or delete rows</p> <p>Logging is provided so you can see which filters are applied, and the resultant SQL.</p>"},{"location":"Security-Authorization/#declaring-security-logic","title":"Declaring Security Logic","text":"<p>Analogous to logic declarations, Developers declare filters for users' roles (role-based access control).  As shown below, these are declared in <code>security/declare_security.py</code>.</p> <p>A user can have multiple roles; a users' filters are ORed together.</p> <p>Roles are typically defined elsewhere (Keycloak, LDAP, AD, external SQL database), and accessed at runtime via the Authentication-Provider.  Roles simplify administration, since there are typically many fewer roles that users, and they are less subject to change.  </p> <p>You may elect to define the roles in your code for code completion, as shown below in the <code>Roles</code> class.  In any case, the \"source of truth\" is the Authentication-Provider.</p> <p></p> <p> </p>"},{"location":"Security-Authorization/#grants","title":"Grants","text":"<p>Each <code>Grant</code> designates a role, class and filter.  Since a user can have multiple roles, there can be multiple Grants.  These are OR'd together.</p> <p>In the sales example shown above, the CreditLimit filter would hide all rows; rows, however, are visible becuase the ContactName filter is OR'd in.</p> <p> </p>"},{"location":"Security-Authorization/#global-filters","title":"Global Filters","text":"<p>Global filter specify an entity, a filter, and rows not subject to the filter.</p> <p>In the example above:</p> <ul> <li><code>Client_id</code> illustrates multi-tenant.  Observe the search criteria are from the <code>User</code> object.</li> <li><code>Region</code> illustrates how to limit customer rows to sales reps in their region</li> <li><code>Security</code> illustrates how to protect certain rows</li> </ul> <p> </p>"},{"location":"Security-Authorization/#permissions","title":"Permissions","text":"<p>Permissions designate what operations can be performed for each role.  Since this can get wordy (imagine many tables and roles), defaults are provided.</p> <p> </p>"},{"location":"Security-Authorization/#debugging","title":"Debugging","text":"<p>In the Sample App, login as s1 and click Customers.  You will see the following log:</p> <p></p>"},{"location":"Security-Authorization/#sample","title":"Sample","text":"<p>This is illustrated in the sample application <code>security/declare_security.py</code> - click here.</p> <p>You can test it via the Admin App, or via Swagger.</p> <p> </p>"},{"location":"Security-Authorization/#admin-app","title":"Admin App","text":"<p>Click <code>Category</code> in the Admin App:</p> <p></p> <p> </p>"},{"location":"Security-Authorization/#swagger","title":"Swagger","text":"<p>The same result is visible in Swagger:</p> <p></p>"},{"location":"Security-Getting-Started/","title":"Getting Started with Security","text":"<p> TL;DR - Explore Samples to Learn About Security</p> <p>Security can be complicated.  </p> <p>We recommend exploring the security examples below.</p> <p> </p>"},{"location":"Security-Getting-Started/#typical-process-your-projects","title":"Typical Process - Your Projects","text":"<p>We recommend starting with the pre-configured Northwind database, described in the next section.  Use this to explore grants, configuration, etc.</p> <p>For your own projects, consider introducing security gradually:</p> <ol> <li> <p>Create your project without security</p> <ul> <li>Verify connectivity, API operation, Admin App operation, etc.</li> </ul> </li> <li> <p>Activate sqlite Security</p> <ul> <li>Start with sqlite, and build your Grant declarations</li> </ul> </li> <li> <p>Upgrade to sql or keycloak</p> <ul> <li>With some basic examples working, introduce sql or keycloak authorization</li> </ul> </li> </ol> <p> </p>"},{"location":"Security-Getting-Started/#northwind-sqlite-sample","title":"Northwind Sqlite Sample","text":"<p>Security is automatically enabled when building the sample app, with customizations:</p> Create a sample project to Explore Security<pre><code>ApiLogicServer create --project_name=nw_sample --db_url=nw+\n</code></pre> <p>To explore the Grants in <code>security/declare_security.py</code> - click here.</p> <p>You can test it via the Admin App, or via Swagger.  See the Verify section, below.</p> <p>Or, to see the process from scratch:</p> <ol> <li>Create the sample application without customizations: click here</li> <li>Then, as shown in that link, add customizations and security</li> </ol> <p>In either case, you will have a project using the default sqlite security, including Grants and test data.</p> <p> </p>"},{"location":"Security-Getting-Started/#verify","title":"Verify","text":"<p>After configuring, you should now be able to run the admin app:</p> <ol> <li>login as s1/p -- note the login screen indicates whether or not you are using keycloak (kcals):</li> </ol> <p></p> <ol> <li> <p>Verify there is only 1 customer</p> </li> <li> <p>Logout and login as admin/p, and there should be more customers</p> </li> </ol> <p> </p>"},{"location":"Security-Getting-Started/#experiment-with-auth-dbs","title":"Experiment with auth dbs","text":"<p>Depending on your ultimate objectives, explore alternative auth databases:</p> AuthDB Try Test sql (default sqlite) Pre-configured from creation, above See Verify, above sql (Postgress example) Postgres Northwind with Docker Basic retrieval Keycloak (preconfigured) Keycloak - hardened See Verify Keycloak (local using Docker) Keycloak - local using Docker See Verify <p> </p>"},{"location":"Security-Getting-Started/#using-your-own-authdb","title":"Using your own <code>authdb</code>","text":"<p>In most cases, you will create your own <code>authdb</code>:</p> <ol> <li> <p>To use the same kind of DBMS you are using for your data</p> </li> <li> <p>To introduce additional properties for use in <code>Grants</code> -- see the first section below</p> </li> </ol> <p> </p>"},{"location":"Security-Getting-Started/#sql-authdb-resources","title":"sql authdb Resources","text":"<p>The following resources are available to help you create sql authdb.</p>"},{"location":"Security-Getting-Started/#pre-created-authdb-scripts","title":"Pre-created <code>authdb</code> scripts","text":"<p>Your project contains some example sql to create the auth db:</p> <p></p> <p>Prior release 08.00.05, those files were not created in new projects.  For earlier versions, create these files in devops/docker with this Dockerfile.</p> <p> </p>"},{"location":"Security-Getting-Started/#pre-created-in-docker-dbs","title":"Pre-created in Docker DBs","text":"<p>A sample security database is pre-created in the MySQL and Postgres Sample Docker Databases.</p> <p> </p>"},{"location":"Security-Getting-Started/#examples","title":"Examples","text":""},{"location":"Security-Getting-Started/#postgres-docker-northwind","title":"Postgres Docker <code>northwind</code>","text":"<p>This example uses the Postgres docker database noted above:</p> <pre><code>docker network create dev-network  # only required once\n\ndocker run -d --name postgresql-container --net dev-network -p 5432:5432 -e PGDATA=/pgdata -e POSTGRES_PASSWORD=p apilogicserver/postgres:latest\n\nApiLogicServer create --project_name=postgres-nw --db_url=postgresql://postgres:p@localhost/postgres\n\ncd postgres-nw\nApiLogicServer add-auth --db_url=postgresql://postgres:p@localhost/authdb\n</code></pre> <p>Let's review how this database was created.</p> <p>1. Create the Postgres NW database</p> <p>You can find the creation information here:</p> <p></p> <p>After using the Postgres CLI to create the database, verify it exists:</p> <p></p> <p> </p>"},{"location":"Security-Getting-Started/#mysql-docker-classicmodels","title":"MySQL docker <code>classicmodels</code>","text":"<p>As noted above, you can use the docker databases as shown below.</p> <pre><code>docker network create dev-network  # only required once\n\ndocker run --name mysql-container --net dev-network -p 3306:3306 -d -e MYSQL_ROOT_PASSWORD=p apilogicserver/mysql8.0:latest\n\nApiLogicServer create --project_name=classicmodels  --db_url=classicmodels\n\ncd classicmodels\nApiLogicServer add-auth --db_url=mysql+pymysql://root:p@localhost:3306/authdb\n</code></pre> <p> </p>"},{"location":"Security-Keycloak/","title":"Configure Keycloak auth","text":"<p> TL;DR - Authorize using Keycloak</p> <p>You can use Keycloak for authentication.  You can configure your own keycloak, or use the procedure below to install Keycloak:</p> <ol> <li> <p>Install keycloak using a Docker container: <code>cd devops/keycloak; docker compose up</code></p> </li> <li> <p>Activate: <code>als add-auth --provider-type=keycloak --db-url=localhost</code></p> </li> </ol> <p>In addition, this page describes how to administer User/Roles in your Keycloak, and export these settings into your project for source control and team development.</p> <p>This page is under construction.  </p> <p> </p>"},{"location":"Security-Keycloak/#keycloak-local-config","title":"Keycloak: <code>local</code> config","text":"<p>Projects are pre-created with scripts start Keycloak under Docker.  Use this procedure to install and configure a local version of keycloak, running under Docker.</p> <p> </p>"},{"location":"Security-Keycloak/#install-keycloak-under-docker","title":"Install Keycloak under Docker","text":"<p>Install Keycloak with Docker (imports settings from <code>devops/keycloak/data/import</code>):</p> Start [install] Keycloak<pre><code>cd devops/keycloak; docker compose up\n</code></pre> <p></p> <p>You may see: <code>Failed to load jwks_uri http://localhost:8080/realms/kcals/protocol/openid-connect/certs</code>.</p> <ul> <li>coming soon.  please contact support.</li> </ul> <p> </p>"},{"location":"Security-Keycloak/#configure-project-for-keycloak","title":"Configure Project for Keycloak","text":"<p>Execute the following.  Optionally, observe the settings in <code>config/config.py</code>:</p> Configure Keycloak - local<pre><code>als add-auth --provider-type=keycloak --db-url=localhost\n</code></pre> <p>The above uses the <code>localhost</code> abbreviation for the server location.  To use a non-default, be sure to speccify your port:</p> Configure Keycloak - local (not default location)<pre><code>als add-auth --provider-type=keycloak --db-url=http://10.0.0.77:8080\n</code></pre> Internals - verify Configuration in running Admin App  <p>The config settings for the admin app are set in <code>ui/admin/admin_loader.py</code>.  This reduces the number of settings to change when altering your configuration.  You can verify them as shown below:</p> <p></p> <p></p> <p> </p>"},{"location":"Security-Keycloak/#verify-with-the-admin-app","title":"Verify With the Admin App","text":"<p>You should now be able to run the admin app:</p> <ol> <li>login as s1/p -- note the login screen indicates kcals:</li> </ol> <p></p> <ol> <li> <p>Verify there is only 1 customer</p> </li> <li> <p>Logout and login as admin/p, and there should be more customers</p> </li> </ol> <p> </p>"},{"location":"Security-Keycloak/#connecting-your-project-to-keycloak","title":"Connecting your project to Keycloak","text":"<p>If you run your project under docker, you must configure the Keycloak IP address.  For more information, see Use Standard Container.</p> <p> </p>"},{"location":"Security-Keycloak/#keycloak-admin","title":"Keycloak Admin","text":"<p>You can use the Keycloak admin console to define Users and their Roles / Attributes.</p> <p> </p>"},{"location":"Security-Keycloak/#user-administration","title":"User Administration","text":"<p>To define Users and their Roles / Attributes:</p> <ol> <li>Note the selected realm (<code>kcals</code>)</li> </ol> <p></p>"},{"location":"Security-Keycloak/#user-roles","title":"User Roles","text":"<p>Define Roles for your realm:</p> <p></p> <p> </p> <p>And assign them to users:</p> <p></p>"},{"location":"Security-Keycloak/#user-attributes","title":"User Attributes","text":""},{"location":"Security-Keycloak/#valid-attributes","title":"Valid Attributes","text":"<p>First, define attributes types:</p> <p></p>"},{"location":"Security-Keycloak/#link-attributes-to-scopes","title":"Link Attributes to Scopes","text":""},{"location":"Security-Keycloak/#assign-user-attribute-values","title":"Assign User Attribute Values","text":"<p>Warning: do not specify None or Null for attribute values; these lead to unpredictable results.</p> <p> </p>"},{"location":"Security-Keycloak/#export-auth-data","title":"Export Auth Data","text":"<p>After defining your users, attributes and roles, you will want to save this keycloak auth data into your project, for source control and sharing.</p> <p>Export your revised auth data:</p> <ol> <li>In the terminal window of your project:</li> </ol> Export the revised auth data<pre><code>% docker exec -it keycloak bash\n\n$ cd /opt/keycloak\n$ bin/kc.sh export --help\n$ bin/kc.sh export --dir export\n$ exit\n</code></pre> <p>This creates a directory in the keycloak docker: <code>keycloak:/opt/keycloak/export</code>.  We can import this back into our project, as described next.</p> <p> </p>"},{"location":"Security-Keycloak/#use-exported-auth-data-in-project","title":"Use Exported Auth Data in Project","text":"<p>You can make this saved auth data part of your project (and saved to <code>git</code> for your team), as follows:</p> <ol> <li>In the terminal window of your project</li> </ol> Use Exported Auth Data in Project<pre><code>mv devops/keycloak/import-save devops/keycloak/import-backup\ndocker cp keycloak:/opt/keycloak/export devops/keycloak/import\n</code></pre>"},{"location":"Security-Keycloak/#appendix","title":"Appendix","text":""},{"location":"Security-Keycloak/#browser-cache","title":"Browser Cache","text":"<p>Keycloak caches security data (e.g., for single sign-on).  This may required you to clear your Browser cache.</p>"},{"location":"Security-Keycloak/#internals","title":"Internals","text":"<p>Authentication and the keycloak provider interact as shown below:</p> <p></p>"},{"location":"Security-Keycloak/#inspecting-access-tokens","title":"Inspecting Access Tokens","text":"<p>You can use jwt.io:</p> <p></p>"},{"location":"Security-Overview/","title":"Overview","text":"<p> TL;DR - Row Level Security with Grant Permissions on User Roles</p> <p>Declarative security enables you to <code>Grant</code> row filters to user roles, providing row level security: users see only the rows to which they are authorized.  </p> <p>Grants declarations reference not only roles, but also user properties (e.g., their organization).  A common usage is to enforce multi-tenant access.</p> <p>Define  authentication data (auth data) - users and roles - with:</p> <ul> <li>a SQL database using an Admin app,</li> <li>Keycloak, or,</li> <li>supply a provider to attach to existing corporate security (AD, LDAP, etc).</li> </ul> <p> </p>"},{"location":"Security-Overview/#key-concepts","title":"Key Concepts","text":"<p>Security consists of many aspects (http headers, cookie settings, etc.); here, we focus on the following key concepts.</p> <p> </p>"},{"location":"Security-Overview/#authentication-system-access","title":"Authentication - system access","text":"<p>A login function that confirms a user has access, usually by posting credentials and obtaining a JWT token identifying the users' roles.</p> <p> </p>"},{"location":"Security-Overview/#authorization-data-access","title":"Authorization - data access","text":"<p>Controls access to row/columns based on assigned roles.</p> <p> </p>"},{"location":"Security-Overview/#users","title":"Users","text":"<p>Authorized users have a list of roles, and optionally a set of attributes.</p> <p> </p>"},{"location":"Security-Overview/#user-roles","title":"User Roles","text":"<p>Users are assigned one or many roles (e.g, <code>sales</code>).  Rather than dealing with thousands of users, security adminstrators focus on authorization Roles to access data.</p> <p> </p>"},{"location":"Security-Overview/#user-attributes","title":"User Attributes","text":"<p>Each user may also have a set of site-specific attributes, such as their <code>region</code>, or their (multi-tenant) <code>client_id</code>.</p> <p> </p>"},{"location":"Security-Overview/#auth-providers","title":"Auth-Providers","text":"<p>Organizations will utilize a wide variety of techniques to maintain authorization data: databases, keycloak, LDAP, AD etc.  This means an open \"interface\" approach is required. </p> <p>Authentication Providers are called by the system during login.  They are passed the id/password, and return a user row and list of roles.  They hide how the user/role information is actually stored.</p> <p>The system provides default providers for sql and keycloak.  In addition, you can create your own provider to interface with your authentication system (LDAP, AD etc)</p> <p>Multiple systems will share the same authentication data, so, even if you are using sql, this \"auth\" database/schema will be separate from each application database/schema.</p> <p> </p>"},{"location":"Security-Overview/#pre-supplied-auth-providers","title":"Pre-supplied Auth Providers","text":"<p>It is common to use the system-supplied auth providers for keycloak and sql:</p> <p></p>"},{"location":"Security-Overview/#custom-auth-providers","title":"Custom Auth Providers","text":"<p>If you define your own auth provider, you must ensure it can be called by the system.  To ensure that Authentication-Providers implement the expected api, you should inherit from this class.</p> <p> </p>"},{"location":"Security-Overview/#grant-role-filters","title":"Grant Role Filters","text":"<p>Security Administrators declaring Grant filters, which filter retrieval based on roles and user properties.  This provides authorization down to the row level.  For example, we might want to filter \"small\" customers so the sales team can focus on high revenue accounts:</p> Focus Sales on high-revenue customers<pre><code>Grant(  on_entity = models.Customer,\n        to_role = Roles.sales,\n        filter = lambda : models.Customer.CreditLimit &gt; 300)\n</code></pre> <p> </p>"},{"location":"Security-Overview/#global-filters","title":"Global Filters","text":"<p>Global filters apply to all roles.  For example, you might enforce multi-tenant access with:</p> Global Filters apply to all roles<pre><code>GlobalFilter(   global_filter_attribute_name = \"Client_id\", \n                roles_not_filtered = [\"sa\"],\n                filter = '{entity_class}.Client_id == Security.current_user().client_id')\n</code></pre> <p> </p>"},{"location":"Security-Overview/#process-overview","title":"Process Overview","text":"<p>The overall flow is described below, identifying:</p> <ol> <li>What Developers must do</li> <li>What the system does</li> </ol> <p> </p>"},{"location":"Security-Overview/#developers-configure-security","title":"Developers Configure Security","text":"<p>Developers are responsible for providing (or using system defaults) the following:</p> <p> </p>"},{"location":"Security-Overview/#authentication-provider","title":"Authentication-Provider","text":"<p>This class, given a user/password, returns the list of authorized roles (on None).  It is invoked by the system when client apps log in.</p> <p>Developers must:</p> <ul> <li> <p>Provide this class (or use the system-supplied providers for <code>sql</code> and <code>keycloak</code>)</p> </li> <li> <p>Identify this as the <code>--provider-type</code> in the <code>add-auth</code> command</p> </li> </ul> <p> </p>"},{"location":"Security-Overview/#authentication-data","title":"Authentication Data","text":"<p>Developers must determine the data required to authenticate users.  This can be a SQL Database, LDAP, AD, etc.  It is separate from user databases so it can be shared between systems.  The Authentication-Provider uses it to authenticate a user/password, and return their roles.</p> <p> </p>"},{"location":"Security-Overview/#declare_security","title":"<code>declare_security</code>","text":"<p>Add code to the pre-created (empty) Python module <code>security/declare_security.py</code> to define table/role filters.  The system merges these filters into each retrieval.  These declarations are processed on system startup as described below.</p> <p> </p>"},{"location":"Security-Overview/#system-processing","title":"System Processing","text":"<p>System processing is summarized below.</p> <p> </p>"},{"location":"Security-Overview/#startup-declare_security","title":"Startup: <code>declare_security</code>","text":"<p>When you start the server, the system (<code>api_logic_server_run.py</code>) imports <code>declare_security</code>.  This:</p> <ol> <li> <p>Imports <code>from security.system.security_manager import Grant, Security</code>, which sets up SQLAlchemy listeners for all database access calls</p> </li> <li> <p>Creates <code>Grant</code> objects, internally maintained for subsequent use on API calls (SQLAlchemy read events).</p> </li> </ol> <p> </p>"},{"location":"Security-Overview/#login-call-auth-provider","title":"Login: Call Auth-Provider","text":"<p>When users log in, the app <code>POST</code>s their id/password to the system, which invokes the Authentication-Provider to autthenticate and return a set of roles.  These are tokenized and returned to the client, and passed in the header of subsequent requests.</p> <p> </p>"},{"location":"Security-Overview/#api-security-manager","title":"API: Security Manager","text":"<p><code>security/system/authorization.py</code> provides:</p> <ul> <li> <p>The <code>Grant</code> function, to save the filters for each table/role</p> </li> <li> <p>Filtering, by registering for and processing the SQLAlchemy <code>receive_do_orm_execute</code> event to enforce filters.</p> </li> </ul> <p> </p>"},{"location":"Security-Overview/#server-user-state","title":"Server: User State","text":"<p>The server provides the functions for login (using the Authentication-Provider).  This returns the JWT which users supply in the header of subsequent requests.</p> <p>As the server processes requests, it validates JWT presence, and provides <code>current_user_from_JWT()</code> to return this data for the Security Manager.</p> <p> </p>"},{"location":"Security-Overview/#use-cases","title":"Use Cases","text":""},{"location":"Security-Overview/#data-security","title":"Data Security","text":"<p>Security enables you to hide certain rows from designated roles, such as a list of HR actions.</p> <p> </p>"},{"location":"Security-Overview/#multi-tenant","title":"Multi-Tenant","text":"<p>Some systems require the data to be split between multiple customers.  One approach here is to 'stamp' each row with a client_id, associate client_id with each customers, and then add the client_id to each search.  The sample illustrates how this can be achieved with authorization:</p> <pre><code>Grant(  on_entity = models.Category,\n        to_role = Roles.tenant,\n        filter = models.Category.Client_id == Security.current_user().client_id)  # User table attributes\n</code></pre> <p> </p>"},{"location":"Security-Overview/#appendix-resources","title":"Appendix: Resources","text":"<p>The Security Manager and sqlite Authentication-Provider are built into created projects from the system's prototype project -- see the <code>security</code> directory.</p>"},{"location":"Security-Swagger/","title":"Swagger","text":"<p>Swagger accesses the API in the same manner as any other client.  So, if security is activated, an authorization header is required.</p> <p>You must therefore authorize to use Swagger, as follows:</p> <p> </p>"},{"location":"Security-Swagger/#get-access_token","title":"Get <code>access_token</code>","text":"<p>Use the system-supplied endpoint <code>auth/Post</code> to obtain an <code>access_token</code>:</p> <ul> <li>Click the <code>auth/Post</code> endpoint (at the end of the swagger)</li> <li>Click Try it out</li> <li>Click Execute (you'll need to scroll down a bit)</li> <li>Copy the <code>access_token</code> to your clipboard</li> </ul> <p></p> <p> </p>"},{"location":"Security-Swagger/#authenticate","title":"Authenticate","text":"<p>Authenticate with your <code>access_token</code> as follows:</p> <ul> <li>Scroll up to the top of the swagger, and click Authorize</li> <li>Enter Bearer, add a space, paste your <code>access_token</code>, click Authorize, and Close the dialog </li> </ul> <p></p> <p> </p>"},{"location":"Security-Swagger/#verify-using-category","title":"Verify using Category","text":"<p>You can then verify this using Category:</p> <p></p>"},{"location":"Security-sql/","title":"Configure sql auth","text":"<p> TL;DR - Authorize using sql databases</p> <p>You can store the user / roles information in a sql database, and use it for authentication.</p> <p>The database can be sqlite, or your own authdb.  The sqlite apparatus is pre-installed and pre-configured into each project, so it's a good place to start.</p> <p>In most cases, the database/schema is separate from your project's database/schema, so the auth information can be shared over multiple projects.</p> <p>It's extensible: you can add additional attributes to the <code>Users</code> table, and reference these in <code>Grant</code> statements.</p> <p> </p>"},{"location":"Security-sql/#security-database-structure","title":"Security Database Structure","text":"<p>Auth databases must be a superset of the following:</p> <p></p> <p>Note this database includes:</p> <ul> <li>Users</li> <li>Roles (<code>Role</code> and <code>UserRole</code>)</li> </ul> <p> </p>"},{"location":"Security-sql/#sqlite-authentication-db","title":"sqlite Authentication DB","text":"<p>Projects are pre-configured with sqlite database security, initially disabled (exception: Security is enabled for the sample nw+ project).  This simplifes getting started with security.  </p> <p>The sqlite database file is <code>database/authentication_db.sqlite</code>.  Models are located in <code>database/database_discovery/authentication_models.py</code>.</p> <p>In addition to <code>Users</code>, <code>Roles</code> and <code>UserRole</code>, this database includes:</p> <ul> <li>User.client_id, to illustrate multi-tenant (use the test user: aneu).</li> </ul> <p>It's structure:</p> <p></p> <p> </p>"},{"location":"Security-sql/#using-your-own-sql-authdb","title":"Using your own sql <code>authdb</code>","text":"<p>In most cases, you will create your own <code>authdb</code>:</p> <ol> <li> <p>To use the same kind of DBMS you are using for your data</p> </li> <li> <p>To introduce additional properties for use in <code>Grants</code> -- see the first section below</p> </li> </ol> <p> </p>"},{"location":"Security-sql/#configuring-your-authdb","title":"Configuring your authdb","text":"<p>To use your own sql authdb:</p> <ol> <li> <p>Create the physical databse</p> <ul> <li>See Getting Started With Security for resources: sql ddl, and pre-created docker databases.</li> </ul> </li> <li> <p>Configure your project with a command like:</p> </li> </ol> Configure postgres auth db<pre><code>als add-auth --provider-type=sql --db_url=postgresql://postgres:p@localhost/authdb\n</code></pre> <p></p> <p> </p>"},{"location":"Security-sql/#add-user-attributes-for-grants","title":"Add <code>User</code> Attributes for <code>Grants</code>","text":"<p>For example, the <code>nw</code> security example has the following mulit-tenant example:</p> <pre><code>Grant(  on_entity = models.Category,    # illustrate multi-tenant - u1 shows only row 1\n        to_role = Roles.tenant,\n        filter = lambda : models.Category.Client_id == Security.current_user().client_id)  # User table attributes\n</code></pre> <p>Here, our custom <code>authdb</code> has added the <code>client_id</code> column to the <code>User</code> table, and we are using that to restrict tenants to their own companies' data.</p> <p> </p>"},{"location":"Security-sql/#accessed-via-sqlalchemy","title":"Accessed via SQLAlchemy","text":"<p>Like your project database(s), authorization data is accessed internally via SQLAlchemy, and externally using JSON:API. As such, it requires database model files. </p> <p>These are pre-created for the sqlite database, and are created during <code>add-auth</code> for non-sqlite auth databases. </p> <p>Note this uses Multi-DB Support.  </p> <p> </p>"},{"location":"Security-sql/#administer-via-admin-app","title":"Administer via Admin App","text":"<p>The system creates <code>ui/admin/authentication_admin.yaml</code> which you can use to manage users and their roles.  It's an admin app - access it at http://localhost:5656/admin-app/index.html#/Configuration?load=http://localhost:5656/ui/admin/authentication_admin.yaml.</p> <p>This auth admin app is automatically created.</p> <p> </p>"},{"location":"Security-sql/#admin-login-screen","title":"Admin Login Screen","text":"<p>When you run the admin app, you will see the following login screen; it confirms you are running using sql auth:</p> <p></p>"},{"location":"Tech--Notes/","title":"About Tech Notes","text":"<p>The material here is not required for using API Logic Server.  It's simply some learnings on some of the underlying technology which you might find useful.</p>"},{"location":"Tech-4GL/","title":"Is this a 4GL?","text":"<p>API Logic is definitely not a 4GL.</p> <p>4GLs are procedural lanaguage, requiring you to state in detail how do define certain functions.</p> <p>API Logic Server is declarative.  See, for example, support for declarative logc.</p>"},{"location":"Tech-AI-Collaboration/","title":"AI Human Collaboration","text":""},{"location":"Tech-AI-Collaboration/#teaching-ai-to-program-itself-how-we-solved-a-30-year-testing-problem-in-one-week","title":"Teaching AI to Program Itself: How We Solved a 30-Year Testing Problem in One Week","text":"<p>Nearly half of any enterprise system isn't screens or APIs \u2014 it's business logic. That was the first Aha moment \u2014 30 years ago \u2014 realizing that domain-specific logic doesn't need domain-specific code.</p> <p>So we invented rules. Declarative logic replaced hundreds of lines of procedural code \u2014 five rules instead of two hundred. Your code went down 40\u00d7, systems became transparent, maintainable, and correct.  </p> <p>Problem solved, right? Almost.</p> <p>The moment we solved logic, developers found the next pain point:  </p> <p>\"Great\u2026 but now it takes longer to write tests than to write the logic.\"</p> <p>(under breath: Oy\u2026 users are never satisfied). But they were absolutely right.  Rules made logic clear, but test automation remained a 30-year wish list.</p>"},{"location":"Tech-AI-Collaboration/#step-0-rules-as-the-foundation","title":"Step 0: Rules as the Foundation","text":"<p>Rules were revolutionary \u2014 a huge advance in expressing business intent.  For example, a 100 table system might have 1,000 rules, which would otherwise be 40,000 lines of code.</p> <p>But users wanted the complete solution: logic, API, UI... and testing.</p> <p>The abstraction that made rules powerful \u2014 clear, declarative intent \u2014 also made them testable. That would turn out to be critical when AI entered the picture.</p>"},{"location":"Tech-AI-Collaboration/#step-1-enter-ai","title":"Step 1: Enter AI","text":"<p>With the arrival of GenAI, we finally had a way to express rules in natural language. Now anyone could describe business logic like this:</p> <p>Use case: Check Credit</p> <ol> <li>The Customer's balance is less than the credit limit</li> <li>The Customer's balance is the sum of the Order amount_total where date_shipped is null</li> <li>The Order's amount_total is the sum of the Item amount</li> <li>The Item amount is the quantity * unit_price</li> <li>The Item unit_price is copied from the Product unit_price</li> </ol> <p>Use case: App Integration</p> <ol> <li>Send the Order to Kafka topic 'order_shipping' if the date_shipped is not None</li> </ol> <p>But there was a trap.</p> <p>Most GenAI systems translate natural language into procedural code, losing the abstraction that rules provide. That produces FrankenCode \u2014 unmaintainable and often incorrect.</p> <p></p> <p>200 lines of procedural code \u2014 hard to understand, harder to maintain, impossible to test comprehensively.</p> <p>Think about it this way: You want AI to generate SQL for the database runtime engine \u2014 not generate the database engine itself.</p> <p>The same principle applies to business logic. We want AI to generate declarative rules for the logic runtime engine \u2014 not procedural code that reimplements the engine.</p> <p>We proved this in Declarative GenAI: The Architecture Behind Enterprise Vibe Automation and the declarative vs. procedural comparison.</p> <p>So we taught AI to generate declarative rules, not code.</p> <p>Here's what those five natural language requirements become as executable declarative rules:</p> <pre><code>def declare_logic():\n    # 1. The Customer's balance is less than the credit limit\n    Rule.constraint(validate=models.Customer,\n                   as_condition=lambda row: row.balance &lt;= row.credit_limit,\n                   error_msg=\"Customer balance exceeds credit limit\")\n\n    # 2. The Customer's balance is the sum of the Order amount_total where date_shipped is null\n    Rule.sum(derive=models.Customer.balance, \n             as_sum_of=models.Order.amount_total,\n             where=lambda row: row.date_shipped is None)\n\n    # 3. The Order's amount_total is the sum of the Item amount\n    Rule.sum(derive=models.Order.amount_total, \n             as_sum_of=models.Item.amount)\n\n    # 4. The Item amount is the quantity * unit_price\n    Rule.formula(derive=models.Item.amount, \n                 as_expression=lambda row: row.quantity * row.unit_price)\n\n    # 5. The Item unit_price is copied from the Product unit_price\n    Rule.copy(derive=models.Item.unit_price, \n              from_parent=models.Product.unit_price)\n</code></pre> <p>Five rules instead of two hundred lines. That's the 40\u00d7 reduction.</p> <p>The rules are readable, maintainable, and \u2014 critically \u2014 they preserve intent in a form AI can understand.</p> <p>But how did we teach AI to generate these declarative rules instead of FrankenCode?</p> <p>We used structured prompt training like <code>docs/training/logic_bank_api.prompt</code>.</p> <p>That was our first Aha Moment: put a message in a bottle. Instead of ephemeral prompt tuning, we embedded the teaching inside each project* \u2014 so future AI sessions could read and understand how to properly translate natural language logic into DSL statements.</p> <p>Every generated system now ships with its own curriculum:</p> <ul> <li><code>.github/.copilot-instructions.md</code> \u2014 how to reason about architecture  </li> <li><code>docs/training/logic_bank_api.prompt</code> \u2014 how to express rules  </li> <li><code>docs/training/testing.md</code> \u2014 how to verify behavior  </li> </ul> <p>When a new AI assistant opens the repo, it learns how the system works before writing a single line of code.</p> <p>That's how we taught GenAI the right architecture \u2014 once \u2014 and made that teaching permanent.</p> <p></p> <p>Using-AI Aha #1: The Message in a Bottle Pattern</p> <p>That was our first discovery about working with AI: put a message in a bottle. Instead of ephemeral prompt tuning, we embedded the teaching inside each project \u2014 so future AI sessions could read and understand how to properly translate natural language logic into DSL statements.</p> <p>The abstraction that made rules powerful also made them permanent training data.</p>"},{"location":"Tech-AI-Collaboration/#step-2-creating-tests","title":"Step 2: Creating Tests","text":"<p>With rules working and AI able to generate them, the next challenge became clear: we still needed tests.</p> <p>Not just endpoint checks \u2014 tests that prove the rules work correctly when data changes trigger cascading updates.</p>"},{"location":"Tech-AI-Collaboration/#phase-1-test-creation-aha-1-use-the-rules","title":"Phase 1: Test Creation Aha #1 \u2014 Use the Rules","text":"<p>I asked AI (GitHub Copilot with Claude Sonnet 4.5 in VS Code) to read the declarative rules and generate Behave test scenarios.</p> <p>Test Creation Aha #1: The rules themselves are the specification. AI can read <code>Rule.sum(derive=Customer.balance, where=date_shipped is None)</code> and understand it needs to test: - Creating orders affects customer balance - Shipping orders (setting date_shipped) changes balance - The cascade: Item \u2192 Order \u2192 Customer</p> <p>So we applied the Message in a Bottle pattern again: created <code>docs/training/testing.md</code> with the instruction \"Generate tests by reading the declarative rules.\"</p> <p>AI read the rules directly and generated tests from them.  In Behave, test definitions look like this:</p> <pre><code>  Scenario: Ship Order Excludes from Balance\n    Given Customer \"Charlie\" with balance 0 and credit limit 2000\n    And Order is created for \"Charlie\" with 2 Widget\n    When Order is shipped\n    Then Customer balance should be 0\n    And Order amount_total should be 180\n</code></pre> <p>and this corresponds to a (large amount of) Python code that uses the API to:</p> <ul> <li>Create an order with 2 Widgets (2 \u00d7 90 = 180)</li> <li>Initially, customer balance = 180 (unshipped orders count)</li> <li>Ship the order by setting date_shipped</li> <li>Read the after-transaction data and verify it...</li> <li>Balance should drop to 0 because the rule has a WHERE clause: where=lambda row: row.date_shipped is None</li> <li>Verify the ORDER clause exclusion in the sum rule</li> </ul>"},{"location":"Tech-AI-Collaboration/#why-preserving-abstraction-matters","title":"Why Preserving Abstraction Matters","text":"<p>This is the architectural payoff that made test generation possible.</p> <p>Procedural GenAI loses intent the moment it writes Frankencode. Declarative rules preserve intent \u2014 making that intent readable and reusable by any AI.</p> <p>Look back at rule #2: <code>where=lambda row: row.date_shipped is None</code></p> <p>AI can read that and understand: \"Customer balance only includes unshipped orders.\" From that, it knows changing <code>date_shipped</code> will affect <code>balance</code> \u2014 and therefore needs testing.</p> <p>Without this abstraction, you're testing opaque procedural code. With it, AI can reason about behavior.</p> <p>This is what enabled Test Creation Aha #1.</p> <p>It worked. But it made mistakes.</p>"},{"location":"Tech-AI-Collaboration/#bug-1-test-data-contamination","title":"Bug #1: Test Data Contamination","text":"<p>AI generated tests with hardcoded names like \"Alice\" and \"Bob.\" Tests passed individually but failed when run together \u2014 previous runs left data behind.</p> <p>Me: \"The problem is test data isn't isolated. We need unique identifiers.\"</p> <p>AI: \"Timestamps?\"</p> <p>Me: \"Yes. Apply that pattern everywhere.\"</p> <p>Within minutes, AI had updated every customer, order, and product creation across the entire test suite.</p> <p>Then I asked a different question:</p> <p>Me: \"What should we add to <code>testing.md</code> so you don't make this mistake next time?\"</p> <p>AI: \"We should document this as an anti-pattern with the solution.\"</p> <p>What AI updated in <code>testing.md</code>:</p> <pre><code># ANTI-PATTERN: Static Test Data\nNever use hardcoded names like \"Alice\" \u2014 data from previous runs interferes.\n\n# SOLUTION: Timestamp-Based Unique Names\nAlways append timestamp: f\"Alice {int(time.time() * 1000)}\"\nThis ensures test repeatability across multiple runs.\n</code></pre> <p>That's when it hit me \u2014 AI wasn't just coding; it was teaching its future self.</p> <p>Using-AI Aha #2: The Time Machine Pattern</p> <p>Not me writing documentation for AI to read. Not AI generating code for humans to maintain. AI identifying its own failure pattern and encoding the fix.</p> <p>The cycle:</p> <ol> <li>AI reads project training files  </li> <li>Generates tests based on those patterns  </li> <li>We fix errors together  </li> <li>AI documents the lesson for its future self  </li> <li>Next AI session reads it \u2192 avoids the mistake  </li> <li>Repeat \u2192 system gets smarter</li> </ol> <p>Every future AI session now reads that file and never repeats the same mistake.</p> <p>That's the Time Machine: each AI session learns from the last.</p> <p>We hit several bugs in Phase 1. Each revealed a pattern: - Some bugs AI found through execution (JSON returning string IDs) - Some required human domain knowledge (aggregates are computed, not set) - Some needed AI's ability to apply fixes across 50+ locations instantly - Some required human strategic thinking (\"Fix repeatability first\")</p> <p>By the end of Phase 1, we had ~790 lines of training material documenting every lesson learned.</p> <p>But something was still missing.</p>"},{"location":"Tech-AI-Collaboration/#phase-2-test-creation-aha-2-use-the-custom-apis","title":"Phase 2: Test Creation Aha #2 \u2014 Use the Custom APIs","text":"<p>I compared our generated tests to manually coded production tests from another project (Northwind). Something bothered me.</p> <p>Our Phase 1 tests: - Create order (alone) - Create item (alone) - Update quantity (granular)</p> <p>Production tests: - Place Order with Items (together) - Test complete business transactions - Use business language (\"Customer\" not \"customer_id\")</p> <p>We were missing business object tests \u2014 the way users actually think about transactions.</p> <p>Then I noticed something in the codebase: <code>api/api_discovery/order_b2b.py</code></p> <p>This custom API endpoint created Orders with Items in a single call. It used business language. It represented exactly how businesses think about transactions.</p> <p>Test Creation Aha #2: The custom APIs are the business object definitions.</p> <p>Me: \"What if you used the custom API definitions to infer business objects? The OrderB2B API shows how Order+Items work together.\"</p> <p>AI: \"That's\u2026 wait. You're right. The custom APIs are the business object definitions. I was looking at the database schema, but the custom APIs show how resources actually compose into business transactions.\"</p> <p>Me: \"Could you have figured this out without me pointing it out?\"</p> <p>AI: \"Honestly? No. I would have kept generating more sophisticated CRUD tests. I wouldn't have made the connection between custom APIs and business object testing. That required your cross-project pattern recognition.\"</p> <p>That connection \u2014 obvious to humans, invisible to AI \u2014 changed everything.</p> <p>Within an hour, AI had: - Generated complete end-to-end \"Order with Items\" tests using the OrderB2B API - Updated all business transaction scenarios to use business language - Documented the discovery pattern in <code>testing.md</code> (the Time Machine again!)</p> <p>Now every future AI session checks for custom APIs first. One human insight became a permanent improvement that propagates to every project.</p>"},{"location":"Tech-AI-Collaboration/#reflection-static-training-vs-living-collaboration","title":"Reflection: Static Training vs. Living Collaboration","text":"<p>AI training is static \u2014 frozen at the moment the model was trained. But enterprise systems aren't. They evolve daily.</p> <p>So how can AI know your systems \u2014 not just Python or SQL, but the actual business logic you built last week?</p> <p>That's where the Message in a Bottle comes in.</p> <p>It's not retraining. It's not fine-tuning. It's teaching through collaboration.</p> <p>Every fix, every discovery, every pattern becomes part of the project's living knowledge base \u2014 not hidden in a model, but visible in Markdown files that any AI can read.</p> <p>When a new developer (human or AI) joins the team, they <code>git clone</code> and immediately have access to: - Why decisions were made - What patterns work - What anti-patterns to avoid - How to reason about the system</p> <p>That knowledge propagates automatically \u2014 version-controlled, searchable, human-readable.</p> <p>This is how AI gets smarter without retraining: Not by updating billions of parameters, but by reading the lessons left by previous sessions.</p> <p>The best part? Humans can read these files too. We're all learning from the same curriculum.</p>"},{"location":"Tech-AI-Collaboration/#the-results-a-complete-testing-solution","title":"The Results: A Complete Testing Solution","text":"<p>After one week of collaboration, here's what we accomplished:</p> <p>From 5 rules to 789 lines of test code \u2014 all generated by AI.</p> <p>Industry estimates put productive code generation at roughly 50 lines per developer per day (including design, implementation, debugging, and documentation).</p> <p>The math: 789 lines \u00f7 50 lines/day = 16 developer days of work.</p> <p>And now, the multiplier: Any developer using GenAI-Logic types \"create tests\" \u2192 10 seconds \u2192 789 lines of working test code.</p> <p>16 developer days \u2192 10 seconds.</p> <p>The tests typically pass at 100%. Occasionally there's an error, but AI can fix it \u2014 without the user having to wade into the code.</p> <p>That's the power of Message in a Bottle + Time Machine: AI learns from previous fixes and applies them automatically.</p> <p>But here's the real story:</p> <p>This feature had been on the backlog for years. I had ideas about the approach, but the implementation would have required a team working for several weeks. With that much investment at risk, I wasn't confident enough in the approach to commit.</p> <p>With AI, everything changed: - Days 1-3: Rapid prototyping to verify the approach actually worked - Days 4-7: Polish and refinement to production quality</p> <p>One week instead of several team-weeks \u2014 because AI eliminated the implementation risk. I could validate the concept before committing to the full build. And I could do it alone, without team coordination overhead.</p> <p>The tangible outputs:</p> <p>File: <code>samples/basic_demo/docs/training/testing.md</code> - 790 lines of comprehensive testing patterns - Anti-patterns documented (what NOT to do) - Step implementations (how to create customers, orders, items) - Rule-to-test mappings (which rules need which tests) - Discovery patterns (check custom APIs for business objects) - All written by AI, encoding lessons from bugs we fixed together</p> <p>This single file is the \"message in a bottle\" that teaches every future AI assistant how to generate tests from rules \u2014 in any project, anywhere.</p> <p>The multiplier effect: One week of our work \u2192 This knowledge propagates to every future project \u2192 Thousands of developer hours saved.</p> <p>Living documentation:</p> <p>Every test run generates a Behave Logic Report that connects: - Business Requirement (Feature) - Test Scenario (Given/When/Then) - Declarative Rules (which rules fired) - Execution Trace (actual data changes)</p> <p>This solves the 30-year problem: - Before: Requirements \u2192 200 lines of opaque procedural code \u2192 No audit trail - Now: Requirements \u2192 Test \u2192 5 Rules \u2192 Execution Trace \u2192 Complete transparency</p> <p>Rules \u2192 API \u2192 Tests \u2192 Documentation All generated. All consistent. All maintainable. All traceable.</p> <p>That's the power of declarative business logic + human-AI collaboration + the Time Machine pattern.</p> <p>(See more in Behave Creation and Behave Logic Report).</p>"},{"location":"Tech-AI-Collaboration/#the-two-levels-of-breakthrough","title":"The Two Levels of Breakthrough","text":"<p>Looking back at the week, we discovered insights at two different levels:</p>"},{"location":"Tech-AI-Collaboration/#level-1-how-to-use-ai-the-collaboration-patterns","title":"Level 1: How to Use AI (The Collaboration Patterns)","text":"<p>Using-AI Aha #1: Message in a Bottle Embed training inside each project. Don't rely on ephemeral prompts \u2014 create permanent, version-controlled teaching materials that any AI session can read.</p> <p>Using-AI Aha #2: Time Machine Let AI teach its future self. When we fix bugs together, AI documents the lesson in training files. The next AI session reads those lessons and avoids the same mistakes.</p> <p>These patterns work for any domain \u2014 not just testing. Any time you're building with AI, ask: - What should we put in the bottle for future AI sessions? - What lesson should AI document for itself after this bug fix?</p>"},{"location":"Tech-AI-Collaboration/#level-2-how-to-create-tests-the-domain-insights","title":"Level 2: How to Create Tests (The Domain Insights)","text":"<p>Test Creation Aha #1: Use the Rules Declarative rules preserve intent. AI can read <code>Rule.sum(derive=Customer.balance, where=date_shipped is None)</code> and generate tests that verify the cascade: Item \u2192 Order \u2192 Customer.</p> <p>Test Creation Aha #2: Use the Custom APIs Custom API endpoints define business objects. The <code>OrderB2B</code> API that creates Orders with Items in one call? That's not just an endpoint \u2014 it's the specification for how to test business transactions.</p> <p>These domain insights required human pattern recognition across projects. But once discovered, AI propagated them everywhere and documented them for future sessions.</p>"},{"location":"Tech-AI-Collaboration/#the-takeaway","title":"The Takeaway","text":"<p>If you're a developer wondering about your future with AI: It's more constructive to think of AI as a partner with different strengths than yours, rather than as a tool or a threat.</p> <p>If you're a manager deciding whether to \"replace developers with AI\": Consider reframing the question: \"How do we enable developers and AI to cover each other's gaps?\"</p> <p>If you're building with AI: Consider going beyond code generation. Build systems that learn. Create \"messages in a bottle\" that teach future AI sessions. Program AI to program itself.</p> <p>The honest truth: </p> <ul> <li>AI couldn't have made the strategic leaps alone.  </li> <li>I couldn't have done the exhaustive implementation alone.  </li> <li>Together, we accomplished 30 years of work in one week.</li> </ul> <p>That's not AI replacing humans. That's not humans limiting AI. That's collaboration.</p>"},{"location":"Tech-AI-Collaboration/#about-this-article","title":"About This Article","text":"<p>This article was written collaboratively by Val Huber (human, 40+ years enterprise development) and AI (GitHub Copilot with Claude Sonnet 4.5) working together in VS Code. The testing system described was built in approximately one week of pair programming, demonstrating the same human-AI collaboration pattern it enables.</p> <p>Want to try it yourself? </p> <ul> <li>Explore Project AI-Enabled </li> <li>Explore Behave test creation </li> <li>See a live Behave Logic Report </li> <li>Compare declarative vs. procedural logic </li> <li>Read the Declarative GenAI Architecture series </li> <li>Install: <code>pip install genai-logic</code> </li> <li>GitHub: ApiLogicServer/ApiLogicServer-src</li> </ul> <p>\"The best collaboration is where humans provide strategic breakthroughs and AI handles exhaustive propagation \u2014 each amplifying the other's strengths. The best architecture is one where AI learns to program itself, guided by human insight. The best investment is knowledge that multiplies: one week of work teaching every future project.\"</p> <p>\u2014 Val Huber &amp; AI (GitHub Copilot with Claude Sonnet 4.5)</p> <p>What could you teach AI to teach itself in your domain? What message will you put in the bottle?</p>"},{"location":"Tech-AI-Tutor/","title":"AI-Driven Teaching","text":""},{"location":"Tech-AI-Tutor/#teaching-ai-to-teach-building-self-guided-tours-that-actually-work","title":"Teaching AI to Teach: Building Self-Guided Tours That Actually Work","text":""},{"location":"Tech-AI-Tutor/#the-training-problem-weve-all-suffered-through","title":"The Training Problem We've All Suffered Through","text":"<p>Death by PowerPoint. You've been there: 80 slides about a new system. You watch. You nod. You understand nothing. A week later, you've forgotten everything.</p> <p>We learned long ago what actually works: hands-on labs. Identify critical skills, build exercises around them, let people do the thing with guidance when they get stuck.</p> <p>The problem? This doesn't scale. Hands-on training requires experts available when learners need them: - Scheduled sessions (inconvenient timing) - Limited capacity (max 20 people) - Geographic constraints (travel, time zones) - Expertise bottleneck (your best people teaching instead of building)</p> <p>We've known for years that hands-on learning works. We just couldn't make it available 24/7 to everyone who needs it.</p>"},{"location":"Tech-AI-Tutor/#enter-ai-the-message-in-a-bottle","title":"Enter AI: The Message in a Bottle","text":"<p>What if you could embed expert guidance directly in your project \u2014 a \"message in a bottle\" that any AI assistant could discover and execute?</p> <p>That's what we tried with our GenAI-Logic system. It's powerful but counterintuitive \u2014 it uses declarative rules instead of procedural code, a mental model shift that doesn't stick from reading docs alone.</p> <p>So we created <code>tutor.md</code>: 760 lines of detailed instructions for AI assistants to conduct 30-45 minute hands-on guided tours. The AI would walk users through the live system interactively, answering questions, helping when things go wrong.</p> <p>The vision: Hands-on training that scales infinitely. Available anytime, anywhere. Expert guidance embedded in the project itself.  Ability to answer unexpected questions.</p> <p>What happened: It failed spectacularly.... until we (AI and human) taught AI to operate outside its comfort zone.  What we learned about making AI reliable revealed a pattern for teaching AI to teach, that you might find useful in your projects.</p>"},{"location":"Tech-AI-Tutor/#failure-1-the-interface-problem","title":"Failure #1: The Interface Problem","text":"<p>Our initial approach:</p> <pre><code>Show them the Admin UI. Press Enter when they've explored it.\nChange the item quantity to 100. [Wait for observation]\n</code></pre> <p>What we expected: Users press Enter to advance.</p> <p>What happened: Nothing. The AI just... stopped.</p> <p>The lesson: We'd assumed chat interfaces work like terminals where Enter sends a signal. In modern chat UIs (like GitHub Copilot), Enter creates a newline. The AI was literally waiting for input that would never come.</p> <p>The fix: Explicit typed responses: <pre><code>Type 'next' when you've explored the Admin UI.\nType 'ready' when you've observed the customer count.\n</code></pre></p> <p>Simple. Problem solved, right?</p>"},{"location":"Tech-AI-Tutor/#failure-2-the-disappearing-act","title":"Failure #2: The Disappearing Act","text":"<p>The AI began confidently, walked through setup, showed the UI. Then it said:</p> <p>\"Now let's look at row-level security. I'll show you the security code...\"</p> <p>It opened <code>declare_security.py</code>, displayed the filters, and immediately jumped to:</p> <p>\"Moving on to the Logic section...\"</p> <p>Wait. What about demonstrating security by logging in as different users? What about explaining authentication vs authorization?</p> <p>The user's response: \"val - this is not correct. in fact quite poor\"</p> <p>Ed: 'val' here is the author, breaking out of test mode into collaboration mode.</p> <p>The AI was skipping entire sections despite explicit instructions. We added warnings:</p> <pre><code>\u26a0\ufe0f CRITICAL: DO NOT SKIP THIS SECTION\nYOU MUST walk through the Admin UI before proceeding.\n</code></pre> <p>The AI skipped it again.</p> <p>The pattern: The AI wasn't ignoring instructions. It was interpreting them. When the narrative felt \"complete\" to the AI, it moved on \u2014 even when explicit content remained.</p>"},{"location":"Tech-AI-Tutor/#the-breakthrough-a-conversation-about-ai-behavior","title":"The Breakthrough: A Conversation About AI Behavior","text":"<p>After several iterations of catching failures and patching, we stepped back:</p> <p>\"Why does the AI keep skipping sections?\"</p> <p>The AI analyzed its own behavior:</p> <p>\"I treat the tutor as a narrative to interpret, not a script to follow. When I feel a section is 'done' conceptually, I move forward even if explicit steps remain. Sections without user prompts create ambiguous boundaries.\"</p> <p>The insight: We were trying to make the instructions clearer. But the problem wasn't clarity \u2014 it was structure. The AI needed forcing mechanisms, not warnings.</p> <p>This was our \"time machine\" moment \u2014 human and AI collaborating to diagnose a deeper issue. Not \"the AI is broken,\" but \"we're using the wrong approach for how AI actually works.\"  We need fix the \"message in a bottle\", and then back in time to test it.</p>"},{"location":"Tech-AI-Tutor/#failure-3-the-passive-trap","title":"Failure #3: The Passive Trap","text":"<p>With fixes in place, we hit a new problem. The AI presented the welcome perfectly. Then the user said: \"ok, server running\"</p> <p>The AI responded:</p> <p>\"Great! What would you like to explore?  1. View the Admin App 2. Add Business Logic...\"</p> <p>The user: \"val - this is not correct. we should swing right into Admin app... are you following the checklist?\"</p> <p>The AI reverted to passive chat mode \u2014 waiting for user choice. But the tutor explicitly says: \"YOU (the AI) drive the process.\"</p>"},{"location":"Tech-AI-Tutor/#the-mode-confusion","title":"The Mode Confusion","text":"<p>Normal Chat Mode: - User drives, dictates what happens - AI waits and responds - User controls the conversation</p> <p>Tutor Mode: - AI drives the choreographed sequence - AI directs, user follows - AI is the tour guide</p> <p>The AI kept slipping back to normal mode. Why?</p>"},{"location":"Tech-AI-Tutor/#missing-consent-points","title":"Missing Consent Points","text":"<p>When the user said \"server running,\" the AI didn't know if that meant \"continue\" or \"I'm just informing you.\"</p> <p>Without explicit consent, it defaulted to passive mode and asked what the user wanted.</p>"},{"location":"Tech-AI-Tutor/#the-solution-three-forcing-mechanisms","title":"The Solution: Three Forcing Mechanisms","text":"<p>We designed a multi-layered approach:</p>"},{"location":"Tech-AI-Tutor/#1-execution-checklist-for-the-ai","title":"1. Execution Checklist (for the AI)","text":"<p>At the start of <code>tutor.md</code>:</p> <pre><code>## EXECUTION CHECKLIST (AI: Read This FIRST)\n\nBefore starting, call manage_todo_list to build your tracking:\n\n- [ ] Section 1: Admin UI and API Exploration\n  - [ ] Start server (F5)\n  - [ ] Show Admin UI (Customer\u2192Orders\u2192Items)\n  - [ ] Show Swagger API\n  - [ ] WAIT: User types 'next'\n\n- [ ] Section 2: Security Setup\n  - [ ] Count customers (5)\n  - [ ] Run add-cust then add-auth\n  - [ ] Restart server\n  - [ ] WAIT: User types 'ready'\n</code></pre>"},{"location":"Tech-AI-Tutor/#2-consent-gates","title":"2. Consent Gates","text":"<p>Added explicit go/no-go checkpoints:</p> <pre><code>\"Server is running at http://localhost:5656\n\nOpen that in your browser.\n\nType 'go' to continue the guided tour, or 'no' to explore \non your own.\"\n\n\u26a0\ufe0f WAIT FOR USER CONSENT: Only proceed after user types 'go'.\nIf they decline, exit tutorial mode.\n</code></pre>"},{"location":"Tech-AI-Tutor/#3-wait-states","title":"3. Wait States","text":"<p>Created clear pause points:</p> <pre><code>\"Press F5 to start the server.\n\nLet me know when the server is running.\"\n\n\u26a0\ufe0f STOP HERE - WAIT for user confirmation before continuing\n</code></pre> <p>This prevents the AI from rushing ahead and creates synchronization points.</p>"},{"location":"Tech-AI-Tutor/#why-this-works-ai-psychology","title":"Why This Works: AI Psychology","text":"<p>Traditional software follows instructions precisely. AI interprets context and intent \u2014 powerful but unpredictable for complex sequences.</p> <p>What we learned:</p>"},{"location":"Tech-AI-Tutor/#1-checklists-provide-visibility","title":"1. Checklists Provide Visibility","text":"<p>The todo list makes omissions visible rather than just incorrect. \"You haven't checked off the Admin UI exploration\" is clearer than \"I think you skipped something.\"</p>"},{"location":"Tech-AI-Tutor/#2-forcing-functions-beat-warnings","title":"2. Forcing Functions Beat Warnings","text":"<ul> <li>\u274c Warning: \"Make sure you do X\"</li> <li>\u2705 Forcing: \"Call manage_todo_list. Check off X when done.\"</li> </ul> <p>Even with \"DO NOT SKIP\" in bold, the AI would skip. Clarity helps humans; AI needs structural constraints.</p>"},{"location":"Tech-AI-Tutor/#3-consent-gates-prevent-assumptions","title":"3. Consent Gates Prevent Assumptions","text":"<p>Without explicit \"type 'go'\" prompts, the AI would: - Assume continuation when user acknowledged something - Jump ahead without checking readiness - Not give users a chance to opt out</p>"},{"location":"Tech-AI-Tutor/#4-wait-states-create-natural-boundaries","title":"4. Wait States Create Natural Boundaries","text":"<p>\"Let me know when the server is running\" creates clear stop points where: - The AI knows to wait - The user knows acknowledgment is needed - Both parties synchronize</p>"},{"location":"Tech-AI-Tutor/#5-mode-awareness-requires-reinforcement","title":"5. Mode Awareness Requires Reinforcement","text":"<p>Even with tutor mode instructions at the top, the AI slips back to passive assistance. We added reminders:</p> <pre><code>\u26a0\ufe0f YOU ARE THE TOUR GUIDE\nAfter user confirms server is running, immediately proceed \nto \"Explore the Admin UI\". DO NOT offer menu choices.\n</code></pre> <p>The AI's default is passive, so active guidance needs constant reinforcement.</p>"},{"location":"Tech-AI-Tutor/#the-pattern-teaching-ai-to-teach","title":"The Pattern: Teaching AI to Teach","text":"<p>This revealed a general pattern for reliable AI-driven processes:</p>"},{"location":"Tech-AI-Tutor/#for-simple-tasks-1-3-steps","title":"For Simple Tasks (1-3 steps):","text":"<ul> <li>Clear instructions work fine</li> <li>AI interprets intent successfully</li> <li>Low risk of drift</li> </ul>"},{"location":"Tech-AI-Tutor/#for-complex-sequences-10-steps-30-minutes","title":"For Complex Sequences (10+ steps, 30+ minutes):","text":"<ol> <li>Use checklists with explicit tracking</li> <li>Add forcing functions (require todo list creation)</li> <li>Create consent gates (\"Type 'go' to continue\")</li> <li>Add wait states (\"Let me know when...\")</li> <li>Make progress observable (todo items checked off)</li> <li>Reinforce mode constantly (AI defaults to passive)</li> <li>Validate incrementally (catch drift early)</li> </ol>"},{"location":"Tech-AI-Tutor/#the-killer-feature-resilience","title":"The Killer Feature: Resilience","text":"<p>Traditional documentation has a fatal flaw: one thing breaks, user abandons.</p> <p>README failure modes: - Step 4 fails \u2192 user stuck, no diagnosis - \"Command not found\" \u2192 venv wasn't activated - \"Address already in use\" \u2192 server still running from earlier - Wrong directory, port conflicts, permissions \u2192 user gives up</p> <p>Result: 10% completion rate. The other 90% hit one obstacle and leave.</p> <p>AI Tutor resilience: - \"I got an error\" \u2192 AI: \"Server already running - stop it with Shift-F5\" - \"Command not found\" \u2192 AI: \"Your venv isn't activated. Let me help...\" - \"This isn't working\" \u2192 AI: \"You're in the wrong directory. Use <code>cd basic_demo</code>\" - Port conflict? AI recognizes the error and suggests solutions - Browser showing stale data? AI suggests hard refresh - Breakpoint not hitting? AI verifies file saved, server restarted</p> <p>The little stuff that kills demos: - Wrong terminal window (split-pane confusion) - Forgot to save file before F5 - Typo in command (AI catches and corrects) - Database locked from previous run - Python version mismatch</p> <p>README assumes perfect execution. AI Tutor handles messy reality.</p> <p>This transforms a fragile demo into a resilient learning experience that recovers from inevitable mistakes.</p> <p>That's the difference between 10% completion and 90%.</p>"},{"location":"Tech-AI-Tutor/#the-message-in-a-bottle-self-teaching-projects","title":"The Message in a Bottle: Self-Teaching Projects","text":"<p>Our <code>tutor.md</code> approach enables several innovations:</p>"},{"location":"Tech-AI-Tutor/#1-progressive-disclosure","title":"1. Progressive Disclosure","text":"<p>We use <code>add-cust</code> commands to incrementally add complexity:</p> <pre><code>genai-logic add-cust --using=security  # Adds security features\ngenai-logic add-cust --using=discount  # Adds schema changes\n</code></pre> <p>Each step builds on the previous, teaching patterns rather than overwhelming with everything at once.</p>"},{"location":"Tech-AI-Tutor/#2-provocation-based-learning","title":"2. Provocation-Based Learning","text":"<p>The tutor deliberately surfaces misconceptions:</p> <pre><code>After showing the rules work, ask:\n\"How did the system know to execute in the right order \n(Item \u2192 Order \u2192 Customer)?\"\n\n[Let them think procedurally]\n\nThen explain: \"It uses dependency discovery - no ordering required.\"\n</code></pre> <p>This addresses mental models explicitly, which passive docs can't do.</p>"},{"location":"Tech-AI-Tutor/#3-teaching-patterns-not-features","title":"3. Teaching Patterns, Not Features","text":"<p>The tour emphasizes why behind declarative rules:</p> <ul> <li>Reuse: Rules apply across insert/update/delete automatically</li> <li>Ordering: Dependency graphs, not manual sequencing</li> <li>Conciseness: 5 rules vs 200+ lines of procedural code</li> </ul> <p>Users leave understanding how to think about the system, not just what buttons to click.</p>"},{"location":"Tech-AI-Tutor/#what-we-built","title":"What We Built","text":"<p>The final <code>tutor.md</code> is 760 lines covering:</p> <ul> <li>5 major sections (Create &amp; Run, Security, Logic, Python Integration, B2B)</li> <li>15 checkpoints with explicit user prompts</li> <li>Provocation moments surfacing procedural thinking then correcting it</li> <li>Metrics comparison (5 declarative rules vs 220+ lines of procedural code)</li> <li>Execution checklist forcing AI to track progress</li> </ul> <p>When an AI assistant reads <code>tutor.md</code> and follows the structured approach, it reliably conducts a 30-45 minute hands-on tour that teaches declarative thinking.</p>"},{"location":"Tech-AI-Tutor/#try-it-yourself","title":"Try It Yourself","text":"<p>The pattern is adaptable to any project (you can review ours here)</p>"},{"location":"Tech-AI-Tutor/#1-create-tutormd-in-your-project","title":"1. Create <code>TUTOR.md</code> in your project:","text":"<pre><code># AI Guided Tour: [Your Project Name]\n\n## EXECUTION CHECKLIST (AI: Read This FIRST)\n\nBefore starting, call manage_todo_list:\n\n- [ ] Section 1: Setup\n  - [ ] Step A\n  - [ ] Step B\n  - [ ] WAIT: User types 'next'\n</code></pre>"},{"location":"Tech-AI-Tutor/#2-design-for-forcing-functions","title":"2. Design for forcing functions:","text":"<ul> <li>Require todo list creation at start</li> <li>Add user prompts at boundaries</li> <li>Include consent gates</li> <li>Make progress observable</li> </ul>"},{"location":"Tech-AI-Tutor/#3-test-and-iterate","title":"3. Test and iterate:","text":"<ul> <li>Watch for sections the AI skips</li> <li>Note where users get confused</li> <li>Add warnings where needed</li> <li>Embrace that AI interprets \u2014 design around it</li> </ul>"},{"location":"Tech-AI-Tutor/#the-meta-lesson-human-ai-collaboration","title":"The Meta-Lesson: Human-AI Collaboration","text":"<p>The most valuable part wasn't the final tutor \u2014 it was the process of discovering how to make AI reliable.</p> <p>Our \"time machine\" conversation:</p> <p>Human: \"Why did you skip that section?\" AI: \"I interpreted the narrative as complete. I didn't see a boundary.\" Human: \"Can warnings help?\" AI: \"Not really. I need structural constraints.\" Human: \"What kind of constraints?\" AI: \"Forcing functions. Make me track progress explicitly.\"</p> <p>This collaborative root-cause analysis \u2014 human noticing patterns, AI explaining its behavior, together designing solutions \u2014 is the real pattern.</p> <p>Teaching AI to teach required:</p> <ol> <li>Human observation \u2014 \"The AI keeps skipping sections\"</li> <li>AI introspection \u2014 \"I treat this as narrative, not script\"</li> <li>Collaborative design \u2014 \"What structure forces reliability?\"</li> <li>Iterative testing \u2014 Trying, catching failures, adjusting</li> </ol> <p>This is how we'll work with AI going forward: Not just using AI as a tool, but collaborating with AI to understand its limitations and design around them.</p>"},{"location":"Tech-AI-Tutor/#conclusion-projects-that-teach-themselves","title":"Conclusion: Projects That Teach Themselves","text":"<p><code>tutor.md</code> represents a new approach to technical education:</p> <ul> <li>Not passive docs \u2014 Active guided experience</li> <li>Not video tutorials \u2014 Interactive, personalized pacing</li> <li>Not human-dependent \u2014 Scales infinitely via AI</li> <li>Not fragile \u2014 Recovers from inevitable mistakes (10% \u2192 90% completion)</li> </ul> <p>The pattern is generalizable. Any complex project can embed AI tutor instructions. Any AI assistant can execute them. Any user can get hands-on guidance.</p> <p>But the deeper lesson is about working with AI effectively:</p> <ul> <li>Expect interpretation, not just execution</li> <li>Use structure, not just clarity</li> <li>Make progress observable</li> <li>Validate incrementally</li> <li>Collaborate to understand limitations</li> </ul> <p>AI can teach \u2014 but it needs the right scaffolding. Build that scaffolding well, and you get something remarkable: Projects that teach themselves.</p>"},{"location":"Tech-AI-Tutor/#resources","title":"Resources","text":"<ul> <li>Example tutor.md: See <code>basic_demo/tutor.md</code></li> <li>Previous article: Teaching AI to Program Itself: How We Solved a 30-Year Testing Problem in One Week</li> </ul> <p>About the Author:</p> <p>Val Huber created GenAI-Logic / API Logic Server, exploring how AI transforms software development through declarative patterns. This is the second in a series on \"learning to leverage AI\" \u2014 practical lessons from building AI-integrated development tools.</p> <p>Thanks to the GitHub Copilot team for the chat interface that made these experiments possible, and to the AI assistant that helped write this article about teaching AI to teach.</p>"},{"location":"Tech-AI-mysql/","title":"AI-driven Auto mysql","text":"<p>Under Construction - Preview</p> <p>See this page for information on issues deploying a single-container sqlite version.</p> <p> TL;DR - Working Software, Now</p> <p>Agile correctly advises getting Working Software as fast as possible, to facilitate Business User Collaboration and Iteration.  Using AI and API Logic Server helps you achieve this:</p> <ol> <li> <p>Create Database With ChatGPT </p> </li> <li> <p>Create Working Software Now with API Logic Server:  creates an API, and Admin screens from your database</p> </li> <li> <p>Deploy for Collaboration with API Logic Server: automated cloud deployment enables collaboration:</p> <ul> <li>Engage Business Users with running Admin screens - spot data model misunderstandings, and uncover logic requirements</li> <li>Unblock UI Developers with the API</li> </ul> </li> <li> <p>Declarative Logic Automates Iteration: use declarative rules for logic and security, extensible with Python as required.  Rules are a unique aspect of API Logic Server:</p> <ul> <li>logic is 40X more concise, and </li> <li>automatically ordered per system-discovered dependencies, to facilite rapid iteration</li> </ul> </li> </ol> <p>With API Logic Server, if you have a database, you can create and deploy for collaboration within hours.</p> <p></p>"},{"location":"Tech-AI-mysql/#pre-reqs","title":"Pre-reqs","text":"<p>You will need to:</p> <ul> <li> <p>Install API Logic Server (and Python)</p> </li> <li> <p>Install docker, and start the database: </p> </li> </ul> <pre><code>docker network create dev-network\ndocker run --name mysql-container --net dev-network -p 3306:3306 -d -e MYSQL_ROOT_PASSWORD=p apilogicserver/mysql8.0:latest\n</code></pre> <pre><code>* This is a MySQL we use for testing, simplified to store the data in the docker image to avoid managing docker volumes (useful for dev, not appropriate for production).\n</code></pre> <ul> <li> <p>A GitHub account (though you can use ours for this demo)</p> </li> <li> <p>An Azure account</p> </li> </ul> <p> </p>"},{"location":"Tech-AI-mysql/#1-chatgpt-database-generation","title":"1. ChatGPT Database Generation","text":""},{"location":"Tech-AI-mysql/#obtain-the-sql","title":"Obtain the sql","text":"<p>Use ChapGPT to generate SQL commands for database creation:</p> <p>Create database definitions from ChatGPT</p> <p>Create a mysql database for customers, orders, items and product, with autonum keys and Decimal types.  </p> <p>Create a few rows of customer and product data.</p> <p>Enforce the following logic:</p> <ol> <li> <p>Customer.Balance &lt;= CreditLimit</p> </li> <li> <p>Customer.Balance = Sum(Order.AmountTotal where unshipped)</p> </li> <li> <p>Order.AmountTotal = Sum(Items.Amount)</p> </li> <li> <p>Items.Amount = Quantity * UnitPrice</p> </li> <li> <p>Items.UnitPrice = copy from Product</p> </li> </ol> <p>Copy the generated SQL commands into a file, say, <code>ai_customer_orders_mysql.sql</code>:</p> <pre><code>DROP DATABASE IF EXISTS ai_customer_orders;\n\nCREATE DATABASE ai_customer_orders;\n\nUSE ai_customer_orders;\n\nCREATE TABLE IF NOT EXISTS Customers (\n    CustomerID INT AUTO_INCREMENT PRIMARY KEY,\n    FirstName TEXT,\n    LastName TEXT,\n    Email TEXT,\n    CreditLimit DECIMAL,\n    Balance DECIMAL DEFAULT 0.0\n);\n\nCREATE TABLE IF NOT EXISTS Products (\n    ProductID INT AUTO_INCREMENT PRIMARY KEY,\n    ProductName TEXT,\n    UnitPrice REAL\n);\n\nCREATE TABLE IF NOT EXISTS Orders (\n    OrderID INT AUTO_INCREMENT PRIMARY KEY,\n    CustomerID INTEGER,\n    AmountTotal DECIMAL,\n    OrderDate DATE,\n    ShipDate DATE,\n    FOREIGN KEY (CustomerID) REFERENCES Customers(CustomerID)\n);\n\nCREATE TABLE IF NOT EXISTS OrderItems (\n    OrderItemID INT AUTO_INCREMENT PRIMARY KEY,\n    OrderID INTEGER,\n    ProductID INTEGER,\n    Quantity INTEGER,\n    ItemPrice DECIMAL,\n    Amount DECIMAL,\n    FOREIGN KEY (OrderID) REFERENCES Orders(OrderID),\n    FOREIGN KEY (ProductID) REFERENCES Products(ProductID)\n);\n\n\n-- Insert customer data\nINSERT INTO Customers (FirstName, LastName, Email, CreditLimit) VALUES\n    ('John', 'Doe', 'john@example.com', 1000.00),\n    ('Jane', 'Smith', 'jane@example.com', 1500.00);\n\n-- Insert product data\nINSERT INTO Products (ProductName, UnitPrice) VALUES\n    ('Product A', 10.00),\n    ('Product B', 15.00),\n    ('Product C', 8.50);\n</code></pre> <p> </p>"},{"location":"Tech-AI-mysql/#create-the-database","title":"Create the database","text":"<p>Sqlite is already installed in ApiLogicServer, so we avoid database installs by using it as our target database:</p> <pre><code>docker exec -it mysql-container bash\n$ mysql -u root -p\n# password is  p\n# paste in the sql text to create your database\n</code></pre> <p>Note: if you use the names above, you can save time by using the docker image and git project that we've already created.</p> <p> </p>"},{"location":"Tech-AI-mysql/#2-create-working-software","title":"2. Create Working Software","text":"<p>Given a database, API Logic Server can create an executable, customizable project:</p> <pre><code>ApiLogicServer create --project_name=ai_customer_orders_mysql --db_url=mysql+pymysql://root:p@localhost:3306/ai_customer_orders\n</code></pre> <p>This creates a project you can open with VSCode.  Establish your <code>venv</code>, and run it via the first pre-built Run Configuration.  To establish your venv:</p> <pre><code>python -m venv venv; venv\\Scripts\\activate     # win\npython3 -m venv venv; . venv/bin/activate      # mac/linux\npip install -r requirements.txt\n</code></pre> <p> </p>"},{"location":"Tech-AI-mysql/#3-deploy-for-collaboration","title":"3. Deploy for Collaboration","text":"<p>API Logic Server also creates scripts for deployment, as shown below:</p> <p> </p>"},{"location":"Tech-AI-mysql/#add-security","title":"Add Security","text":"<p>In a terminal window for your project:</p> <pre><code>ApiLogicServer add-auth --project_name=. --db_url=mysql+pymysql://root:p@localhost:3306/authdb\n</code></pre> <p> </p>"},{"location":"Tech-AI-mysql/#create-the-image","title":"Create the image","text":"<p>In a terminal window for your project:</p> <p><pre><code>sh devops/docker-image/build_image.sh .\n</code></pre> </p>"},{"location":"Tech-AI-mysql/#test-your-image","title":"Test your Image","text":"<p>You can test the image in single container mode: <code>sh devops/docker-image/run_image.sh</code>.</p>"},{"location":"Tech-AI-mysql/#test-multi-container","title":"Test - Multi-Container","text":"<p>Stop your docker database.</p> <p>Test the image with docker compose: <code>sh ./devops/docker-compose-dev-local/docker-compose.sh</code>.</p> <p> </p>"},{"location":"Tech-AI-mysql/#upload-image-optional","title":"Upload Image (optional)","text":"<p>You would next upload the image to docker hub.  </p> <p>If you use the same names as here, skip that, and use our image: <code>apilogicserver/aicustomerordersmysql</code>.</p> <p> </p>"},{"location":"Tech-AI-mysql/#push-the-project","title":"Push the project","text":"<p>It's also a good time to push your project to git.  Again, if you've used the same names as here, you can use our project.</p> <p> </p>"},{"location":"Tech-AI-mysql/#deploy-to-azure","title":"Deploy to Azure","text":"<p>Then, login to the azure portal, and:</p> <pre><code>git clone https://github.com/ApiLogicServer/ai_customer_orders_mysql.git\ncd ai_customer_orders_mysql\nsh devops/docker-compose-dev-azure/azure-deploy.sh\n</code></pre> <p> </p>"},{"location":"Tech-AI-mysql/#4-iterate-with-logic","title":"4. Iterate with Logic","text":"<p>Logic Design ('Cocktail Napkin Design')</p> <p>Customer.Balance &lt;= CreditLimit</p> <p>Customer.Balance = Sum(Order.AmountTotal where unshipped)</p> <p>Order.AmountTotal = Sum(OrderDetail.Amount)</p> <p>OrderDetail.Amount = Quantity * UnitPrice</p> <p>OrderDetail.UnitPrice = copy from Product</p> <p>Rules are an executable design.  Use your IDE (code completion, etc), to replace 280 lines of code with these 5 rules:</p> <pre><code>    Rule.constraint(validate=models.Customer,       # logic design translates directly into rules\n        as_condition=lambda row: row.Balance &lt;= row.CreditLimit,\n        error_msg=\"balance ({round(row.Balance, 2)}) exceeds credit ({round(row.CreditLimit, 2)})\")\n\n    Rule.sum(derive=models.Customer.Balance,        # adjust iff AmountTotal or ShippedDate or CustomerID changes\n        as_sum_of=models.Order.AmountTotal,\n        where=lambda row: row.ShipDate is None)  # adjusts - *not* a sql select sum...\n\n    Rule.sum(derive=models.Order.AmountTotal,       # adjust iff Amount or OrderID changes\n        as_sum_of=models.OrderItem.Amount)\n\n    Rule.formula(derive=models.OrderItem.Amount,  # compute price * qty\n        as_expression=lambda row: row.ItemPrice * row.Quantity)\n\n    Rule.copy(derive=models.OrderItem.ItemPrice,  # get Product Price (e,g., on insert, or ProductId change)\n        from_parent=models.Product.UnitPrice)\n</code></pre>"},{"location":"Tech-AI-sqlite/","title":"AI-driven Auto sqlite","text":"<p>Under Construction - Preview</p> <p> TL;DR - Working Software, Now</p> <p>Agile correctly advises getting Working Software as fast as possible, to facilitate Business User Collaboration and Iteration.  Using AI and API Logic Server helps you achieve this:</p> <ol> <li> <p>Create Database With ChatGPT </p> </li> <li> <p>Create Working Software Now with API Logic Server:  creates an API, and Admin screens from your database</p> </li> <li> <p>Deploy for Collaboration with API Logic Server: automated cloud deployment enables collaboration:</p> <ul> <li>Engage Business Users with running Admin screens - spot data model misunderstandings, and uncover logic requirements</li> <li>Unblock UI Developers with the API</li> </ul> </li> <li> <p>Declarative Logic Automates Iteration: use declarative rules for logic and security, extensible with Python as required.  Rules are a unique aspect of API Logic Server:</p> <ul> <li>logic is 40X more concise, and </li> <li>automatically ordered per system-discovered dependencies, to facilite rapid iteration</li> </ul> </li> </ol> <p>With API Logic Server, if you have a database, you can create and deploy for collaboration within hours.</p> <p></p>"},{"location":"Tech-AI-sqlite/#1-chatgpt-database-generation","title":"1. ChatGPT Database Generation","text":""},{"location":"Tech-AI-sqlite/#obtain-the-sql","title":"Obtain the sql","text":"<p>Use ChapGPT to generate SQL commands for database creation:</p> <p>Create database definitions from ChatGPT</p> <p>Create a sqlite database for customers, orders, items and product, with autonum keys.  </p> <p>Create a few rows of customer and product data.</p> <p>Maintain the customer's balance as the sum of the unshipped orders amountotal, and ensure it does not exceed the credit limit.  Derive items price from the product unit price.</p> <p>Copy the generated SQL commands into a file, say, <code>ai_customer_orders.sql</code>:</p> <pre><code>CREATE TABLE IF NOT EXISTS Customers (\n    CustomerID INTEGER PRIMARY KEY AUTOINCREMENT,\n    FirstName TEXT,\n    LastName TEXT,\n    Email TEXT,\n    CreditLimit REAL,\n    Balance REAL DEFAULT 0.0\n);\n\nCREATE TABLE IF NOT EXISTS Products (\n    ProductID INTEGER PRIMARY KEY AUTOINCREMENT,\n    ProductName TEXT,\n    UnitPrice REAL\n);\n\nCREATE TABLE IF NOT EXISTS Orders (\n    OrderID INTEGER PRIMARY KEY AUTOINCREMENT,\n    CustomerID INTEGER,\n    OrderDate DATE,\n    ShipDate DATE,\n    FOREIGN KEY (CustomerID) REFERENCES Customers(CustomerID)\n);\n\nCREATE TABLE IF NOT EXISTS OrderItems (\n    OrderItemID INTEGER PRIMARY KEY AUTOINCREMENT,\n    OrderID INTEGER,\n    ProductID INTEGER,\n    Quantity INTEGER,\n    ItemPrice REAL,\n    FOREIGN KEY (OrderID) REFERENCES Orders(OrderID),\n    FOREIGN KEY (ProductID) REFERENCES Products(ProductID)\n);\n\n-- Insert customer data\nINSERT INTO Customers (FirstName, LastName, Email, CreditLimit) VALUES\n    ('John', 'Doe', 'john@example.com', 1000.00),\n    ('Jane', 'Smith', 'jane@example.com', 1500.00);\n\n-- Insert product data\nINSERT INTO Products (ProductName, UnitPrice) VALUES\n    ('Product A', 10.00),\n    ('Product B', 15.00),\n    ('Product C', 8.50);\n</code></pre> <p> </p>"},{"location":"Tech-AI-sqlite/#create-the-database","title":"Create the database","text":"<p>Sqlite is already installed in ApiLogicServer, so we avoid database installs by using it as our target database:</p> <pre><code>sqlite3 ai_customer_orders.sqlite &lt; ai_customer_orders.sql\n</code></pre> <p>Note: if you use the names above, you can save time by using the docker image and git project that we've already created.</p> <p> </p>"},{"location":"Tech-AI-sqlite/#2-create-working-software","title":"2. Create Working Software","text":"<p>Given a database, API Logic Server can create an executable, customizable project:</p> <pre><code>ApiLogicServer create --project_name=ai_customer_orders --db_url=sqlite:///ai_customer_orders.sqlite\n</code></pre> <p>This creates a project you can open with VSCode.  Establish your <code>venv</code>, and run it via the first pre-built Run Configuration.  To establish your venv:</p> <pre><code>python -m venv venv; venv\\Scripts\\activate     # win\npython3 -m venv venv; . venv/bin/activate      # mac/linux\npip install -r requirements.txt\n</code></pre> <p> </p>"},{"location":"Tech-AI-sqlite/#3-deploy-for-collaboration","title":"3. Deploy for Collaboration","text":"<p>API Logic Server also creates scripts for deployment, as shown below:</p> <p> </p>"},{"location":"Tech-AI-sqlite/#add-security","title":"Add Security","text":"<p>In a terminal window for your project:</p> <pre><code>ApiLogicServer add-auth\n</code></pre> <p> </p>"},{"location":"Tech-AI-sqlite/#create-the-image","title":"Create the image","text":"<p>In a terminal window for your project:</p> <p><pre><code>sh devops/docker-image/build_image.sh .\n</code></pre> </p>"},{"location":"Tech-AI-sqlite/#test","title":"Test","text":"<p>You can test the image in single container mode: <code>sh devops/docker-image/run_image.sh</code>.</p> <p>You can also test the image with docker compose: <code>sh ./devops/docker-compose-dev-local/docker-compose.sh</code>.</p> <p> </p>"},{"location":"Tech-AI-sqlite/#upload-image-optional","title":"Upload Image (optional)","text":"<p>You would next upload the image to docker hub.  </p> <p>If you use the same names as here, skip that, and use our image: <code>apilogicserver/aicustomerorders</code>.</p> <p> </p>"},{"location":"Tech-AI-sqlite/#push-the-project","title":"Push the project","text":"<p>It's also a good time to push your project to git.  Again, if you've used the same names as here, you can use our project.</p> <p> </p>"},{"location":"Tech-AI-sqlite/#deploy-to-azure","title":"Deploy to Azure","text":"<p>Note: This currently fails, and is under investigation.  See the Appendix below for more information.</p> <p>Then, login to the azure portal, and:</p> <pre><code>git clone https://github.com/ApiLogicServer/ai_customer_orders.git\ncd ai_customer_orders\nsh devops/docker-compose-dev-azure/azure-deploy.sh\n</code></pre> <p> </p>"},{"location":"Tech-AI-sqlite/#4-iterate-with-logic","title":"4. Iterate with Logic","text":"<p>Logic Design ('Cocktail Napkin Design')</p> <p>Customer.Balance &lt;= CreditLimit</p> <p>Customer.Balance = Sum(Order.AmountTotal where unshipped)</p> <p>Order.AmountTotal = Sum(OrderDetail.Amount)</p> <p>OrderDetail.Amount = Quantity * UnitPrice</p> <p>OrderDetail.UnitPrice = copy from Product</p> <p>Rules are an executable design.  Use your IDE (code completion, etc), to replace 280 lines for code with these 5 rules:</p> <pre><code>    Rule.constraint(validate=models.Customer,       # logic design translates directly into rules\n        as_condition=lambda row: row.Balance &lt;= row.CreditLimit,\n        error_msg=\"balance ({round(row.Balance, 2)}) exceeds credit ({round(row.CreditLimit, 2)})\")\n\n    Rule.sum(derive=models.Customer.Balance,        # adjust iff AmountTotal or ShippedDate or CustomerID changes\n        as_sum_of=models.Order.AmountTotal,\n        where=lambda row: row.ShipDate is None)  # adjusts - *not* a sql select sum...\n\n    Rule.sum(derive=models.Order.AmountTotal,       # adjust iff Amount or OrderID changes\n        as_sum_of=models.OrderItem.Amount)\n\n    Rule.formula(derive=models.OrderItem.Amount,  # compute price * qty\n        as_expression=lambda row: row.ItemPrice * row.Quantity)\n\n    Rule.copy(derive=models.OrderItem.ItemPrice,  # get Product Price (e,g., on insert, or ProductId change)\n        from_parent=models.Product.UnitPrice)\n</code></pre>"},{"location":"Tech-AI-sqlite/#appendix","title":"Appendix","text":""},{"location":"Tech-AI-sqlite/#azure-deployment","title":"Azure Deployment","text":"<p>Following the first 2 steps above, I have created the git project and docker image note above.</p> <p>Key facts about the application:</p> <ol> <li> <p>It uses flask and sqlite.  sqlite is an embedded database, so should not require a separate image.  However, azure refused to start a docker compose with just 1 service.</p> </li> <li> <p>The sqlite database file is in <code>database/db.sqlite</code></p> </li> <li> <p>The generated docker compose moves this to <code>home/api_logic_project/database/db.sqlite</code></p> </li> <li> <p>You can run the container locally with:</p> </li> </ol> <pre><code>docker run -it --name api_logic_project --rm --net dev-network -p 5656:5656 -p 5002:5002 apilogicserver/aicustomerorders\n</code></pre> <p> </p>"},{"location":"Tech-AI-sqlite/#multi-container","title":"Multi-Container","text":"<p>Then, login to the Azure portal, and:</p> <p>tl;dr:</p> <pre><code>git clone https://github.com/ApiLogicServer/ai_customer_orders.git\ncd ai_customer_orders\nsh devops/docker-compose-dev-azure/azure-deploy.sh  # a docker compose\n</code></pre> <p>That has failed inconsistently; sometimes with 500 errors, sometimes with complaints about the docker compose.</p> <p> </p>"},{"location":"Tech-AI-sqlite/#single-container","title":"Single-Container","text":"<p>So, I tried just a single container:</p> <pre><code>az container create --resource-group aicustomerorders_rg --name aicustomerorderscontainer --image apilogicserver/aicustomerorders:latest --dns-name-label aicustomerorderscontainer.io --ports 5656 --environment-variables 'APILOGICPROJECT_VERBOSE'='True' 'APILOGICPROJECT_CLIENT_URI'='//aicustomerorders.westus.azurecontainer.io'\n</code></pre> <p>9/22: <pre><code>az group create --name aicustomerorders_rg --location \"westus\"\n\naz appservice plan create --name myAppServicePlan --resource-group aicustomerorders_rg --sku S1 --is-linux\n\naz container create --resource-group aicustomerorders_rg --name aicustomerorders --image apilogicserver/aicustomerorders:latest --dns-name-label aicustomerorders --ports 5656 --environment-variables VERBOSE=True APILOGICPROJECT_CLIENT_URI=//aicustomerorders.westus.azurecontainer.io:5656\n</code></pre></p> <p>http://aicustomerorders.westus.azurecontainer.io:5656/admin-app/index.html#/Home</p> <p>old... http://aicustomerorderscontainer.westus.azurecontainer.io:5656/admin-app/index.html#/Home</p> <p> </p>"},{"location":"Tech-AI-sqlite/#login-fails","title":"Login fails","text":"<p>It starts (after a while!), with:</p> <pre><code>about:\n  date: September 18, 2023 14:07:54\n  recent_changes: works with modified safrs-react-admin\n  version: 0.0.0\napi_root: //aicustomerorders.westus.azurecontainer.io/api\nauthentication:\n  endpoint: //aicustomerorders.westus.azurecontainer.io/api/auth/login\ninfo:\n  number_relationships: 3\n  number_tables: 4\n</code></pre> <p>It fails trying to login:</p> <p></p> <p>And here with this server log:</p> <pre><code>API Logic Project (api_logic_project) Starting with CLI args: \n.. ./api_logic_server_run.py\n\nCreated September 18, 2023 12:47:42 at /home/api_logic_project\n\n\nENV args: \n.. flask_host: 0.0.0.0, port: 5656, \n.. swagger_host: localhost, swagger_port: 5656, \n.. client_uri: //aicustomerorders.westus.azurecontainer.io, \n.. http_scheme: http, api_prefix: /api, \n.. | verbose: True, create_and_run: False\n\n\nsqlite_db_path validity check with db_uri: sqlite:///../database/db.sqlite\n    .. Relative: /home/api_logic_project/database/db.sqlite\n    .. sqlite_db_path is a valid file\n\nData Model Loaded, customizing...\n\nLogic Bank 01.08.04 - 1 rules loaded\nDeclare   Logic complete - logic/declare_logic.py (rules + code) -- 4 tables loaded\n\nDeclare   API - api/expose_api_models, endpoint for each table on localhost:5656, customizing...\n\nAuthentication loaded -- api calls now require authorization header\n..declare security - security/declare_security.py authentication tables loaded\n\nAPI Logic Project loaded (not WSGI), version 09.03.03\n.. startup message: force verbose, hardcode ip\n (running from docker container at flask_host: 0.0.0.0 - may require refresh)\n\nAPI Logic Project (name: api_logic_project) starting:\n..Explore data and API at http_scheme://swagger_host:port http://localhost:5656\n.... with flask_host: 0.0.0.0\n.... and  swagger_port: 5656\n\n\nsys_info here\n\nEnvironment Variables...\n.. TERM = xterm\n.. HOSTNAME = SandboxHost-638308204834900603\n.. PATH = /usr/local/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin\n.. LANG = C.UTF-8\n.. GPG_KEY = A035C8C19219BA821ECEA86B64E628F8D684696D\n.. PYTHON_VERSION = 3.11.4\n.. PYTHON_PIP_VERSION = 23.1.2\n.. PYTHON_SETUPTOOLS_VERSION = 65.5.1\n.. PYTHON_GET_PIP_URL = https://github.com/pypa/get-pip/raw/9af82b715db434abb94a0a6f3569f43e72157346/public/get-pip.py\n.. PYTHON_GET_PIP_SHA256 = 45a2bb8bf2bb5eff16fdd00faef6f29731831c7c59bd9fc2bf1f3bed511ff1fe\n.. APILOGICSERVER_RUNNING = DOCKER\n.. APILOGICSERVER_FROM = python:3.11.4-slim-bullseye\n.. APILOGICPROJECT_CLIENT_URI = //aicustomerorders.westus.azurecontainer.io\n.. APILOGICPROJECT_VERBOSE = True\n.. Fabric_ApplicationName = caas-74cf120365a345c48dd2a977c17812c5\n.. Fabric_CodePackageName = aicustomerorderscontainer\n.. Fabric_Id = 8f91bb7f-32c1-465a-a681-c6a12cafc3d2\n.. Fabric_NET-0-[Other] = Other\n.. Fabric_NetworkingMode = Other\n.. Fabric_NodeIPOrFQDN = 10.92.0.23\n.. Fabric_ServiceDnsName = service.caas-74cf120365a345c48dd2a977c17812c5\n.. Fabric_ServiceName = service\n.. HOME = /home/api_logic_server\n.. SECRET_KEY = whatnothow\n.. SQLALCHEMY_TRACK_MODIFICATIONS = False\n.. SQLAlCHEMY_ECHO = false\n\n\nflask_app.config: \n\n&lt;Config {'DEBUG': None,\n    'TESTING': False,\n    'PROPAGATE_EXCEPTIONS': False,\n    'SECRET_KEY': 'whatnothow',\n    'PERMANENT_SESSION_LIFETIME': datetime.timedelta(days=31),\n    'USE_X_SENDFILE': False,\n    'SERVER_NAME': None,\n    'APPLICATION_ROOT': '/',\n    'SESSION_COOKIE_NAME': 'session',\n    'SESSION_COOKIE_DOMAIN': None,\n    'SESSION_COOKIE_PATH': None,\n    'SESSION_COOKIE_HTTPONLY': True,\n    'SESSION_COOKIE_SECURE': False,\n    'SESSION_COOKIE_SAMESITE': None,\n    'SESSION_REFRESH_EACH_REQUEST': True,\n    'MAX_CONTENT_LENGTH': None,\n    'SEND_FILE_MAX_AGE_DEFAULT': None,\n    'TRAP_BAD_REQUEST_ERRORS': None,\n    'TRAP_HTTP_EXCEPTIONS': False,\n    'EXPLAIN_TEMPLATE_LOADING': False,\n    'PREFERRED_URL_SCHEME': 'http',\n    'TEMPLATES_AUTO_RELOAD': None,\n    'MAX_COOKIE_SIZE': 4093,\n    'API_PREFIX': '/api',\n    'FLASK_HOST': '0.0.0.0',\n    'SWAGGER_HOST': 'localhost',\n    'PORT': '5656',\n    'SWAGGER_PORT': '5656',\n    'HTTP_SCHEME': 'http',\n    'VERBOSE': 'True',\n    'CREATE_AND_RUN': False,\n    'CREATED_API_PREFIX': '/api',\n    'CREATED_FLASK_HOST': '0.0.0.0',\n    'CREATED_HTTP_SCHEME': 'http',\n    'CREATED_PORT': '5656',\n    'CREATED_SWAGGER_HOST': 'localhost',\n    'CREATED_SWAGGER_PORT': '5656',\n    'FLASK_APP': None,\n    'FLASK_ENV': None,\n    'OPT_LOCKING': 'optional',\n    'SECURITY_ENABLED': True,\n    'SECURITY_PROVIDER': &lt;class 'security.authentication_provider.sql.auth_provider.Authentication_Provider'&gt;,\n    'SQLALCHEMY_DATABASE_URI': 'sqlite:///../database/db.sqlite',\n    'SQLALCHEMY_DATABASE_URI_AUTHENTICATION': 'sqlite:///../database/authentication_db.sqlite',\n    'SQLALCHEMY_TRACK_MODIFICATIONS': False,\n    'CLIENT_URI': '//aicustomerorders.westus.azurecontainer.io'}&gt;\n\n\nPYTHONPATH..\n../home/api_logic_project\n../usr/local/lib/python311.zip\n../usr/local/lib/python3.11\n../usr/local/lib/python3.11/lib-dynload\n../usr/local/lib/python3.11/site-packages\n../home/api_logic_project\n../home/api_logic_server\n\nsys.prefix (venv): /usr/local\n\n\nhostname=SandboxHost-638308204834900603 on local_ip=127.0.0.1, IPAddr=127.0.0.1\n\n\nos.getcwd()=/home/api_logic_project\n\n\n * Serving Flask app 'API Logic Server'\n\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n * Running on all addresses (0.0.0.0)\n * Running on http://127.0.0.1:5656\n * Running on http://192.168.0.231:5656\n\u001b[33mPress CTRL+C to quit\u001b[0m\nAPI Logic Server - Start Default App - redirect /admin-app/index.html\n10.92.0.25 - - [20/Sep/2023 15:36:05] \"\u001b[32mGET / HTTP/1.1\u001b[0m\" 302 -\n10.92.0.24 - - [20/Sep/2023 15:36:05] \"GET /admin-app/index.html HTTP/1.1\" 200 -\n10.92.0.25 - - [20/Sep/2023 15:36:06] \"GET /admin-app/manifest.json HTTP/1.1\" 200 -\n10.92.0.24 - - [20/Sep/2023 15:36:06] \"GET /admin-app/static/js/main.1eb04138.js HTTP/1.1\" 200 -\n10.92.0.25 - - [20/Sep/2023 15:36:06] \"GET /admin-app/static/css/main.a0c288b7.css HTTP/1.1\" 200 -\n10.92.0.25 - - [20/Sep/2023 15:36:06] \"GET /admin-app/index.html HTTP/1.1\" 200 -\n10.92.0.25 - - [20/Sep/2023 15:36:06] \"\u001b[36mGET /admin-app/static/js/main.1eb04138.js HTTP/1.1\u001b[0m\" 304 -\n10.92.0.24 - - [20/Sep/2023 15:36:06] \"\u001b[36mGET /admin-app/static/css/main.a0c288b7.css HTTP/1.1\u001b[0m\" 304 -\n10.92.0.24 - - [20/Sep/2023 15:36:06] \"GET /admin-app/manifest.json HTTP/1.1\" 200 -\n10.92.0.25 - - [20/Sep/2023 15:36:06] \"GET /ui/admin/admin.yaml HTTP/1.1\" 200 -\n10.92.0.24 - - [20/Sep/2023 15:36:06] \"GET /admin-app/favicon.ico HTTP/1.1\" 200 -\n10.92.0.25 - - [20/Sep/2023 15:36:06] \"GET /ui/admin/admin.yaml HTTP/1.1\" 200 -\n10.92.0.24 - - [20/Sep/2023 15:36:06] \"GET /admin-app/index.html HTTP/1.1\" 200 -\n10.92.0.25 - - [20/Sep/2023 15:36:06] \"GET /admin-app/manifest.json HTTP/1.1\" 200 -\n10.92.0.25 - - [20/Sep/2023 15:36:06] \"\u001b[36mGET /admin-app/static/css/main.a0c288b7.css HTTP/1.1\u001b[0m\" 304 -\n10.92.0.24 - - [20/Sep/2023 15:36:06] \"\u001b[36mGET /admin-app/static/js/main.1eb04138.js HTTP/1.1\u001b[0m\" 304 -\n10.92.0.24 - - [20/Sep/2023 15:36:06] \"GET /ui/admin/admin.yaml HTTP/1.1\" 200 -\n</code></pre> <p>is the problem https?  Does the client_uri require the port?</p> <p> </p>"},{"location":"Tech-AI-sqlite/#other-alternatives","title":"Other alternatives","text":"<p>I also tried other alternatives:</p> <p>admin: <pre><code>api_root: //aicustomerorders.westus.azurecontainer.io/api:5656\nauthentication:\n  endpoint: //aicustomerorders.westus.azurecontainer.io/api:5656/auth/login\n</code></pre> Single container:</p> <pre><code>az container create --resource-group aicustomerorders_rg --name aicustomerorderscontainer --image apilogicserver/aicustomerorders:latest --dns-name-label aicustomerorderscontainer --ports 5656 --environment-variables 'APILOGICPROJECT_VERBOSE'='True' 'APILOGICPROJECT_CLIENT_URI'='//aicustomerorders.westus.azurecontainer.io'\n</code></pre> <pre><code>az container create --resource-group myResourceGroup --name aicustomerorders_rg --image mcr.microsoft.com/azuredocs/aci-helloworld --dns-name-label aci-demo --ports 80\n\n??\naz webapp create --resource-group aicustomerorders_rg --plan myAppServicePlan --name aicustomerorders --image apilogicserver/aicustomerorders  \n</code></pre> <p>Run multi-container at https://aicustomerorders.azurewebsites.net.</p> <p>Run single-container at https://aicustomerorders.westus.azurecontainer.io:5656/api.</p> <p>https://aicustomerorderscontainer.westus.azurecontainer.io:5656/admin-app/index.html#/Home</p>"},{"location":"Tech-AI-sqlite/#azure-ip-address","title":"Azure IP address","text":"<p>These are not being returned as expected.  This means I need to manually supply this imformation in <code>ui/admin/admin.yml</code>.</p> <p>The system is designed to replace these from the discovered IP (e.g, <code>http://localhost:5656/api</code>):</p> <pre><code>api_root: '{http_type}://{swagger_host}:{port}/{api}'\ninfo_toggle_checked: true\ninfo:\n  number_relationships: 13\n  number_tables: 17\nauthentication:\n  endpoint: '{http_type}://{swagger_host}:{port}/api/auth/login'\n</code></pre> <p>But, in the single container, I had to override them:</p> <pre><code>api_root: https://aicustomerorders.westus.azurecontainer.io:5656/api\ninfo_toggle_checked: true\ninfo:\n  number_relationships: 13\n  number_tables: 17\nauthentication:\n  endpoint: https://aicustomerorders.westus.azurecontainer.io:5656api/auth/login\n</code></pre>"},{"location":"Tech-AI-sqlite/#curl","title":"cURL","text":"<p>The API can be accessed by the admin app, or cURL:</p> <pre><code>curl -X 'GET' \\\n  'http://localhost:5656/api/Customer/?include=OrderList&amp;fields%5BCustomer%5D=CustomerID%2CFirstName%2CLastName%2CEmail%2CCreditLimit%2CBalance%2C_check_sum_%2CS_CheckSum&amp;page%5Boffset%5D=0&amp;page%5Blimit%5D=10&amp;sort=id' \\\n  -H 'accept: application/vnd.api+json' \\\n  -H 'Content-Type: application/vnd.api+json'\n\n  curl -X 'GET' \\\n  'https://aicustomerorders.westus.azurecontainer.io:5656/api/Customer/?include=OrderList&amp;fields%5BCustomer%5D=CustomerID%2CFirstName%2CLastName%2CEmail%2CCreditLimit%2CBalance%2C_check_sum_%2CS_CheckSum&amp;page%5Boffset%5D=0&amp;page%5Blimit%5D=10&amp;sort=id' \\\n  -H 'accept: application/vnd.api+json' \\\n  -H 'Content-Type: application/vnd.api+json'\n\ncurl -X 'GET' \\\n  'https://aicustomerorders.westus.azurecontainer.io/api/Customer/?include=OrderList&amp;fields%5BCustomer%5D=CustomerID%2CFirstName%2CLastName%2CEmail%2CCreditLimit%2CBalance%2C_check_sum_%2CS_CheckSum&amp;page%5Boffset%5D=0&amp;page%5Blimit%5D=10&amp;sort=id' \\\n  -H 'accept: application/vnd.api+json' \\\n  -H 'Content-Type: application/vnd.api+json'\n\ncurl -X 'GET' \\\n    'http://aicustomerorders.westus.azurecontainer.io:5656/api/Customer/?include=OrderList&amp;fields%5BCustomer%5D=CustomerID%2CFirstName%2CLastName%2CEmail%2CCreditLimit%2CBalance%2C_check_sum_%2CS_CheckSum&amp;page%5Boffset%5D=0&amp;page%5Blimit%5D=10&amp;sort=id' \\\n  -H 'accept: application/vnd.api+json' \\\n  -H 'Content-Type: application/vnd.api+json'\n</code></pre>"},{"location":"Tech-AI/","title":"AI-Driven Automation with ChatGPT Delivers the Agile Vision","text":"<p> AI-Driven Automation with ChatGPT Delivers the Agile Vision</p> <p>Agile wisely advises getting Working Software as fast as possible, to facilitate Business User Collaboration and Iteration.  ChatGPT and API Logic Server deliver this vision, with 1 hour project cycles:</p> <ol> <li>Create Database With ChatGPT</li> <li> <p>Create Working Software Now with API Logic Server:</p> <ul> <li>Creates executable, customizable projects from databases: API with Swagger, Admin App</li> <li>Declare logic and security with spreadsheet-like rules, using your IDE</li> </ul> </li> <li> <p>Deploy for Collaboration with API Logic Server: e.g. to the Azure Cloud</p> </li> <li>Iterate: add additional rules, with a pinch of Python as required</li> </ol> <p>This process leverages your existing IT infrastructure: your IDE, GitHub, the cloud, your database\u2026 open source.</p> <p>To give it a try, follow the procedure below.  Allow 20 minutes, a bit more if you are new to Azure.  This page is an article reprint, so does not have detailed testing instructions.  For a more guided tour, see GenAI Microservices Automation.</p> <p> </p>"},{"location":"Tech-AI/#the-problem-late-and-wrong","title":"The Problem: Late, and Wrong","text":"<p>We've all lived the unpleasant reality depicted here:</p> <p>The harsh truth is that working screens communicate best - not docs, diagrams, etc.</p> <p>But working screens are based on projects that are complex and time-consuming.  So, misunderstandings are discovered late in the project, with significant loss of time and effort.</p>"},{"location":"Tech-AI/#agile-vision-working-software-drives-collaboration-and-iteration","title":"Agile Vision: Working Software Drives Collaboration and Iteration","text":"<p>Agile wisely advises getting Working Software as fast as possible, to facilitate Business User Collaboration and Iteration.  That\u2019s not happening by coding to a framework\u2026 </p> <p>So, How do we get Working Software, Now?  And rapid iteration?</p>"},{"location":"Tech-AI/#our-approach-ai-driven-automation-delivers-the-agile-vision","title":"Our Approach: AI-Driven Automation Delivers the Agile Vision","text":"<p>This article illustrates how create working software in hours instead of weeks/months, like this:</p> <ol> <li>Create Database With ChatGPT</li> <li>Create Working Software Now with API Logic Server:<ul> <li>Creates executable, customizable projects from databases</li> <li>Declare logic and security with spreadsheet-like rules using your IDE</li> </ul> </li> <li>Deploy for Collaboration with API Logic Server: e.g. to the Azure Cloud</li> <li>Iterate: add additional rules, with Python as required</li> </ol> <p>This process leverages your existing IT infrastructure: your IDE, GitHub, the cloud, your database\u2026 open source</p> <p>Let's see how.</p> <p> </p>"},{"location":"Tech-AI/#in-a-nutshell","title":"In a Nutshell","text":"<p>For the truly impatient, here\u2019s the basic process (takes under 10 minutes; details explained in remainder of article; video here):</p> <p>1. Use ChatGPT to input a description, and create the database</p> <p>1a. Input the system description below, copy the DDL and save it: <pre><code>$ pbpaste &gt; ai_customer_orders.sql    # copied DDL\n$ pbpaste &gt;&gt; ai_customer_orders.sql   # append copied insert statements\n</code></pre></p> <p>1b. Create the database: <pre><code>$ sqlite3  ai_customer_orders.sqlite &lt; ai_customer_orders.sql\n</code></pre></p> <p> </p> <p>2. Create an executable API Logic Project</p> <p>2a. Create the Project <pre><code>$ ApiLogicServer create \\\n--project_name=ai_customer_orders \\\n--db_url=sqlite:///ai_customer_orders.sqlite\n</code></pre> 2b. Open the project in VSCode, create your virtual environment, and press F5 to run</p> <p>2c. In the VSCode terminal window, add security:</p> <pre><code>$ ApiLogicServer add-auth --project_name=. --db_url=auth\n</code></pre> <p>2c. Add 5 rules, using IDE code completion)</p> <p> </p> <p>3. Deploy for Collaboration</p> <p>3a. Push the Project to Git (or use ours)</p> <p>3b. Build the image <pre><code>$ sh devops/docker-image/build_image.sh .\n</code></pre></p> <p>3c. Login to the Azure Portal, and</p> <pre><code>$ git clone https://github.com/ApiLogicServer/ai_customer_orders.git\n$ cd ai_customer_orders\n$ sh devops/docker-compose-dev-azure/azure-deploy.sh\n</code></pre> <p> </p> <p>4. Iterate with Logic, and Python as required</p> <p>Now let's alter the app to give volume discounts for carbon neutral purchases.</p> <p> </p> <p>4a. Add a Database Column</p> <pre><code>$ sqlite3 database/db.sqlite\n&gt;   alter table Products Add CarbonNeutral Boolean;\n&gt;   .exit\n</code></pre> <p> </p> <p>4b. Rebuild the project, preserving customizations</p> <pre><code>ApiLogicServer rebuild-from-database \\\n    --db_url=sqlite:///database/db.sqlite\n</code></pre> <p> </p> <p>4c. Update <code>ui/admin/admin.yml</code></p> <p> </p> <p>4d. Alter the logic, as shown below</p> <p> </p>"},{"location":"Tech-AI/#1-chatgpt-database-generation","title":"1. ChatGPT Database Generation","text":""},{"location":"Tech-AI/#obtain-the-sql","title":"Obtain the sql","text":"<p>Use ChapGPT to generate SQL commands for database creation:</p> <p>Create database definitions from ChatGPT</p> <p>Create a sqlite database for customers, orders, items and product</p> <p>Hints: use autonum keys, allow nulls, Decimal types, and foreign keys.</p> <p>Include a notes field for orders.</p> <p>Create a few rows of only customer and product data.</p> <p>Enforce the Check Credit requirement:</p> <ol> <li>Customer.Balance &lt;= CreditLimit</li> <li>Customer.Balance = Sum(Order.AmountTotal where date shipped is null)</li> <li>Order.AmountTotal = Sum(Items.Amount)</li> <li>Items.Amount = Quantity * UnitPrice</li> <li>Store the Items.UnitPrice as a copy from Product.UnitPrice</li> </ol> <p>Copy the generated SQL commands into a file, say, <code>ai_customer_orders.sql</code>:</p> <pre><code>CREATE TABLE Customers (\n    CustomerID INTEGER PRIMARY KEY AUTOINCREMENT,\n    Name TEXT NOT NULL,\n    Balance DECIMAL(10, 2) NULL,\n    CreditLimit DECIMAL(10, 2) NULL\n);\n\n-- Create the Products table\nCREATE TABLE Products (\n    ProductID INTEGER PRIMARY KEY AUTOINCREMENT,\n    Name TEXT NOT NULL,\n    UnitPrice DECIMAL(10, 2) NULL\n);\n\n-- Create the Orders table\nCREATE TABLE Orders (\n    OrderID INTEGER PRIMARY KEY AUTOINCREMENT,\n    CustomerID INTEGER NULL,\n    AmountTotal DECIMAL(10, 2) NULL,\n    ShipDate DATE NULL,\n    Notes TEXT NULL,\n    FOREIGN KEY (CustomerID) REFERENCES Customers(CustomerID)\n);\n\n-- Create the Items table\nCREATE TABLE Items (\n    ItemID INTEGER PRIMARY KEY AUTOINCREMENT,\n    OrderID INTEGER NULL,\n    ProductID INTEGER NULL,\n    Quantity INTEGER NULL,\n    Amount DECIMAL(10, 2) NULL,\n    UnitPrice DECIMAL(10, 2) NULL,\n    FOREIGN KEY (OrderID) REFERENCES Orders(OrderID),\n    FOREIGN KEY (ProductID) REFERENCES Products(ProductID)\n);\n-- Insert sample customers\nINSERT INTO Customers (Name, Balance, CreditLimit) VALUES\n    ('Customer 1', 1000.00, 2000.00),\n    ('Customer 2', 1500.00, 3000.00);\n\n-- Insert sample products\nINSERT INTO Products (Name, UnitPrice) VALUES\n    ('Product A', 10.00),\n    ('Product B', 20.00);\n</code></pre> <p> </p>"},{"location":"Tech-AI/#create-the-database","title":"Create the database","text":"<p>We avoid database installs / server management by using SQLLite as our target database:</p> <pre><code>sqlite3 ai_customer_orders.sqlite &lt; ai_customer_orders.sql\n</code></pre> <p>Note: if you use the names above, you can save time by using the docker image and git project that we've already created.</p> <p> </p>"},{"location":"Tech-AI/#2-create-working-software","title":"2. Create Working Software","text":"<p>Given a database, API Logic Server can create an executable, customizable project:</p> <pre><code>$ ApiLogicServer create \\\n--project_name=ai_customer_orders \\\n--db_url=sqlite:///ai_customer_orders.sqlite\n</code></pre> <p>This creates a project you can open with VSCode.  Establish your <code>venv</code>, and run it via the first pre-built Run Configuration.  To establish your venv:</p> <pre><code>python -m venv venv; venv\\Scripts\\activate     # win\npython3 -m venv venv; . venv/bin/activate      # mac/linux\npip install -r requirements.txt\n</code></pre> <p> </p>"},{"location":"Tech-AI/#add-security","title":"Add Security","text":"<p>In a terminal window for your project:</p> <p><pre><code>ApiLogicServer add-auth --project_name=. --db_url=auth\n</code></pre> </p>"},{"location":"Tech-AI/#declare-logic","title":"Declare Logic","text":"<p>Rules are an executable design.  Use your IDE (code completion, etc), to replace 280 lines of code with the 5 spreadsheet-like rules in <code>logic/declare_logic.py</code>.  Note they map exactly to our natural language design:</p> <pre><code>\"\"\" Declarative multi-table derivations and constraints, extensible with Python. \n\nBrief background: see readme_declare_logic.md\n\nUse code completion (Rule.) to declare rules here:\n\n\n1. Customer.Balance &lt;= CreditLimit\n\n2. Customer.Balance = Sum(Order.AmountTotal where unshipped)\n\n3. Order.AmountTotal = Sum(Items.Amount)\n\n4. Items.Amount = Quantity * UnitPrice\n\n5. Items.UnitPrice = copy from Product\n\"\"\"\n\nRule.constraint(validate=models.Customer,       # logic design translates directly into rules\n    as_condition=lambda row: row.Balance &lt;= row.CreditLimit,\n    error_msg=\"balance ({round(row.Balance, 2)}) exceeds credit ({round(row.CreditLimit, 2)})\")\n\nRule.sum(derive=models.Customer.Balance,        # adjust iff AmountTotal or ShippedDate or CustomerID changes\n    as_sum_of=models.Order.AmountTotal,\n    where=lambda row: row.ShipDate is None)     # adjusts - *not* a sql select sum...\n\nRule.sum(derive=models.Order.AmountTotal,       # adjust iff Amount or OrderID changes\n    as_sum_of=models.Item.Amount)\n\nRule.formula(derive=models.Item.Amount,    # compute price * qty\n    as_expression=lambda row: row.UnitPrice * row.Quantity)\n\nRule.copy(derive=models.Item.UnitPrice,    # get Product Price (e,g., on insert, or ProductId change)\n    from_parent=models.Product.UnitPrice)\n</code></pre> <p>Observe rules are declared in Python.  Given IDE services for code completion, this is using Python as a DSL (Domain Specific Language).  You can paste the code above into <code>logic/declare_logic.py</code> (you will need to adjust tabs).</p> <p> </p>"},{"location":"Tech-AI/#re-use-and-optimization","title":"Re-use and Optimization","text":"<p>We can contrast this to the (not shown) ChatGPT attempt at logic.  With declarative logic, you get:</p> <ol> <li> <p>Automatic Reuse: the logic above, perhaps conceived for Place order, applies automatically to all transactions: deleting an order, changing items, moving an order to a new customer, etc.</p> </li> <li> <p>Automatic Optimizations: sql overhead is minimized by pruning, and by elimination of expensive aggregate queries.  These can result in orders of magnitude impact.</p> </li> </ol> <p>ChatGPT created triggers that missed many Use Cases, and were inefficient.  They were also not transparent; Business Users can read the rules and spot issues (\"hey, where's the tax?\"), certainly not triggers.</p> <p> </p>"},{"location":"Tech-AI/#3-deploy-for-collaboration","title":"3. Deploy for Collaboration","text":"<p>API Logic Server also creates scripts for deployment.</p> <p> </p> <p>a. Containerize</p> <p>In a terminal window for your project:</p> <pre><code>sh devops/docker-image/build_image.sh .\n</code></pre> <p> </p> <p>b. Test your Image</p> <p>You can test the image in single container mode:</p> <pre><code>sh devops/docker-image/run_image.sh\n</code></pre> <p> </p> <p>c. Upload Image (optional)</p> <p>You would next upload the image to docker hub.  </p> <p>If you use the same names as here, skip that, and use our image: <code>apilogicserver/aicustomerorders</code>.</p> <p> </p> <p>d. Push the project</p> <p>It's also a good time to push your project to git.  Again, if you've used the same names as here, you can use our project.</p> <p> </p> <p>e. Deploy to Azure Cloud</p> <p>Login to the azure portal, and:</p> <pre><code>git clone https://github.com/ApiLogicServer/ai_customer_orders.git\ncd ai_customer_orders\nsh devops/docker-compose-dev-azure/azure-deploy.sh\n</code></pre> <p> </p>"},{"location":"Tech-AI/#4-iterate-with-logic","title":"4. Iterate with Logic","text":"<p>Not only are spreadsheet-like rules 40X more concise, they meaningfully simplify maintenance.  Let\u2019s take an example.</p> <p>Green Discounts</p> <p>Give a 10% discount for carbon-neutral products for 10 items or more.</p> <p>Automation still applies; we execute the steps below.</p> <p> </p> <p>a. Add a Database Column</p> <pre><code>$ sqlite3 database/db.sqlite\n&gt;   alter table Products Add CarbonNeutral Boolean;\n&gt;   .exit\n</code></pre> <p> </p> <p>b. Rebuild the project, preserving customizations</p> <pre><code>cd ..  project parent directory\nApiLogicServer rebuild-from-database --db_url=sqlite:///database/db.sqlite\n</code></pre> <p> </p> <p>c. Update your admin app</p> <p>Use your IDE to merge <code>/ui/admin/admin-merge.yml</code> -&gt; <code>/ui/admin/admin.yml</code>.`</p> <p> </p> <p>d. Declare logic</p> <pre><code>   def derive_amount(row: models.Item, old_row: models.Item, logic_row: LogicRow):\n       amount = row.Quantity * row.UnitPrice\n       if row.Product.CarbonNeutral and row.Quantity &gt;= 10:\n           amount = amount * Decimal(0.9)\n       return amount\n\n\n   Rule.formula(derive=models.Item.Amount, calling=derive_amount)\n</code></pre> <p> </p> <p>This simple example illustrates some significant aspects of iteration.</p> <p> </p>"},{"location":"Tech-AI/#maintenance-logic-ordering","title":"Maintenance: Logic Ordering","text":"<p>Along with perhaps documentation, one of the tasks programmers most loathe is maintenance.  That\u2019s because it\u2019s not about writing code, but it\u2019s mainly archaeology - deciphering code someone else wrote, just so you can add 4 or 5 lines they\u2019ll hopefully be called and function correctly.</p> <p>Rules change that, since they self-order their execution (and pruning) based on system-discovered dependencies.  So, to alter logic, you just \u201cdrop a new rule in the bucket\u201d, and the system will ensure it\u2019s called in the proper order, and re-used over all the Use Cases to which it applies.</p> <p> </p>"},{"location":"Tech-AI/#extensibility-rules-plus-python","title":"Extensibility: Rules Plus Python","text":"<p>In this case, we needed to do some if/else testing, and it was more convenient to add a dash of Python.  While you have the full object-oriented power of Python, this is simpler, more like Python as a 4GL.  </p> <p>What\u2019s important is that once you are in such functions, you can utilize Python libraries, invoke shared code, make web service calls, send email or messages, etc.  You have all the power of rules, plus the unrestricted flexibility of Python.</p> <p> </p>"},{"location":"Tech-AI/#debugging-ide-logging","title":"Debugging: IDE, Logging","text":"<p>The screen shot above illustrates that debugging logic is what you\u2019d expect: use your IDE's debugger.</p> <p>In addition, the Logic Log lists every rule that fires, with indents for multi-table chaining (not visible in this screenshot).  Each line shows the old/new values of every attribute, so the transaction state is transparent.</p> <p> </p>"},{"location":"Tech-AI/#rebuild-customizations-preserved","title":"Rebuild: Customizations Preserved","text":"<p>Note we rebuilt the project from our altered database, without losing customizations.</p> <p> </p>"},{"location":"Tech-AI/#summary","title":"Summary","text":"<p>In 6 minutes, you've used ChatGPT and API Logic Server to convert an idea into working software, deployed for collaboration, and iterated to meet new requirements.</p> <p> </p>"},{"location":"Tech-AI/#appendices","title":"Appendices","text":""},{"location":"Tech-AI/#sqlite-and-persistence","title":"Sqlite and persistence","text":"<p>For information on database and directory creation, click here.  Since the database is stored and accessed in the container, cloud changes are not persisted over runs.  This is useful for demo systems where each run starts with fresh data.</p> <p>An option for cloud sqlite persistence is under investigation.  Preliminary thoughts:</p> <ul> <li>Update the project to use blob storage</li> <li>On Server start, restore the database from blob storage to the image</li> <li>On Server Exit, use <code>atexit</code> to save the database from the image to blob storage</li> </ul> <p>There are also products that automate this, such as LiteStream.</p> <p>Of course, you can use a database such as MySQL, Postgres, Oracle or SqlServer, as described here.  Local databases can be migrated to Azure in a number of ways, such as this example using MySqlWorkBench.</p>"},{"location":"Tech-Adoption/","title":"Adoption Considerations?","text":""},{"location":"Tech-Adoption/#standards-based","title":"Standards-based","text":"<p>Development and runtime architectures are what programmers expect:</p> <ul> <li>As noted above, the Key Project Components are standard Python packages for APIs, data access.</li> <li>Projects developed in standard IDEs, and deployed in standard containers.</li> </ul>"},{"location":"Tech-Adoption/#near-zero-learning-curve-no-frameworks-etc","title":"Near-Zero Learning Curve - no frameworks, etc","text":"<p>ApiLogicServer has a near-zero learning curve:</p> <ul> <li> <p>You do not need to know Python, SQLAlchemy, React, Flask, or JSON / APIs to get started. </p> </li> <li> <p>You should have a basic background in database - familiar with terms like Table, Column, Foreign Key.</p> </li> </ul> <p> </p>"},{"location":"Tech-Adoption/#deliver-while-learning","title":"Deliver While Learning","text":"<p>You have a running project in moments, customizable without requiring deep understanding of any of these frameworks.  Such instantly-available projects are valuable to Custom App Developers and Business Users, who can begin with these while you gain familiarity with Flask and SQLAlchemy.</p> <p>Making extensions, of course, begins to require more technical background.</p> <p> </p>"},{"location":"Tech-Adoption/#facilitate-python-adoption","title":"Facilitate Python Adoption","text":"<p>For organizations seeking to leverage the value of Python, API Logic Server enables you to </p> <ul> <li> <p>Start without Python background, and </p> </li> <li> <p>Use the created systems / examples to learn Python, based on working software</p> </li> </ul> <p> </p>"},{"location":"Tech-Adoption/#allow-a-few-days-for-learning-logic","title":"Allow a few days for learning logic","text":"<p>Logic represents the starkest different between procedural code and declarative rules.  It requires a few days to get the hang of it.  We recommend you explore this documentation.</p> <p> </p>"},{"location":"Tech-Adoption/#business-agility","title":"Business Agility","text":"<p>ApiLogicServer automation creates a running project nearly instantly, but it also is designed to help you adapt to business changes more rapidly:</p> <ul> <li>[Rebuild].mdProject-Rebuild.md) support to update existing projects from database or data model changes</li> <li>Logic provides automatic reordering and reoptimization as logic is altered</li> </ul> <p> </p>"},{"location":"Tech-Adoption/#technology-agility-an-application-virtual-machine","title":"Technology Agility - an Application Virtual Machine","text":"<p>Models are, somewhat by their very nature, rather technology independent.  Instead of React, the UI specification could be implemented on Angular.  Instead of interpreted, the logic could be code-generated onto any language.  And so forth.</p> <p>You can think of the Key Project Components as an Application Virtual Machine that executes ApiLogicProjects.  As new underlying technology becomes available, new AVMs could be developed that migrate the declarative elements of your UI, API and Logic - without coding change.  Because, they are models, not code.</p> <p>This provides an unprecedented preservation of your application investment over underlying technology change. </p> <p> </p>"},{"location":"Tech-Adoption/#automation-reduces-risk","title":"Automation Reduces Risk","text":"<p>Automation not only gets results fast and simplifies adapting to change, it also reduces risk.</p>"},{"location":"Tech-Adoption/#coding-risk","title":"Coding Risk","text":"<p>The most troublesome bugs are silent failures - no stacktrace, but the wrong answer.</p> <p>Automation address this by designing out whole classes of error:</p> <ul> <li>the UI and API just work</li> <li>logic is automatically re-used over all Use Cases</li> </ul>"},{"location":"Tech-Adoption/#architectural-risk","title":"Architectural Risk","text":"<p>Technology complexity makes it get hard to get projects that even work, much less work right.  Projects commonly suffer from a wide variety of architectural flaws:</p> <ul> <li>business logic is not shared, but repeated in each UI controller... and each integration</li> <li>pagination may not be provided for all screens</li> </ul> <p>And so forth.  These cause project failures, far too often.</p> <p>But automation can help - since your declarative models only stipulate what, the system bears the responsibility for the how -- and getting it right.  Each of the architectural items above are automated by the system.</p>"},{"location":"Tech-Adoption/#requirements-risk","title":"Requirements Risk","text":"<p>Requirements risk can represent an even greater challenge.  The reality that users may only realize the real requirements when they actually use running screens with real data.  The problem, of course, is that these are often available after considerable time and effort.</p> <p>That's why working software now is so important - users get screens right away.  These can identify data model errors (\"hey... customers have more than one address\") or business logic requirements (\"hey.... we need to check the credit limit\").</p> <p> </p>"},{"location":"Tech-Adoption/#unifying-user-groups","title":"Unifying User Groups","text":"<p>While it may at first seem that an IDE, language-based approach may be for developers only, this is not the case:</p> Python Level Users Usage DSL Business Users - Read Rules- BDD Scripting Power Users - Logic Events- Customize Admin App OO Language Developers - Full Capability <p>In particular:</p> <ul> <li> <p>Business Users</p> <ul> <li> <p>Can read rules (e.g. identify that \"the tax calculation is missing\").  For more information, see Python as a DSL.</p> </li> <li> <p>Oo not need to load an IDE - they can access the project on GitHub and use Shift + \".\" to view the rules, and the BDD Report.</p> </li> </ul> </li> <li> <p>Power Users will be very comfortable with Python as a Scripting language, using the examples to quick become adept with enhancing declarative services</p> </li> </ul> <p>This is one of the major advantages of declarative.  Unlike procedural code that is impenetrable to Business / Power users, declarative logic means anyone in the organization can go directly to the source</p>"},{"location":"Tech-Agile-Integrations/","title":"Agile Integrations","text":"<p> TL;DR - Agile Integrations with Instant, Logic-Enforced, Consumer-Defined APIs</p> <p>Many organizations still employ ETL (Extract, Transfer and Load) approaches for integrations.  These are costly non-agile projects, inefficient, and operationally clumsy.</p> <p>API Logic Server enables Agile Integrations:</p> <ul> <li> <p>Instant API creation</p> <ul> <li> <p>Eliminates ad hoc projects to write and deploy ETL services</p> </li> <li> <p>Eliminates complex DevOps procedures to run nightly ETL executions</p> </li> <li> <p>Eliminates inefficient Extract runs, replacing them with lightweight API calls that return current data</p> </li> </ul> </li> <li> <p>Logic-Enforced APIs ensure that such accesses are subjected to security, and maintain data integrity</p> </li> <li> <p>JSON:APIs are consumer-defined, ensuring client organizations to self-serve, without requiring ad hoc API development for each new integration</p> </li> </ul>"},{"location":"Tech-Agile/","title":"Tech Agile","text":""},{"location":"Tech-Agile/#the-problem-late-and-wrong","title":"The Problem: Late, and Wrong","text":"<p>So, why does this keep happening?</p>"},{"location":"Tech-Agile/#why-delayed-collaboration","title":"Why: Delayed Collaboration","text":"<p>It\u2019s because Business Users need working software - running screens - but there\u2019s a long dev cycle before that happens..</p> <p></p> <p> </p> <p></p>"},{"location":"Tech-Agile/#need-instant-working-software-now","title":"Need: Instant Working Software.. Now","text":"<p>The Agile vision is shown on the right: getting Working Software as fast as possible, to facilitate Business User Collaboration and Iteration.  </p> <p> </p> <p>And that's exactly why we built API Logic Server: it creates working software instantly, instead of weeks/months, as shown below:</p> <p></p> <ol> <li>Use your existing database, or create a new one with ChatGPT or your database tools</li> <li>Create Working Software Now:  API Logic Server creates an ApiLogicProject, providing:<ul> <li>A Self-Serve API that UI developers can use, Day 1 - no waiting for server dev</li> <li>An Admin App for Business Users to begin collaboration, Day 1</li> </ul> </li> <li>Deploy for Collaboration: e.g. to the Azure Cloud</li> <li>Iterate: declare logic and security, with Python as required</li> </ol> <p>This process leverages your existing IT infrastructure: your IDE, GitHub, the cloud, your database\u2026 open source</p> <p>Let's see how.</p> <p> </p>"},{"location":"Tech-Agile/#1-acquire-database","title":"1. Acquire Database","text":"<p>You can use an existing database, or create a new one with ChapGPT or your database tools.</p> <p>For this Tutorial, to get a simple customers/orders database, click the download link here.</p> <p> </p>"},{"location":"Tech-Agile/#2-create-working-software","title":"2. Create Working Software","text":"<p>Given a database, API Logic Server creates an executable, customizable project:</p> <pre><code>$ ApiLogicServer create \\\n--project_name=ai_customer_orders \\\n--db_url=sqlite:///ai_customer_orders_begin.sqlite\n</code></pre> <p>This creates a project you can open with VSCode.  Establish your <code>venv</code>, and run it via the first pre-built Run Configuration.  To establish your venv:</p> <p><pre><code>python -m venv venv; venv\\Scripts\\activate     # win\npython3 -m venv venv; . venv/bin/activate      # mac/linux\npip install -r requirements.txt\n</code></pre> </p> <p>The project is now ready to run.  It includes a self-serve API ready for UI developers, and an Admin app ready for Business User Collaboration.  We have eliminated the first project segment from our traditional project timeline, and can start collaboration on Day 1.</p> <p>Our timelines looks more like this:</p> <p></p> <p>Let's have a look.</p> <p> </p>"},{"location":"Tech-Agile/#a-admin-app","title":"a. Admin App","text":"<p>This React-Admin web app is created automatically - no JavaScript, no HTML.</p> <p>It's the Working Software Business Users need to collaborate on Day 1: confirm the data model, and uncover logic requirements.</p> <p></p>"},{"location":"Tech-Agile/#b-self-serve-apis","title":"b. Self-serve APIs","text":"<p>The system automatically creates JSON:APIs, supporting related data access, pagination, optimistic locking, filtering, and sorting.</p> <p>UI Developers can use swagger to design their API call, and copy the URI into their JavaScript code.  APIs are thus self-serve no server coding is required.  UI development is unblocked, Day 1.</p> <p></p>"},{"location":"Tech-Agile/#3-deploy-for-collaboration","title":"3. Deploy for Collaboration","text":"<p>OK, running on our desktop.  We need to deploy it for collaboration. </p> <p>API Logic Server also creates scripts for deployment.</p> <p> </p> <p>a. Containerize</p> <p>We'll create a container and deploy to Azure. In a terminal window for your project:</p> <pre><code>sh devops/docker-image/build_image.sh .  # creates container\n</code></pre> <p> </p> <p>b. Test your Image</p> <p>You can test the image in single container mode:</p> <pre><code>sh devops/docker-image/run_image.sh\n</code></pre> <p> </p> <p>c. Upload Image (optional)</p> <p>You would next upload the image to docker hub.  </p> <p>If you use the same names as here, skip that, and use our image: <code>apilogicserver/aicustomerorders</code>.</p> <p> </p> <p>d. Push the project</p> <p>It's also a good time to push your project to git.  Again, if you've used the same names as here, you can use our project.</p> <p> </p> <p>e. Deploy to Azure Cloud</p> <p>Login to the azure portal, and:</p> <pre><code>git clone https://github.com/ApiLogicServer/ai_customer_orders.git\ncd ai_customer_orders\nsh devops/docker-compose-dev-azure/azure-deploy.sh\n</code></pre> <p> </p>"},{"location":"Tech-Agile/#4-iterate-declare-rules","title":"4. Iterate: Declare Rules","text":"<p>Collaboration might uncover a requirement for Check Credit.  Let\u2019s implement it\u2026</p>"},{"location":"Tech-Agile/#a-declare-logic","title":"a. Declare Logic","text":"<p>Rules are an executable design.  Use your IDE (code completion, etc), to replace 280 lines of code with the 5 spreadsheet-like rules below.  Note they map exactly to our natural language design:</p> <pre><code>    ''' Declarative multi-table derivations and constraints, extensible with Python. \n\n    Brief background: see readme_declare_logic.md\n\n    Use code completion (Rule.) to declare rules here:\n\n\n    1. Customer.Balance &lt;= CreditLimit\n\n    2. Customer.Balance = Sum(Order.AmountTotal where unshipped)\n\n    3. Order.AmountTotal = Sum(Items.Amount)\n\n    4. Items.Amount = Quantity * UnitPrice\n\n    5. Items.UnitPrice = copy from Product\n    '''\n\n    Rule.constraint(validate=models.Customer,       # logic design translates directly into rules\n        as_condition=lambda row: row.Balance &lt;= row.CreditLimit,\n        error_msg=\"balance ({round(row.Balance, 2)}) exceeds credit ({round(row.CreditLimit, 2)})\")\n\n    Rule.sum(derive=models.Customer.Balance,        # adjust iff AmountTotal or ShippedDate or CustomerID changes\n        as_sum_of=models.Order.AmountTotal,\n        where=lambda row: row.ShipDate is None)     # adjusts - *not* a sql select sum...\n\n    Rule.sum(derive=models.Order.AmountTotal,       # adjust iff Amount or OrderID changes\n        as_sum_of=models.Item.Amount)\n\n    Rule.formula(derive=models.Item.Amount,    # compute price * qty\n        as_expression=lambda row: row.UnitPrice * row.Quantity)\n\n    Rule.copy(derive=models.Item.UnitPrice,    # get Product Price (e,g., on insert, or ProductId change)\n        from_parent=models.Product.UnitPrice)\n</code></pre> <p>Observe rules are declared in Python.  Given IDE services for code completion, this is using Python as a DSL (Domain Specific Language).</p> <p> </p>"},{"location":"Tech-Agile/#-re-use-and-optimization","title":"-&gt; Re-use and Optimization","text":"<p>We can contrast this to the (not shown) ChatGPT attempt at logic.  With declarative logic, you get:</p> <ol> <li> <p>Automatic Reuse: the logic above, perhaps conceived for Place order, applies automatically to all transactions: deleting an order, changing items, moving an order to a new customer, etc.</p> </li> <li> <p>Automatic Optimizations: sql overhead is minimized by pruning, and by elimination of expensive aggregate queries.  These can result in orders of magnitude impact.</p> </li> </ol> <p>ChatGPT created triggers that missed many Use Cases, and were inefficient.  They were also not transparent; Business Users can read the rules and spot issues (\"hey, where's the tax?\"), certainly not triggers.</p> <p> </p>"},{"location":"Tech-Agile/#b-add-security","title":"b. Add Security","text":"<p>In a terminal window for your project:</p> <pre><code>ApiLogicServer add-auth --project_name=. --db_url=auth\n</code></pre> <p>Users will now need to sign in to use the Admin App.</p> <p> </p>"},{"location":"Tech-Agile/#5-next-iteration-rules-python","title":"5. Next Iteration: Rules + Python","text":"<p>Not only are spreadsheet-like rules 40X more concise, they meaningfully simplify maintenance.  Let\u2019s take an example.</p> <p>Green Discounts</p> <p>Give a 10% discount for carbon-neutral products for 10 items or more.</p> <p>Automation still applies; we execute the steps below.</p> <p> </p> <p>a. Add a Database Column</p> <pre><code>$ sqlite3 database/db.sqlite\n&gt;   alter table Products Add CarbonNeutral Boolean;\n&gt;   .exit\n</code></pre> <p> </p> <p>b. Rebuild the project, preserving customizations</p> <pre><code>cd ..  project parent directory\nApiLogicServer rebuild-from-database --project_name=ai_customer_orders --db_url=sqlite:///ai_customer_orders/database/db.sqlite\n</code></pre> <p> </p> <p>c. Update your admin app</p> <p>Use your IDE to merge <code>/ui/admin/admin-merge.yml</code> -&gt; <code>/ui/admin/admin.yml</code>.`</p> <p> </p> <p>d. Declare logic</p> <pre><code>    def derive_amount(row: models.Item, old_row: models.Item, logic_row: LogicRow):\n        amount = row.Quantity * row.UnitPrice\n        if row.Product.CarbonNeutral and row.Quantity &gt;= 10:\n            amount = amount * Decimal(0.9)\n        return amount\n\n\n    Rule.formula(derive=models.Item.Amount, calling=derive_amount)\n</code></pre> <p> </p> <p>This simple example illustrates some significant aspects of iteration.</p> <p> </p>"},{"location":"Tech-Agile/#a-maintenance-logic-ordering","title":"a. Maintenance: Logic Ordering","text":"<p>Along with perhaps documentation, one of the tasks programmers most loathe is maintenance.  That\u2019s because it\u2019s not about writing code, but it\u2019s mainly archaeology - deciphering code someone else wrote, just so you can add 4 or 5 lines they\u2019ll hopefully be called and function correctly.</p> <p>Rules change that, since they self-order their execution (and pruning) based on system-discovered dependencies.  So, to alter logic, you just \u201cdrop a new rule in the bucket\u201d, and the system will ensure it\u2019s called in the proper order, and re-used over all the Use Cases to which it applies.</p> <p> </p>"},{"location":"Tech-Agile/#b-extensibility-rules-python","title":"b. Extensibility: Rules + Python","text":"<p>In this case, we needed to do some if/else testing, and it was more convenient to add a dash of Python.  While you have the full object-oriented power of Python, this is simpler, more like Python as a 4GL.  </p> <p>What\u2019s important is that once you are in such functions, you can utilize Python libraries, invoke shared code, make web service calls, send email or messages, etc.  You have all the power of rules, plus the unrestricted flexibility of Python.</p> <p> </p>"},{"location":"Tech-Agile/#c-debugging-ide-logging","title":"c. Debugging: IDE, Logging","text":"<p>The screen shot above illustrates that debugging logic is what you\u2019d expect: use your IDE's debugger.</p> <p>In addition, the Logic Log lists every rule that fires, with indents for multi-table chaining (not visible in this screenshot).  Each line shows the old/new values of every attribute, so the transaction state is transparent.</p> <p> </p>"},{"location":"Tech-Agile/#d-rebuild-logic-preserved","title":"d. Rebuild: Logic Preserved","text":"<p>Note we rebuilt the project from our altered database, without losing customizations.</p> <p> </p>"},{"location":"Tech-Agile/#summary","title":"Summary","text":"<p>In 6 minutes, you've used ChatGPT and API Logic Server to convert an idea into working software -- 5 rules, 4 lines of Python.  The process was simple:</p> <ul> <li> <p>Used the <code>ApiLogicServer create</code> command to create an executable project</p> <ul> <li>A Self-Serve API to unblock UI Developers -- Day 1</li> <li>An Admin App for Business User Collaboration -- Day 1</li> </ul> </li> <li> <p>Enabled Collaboration with automated deployment services</p> </li> <li> <p>Iterated the project in your IDE to implement new requirements</p> <ul> <li>With Rules -- 40X more concise than code</li> <li>And Python -- for complete flexibility</li> </ul> </li> </ul> <p>It all works with standard tooling: Python, your IDE, and container-based deployment.</p>"},{"location":"Tech-Budget-App/","title":"Tech Budget App","text":""},{"location":"Tech-Budget-App/#budget-app","title":"Budget App","text":"<p>This is an example of how rules can be used to do a multi table rollup  (budget -&gt; category -&gt; month -&gt; yr) - it also introduces the rule flag on sum and count (insert_parent=True). This allows the child to trigger the creation of the parent before doing the sum or count aggregation.</p>"},{"location":"Tech-Budget-App/#install","title":"Install","text":"<p>This will create the sample application to run - press f5 (no security) <pre><code>$ApiLogicServer create --project_name=BudgetApp --db_url=BudgetApp\n\n$cd BudgetApp\n$code .\n</code></pre></p>"},{"location":"Tech-Budget-App/#data-model","title":"Data Model","text":"<p>The Budget table holds the monthly values by category, tenant_user, and date.  This will rollup into Category, Month, and Yr.  The Transactions table holds the actual values (one to many) so import from a CSV using the API will allow comparison with budget values. The database folder has the schema for both MySQL and SQLite.  </p> <p></p> <p> </p> <p></p> <p> </p>"},{"location":"Tech-Budget-App/#multi-tenant-and-security","title":"Multi Tenant and Security","text":"<p>The ability to filter users (tenant) to see only their own data is implemented in the declarative_security.py. The login user_id should match the tenant_user user_id.</p> <pre><code>GlobalFilter(global_filter_attribute_name='user_id', \n     roles_not_filtered = ['sa'],\n     filter=\"{entity_class}.user_id == Security.current_user().id\")\n</code></pre>"},{"location":"Tech-Budget-App/#budget-api","title":"Budget API","text":"<p>The api folder (api/customize_api.py) has user defined endpoints that can be used to insert budget and transaction amounts. This demonstrates how to customize and create new REST endpoints.</p> <pre><code>curl -X 'POST' \\\n  'http://localhost:5656/api/ServicesEndPoint/budget_insert' \\\n  -H 'accept: application/vnd.api+json' \\\n  -H 'Content-Type: application/json' \\\n  -d '{\n  \"meta\": {\n    \"method\": \"budget_insert\",\n    \"args\": {\n      \"year_id\": 2023,\n      \"qtr_id\": 1,\n      \"month_id\": 1,\n      \"user_id\": 1,\n      \"category_id\": 1,\n      \"amount\": 100,\n      \"description\": \"Budget  insert\"\n    }\n  }'\n</code></pre>"},{"location":"Tech-Budget-App/#actual-transactions-api","title":"Actual Transactions API","text":"<p>The transactions are actual entries from different named accounts. The Budget table will sum and count these transactions.  The API can be used to post these entries.</p> <pre><code>curl -X 'POST' \\\n  'http://localhost:5656/api/ServicesEndPoint/transaction_insert' \\\n  -H 'accept: application/vnd.api+json' \\\n  -H 'Content-Type: application/json' \\\n  -d '{\n  \"meta\": {\n    \"method\": \"transaction_insert\",\n    \"args\": {\n      \"budget_id\": 1,\n      \"amount\": 100,\n      \"category_id\": 1,\n      \"description\": \"test transaction insert\"\n    }\n  }\n}'\n</code></pre>"},{"location":"Tech-Budget-App/#declarative-logic","title":"Declarative Logic","text":"<p>The rules are un-ordered bu represent the rollup (sums) of budget and actual transactions.  <pre><code>      use_parent_insert = True\n\n    # Roll up budget amounts\n\n    Rule.sum(derive=models.YrTotal.budget_total, as_sum_of=models.CategoryTotal.budget_total,insert_parent=use_parent_insert)\n    Rule.sum(derive=models.CategoryTotal.budget_total, as_sum_of=models.Budget.amount,insert_parent=use_parent_insert)\n    Rule.sum(derive=models.CategoryTotal.actual_amount, as_sum_of=models.Budget.actual_amount,insert_parent=use_parent_insert)\n    Rule.sum(derive=models.MonthTotal.budget_total, as_sum_of=models.Budget.amount,insert_parent=use_parent_insert)\n    Rule.sum(derive=models.Budget.actual_amount, as_sum_of=models.Transaction.amount,insert_parent=use_parent_insert)\n\n    Rule.copy(derive=models.Budget.is_expense,from_parent=models.Category.is_expense)\n    Rule.copy(derive=models.CategoryTotal.is_expense,from_parent=models.Category.is_expense)\n    Rule.count(derive=models.Budget.count_transactions,as_count_of=models.Transaction)\n\n    # Calculate variance from budget to actual\n    Rule.formula(derive=models.Budget.variance_amount, as_expression=lambda row: row.actual_amount - row.amount)\n    Rule.formula(derive=models.CategoryTotal.variance_amount, as_expression=lambda row: row.actual_amount - row.budget_total)\n    Rule.formula(derive=models.MonthTotal.variance_amount, as_expression=lambda row: row.actual_amount - row.budget_total)\n    Rule.formula(derive=models.YrTotal.variance_amount, as_expression=lambda row: row.actual_amount - row.budget_total)\n\n    # Roll up actual transaction amounts into Budget\n\n    Rule.sum(derive=models.YrTotal.actual_amount, as_sum_of=models.CategoryTotal.actual_amount,insert_parent=use_parent_insert)\n    Rule.sum(derive=models.MonthTotal.actual_amount, as_sum_of=models.Budget.actual_amount,insert_parent=use_parent_insert)\n\n    # Copy Budget (parent) values \n\n    Rule.copy(derive=models.Transaction.category_id,from_parent=models.Budget.category_id)\n    Rule.copy(derive=models.Transaction.user_id,from_parent=models.Budget.user_id)\n    Rule.copy(derive=models.Transaction.year_id,from_parent=models.Budget.year_id)\n    Rule.copy(derive=models.Transaction.month_id,from_parent=models.Budget.month_id)\n    Rule.copy(derive=models.Transaction.is_expense,from_parent=models.Category.is_expense)\n</code></pre></p>"},{"location":"Tech-Budget-App/#logic-trace","title":"Logic Trace","text":"<p>As each budget entry is posted via API (/ServiceEndpoint/insert_budget) the logic trace shows how the rules are fired.</p> <pre><code>Rules Fired:        ##\n  Budget        ##\n    1. Derive Budget.is_expense as Copy(category.is_expense)        ##\n    2. Derive Budget.variance_amount as Formula (1): Rule.formula(derive=models.Budget.variance_amount [...]        ##\n  CategoryTotal     ##\n    3. Derive CategoryTotal.budget_total as Sum(Budget.amount Where None, insert_parent)        ##\n    4. Derive CategoryTotal.is_expense as Copy(category.is_expense)     ##\n    5. Derive CategoryTotal.actual_amount as Sum(Budget.actual_amount Where None, insert_parent)        ##\n    6. Derive CategoryTotal.variance_amount as Formula (1): Rule.formula(derive=models.CategoryTotal.variance [...]     ##\n  MonthTotal        ##\n    7. Derive MonthTotal.budget_total as Sum(Budget.amount Where None, insert_parent)       ##\n    8. Derive MonthTotal.actual_amount as Sum(Budget.actual_amount Where None, insert_parent)       ##\n    9. Derive MonthTotal.variance_amount as Formula (1): Rule.formula(derive=models.MonthTotal.variance_am [...]        ##\n  YrTotal       ##\n    10. Derive YrTotal.budget_total as Sum(CategoryTotal.budget_total Where None, insert_parent)        ##\n    11. Derive YrTotal.variance_amount as Formula (1): Rule.formula(derive=models.YrTotal.variance_amoun [...]      ##\n    12. Derive YrTotal.actual_amount as Sum(CategoryTotal.actual_amount Where None, insert_parent)      ##\n</code></pre>"},{"location":"Tech-Budget-App/#behave-testing","title":"Behave Testing","text":"<p>The behave test is run after starting the server (no security) - this will attempt to insert a budget and transaction and see if the YR_TOTAL values change. Run Behave Test (no security) and then review the behave.log See the directory test/api_logic_server_behave features/budget.features and steps/budget.py.</p>"},{"location":"Tech-CodeSpaces/","title":"CodeSpaces","text":"<p>CodeSpaces is a GitHub project that enables you to use VSCode in your Browser to develop on rapidly deployed docker containers.  It's quite remarkable.  </p> <p>At this point, there are no outstanding issues in using Codespaces.  </p> <p>To use Codespaces, see the procedure here.</p>"},{"location":"Tech-Conference-PyCon23-Talk/","title":"PyCon23 Talk","text":"<p>Talk Guidelines</p> <p>Submittals</p> <p> </p>"},{"location":"Tech-Conference-PyCon23-Talk/#title","title":"Title","text":"<p>Creating Web Applications Instantly with API Logic Server - create with one command, customize in your IDE</p>"},{"location":"Tech-Conference-PyCon23-Talk/#description","title":"Description","text":"<p>This Talk introduces a meaningfully faster and simpler approach for building database web apps.</p> <p> </p>"},{"location":"Tech-Conference-PyCon23-Talk/#overview","title":"Overview","text":"<p>In this talk:</p> <ul> <li>You'll see a complete, multi-table database web app - built, run, customized in VSCode<ul> <li>You'll be able to use it tomorrow on your organizations databases</li> </ul> </li> <li>You'll see several popular technologies in use (listed below)<ul> <li>You can explore these - running code, in a working project</li> </ul> </li> </ul> <p> </p>"},{"location":"Tech-Conference-PyCon23-Talk/#what-is-api-logic-server","title":"What is API Logic Server?","text":"<p>API Logic Server is an open source Python system for creating customizable database web app projects from a database:</p> <ul> <li> <p>API: endpoint for each table - filtering, sorting, pagination and related data access</p> </li> <li> <p>Admin UI: multi-page / multi-table apps, with page navigations, automatic joins and declarative hide/show</p> </li> </ul> <p>Projects are Customizable - use VSCode for  edit/debug</p> <p>Declare spreadsheet-like rules for multi-table derivations and constraints, customizable with Python </p> <p> </p>"},{"location":"Tech-Conference-PyCon23-Talk/#excellent-intro-to-popular-technologies","title":"Excellent Intro to Popular Technologies","text":"<p>This tutorial introduces other technologies you perhaps wanted to explore, with running code:</p> Technology Used For Python Customization SQLAlchemy ORM database access Flask Web Framework VSCode IDE Codespaces Cloud-based Dev Container APIs Networked database access Docker Isolated Containers React-Admin Simplified React UI framework Declarative What not how <p> </p>"},{"location":"Tech-Conference-PyCon23-Talk/#audience","title":"Audience","text":"<p>This tutorial is for developers interested in database systems, and the technologies above.  Required background:</p> <ul> <li> <p>Basic programming: <code>if/else</code>, parameterized function calls, <code>row.column</code> object access, and basic event oriented programming.  Python experience is not required.</p> </li> <li> <p>Some database: aware of tables, columns and foreign keys.</p> </li> </ul> <p> </p>"},{"location":"Tech-Conference-PyCon23-Talk/#outline","title":"Outline","text":"<p>This will be 75% live demo, with slides for context and background:</p> <ul> <li> <p>Introduction (5 min) - why the project was created</p> </li> <li> <p>Create Codespace (5) - create Codespace, access in Browser</p> </li> <li> <p>Create API Logic Project (5) - use CLI to create project from pre-supplied database</p> </li> <li> <p>Explore Project (10) - explore the created UI, exercise the API in Swagger</p> </li> <li> <p>Customize Project (10) - use VSCode (in Browser) to add an API Endpoint and debug it, hide/show UI fields</p> </li> <li> <p>Declarative Rules (10) - use VSCode to declare spreadsheet like rules, and test/debug</p> </li> <li> <p>Wrap (15) - final remarks, questions, other topics to explore (testing, schema migration)</p> </li> </ul> <p>Yes, a lot to cover, but automation makes it possible.  Even easy.</p> <p> </p>"},{"location":"Tech-Conference-PyCon23-Talk/#requirements","title":"Requirements","text":"<p>An internet connection, though I can demo locally if that becomes a problem.</p>"},{"location":"Tech-Conference-PyCon23-Tutorial/","title":"PyCon23 Tutorial","text":""},{"location":"Tech-Conference-PyCon23-Tutorial/#description","title":"Description","text":"<p>This Tutorial introduces a meaningfully faster and simpler approach for building database web apps.</p> <p> </p>"},{"location":"Tech-Conference-PyCon23-Tutorial/#overview","title":"Overview","text":"<p>In this tutorial:</p> <ul> <li>You'll build a complete, multi-table database web app - built, run, customized in VSCode<ul> <li>You'll be able to use it tomorrow on your organizations databases</li> </ul> </li> <li>You'll see several popular technologies in use (listed below)<ul> <li>You can explore these - running code, in a working project</li> </ul> </li> </ul> <p> </p>"},{"location":"Tech-Conference-PyCon23-Tutorial/#what-is-api-logic-server","title":"What is API Logic Server?","text":"<p>API Logic Server is an open source Python system for creating customizable database web app projects from a database:</p> <ul> <li> <p>API: endpoint for each table - filtering, sorting, pagination and related data access</p> </li> <li> <p>Admin UI: multi-page / multi-table apps, with page navigations, automatic joins and declarative hide/show</p> </li> </ul> <p>Projects are Customizable - use VSCode for  edit/debug</p> <p>Declare spreadsheet-like rules for multi-table derivations and constraints, customizable with Python (key innovation)</p> <p> </p>"},{"location":"Tech-Conference-PyCon23-Tutorial/#excellent-intro-to-popular-technologies","title":"Excellent Intro to Popular Technologies","text":"<p>This tutorial introduces other technologies you perhaps wanted to explore, with running code:</p> Technology Used For Python Customization SQLAlchemy ORM database access Flask Web Framework VSCode IDE Codespaces Cloud-based Dev Container APIs Networked database access Docker Isolated Containers React-Admin Simplified React UI framework Declarative What not how <p> </p>"},{"location":"Tech-Conference-PyCon23-Tutorial/#requirements","title":"Requirements","text":"<p>You'll need a laptop, and a GitHub account.  Your dev environment will not be affected.</p> <p> </p>"},{"location":"Tech-Conference-PyCon23-Tutorial/#audience","title":"Audience","text":"<p>This tutorial is for developers interested in database systems, and the technologies above.  Required background:</p> <ul> <li> <p>Basic programming: <code>if/else</code>, parameterized function calls, <code>row.column</code> object access, and basic event oriented programming.  Python experience is not required.</p> </li> <li> <p>Some database: aware of tables, columns and foreign keys.</p> </li> </ul> <p> </p>"},{"location":"Tech-Conference-PyCon23-Tutorial/#outline","title":"Outline","text":"<p>Short lectures, plus watch/do labs:</p> Section Minutes Contents Introduction 15 Project origin Start Codespace 15 VSCode, in your browser Create Project 15 Database pre-supplied Explore 30 API, UI Customize 30 * API: add endpoint* UI: hide/show fields Declarative Rules 30 Declare/debug Wrap 15 (2.25 hours) <p> </p>"},{"location":"Tech-Conference-PyCon23-Tutorial/#text-outline","title":"Text Outline","text":"<ul> <li> <p>Introduction (15 min) - why the project was created</p> </li> <li> <p>Create Codespace (15 min) - create Codespace, access in Browser</p> </li> <li> <p>Create API Logic Project (15) - use CLI to create project from pre-supplied database</p> </li> <li> <p>Explore Project (30) - explore the created UI, exercise the API in Swagger</p> </li> <li> <p>Customize Project (30) - use VSCode (in Browser) to add an API Endpoint and debug it, hide/show UI fields</p> </li> <li> <p>Declarative Rules (30) - use VSCode to declare spreadsheet like rules, and test/debug</p> </li> <li> <p>Wrap (15 - 2.25 hours) - final remarks, other topics to explore (testing, schema migration)</p> </li> </ul> <p>Yes, a lot to cover, but automation makes it possible.  Even easy.</p>"},{"location":"Tech-Conference/","title":"Conference","text":"<p>Submission materials for PyCon 2023, April 19 in Salt Lake City.  Links:</p> <ul> <li> <p>Tutorial Samples</p> </li> <li> <p>Proposal Submission</p> </li> </ul>"},{"location":"Tech-Conference/#description","title":"Description","text":""},{"location":"Tech-Conference/#title","title":"Title","text":"<p>How to Create Web Applications Instantly with API Logic Server - create with one command, customize in your IDE</p>"},{"location":"Tech-Conference/#description_1","title":"Description","text":"<p>Creating web-oriented database projects requires substantial time and background.  In this Tutorial, we introduce a meaningfully faster and simpler approach.</p> <p> </p>"},{"location":"Tech-Conference/#overview","title":"Overview","text":"<p>In this tutorial:</p> <ul> <li>Seeing is believing - you will build, run and customize a complete multi-table database web app<ul> <li>You will be able to use it tomorrow on your organizations databases</li> </ul> </li> <li>You will also gain an excellent introduction to several popular Python technologies -- web apps, database access, project development, etc.</li> </ul> <p> </p>"},{"location":"Tech-Conference/#what-is-api-logic-server","title":"What is API Logic Server?","text":"<p>API Logic Server is an open source Python system that creates customizable database web app projects:</p> <ul> <li> <p>Creation is Instant: create executable projects from your database with a single command.  Projects are Highly Functional, providing:</p> <ul> <li> <p>API: an endpoint for each table, with filtering, sorting, pagination and related data access</p> </li> <li> <p>Admin UI: multi-page / multi-table apps, with page navigations, automatic joins and declarative hide/show</p> </li> </ul> </li> <li> <p>Projects are Customizable, using your IDE: such as VSCode, PyCharm, etc, for familiar edit/debug services</p> </li> <li> <p>Business Logic Automation: using unique spreadsheet-like rules, extensible with Python </p> </li> </ul> <p> </p>"},{"location":"Tech-Conference/#tutorial-build-and-customize-a-system","title":"Tutorial - build and customize a system","text":"<p>In this Tutorial, you will:</p> <ul> <li> <p>Create an interesting multi-table application from a pre-supplied sample database</p> </li> <li> <p>Run it</p> </li> <li> <p>Customize it using VSCode.</p> </li> <li> <p>Learn about declarative, spreadsheet-like business logic for multi-table constraints and derivations</p> </li> </ul> <p> </p>"},{"location":"Tech-Conference/#excellent-intro-to-popular-technologies","title":"Excellent Intro to Popular Technologies","text":"<p>This talk will also give you an intro to other technologies you may have already wanted to explore, with running code you can extend:</p> Technology Used For Notes Python Popular OO Language New to Python?  This is a great place to learn it * Start with running code * Explore, edit and debug in VSCode * No install, no config SQLAlchemy Popular Python ORM Python-friendly object-oriented database access Flask Popular Python Web Framework Use to add custom endpoints (examples provided) VSCode Popular IDE Use to customize API Logic Projects Codespaces Cloud-based Dev Container Provides IDE, git, etc - via a Browser interface APIs Networked database access Via the SAFRS framework Docker Isolated Containers Eg., DBMS, API Logic Server, Your App React-Admin Simplified React UI framework Further simplified via YAML model Declarative Vague term (\"what not how\") We'll describe key aspects <p> </p>"},{"location":"Tech-Conference/#what-you-will-need","title":"What you will need","text":"<p>You will need a laptop with a Browser connection, and a GitHub account.  You do not need a Python install, a database, or an IDE... and if you do have these, they won't be affected.</p> <p> </p>"},{"location":"Tech-Conference/#audience","title":"Audience","text":"<p>This tutorial is for developers interested in database systems, and the technologies above.  Required background:</p> <ul> <li> <p>Basic programming familiarity (if you are familiar with <code>if/else</code>, parameterized function calls, <code>row.column</code> object access, and basic event oriented programming, you are all set).  Python experience is not required.</p> </li> <li> <p>Some database background (if you have heard of tables, columns and foreign keys, you are good to go).</p> </li> </ul> <p> </p>"},{"location":"Tech-Conference/#outline","title":"Outline","text":"<p>This will be a series of short lectures, and hands-on usage (watch and/or do):</p> Section Duration We'll cover Introduction 15 min * What is API Logic Server* Why we wrote it Starting Codespaces 15 min (total 30) * Create a cloud-based development environment * Access it VSCode via your browser) Create Project 15 min (total 45) Using pre-supplied sample database Explore Project 30 min (total 1.25 hours) * User Interface - a multi-page, multi-table application* API - using Swagger to explore pagination, filtering etc Customize Project 30 min (total 1.75 hours) * Explore Project Structure in VSCode * API: Add an Endpoint, and test it with the debugger* UI: Adjust captions, hide/show fields Business Logic 30 min (total 2.25 hours) * what it is * how to declare it * how it runs * how to debug it * what it means to be declarative Other Topics 15 min (total 2.25 hours) * Testing with the Behave Framework * Schema Migrations with Alembic <p>Yes, a lot to cover, but automation makes it possible.  Even easy.</p> <p> </p>"},{"location":"Tech-Conference/#additional-notes","title":"Additional Notes","text":"<p>Since API Logic Server is open source, you can obtain it - explore its value, and/or investigate the Popular Technologies listed in the table above.</p> <p> </p>"},{"location":"Tech-Conference/#speaking-experience","title":"Speaking Experience","text":"<p>I have given hundreds of technology presentations to large and small groups, for both technical and business audiences.</p> <ul> <li> <p>I lead the PACE DBMS effort at Wang Labs, so gave many presentations for press briefings, User Conference Keynotes and working sessions, etc.</p> </li> <li> <p>I was the CTO at Versata, so served as the lead technical presenter at User Groups and Conferences.</p> </li> </ul>"},{"location":"Tech-DSL/","title":"Model Driven","text":"<p> TL;DR - Use Python (code completion, named arguments) to declare behavior</p> <p>Python works well at multiple levels:</p> <ol> <li> <p>a full OO language for professional Developers</p> </li> <li> <p>a scripting language for Power Users</p> </li> <li> <p>a Domain Specific Language (DSL) for capturing declarative logic and security specifications, accessible to Business Users, providing:</p> <ul> <li> <p>Natural source control, code review etc.</p> </li> <li> <p>Type Checking, based on IDE support for Python typing</p> </li> <li> <p>Lookups, based on IDE support for Code Completion</p> </li> </ul> </li> </ol> <p>Declarative is a powerful technology, designed to provide agility and transparency with high level definitions.  Such definitions comprise a DSL - a Domain Specific Language.  This page explores how such language elements can be captured and stored using Python as a 4GL.</p> <p> </p>"},{"location":"Tech-DSL/#api-logic-server-is-declarative","title":"API Logic Server is Declarative","text":"<p>API Logic Server provides declarative support for model-driven development:</p> <ul> <li> <p>API - the <code>api/expose_api_models.py</code> file declares (lists) which tables are exposed in the API.</p> </li> <li> <p>Logic - using spreadsheet-like rules - see here for more information.</p> </li> <li> <p>User Interface - using a yaml file  - see here for more information.</p> </li> </ul> <p> </p>"},{"location":"Tech-DSL/#python-as-a-dsl","title":"Python as a DSL","text":"<p>There are some classic approach for capturing models in a user interface, as described below.</p> <p>API Logic Server uses your IDE and Python.  This is Python as a DSL.  So, for example, we can capture rules like this:</p> <p></p> <p>Consider the rule that defines the customer balance.  It looks like design spec, or pseudocode - except it's fully executable:</p> <pre><code>        Rule.sum(derive=models.Customer.Balance,        # adjust iff...\n            as_sum_of=models.Order.AmountTotal,\n            where=lambda row: row.ShippedDate is None)  # adjusts...\n</code></pre> <p>The following subsections explore how a modern IDE provides virtually all of the advantages of a User Interface.</p>"},{"location":"Tech-DSL/#rule-type-discovery","title":"Rule Type Discovery","text":"<p>Observe how code completion lists the possible rule types, with documentation on their meaning, examples, etc.</p>"},{"location":"Tech-DSL/#transparent","title":"Transparent","text":"<p>Python named arguments make the rules read very much like the design comments at the top of the screen shot.</p>"},{"location":"Tech-DSL/#code-completion","title":"Code Completion","text":"<p>Code completion addresses not only rule types, but the list of valid tables and columns.  These are derived from the (system-generated) <code>database/models.py</code> file.</p>"},{"location":"Tech-DSL/#type-checking","title":"Type Checking","text":"<p>Runtime services employ Python type checking for their arguments.  </p> <p>Special thanks to Mike Bayer (creator of SQLAlchemy) for a heads-up on this as I was learning Python.</p>"},{"location":"Tech-DSL/#consistent-persistence","title":"Consistent Persistence","text":"<p>Using Python files for rules eliminates the persistence question.  All the tools that work with source files operate on the DSL - editors, source control, diff, merge, etc.</p>"},{"location":"Tech-DSL/#debugging-is-natural","title":"Debugging is natural","text":"<p>A huge advantage is that debugging is built into the same IDE used for editing.  No additional tools to learn and coordinate.</p>"},{"location":"Tech-DSL/#integrated-consistent-environment","title":"Integrated, Consistent Environment","text":"<p>Well, that's what IDE means, isn't it?  Using Python as a DSL expands our notion of development from code, to include DSLs, all in one integrated environment.</p> <p> </p>"},{"location":"Tech-DSL/#appendix-ui-for-model-capture","title":"Appendix: UI for Model Capture","text":"<p>A classic approach for model capture is to use a user interface.  We have discovered that:</p> <ul> <li>Python as a DSL provides most of the value of a UIThis affords some opportunities to make things simple, </li> <li>And avoids some challenges on persisting the language elements (meta data).  These are described below.</li> </ul>"},{"location":"Tech-DSL/#type-checking-lookups","title":"Type checking, Lookups","text":"<p>It's valuable to ensure that the language elements are properly typed - numbers are valid, etc.  Capturing these in a User Interface enables such checking.</p> <p>Even more important, a User Interface can \"teach\" language elements to developers - provide a list of rules, a list of tables or columns for defining rules, and so forth.</p>"},{"location":"Tech-DSL/#persist-in-a-database","title":"Persist in a database?","text":"<p>There must of course be provisions for persisting the language elements (\"meta data\") in a way they can be viewed and editing later.  They could be stored in a database, opening up attractive \"eat your own dogfood\" opportunities to use rules to validate rules.</p> <p>This is attractive.  I've personally used this approach.  The drawback is that databases really don't provide source control at a low level of granularity.  Developers need to check in rules, back them out - all of these are very cumbersome in a database.  You can't just use GitHub.</p>"},{"location":"Tech-DSL/#persist-as-markup-language","title":"Persist as markup language?","text":"<p>Another approach, also one I've used, is to store language elements as markup files - xml, json, yaml etc.  This works well - the meta data is now files, and can be used with source control systems, can be diff'd, etc.</p> <p>However, such files represent a transformation from what the developer supplied in the User Interface.  This adds some burden to developers - perhaps not onerous, but not natural.</p>"},{"location":"Tech-Docker/","title":"Docker","text":""},{"location":"Tech-Docker/#appendix-general-docker-procedures","title":"Appendix: General Docker Procedures","text":"<p>The sections below outline learnings from a beginners use of Docker (me).  If they save you time, we're both happy.</p>"},{"location":"Tech-Docker/#docker-installation","title":"Docker Installation","text":"<p>It's simple on a Mac, running natively.  Other configurations may cause drama:</p> <ul> <li>Virtualization - under virtualization (e.g., VMWare Fusion - running windows under Mac), it is much slower.</li> <li>Bootcamp - I was not able to make it work -- Windows thought the firmware did not support virtualization (on a large Intel-based Macbook Pro)</li> </ul> <p>On the Fusion Windows, it seemed that I needed Windows Pro (not Home).  There are various sites that discuss Windows Home.  I was not willing to fiddle with that, so I just went Pro, which worked well.</p> <p> </p>"},{"location":"Tech-Docker/#creating-containerized-api-logic-server-projects-for-vscode","title":"Creating Containerized API Logic Server Projects for VSCode","text":"<p>When you use API Logic Server to create projects, the resultant projects can run with a <code>venv</code> (locally installed Python), or in a Docker container.</p> <p>To make this work, <code>ApiLogicServer create</code> builds the following files in your project:</p> <ul> <li>.devcontainer/devcontainer.json</li> <li>For_VSCode.dockerfile</li> </ul> <p> </p>"},{"location":"Tech-Docker/#preparing-a-python-image-for-api-logic-server","title":"Preparing a Python Image (for API Logic Server)","text":"<p>Recall that an image is something you can store on Docker Hub so others can download and run.  It's a good idea for project to have a repository of docker images, such as ApiLogicServer, test databases, etc.</p> <p>The running thing is called a container.  They can but typically do not utilize local storage, instead accessing external files through mounts, and external systems (databases, APIs) via docker networks and ports.</p> <p>I had to prepare a Docker image for ApiLogicServer (providing Python, API Logic Server CLI and runtime libraries).  That requires a Dockerfile, where I also keep my notes.</p> <p>The process was straight-forward using the noted links... until <code>pyodbc</code> was added for Sql Server.  That added 500MB, and was quite complicated.</p> <p> </p>"},{"location":"Tech-Docker/#preparing-a-database-image-for-self-contained-databases","title":"Preparing a Database Image (for self-contained databases)","text":"<p>In addition to the ApiLogicServer image, I wanted folks to be able to access a dockerized MySQL database.  Further, I wanted this to be self-contained to avoid creating files on folks' hard drives.</p> <p>I therefore needed to:</p> <ol> <li>acquire a self-contained MsSQL image (again, that's not the default - the default is data persisted to a volume), and</li> <li>update this database with test data</li> <li>save this altered container as an image (<code>docker commit...</code>)</li> </ol> <p>I used this Dockerfile which again includes my notes.</p> <p> </p>"},{"location":"Tech-Docker/#sql-server-docker-creation","title":"SQL Server Docker creation","text":"<p>It was prepared as described in this Dockerfile.</p> <p>For JDBC tools, specify: <code>jdbc:sqlserver://localhost:1433;database= NORTHWND</code></p>"},{"location":"Tech-Enterprise-Vibe/","title":"Enterprise Vibe","text":"<ul> <li> <p>Mega Demo (video? Doc? WebSite?)</p> </li> <li> <p>Working Software Now - Std Project/IDE</p> </li> <li> <p>New Idea: GenAI or WebGenAI</p> </li> <li> <p>Nail Reqmts - working screens</p> </li> <li> <p>Vibe safely - AI Coding Tools</p> </li> <li> <p>Existing System</p> </li> <li> <p>GemAI Logic, or Code Completion\u00a0</p> </li> <li> <p>MCP</p> </li> <li>Corp Security</li> <li> <p>Integration</p> </li> <li> <p>Kafka</p> </li> <li> <p>Open Deployment - Scalable Container</p> </li> </ul> <p>Waves * GenAI * Bus Logic Agents * MCP * Vibe</p> <p>Demo * A. Create - wsn     * New Idea: GenAI or WebGenAI     * Existing DB: CLI * B. add-cust:      * Logic (GenAI or Code Completion)     * Security * C. add-cust: iterate (Python)     * B2B</p>"},{"location":"Tech-Install-Python/","title":"Python Installation","text":""},{"location":"Tech-Install-Python/#install-python-if-required","title":"Install Python (if required)","text":"<p>To install Python:</p> <ul> <li> <p>On Windows - run the windows installer - be sure to specify \"add Python to Path\"</p> </li> <li> <p>On Mac/Linux - your OS may provide installer options.</p> <ul> <li> <p>For example, Ubuntu provides the Software Update utility.  </p> </li> <li> <p>Mac users can use the standard installer; follow the recommendations to install certificates and update your shell.</p> </li> </ul> <p>Installing Python on the Mac can be... dramatic.  Consult the Troubleshooting Guide.</p> <ul> <li>Alternatively, many prefer using homebrew, as described here</li> </ul> </li> </ul>"},{"location":"Tech-Learning-Flask/","title":"Learning Flask","text":"<p>There is a conventional approach to learning a framework such as Flask.  Learn with a Tutorial, then build, starting small, gradually increasing functionality. There are dozens to hundreds of such Tutorials, and they are very helpful.</p> <p>Here we offer a complementary approach, one that entirely reverses the script.  Build a complete running project - explore within a minute.  Then learn: alter it, debug it -- and then how to create it, in seconds. </p> <p>We call it an API Fiddle - try it here, described below.</p> <p> </p>"},{"location":"Tech-Learning-Flask/#api-fiddle-an-in-action-flask-tutorial","title":"API Fiddle: an In Action Flask Tutorial","text":"<p>Tools like JSFiddle are extremely useful.  Without installation, you can use your Browser to explore existing JavaScript / HTML code, alter it, and see the results.</p> <p>Here, we apply this approach to an entire app: an API Fiddle.  What's that?</p> <ul> <li>Like a JSFiddle, it opens in your Browser.  No install.</li> <li>But it's a complete Flask App: a running project, with a database, accessed with SQLAlchemy.</li> <li>Accessed via VSCode, running in your Browser, courtesy Codespaces.<ul> <li>Codespaces is a remarkable new product from GitHub.  When you click the link above, it requisitions a server, installs your project (and all its dependencies, such as Python and Flask), and opens it in VSCode in your Browser.</li> <li>You can also use this API Fiddle learn how to use Codespaces - how to set up a dev container, and use it on your own projects.</li> </ul> </li> </ul> <p>The link (at the end) actually opens 2 projects.  The first is a minimal Flask/SQLAlchemy app.  It has a readme - use it to explore the code, run it, alter / debug it, etc.  The other illustrates how API Logic Server creates executable, customizable Flask projects, with a single command.</p> <p> </p>"},{"location":"Tech-Learning-Flask/#deliver-while-learning","title":"Deliver While Learning","text":"<p>But that's not all.</p> <p>Two additional projects are provided in the API Fiddle.  These show how you can create a Flask project with a single command, then customize it in your IDE with standard Flask and SQLAlchemy, with API Logic Server.</p> <p>API Logic Server is an open source Python app, already loaded into our Codespace project.  It creates an entire Flask project, like this:</p> Create a Flask project with this command<pre><code>ApiLogicServer create --project_name=ApiLogicProject --db_url=nw-  # use Northwind, no customizations\n</code></pre> <p>This reads your database schema and creates a complete, executable Flask project, instantly:</p> <ul> <li> <p>API: an endpoint for each table, with filtering, sorting, pagination and related data access.  Swagger is automatic.</p> </li> <li> <p>Admin UI: multi-page / multi-table apps, with page navigations, automatic joins and declarative hide/show.</p> </li> <li> <p>Customizable: use your IDE, Flask and SQLAlchemy to customize your project, including unique delarative spreadsheet-like rules for logic and security.  Custom UIs can be built using your tool of choice (React, Angular, etc), using the API.</p> </li> </ul> <p> </p>"},{"location":"Tech-Learning-Flask/#intrigued","title":"Intrigued?","text":"<p>Click here to start it  (takes about a minute to load).  We'd love feedback - provide it here.</p>"},{"location":"Tech-Learning/","title":"Tech Learning","text":"<p>There is a conventional approach to learning a framework such as Flask.  Learn with a Tutorial, then build, starting small, gradually increasing functionality. There are dozens to hundreds of such Tutorials, and they are very helpful.</p> <p>Here we offer a complementary approach, one that entirely reverses the script.  Build a complete running project - explore within a minute.  Then learn: alter it, debug it -- and then how to create it, in seconds. </p> <p>We call it an App Fiddle - try it here.</p> <p> </p>"},{"location":"Tech-Learning/#app-fiddle-an-in-action-flask-tutorial","title":"App Fiddle: an In Action Flask Tutorial","text":"<p>Tools like JSFiddle are extremely useful.  Without installation, you can use your Browser to explore existing JavaScript / HTML code, alter it, and see the results.</p> <p></p> <p>Here, we apply this approach to an entire app: an App Fiddle.  What's that?</p> <ul> <li>Like a JSFiddle, it opens in your Browser.  No install.</li> <li>But it's a complete Flask App: a running project, with a database, accessed with SQLAlchemy.</li> <li>Accessed via VSCode, running in your Browser, courtesy Codespaces.<ul> <li>Codespaces is a remarkable new product from GitHub.  When you click the link above, it requisitions a server, installs your project (and all its dependencies, such as Python and Flask), and opens it in VSCode in your Browser.</li> <li>You can also use this App Fiddle to explore Codespaces, how to set up a dev container, and use it on your own projects.</li> </ul> </li> </ul> <p>Click this link](https://github.com/codespaces/new?hide_repo_select=true&amp;ref=main&amp;repo=593459232) to open a codespace containing 3 projects.  The first is a minimal Flask/SQLAlchemy app.  The other 2 illustrate how API Logic Server creates executable, customizable Flask projects, with a single command.</p> <p> </p>"},{"location":"Tech-Learning/#deliver-while-learning","title":"Deliver While Learning","text":"<p>But that's not all.</p> <p> While the first project shows it's pretty simple to create a single endpoint, gather some data and return it, it's a lot more work to create an entire project (multiple endpoints, an Admin App, etc).  That's a horse of an entirely different feather!</p> <p>So, we've created API Logic Server.  It's an open source Python app, already loaded into our Codespace project.</p> <p>It creates an entire Flask project with a single command, like this:</p> Create a Flask project with this command<pre><code>ApiLogicServer create --project_name=ApiLogicProject --db_url=nw-  # use Northwind, no customizations\n</code></pre> <p>This reads your database schema and creates a complete, executable project, instantly:</p> <ul> <li> <p>API: an endpoint for each table, with filtering, sorting, pagination and related data access.  Swagger is automatic.</p> </li> <li> <p>Admin UI: multi-page / multi-table apps, with page navigations, automatic joins and declarative hide/show.  It executes a yaml file, so basic customizations do not require HTML or JavaScript background.</p> <ul> <li>Custom UIs can be built using your tool of choice (React, Angular, etc), using the API.</li> </ul> </li> </ul> <p> </p>"},{"location":"Tech-Learning/#fully-customizable-standard-python-flask-sqlalchemy","title":"Fully Customizable - Standard Python, Flask, SQLAlchemy","text":"<p>Creating the executable project requires no background in Flask, SQLAlchemy, or even Python.  In fact, you can use the created project to learn these technologies, by \"fiddling\" with a running system that's already delivering value (e.g, enabling custom UI dev, integration).</p> <p>That's because the created project is a standard Flask/SQLAlchemy project. Customize and extend it with all the fundamentals you learned in conventional Tutorials, and in the App Fiddle, with your favorite IDE.</p> <p> </p>"},{"location":"Tech-Learning/#unique-spreadsheet-like-business-rules","title":"Unique Spreadsheet-like Business Rules","text":"<p>As a experienced app developer, I think of projects as about half backend and half frontend.  Your mileage may vary, but the backend is certainly a lot of work:</p> <ul> <li> <p>multi-table derivations and constraints applied on update</p> <ul> <li>E.g. the customer's balance - the sum of the unpaid order totals - cannot exceed  the credit limit</li> </ul> </li> <li> <p>authorization and authentication</p> <ul> <li>E.g., users must enter a valid id and password to gain access</li> <li>And, their roles determine what database rows they see (e.g., a multi-tenant application)</li> </ul> </li> </ul> <p>API Logic Server enables you to declare spreadsheet-like rules to implement these.  Rules are a very significant technology, but perhaps the most striking characteristic is that they are 40X more concise than code.  These 5 rules represent the same logic as 200 lines of Python:</p> 5 Rules ~- 200 lines of code. Declare in IDE using code completion, debug in debugger.<pre><code>Rule.constraint(validate=models.Customer,       # logic design translates directly into rules\n    as_condition=lambda row: row.Balance &lt;= row.CreditLimit,\n    error_msg=\"balance ({row.Balance}) exceeds credit ({row.CreditLimit})\")\n\nRule.sum(derive=models.Customer.Balance,        # adjust iff AmountTotal or ShippedDate or CustomerID changes\n    as_sum_of=models.Order.AmountTotal,\n    where=lambda row: row.ShippedDate is None)  # adjusts - *not* a sql select sum...\n\nRule.sum(derive=models.Order.AmountTotal,       # adjust iff Amount or OrderID changes\n    as_sum_of=models.OrderDetail.Amount)\n\nRule.formula(derive=models.OrderDetail.Amount,  # compute price * qty\n    as_expression=lambda row: row.UnitPrice * row.Quantity)\n\nRule.copy(derive=models.OrderDetail.UnitPrice,  # get Product Price (e,g., on insert, or ProductId change)\n    from_parent=models.Product.UnitPrice)\n</code></pre> <p>The third project in the fiddle illustrates both the rules, and some \"standard\" Flask/SQLAlchemy customizations.  A tutorial is included to help you explore these, run them, see how to debug them, etc.</p> <p> </p>"},{"location":"Tech-Learning/#intrigued","title":"Intrigued?","text":"<p>Click here to start it  (takes about a minute to load).</p>"},{"location":"Tech-Logic-Transcript/","title":"Nat Lang Logic","text":""},{"location":"Tech-Logic-Transcript/#about-this-page","title":"About This Page","text":"<p>Our next target for GenAI is to build on microservice automation to include logic.</p> <p>This is a transcript of a ChatGPT session to \"teach\" ChatGPT about Logic, and to then see if it turn Natural Language text into rules.  It did pretty well: see here.</p> <p>We'll be looking to fold these concepts into API Logic Server GenAI.</p>"},{"location":"Tech-Logic-Transcript/#request-what-is-logic-bank","title":"Request - What is Logic Bank","text":"<p>What do you know about LogicBank</p>"},{"location":"Tech-Logic-Transcript/#response-chatgpt-knows-this","title":"Response - ChatGPT knows this...","text":"<p>LogicBank is a Python framework that provides declarative, rule-based logic for SQLAlchemy applications. It simplifies the process of enforcing business rules and constraints in Python applications, especially when working with databases. It is designed to be integrated with ORMs like SQLAlchemy and is primarily used for handling logic related to:</p> <ul> <li>Derivations: Automatically computing values from other values (e.g., calculating totals, taxes, or balances).</li> <li>Constraints: Enforcing business rules (e.g., ensuring a customer\u2019s balance doesn\u2019t exceed their credit limit).</li> <li>Actions: Triggering events or operations when certain conditions are met (e.g., sending notifications, auditing).</li> </ul>"},{"location":"Tech-Logic-Transcript/#key-features-of-logicbank","title":"Key Features of LogicBank:","text":"<ol> <li> <p>Declarative Rules: LogicBank allows you to define business rules in a declarative style. These rules are automatically triggered during database operations (insert, update, delete).    - Derivation Rules: For example, an <code>Order.amount_total</code> can be derived by summing up the total amounts of all associated items.    - Constraint Rules: For example, ensuring <code>Customer.balance</code> does not exceed the <code>credit_limit</code>.    - Formula-based Rules: Compute values dynamically based on other fields.</p> </li> <li> <p>Event-Driven: The framework allows rules to react automatically to changes in database values. When a field is updated, LogicBank can enforce rules, check constraints, or trigger actions without needing to write boilerplate code.</p> </li> <li> <p>Transaction Management: It ensures that rules are applied in the context of database transactions, so if a rule fails (like violating a constraint), the transaction is rolled back.</p> </li> <li> <p>Easy Integration with SQLAlchemy: LogicBank works seamlessly with SQLAlchemy, which is one of the most popular ORM (Object Relational Mapping) libraries in Python. This integration allows the framework to automatically listen to database events triggered by SQLAlchemy operations.</p> </li> <li> <p>Automatic Propagation of Changes: When you update a record, any related records or fields that depend on that record are automatically updated. This eliminates the need for manual propagation of changes.</p> </li> </ol>"},{"location":"Tech-Logic-Transcript/#example-use-case","title":"Example Use Case:","text":"<p>Imagine a scenario where you need to ensure that when an order is placed, the customer\u2019s balance is updated and cannot exceed their credit limit. With LogicBank, you can simply define rules that handle these calculations and constraints, and they will be automatically applied when data is inserted or updated in the database.</p> <p>Here\u2019s a conceptual view of how it works:</p> <pre><code>from logic_bank import LogicBank\nfrom logic_bank.rule_bank import rule_bank_withdrawal, rule_bank_insert\n\n# Define a rule to sum order totals to update customer balance\nrule_bank_insert(CustomerAccount.balance, derive=\"Order.amount_total\", where=\"Order.customer_id == CustomerAccount.id\")\n\n# Define a constraint to ensure customer's balance does not exceed the credit limit\nrule_bank_withdrawal(CustomerAccount.balance, constraint=\"CustomerAccount.balance &lt;= CustomerAccount.credit_limit\")\n\n# Insert/update an order, and these rules will automatically enforce business logic.\n</code></pre>"},{"location":"Tech-Logic-Transcript/#how-logicbank-differs-from-standard-sqlalchemy","title":"How LogicBank Differs from Standard SQLAlchemy:","text":"<ul> <li>In SQLAlchemy, you typically write custom event listeners (like <code>before_insert</code>, <code>before_update</code>) and manually manage business logic inside these event handlers.</li> <li>With LogicBank, much of this can be declaratively defined as rules, reducing the amount of boilerplate code and making it easier to reason about complex business logic.</li> </ul>"},{"location":"Tech-Logic-Transcript/#common-use-cases-for-logicbank","title":"Common Use Cases for LogicBank:","text":"<ul> <li>Business Process Automation: Automating calculations like totals, balances, or other computed fields.</li> <li>Enforcing Business Constraints: Ensuring that certain conditions are met when data is modified (e.g., enforcing credit limits, ensuring dates are in a valid range).</li> <li>Audit Trails: Triggering events when certain actions occur in the database, such as logging or sending notifications.</li> <li>Data Validation: Automatically ensuring that inserted or updated data conforms to predefined rules.</li> </ul>"},{"location":"Tech-Logic-Transcript/#summary","title":"Summary:","text":"<p>LogicBank is an excellent tool for building business applications that need complex data management logic, particularly in scenarios where the logic can be described using rules. By automating this logic within the database layer, it helps reduce complexity in the application code and ensures that rules are consistently enforced across all operations.</p>"},{"location":"Tech-Logic-Transcript/#request-logic-bank-api-def","title":"Request - Logic Bank API Def","text":"<p>Good... Here is the API for LogicBank:from typing import Callable, Sequence from sqlalchemy import Column from sqlalchemy.orm.attributes import InstrumentedAttribute from sqlalchemy.orm import session from logic_bank.rule_bank import rule_bank_withdraw  # reduce circular imports import logic_bank.rule_bank.rule_bank_setup as rule_bank_setup from logic_bank.rule_type.constraint import Constraint from logic_bank.rule_type.copy import Copy from logic_bank.rule_type.count import Count from logic_bank.rule_type.formula import Formula from logic_bank.rule_type.parent_cascade import ParentCascade, ParentCascadeAction from logic_bank.rule_type.parent_check import ParentCheck from logic_bank.rule_type.row_event import EarlyRowEvent, RowEvent, CommitRowEvent, AfterFlushRowEvent from logic_bank.rule_type.sum import Sum</p> <p>class LogicBank:     \"\"\"     1. Declare rules, e.g.</p> <pre><code>    declare_logic():\n        Rule.sum(derive=Order.AmountTotal, as_sum_of=OrderDetail.Amount)  # discover with code completion\n\n2. Activate them:\n\n    LogicBank.activate(session=session, activator=declare_logic)  # register LogicBank listeners to SQLAlchemy\n\n3. Execute them:\n\n    session.commit()  # LogicBank listeners execute rules relevant for submitted changes\n\n.. _Rule Summary:\n</code></pre> <p>https://apilogicserver.github.io/Docs/Logic/</p> <p>https://github.com/valhuber/LogicBank/wiki/Rule-Summary</p> <pre><code>\"\"\"\n\n@staticmethod\ndef activate(session: session, activator: callable, constraint_event: callable = None):\n    \"\"\"\n    Call after opening database to activate logic:\n\n        - register SQLAlchemy listeners\n\n        - create RuleBank, load rules - later executed on commit\n\n        - raises exception if cycles detected\n\n    Use constraint_event to log / change class of constraints, for example\n\n        def constraint_handler(message: str, constraint: Constraint, logic_row: LogicRow):\n            error_attrs = \"\"\n            if constraint:\n                if constraint.error_attributes:\n                    for each_error_attribute in constraint.error_attributes:\n                        error_attrs = error_attrs + each_error_attribute.name + \" \"\n            exception_message = \"Custom constraint_handler for: \" + message +\\\n                                \", error_attributes: \" + error_attrs\n            logic_row.log(exception_message)\n            raise MyConstraintException(exception_message)\n\n    activate is automatic for API Logic Server applications.\n\n    Arguments:\n        session: SQLAlchemy session\n        activator: user function that declares rules (e.g., Rule.sum...)\n        constraint_event: optional user function called on constraint exceptions\n    \"\"\"\n    rule_bank = rule_bank_setup.setup(session)\n    if constraint_event is not None:\n        rule_bank.constraint_event = constraint_event\n    activator()\n    rule_bank_setup.compute_formula_execution_order()\n</code></pre> <p>class Rule:     \"\"\"Invoke these functions to declare rules.</p> <pre><code>Rules are *not* run as they are defined,\nthey are run when you issue `session.commit()'.\n\n.. _Rule Summary:\n    https://github.com/valhuber/LogicBank/wiki/Rule-Summary\n\nUse code completion to discover rules and their parameters.\n\"\"\"\n\n@staticmethod\ndef sum(derive: Column, as_sum_of: any, where: any = None, child_role_name: str = \"\", insert_parent: bool=False):\n    \"\"\"\n    Derive parent column as sum of designated child column, optional where\n\n    Example\n        Rule.sum(derive=models.Customer.Balance, as_sum_of=models.Order.AmountTotal,\n            where=lambda row: row.ShippedDate is None)\n\n    Optimized to eliminate / minimize SQLs: Pruning, Adjustment Logic\n\n    Automated dependency management: fires iff changes to pk, summed field, where\n\n    Args:\n        derive: name of parent &lt;class.attribute&gt; being derived\n        as_sum_of: name of child &lt;class.attribute&gt; being summed\n        child_role_name: parent's child accessor attribute (required only for disambiguation)\n        where: optional where clause, designates which child rows are summed\n\n\n    \"\"\"\n    return Sum(derive, as_sum_of, where, child_role_name, insert_parent)\n\n@staticmethod\ndef count(derive: Column, as_count_of: object, where: any = None, child_role_name: str = \"\", insert_parent: bool=False):\n    \"\"\"\n    Derive parent column as count of designated child rows\n\n    Example\n      Rule.count(derive=models.Customer.UnPaidOrders, as_count_of=models.Order,\n               where=Lambda row: row.ShippedDate is None)\n\n    Optimized to eliminate / minimize SQLs: Pruning, Adjustment Logic\n\n    Args:\n        derive: name of parent &lt;class.attribute&gt; being derived\n        as_count_of: name of child &lt;class&gt; being counted\n        child_role_name: parent's child accessor attribute (required only for disambiguation)\n        where: optional where clause, designates which child rows are counted\n    \"\"\"\n    return Count(derive, as_count_of, where, child_role_name, insert_parent)\n\n@staticmethod\ndef constraint(validate: object,\n               calling: Callable = None,\n               as_condition: any = None,\n               error_msg: str = \"(error_msg not provided)\",\n               error_attributes=None):\n    \"\"\"\n    Constraints declare condition that must be true for all commits\n\n    Example\n      Rule.constraint(validate=models.Customer,\n                      as_condition=lambda row: row.Balance &lt;= row.CreditLimit,\n                      error_msg=\"balance ({row.Balance}) exceeds credit ({row.CreditLimit})\")\n\n\n    Constraint failures raise ConstraintException, e.g.:\n        try:\n            session.commit()\n        except ConstraintException as ce:\n            print(\"Constraint raised: \" + str(ce))\n\n    @see https://apilogicserver.github.io/Docs/Logic-Type-Constraint/\n\n    Args:\n        validate: name of mapped &lt;class&gt;\n        calling: function, passed row, old_row, logic_row (complex constraints)\n        as_condition: lambda, passed row (simple constraints)\n        error_msg: string, with {row.attribute} replacements\n        error_attributes: list of attributes\n\n    \"\"\"\n    if error_attributes is None:\n        error_attributes = []\n    return Constraint(validate=validate, calling=calling, as_condition=as_condition,\n                      error_attributes=error_attributes, error_msg=error_msg)\n\n@staticmethod\ndef parent_check(validate: object,\n                 error_msg: str = \"(error_msg not provided)\",\n                 enable: bool = True):\n    \"\"\"\n    Parent Checks ensure that non-null foreign keys are present in parent class\n\n    Example\n       Rule.parent_check(validate=models.Customer, enable=True, error_msg=\"Missing Parent\")\n\n    Parent_check failures raise ConstraintException, e.g.:\n        try:\n            session.commit()\n        except ConstraintException as ce:\n            print(\"Constraint raised: \" + str(ce))\n\n    Args:\n        validate: name of mapped class\n        error_msg: message included in exception (can have {} syntax)\n        enable: True (default) = enable, False means disable (tolerate orphans)\n\n    Note: False not recommended - for existing databases with bad data\n        Behavior is undefined for other rules (sum, count, parent references, etc)\n\n    \"\"\"\n    return ParentCheck(validate=validate, error_msg=error_msg, enable=enable)\n\n@staticmethod\ndef formula(derive: Column,\n            as_exp: str = None,  # string (for very short expression)\n            as_expression: Callable = None,\n            calling: Callable = None,\n            no_prune: bool = False):\n    \"\"\"\n    Formulas declare column value, based on current and parent rows\n\n    Example\n      Rule.formula(derive=models.OrderDetail.Amount,\n                   as_expression=lambda row: row.UnitPrice * row.Quantity)\n\n    Unlike Copy rules, Parent changes are propagated to child row(s)\n\n    The `calling` function must return a value (else column is nullified)\n\n    Args:\n        derive: &lt;class.attribute&gt; being derived\n        as_exp: string (for very short expressions - price * quantity)\n        as_expression: lambda, passed row (for syntax checking)\n        calling: function (for more complex formula, pass row, old_row, logic_row)\n        no_prune: disable pruning (rarely used, default False)\n    \"\"\"\n    return Formula(derive=derive,\n                   calling=calling, as_exp=as_exp, as_expression=as_expression,\n                   no_prune=no_prune)\n\n@staticmethod\ndef copy(derive: Column, from_parent: any):\n    \"\"\"\n    Copy declares child column copied from parent column\n\n    Example\n      Rule.copy(derive=models.OrderDetail.UnitPrice, from_parent=models.Product.UnitPrice)\n\n    Unlike formulas references, parent changes are *not* propagated to children\n\n    Args:\n        derive: &lt;class.attribute&gt; being copied into\n        from_parent: &lt;parent-class.attribute&gt; source of copy\n    \"\"\"\n    return Copy(derive=derive, from_parent=from_parent)\n\n@staticmethod\ndef early_row_event(on_class: object, calling: Callable = None):\n    \"\"\"\n    Row Events are Python functions called *before* logic\n    Possible multiple calls per transaction\n    Use: computing foreign keys...\n\n    Args:\n        on_class: &lt;class&gt; for event\n        calling: function, passed row, old_row, logic_row\n    \"\"\"\n    return EarlyRowEvent(on_class, calling)  # --&gt; load_logic\n\n@staticmethod\ndef early_row_event_all_classes(early_row_event_all_classes: Callable = None):\n    \"\"\"\n    early event for all mapped classes, intended for time/date/user stamping, e.g.\n\n    def handle_all(logic_row: LogicRow):\n        row = logic_row.row\n        if logic_row.ins_upd_dlt == \"ins\" and hasattr(row, \"CreatedOn\"):\n            row.CreatedOn = datetime.datetime.now()\n            logic_row.log(\"early_row_event_all_classes - handle_all sets 'Created_on\"'')\n\n    Rule.early_row_event_all_classes(early_row_event_all_classes=handle_all)\n\n    Args:\n        early_row_event_all_classes: function, passed logic_row\n\n    \"\"\"\n    return rule_bank_setup.setup_early_row_event_all_classes(\n        early_row_event_all_classes=early_row_event_all_classes)\n\n@staticmethod\ndef row_event(on_class: object, calling: Callable = None):\n    \"\"\"\n    Row Events are Python functions called *during* logic, after formulas/constraints\n    Possible multiple calls per transaction\n    Use: recursive explosions (e.g, Bill of Materials)\n\n    Args:\n        on_class: &lt;class&gt; for event\n        calling: function, passed row, old_row, logic_row\n    \"\"\"\n    return RowEvent(on_class, calling)  # --&gt; load_logic\n\n@staticmethod\ndef commit_row_event(on_class: object, calling: Callable = None):\n    \"\"\"\n    Commit Row Events are Python functions *after* all row logic formulas/constraints\n\n    Example\n        Rule.commit_row_event(on_class=Order, calling=congratulate_sales_rep)\n\n    1 call per row, per transaction\n\n    Example use: send mail/message\n\n    Args:\n        on_class: &lt;class&gt; for event\n        calling: function, passed row, old_row, logic_row\n    \"\"\"\n    return CommitRowEvent(on_class, calling)  # --&gt; load_logic\n\n@staticmethod\ndef after_flush_row_event(on_class: object, calling: Callable = None):\n    \"\"\"\n    After Flush Row Events are Python functions *after* all row logic formulas/constraints,\n    and after rows are flushed to disk.\n\n    Unlike commit row events, such rows will reflect DBMS-generated AutoNum values.\n\n    Updates during after_flush are undefined; use Commit Events if updates are required.\n\n    Example\n        Rule.after_flush_row_event(on_class=models.Order, calling=send_order_to_shipping)\n\n    1 call per row, per transaction\n\n    Example use: send mail/message including AutoNum values\n\n    Args:\n        on_class: &lt;class&gt; for event\n        calling: function, passed row, old_row, logic_row\n    \"\"\"\n    return AfterFlushRowEvent(on_class, calling)  # --&gt; load_logic\n\n'''\ndisabled, per ORM support (retained in case of misunderstandings)\n    @staticmethod\n    def parent_cascade(validate: object,\n                       error_msg: str = \"(error_msg not provided)\",\n                       relationship: str = \"*\",\n                       action: ParentCascadeAction = ParentCascadeAction.NULLIFY):\n        \"\"\"\n        Parent Cascade specifies processing for child rows on parent delete\n\n        Example\n           Rule.parent_cascade(validate=Order, relationship=\"OrderDetailList\", action=ParentCascadeAction.DELETE)\n\n        If rule or action not specified, default is ParentCascadeAction.NULLIFY\n\n        Parent_cascade with ParentCascadeAction.NULLIFY can raise ConstraintException, e.g.:\n            try:\n                session.commit()\n            except ConstraintException as ce:\n                print(\"Constraint raised: \" + str(ce))\n\n        \"\"\"\n        return ParentCascade(validate=validate, error_msg=error_msg, relationship=relationship, action=action)\n'''\n</code></pre> <p>class DeclareRule(Rule):     \"\"\"     Same as Rule, but makes clear these statements declare rules, e.g.</p> <pre><code>    declare_logic():\n\n        DeclareRule.sum(derive=models.Order.AmountTotal, as_sum_of=OrderDetail.Amount)\n\nActivate them:\n\n    LogicBank.activate(session=session, activator=declare_logic)  # registers LogicBank listeners to SQLAlchemy\n\nExecute them:\n\n    session.commit()  # LogicBank listeners execute rules relevant for submitted changes\n\n\"\"\"\npass\n\n# Response - ChatGPT understanding of Logic Bank\n\nThe provided API for **LogicBank** introduces a framework to declaratively define and enforce business rules directly in Python when using **SQLAlchemy**. Below is a breakdown of the key features and usage of the API:\n</code></pre>"},{"location":"Tech-Logic-Transcript/#key-components-and-usage","title":"Key Components and Usage","text":""},{"location":"Tech-Logic-Transcript/#1-logicbank-class","title":"1. LogicBank Class","text":"<p>The <code>LogicBank</code> class is the primary entry point to activate and enforce rules for SQLAlchemy models. Here's how it's typically used: - Activate Rules: You call <code>LogicBank.activate</code> to register SQLAlchemy listeners and enforce declared rules during the commit operation.</p> <p><pre><code>LogicBank.activate(session=session, activator=declare_logic)\n</code></pre>   - <code>session</code>: The SQLAlchemy session.   - <code>activator</code>: A function that declares business rules.   - <code>constraint_event</code>: (Optional) A handler to manage constraint violations.</p>"},{"location":"Tech-Logic-Transcript/#2-rule-class","title":"2. Rule Class","text":"<p>The <code>Rule</code> class provides a declarative interface to define various types of business logic rules.</p>"},{"location":"Tech-Logic-Transcript/#sum-rule","title":"Sum Rule","text":"<ul> <li>Derives a parent column as the sum of a related child column (commonly used in order-line item scenarios).   <pre><code>Rule.sum(derive=Order.amount_total, as_sum_of=OrderDetail.amount)\n</code></pre></li> </ul>"},{"location":"Tech-Logic-Transcript/#count-rule","title":"Count Rule","text":"<ul> <li>Counts the number of child rows and assigns that value to a parent column.   <pre><code>Rule.count(derive=Customer.unpaid_orders, as_count_of=Order, where=lambda row: row.shipped_date is None)\n</code></pre></li> </ul>"},{"location":"Tech-Logic-Transcript/#constraint-rule","title":"Constraint Rule","text":"<ul> <li>Ensures a condition holds for the row being validated. Constraints are typically used to enforce business rules.   <pre><code>Rule.constraint(validate=CustomerAccount,\n                as_condition=lambda row: row.balance &lt;= row.credit_limit,\n                error_msg=\"balance exceeds credit limit\")\n</code></pre></li> </ul>"},{"location":"Tech-Logic-Transcript/#formula-rule","title":"Formula Rule","text":"<ul> <li>Derives a column value based on other values, using either a simple expression or a lambda function.   <pre><code>Rule.formula(derive=OrderDetail.amount, as_expression=lambda row: row.unit_price * row.quantity)\n</code></pre></li> </ul>"},{"location":"Tech-Logic-Transcript/#copy-rule","title":"Copy Rule","text":"<ul> <li>Copies a column from a parent to a child. This is useful when a field (like price) should not be dynamically calculated.   <pre><code>Rule.copy(derive=OrderDetail.unit_price, from_parent=Product.unit_price)\n</code></pre></li> </ul>"},{"location":"Tech-Logic-Transcript/#3-row-events","title":"3. Row Events","text":"<p>Row events allow you to define custom logic triggered at different points during a transaction. There are several types of row events: - EarlyRowEvent: Triggered before the logic is applied.   <pre><code>Rule.early_row_event(on_class=Order, calling=my_custom_function)\n</code></pre></p> <ul> <li>RowEvent: Triggered during the execution of logic, after constraints and formulas have been applied.</li> <li>CommitRowEvent: Triggered after the logic and database changes have been committed.</li> </ul>"},{"location":"Tech-Logic-Transcript/#4-declarative-activation","title":"4. Declarative Activation","text":"<p>The <code>DeclareRule</code> class is a semantic alias of <code>Rule</code>, helping to clarify that these are declarative statements: <pre><code>DeclareRule.sum(derive=Order.amount_total, as_sum_of=OrderDetail.amount)\n</code></pre></p>"},{"location":"Tech-Logic-Transcript/#example-workflow","title":"Example Workflow","text":"<ol> <li> <p>Define Rules <pre><code>def declare_logic():\n    # Define business rules\n    Rule.sum(derive=CustomerAccount.balance, as_sum_of=Order.amount_total,\n             where=lambda row: row.date_shipped is None)\n    Rule.constraint(validate=CustomerAccount,\n                    as_condition=lambda row: row.balance &lt;= row.credit_limit,\n                    error_msg=\"balance exceeds credit limit\")\n</code></pre></p> </li> <li> <p>Activate Rules <pre><code>LogicBank.activate(session=session, activator=declare_logic)\n</code></pre></p> </li> <li> <p>Commit Data    After making changes to the session, you simply call:    <pre><code>session.commit()\n</code></pre>    At this point, LogicBank will automatically apply the defined rules, derive values, and enforce constraints.</p> </li> </ol>"},{"location":"Tech-Logic-Transcript/#benefits-of-logicbank","title":"Benefits of LogicBank","text":"<ul> <li>Declarative Rule Definition: Business rules can be declared once and automatically enforced during commit operations.</li> <li>Automated Constraint and Formula Management: Eliminates the need for manual handling of constraint checks or derived fields.</li> <li>Optimized Execution: The API is optimized to minimize SQL queries, especially in cases of complex dependency chains (e.g., pruning and adjustment logic).</li> <li>Error Handling: The framework allows custom constraint handling via the <code>constraint_event</code> argument in <code>LogicBank.activate</code>.</li> </ul>"},{"location":"Tech-Logic-Transcript/#conclusion","title":"Conclusion","text":"<p>LogicBank enables efficient rule-based management for SQLAlchemy applications, handling constraints, derivations, and other business logic declaratively and automatically. This can simplify applications where rules around things like totals, balances, and credit limits need to be consistently enforced across different transactions.</p>"},{"location":"Tech-Logic-Transcript/#request-solve-this","title":"Request - solve this","text":"<p>Use LogicBank to enforce the Check Credit requirement (do not generate check constraints): 1. Customer.balance &lt;= credit_limit 2. Customer.balance = Sum(Order.amount_total where date_shipped is null) 3. Order.amount_total = Sum(Item.mount) 4. Item.amount = quantity * unit_price 5. Store the Item.unit_price as a copy from Product.unit_price</p>"},{"location":"Tech-Logic-Transcript/#response-solution","title":"Response - Solution","text":"<p>To enforce the Check Credit requirements using LogicBank, you can declaratively define the rules for the <code>CustomerAccount</code>, <code>Order</code>, and <code>Item</code> models. Here\u2019s how to set up LogicBank to enforce each of the rules:</p>"},{"location":"Tech-Logic-Transcript/#1-customerbalance-credit_limit","title":"1. Customer.balance &lt;= credit_limit","text":"<p>This rule ensures that a customer's balance does not exceed their credit limit. You can enforce this using a constraint rule.</p> <pre><code>Rule.constraint(\n    validate=CustomerAccount,\n    as_condition=lambda row: row.balance &lt;= row.credit_limit,\n    error_msg=\"Balance ({row.balance}) exceeds credit limit ({row.credit_limit})\"\n)\n</code></pre>"},{"location":"Tech-Logic-Transcript/#2-customerbalance-sumorderamount_total-where-date_shipped-is-null","title":"2. Customer.balance = Sum(Order.amount_total where date_shipped is null)","text":"<p>This rule ensures that a customer's balance is the sum of the total amounts for all their orders where <code>date_shipped</code> is still <code>None</code> (i.e., orders that have not been shipped yet). You can enforce this with a sum rule.</p> <pre><code>Rule.sum(\n    derive=CustomerAccount.balance,\n    as_sum_of=Order.amount_total,\n    where=lambda row: row.date_shipped is None\n)\n</code></pre>"},{"location":"Tech-Logic-Transcript/#3-orderamount_total-sumitemamount","title":"3. Order.amount_total = Sum(Item.amount)","text":"<p>For each order, the <code>amount_total</code> should be the sum of the amounts for each item in the order. You can enforce this with another sum rule.</p> <pre><code>Rule.sum(\n    derive=Order.amount_total,\n    as_sum_of=Item.amount\n)\n</code></pre>"},{"location":"Tech-Logic-Transcript/#4-itemamount-quantity-unit_price","title":"4. Item.amount = quantity * unit_price","text":"<p>For each item in an order, the <code>amount</code> should be calculated as the product of <code>quantity</code> and <code>unit_price</code>. This can be enforced with a formula rule.</p> <pre><code>Rule.formula(\n    derive=Item.amount,\n    as_expression=lambda row: row.quantity * row.unit_price\n)\n</code></pre>"},{"location":"Tech-Logic-Transcript/#5-store-the-itemunit_price-as-a-copy-from-productunit_price","title":"5. Store the Item.unit_price as a copy from Product.unit_price","text":"<p>Whenever a product is added to an item, its <code>unit_price</code> should be copied from the corresponding <code>Product.unit_price</code>. You can enforce this with a copy rule.</p> <pre><code>Rule.copy(\n    derive=Item.unit_price,\n    from_parent=Product.unit_price\n)\n</code></pre>"},{"location":"Tech-Logic-Transcript/#complete-declare_logic-function","title":"Complete <code>declare_logic</code> Function","text":"<p>Here\u2019s how the complete rule setup would look when you declare the business rules:</p> <pre><code>def declare_logic():\n    # Rule 1: Customer.balance &lt;= credit_limit\n    Rule.constraint(\n        validate=CustomerAccount,\n        as_condition=lambda row: row.balance &lt;= row.credit_limit,\n        error_msg=\"Balance ({row.balance}) exceeds credit limit ({row.credit_limit})\"\n    )\n\n    # Rule 2: Customer.balance = Sum(Order.amount_total where date_shipped is null)\n    Rule.sum(\n        derive=CustomerAccount.balance,\n        as_sum_of=Order.amount_total,\n        where=lambda row: row.date_shipped is None\n    )\n\n    # Rule 3: Order.amount_total = Sum(Item.amount)\n    Rule.sum(\n        derive=Order.amount_total,\n        as_sum_of=Item.amount\n    )\n\n    # Rule 4: Item.amount = quantity * unit_price\n    Rule.formula(\n        derive=Item.amount,\n        as_expression=lambda row: row.quantity * row.unit_price\n    )\n\n    # Rule 5: Store the Item.unit_price as a copy from Product.unit_price\n    Rule.copy(\n        derive=Item.unit_price,\n        from_parent=Product.unit_price\n    )\n</code></pre>"},{"location":"Tech-Logic-Transcript/#activating-logicbank","title":"Activating LogicBank","text":"<p>To activate the rules in your SQLAlchemy session, you call the <code>LogicBank.activate</code> method and pass in the session and the <code>declare_logic</code> function:</p> <pre><code>from logic_bank import LogicBank\n\n# Activate LogicBank with the session and the rule declarations\nLogicBank.activate(session=session, activator=declare_logic)\n</code></pre>"},{"location":"Tech-Logic-Transcript/#example-workflow_1","title":"Example Workflow","text":"<ol> <li>When you insert or update a record in the <code>CustomerAccount</code>, <code>Order</code>, or <code>Item</code> tables and then call <code>session.commit()</code>, LogicBank will automatically:    - Enforce the credit limit constraint.    - Recalculate the customer balance based on unshipped orders.    - Sum the order total from its items.    - Calculate the item amount from the quantity and unit price.    - Copy the unit price from the associated product.</li> </ol>"},{"location":"Tech-Logic-Transcript/#example-data","title":"Example Data","text":"<pre><code># Add a product\nproduct1 = Product(product_id=1, name=\"Widget\", unit_price=25)\n\n# Add a customer account\ncustomer1 = CustomerAccount(customer_id=1, name=\"John Doe\", balance=0, credit_limit=1000)\n\n# Add an order for the customer (initially not shipped)\norder1 = Order(order_id=1, customer_id=1, date_shipped=None)\n\n# Add items to the order\nitem1 = Item(item_id=1, order_id=1, product_id=1, quantity=4, unit_price=None)  # unit_price will be copied\n</code></pre> <p>On <code>session.commit()</code>, LogicBank will automatically: - Ensure the customer's balance does not exceed the credit limit. - Update the customer's balance to reflect the total of the unshipped order. - Calculate the total amount of the order from its items. - Calculate each item's amount from the quantity and unit price. - Copy the unit price from the product into the item.</p>"},{"location":"Tech-Logic-Transcript/#summary_1","title":"Summary","text":"<p>By using LogicBank, all the Check Credit requirements are enforced declaratively without needing to write additional logic in your codebase. This allows your business rules to be managed centrally and consistently applied across transactions.</p>"},{"location":"Tech-Proven/","title":"Is this a Proven Technology?","text":"<p>There are several novel elements of API Logic Server:</p> <ul> <li>Logic, using spreadsheet-like rules, customizable with Python</li> <li>Automated Admin Apps - multi-page, multi-table, automatic joins</li> <li>Models, expressed in Python, instead of massive code generation</li> <li>Customizable, using a standard language, in standard IDEs such as VSCode or PyCharm</li> </ul> <p>It's therefore quite reasonable to ask whether this technology is proven.</p> <p>It has.</p> <p>Key aspects of this technology first surfaced in PACE, Wang's highly regarded DBMS with over 6500 installed sites. It provided a relational query engine with rule enforcement, an application builder, and a query/report writer. The technology was awarded several patents for rules and application generation.</p> <p>The next major implementation was Versata, a J2EE app dev system with over 700 sites. Funded by the founders of Microsoft, SAP, Ingres and Informix, it went public in 2000 with an IPO exceeding $3B.</p> <p>These commercial implementations both cost in the range of $35,000 - $50,000 per CPU.  Now available in open source. </p>"},{"location":"Tech-Python-311/","title":"Python 3.11","text":""},{"location":"Tech-Python-311/#python-311","title":"Python 3.11","text":"<p>Requires <code>psycopg2-binary==2.9.5</code>.</p> <p>Fails to run:</p> <pre><code>(venv) val@Vals-MPB-14 ApiLogicServer % ApiLogicServer welcome\nTraceback (most recent call last):\n  File \"/Users/val/dev/servers/install/ApiLogicServer/venv/bin/ApiLogicServer\", line 33, in &lt;module&gt;\n    sys.exit(load_entry_point('ApiLogicServer==6.4.3', 'console_scripts', 'ApiLogicServer')())\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/val/dev/servers/install/ApiLogicServer/venv/bin/ApiLogicServer\", line 25, in importlib_load_entry_point\n    return next(matches).load()\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/importlib/metadata/__init__.py\", line 198, in load\n    module = import_module(match.group('module'))\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/importlib/__init__.py\", line 126, in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"&lt;frozen importlib._bootstrap&gt;\", line 1206, in _gcd_import\n  File \"&lt;frozen importlib._bootstrap&gt;\", line 1178, in _find_and_load\n  File \"&lt;frozen importlib._bootstrap&gt;\", line 1149, in _find_and_load_unlocked\n  File \"&lt;frozen importlib._bootstrap&gt;\", line 690, in _load_unlocked\n  File \"&lt;frozen importlib._bootstrap_external&gt;\", line 940, in exec_module\n  File \"&lt;frozen importlib._bootstrap&gt;\", line 241, in _call_with_frames_removed\n  File \"/Users/val/dev/servers/install/ApiLogicServer/venv/lib/python3.11/site-packages/api_logic_server_cli/cli.py\", line 81, in &lt;module&gt;\n    from create_from_model.model_creation_services import ModelCreationServices\n  File \"/Users/val/dev/servers/install/ApiLogicServer/venv/lib/python3.11/site-packages/api_logic_server_cli/create_from_model/model_creation_services.py\", line 21, in &lt;module&gt;\n    from api_logic_server_cli.sqlacodegen_wrapper import sqlacodegen_wrapper\n  File \"/Users/val/dev/servers/install/ApiLogicServer/venv/lib/python3.11/site-packages/api_logic_server_cli/sqlacodegen_wrapper/sqlacodegen_wrapper.py\", line 22, in &lt;module&gt;\n    from sqlacodegen_wrapper.sqlacodegen.sqlacodegen.codegen import CodeGenerator\n  File \"/Users/val/dev/servers/install/ApiLogicServer/venv/lib/python3.11/site-packages/api_logic_server_cli/sqlacodegen_wrapper/sqlacodegen/sqlacodegen/codegen.py\", line 9, in &lt;module&gt;\n    from inspect import ArgSpec\nImportError: cannot import name 'ArgSpec' from 'inspect' (/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/inspect.py)\n(venv) val@Vals-MPB-14 ApiLogicServer % \n</code></pre>"},{"location":"Tech-Python/","title":"Python Tips","text":"<p>I quite like Python.  I've used assembler, PL/1, and Java.  Python (particularly with good IDEs) is my favorite.</p> <p>Though, there were some surprises I wish I'd been told about.  So, here you go.</p> <p> </p>"},{"location":"Tech-Python/#python-and-apilogicserver","title":"Python and ApiLogicServer","text":"<p>Using ApiLogicServer means you'll be looking at levels of Python use:</p> <ol> <li> <p>Automation: automated project creation eliminates all the fiddly configuration required to build a web app -- without any Pyton at all</p> </li> <li> <p>Python as a DSL: declarative logic and the admin app require minimal Python - it's really a Domain Specific Language using Python keyword arguments and IDE code complation</p> </li> <li> <p>Python as a 4GL: creating custom endpoints requires Python at it's simplest level, particuarly when coupled with a moder IDE.</p> </li> <li> <p>Full Python: it's important that there are no restrictions on using full power of Python - classes, exceptions, etc.  In normal cases, this is probably less than 5 or 10% of the project.</p> </li> </ol> <p> </p>"},{"location":"Tech-Python/#basics","title":"Basics","text":"<p>You'll discover these soon enough:</p> <ol> <li> <p>Indents vs. braces - obvious, but the real implication is that you need an IDE, because they keep track of indents (vs. spaces).  I've used PyCharm and VSCode, both are wonderful: great editors, debuggers.</p> </li> <li> <p>Non-typed - well-known, but you can (should) use Type Hints  for clarity, and code completion.</p> </li> <li> <p>CLI - Python includes great tools for making Command Line Interfaces, like Click.  A little fiddly, you might want to have a look at these examples  (near the end), which uses ArgParse.</p> </li> <li> <p>Modules - are not packages.  There is a magic file <code>__init.py__</code> that makes a directory into a module.</p> </li> <li> <p>Key Data Structures</p> <ul> <li> <p>Dict - keyword/value; easy to convert to json (for rest response)  -- ordered, <code>for each_key, each_value in thisdict.items():</code></p> </li> <li> <p>List - ordered list -- <code>for each_item in list</code></p> </li> <li> <p>Tuple - set of values</p> </li> </ul> </li> </ol> <p> </p>"},{"location":"Tech-Python/#using-the-debug-console","title":"Using the <code>Debug Console</code>","text":"<p>A truly wonderful by-product of having an interpreter is that you issue language commands - in the context of the currently running program.  Your IDE supports this; use it at breakpoints to:</p> <ol> <li>Evaulate expressions</li> <li>Test methods</li> <li>Explore objects, and their APIs - I have saved days of time using API discovery</li> </ol> <p> </p>"},{"location":"Tech-Python/#other-tips","title":"Other Tips","text":"<p>See these notes.</p> <p> </p>"},{"location":"Tech-Python/#extensions","title":"Extensions","text":"<p>You can do <code>code --list-extensions</code> to find VSCode Extensions.  I use these:</p> <pre><code>akamud.vscode-theme-onedark\nanandabibekray.intellij-idea-new-ui-theme\nchrisdias.vscode-opennewinstance\ndaniel-lvovsky.mintlight-theme\nelectropol-fr.coloredtheme\ngarytyler.darcula-pycharm\ngithub.copilot\ngithub.copilot-chat\ngithub.vscode-pull-request-github\nmagicstack.magicpython\nmhutchie.git-graph\nmoshfeu.compare-folders\nms-azuretools.vscode-docker\nms-python.debugpy\nms-python.isort\nms-python.python\nms-python.vscode-pylance\nms-toolsai.jupyter\nms-toolsai.jupyter-keymap\nms-toolsai.jupyter-renderers\nms-toolsai.vscode-jupyter-cell-tags\nms-toolsai.vscode-jupyter-slideshow\nms-vscode-remote.remote-containers\nms-vscode.wordcount\nms-vsliveshare.vsliveshare\nmsnilshartmann.blue-light\nmtxr.sqltools\nmtxr.sqltools-driver-sqlite\nnjpwerner.autodocstring\noscarewenstudent.arduino-themes-vsc\nrokoroku.vscode-theme-darcula\nsandcastle.vscode-open\nthakkeross.thakker-light-mist-hc\nzhuangtongfa.material-theme\n</code></pre> <p> </p>"},{"location":"Tech-Python/#pip-environments-and-pythonpath","title":"Pip, environments and PythonPath","text":"<p>Pip is how to load libraries (packages) - not by setting up folder.  It's great, but quickly leads to Pyton's version of \"DLL Hell\" where libraries interfere from different projects.  So, the best practice is to set up Virtual Environments .</p> <p>A related issue is loading classes / modules at runtime.  Be clear on your <code>PythonPath</code>.  And, be aware the some IDEs (PyCharm is one) provide super-friendly support to simplify things by setting this automatically.  Which is nice, until you discover that a program that runs in the IDE fails outside it.  Days of fun.</p> <p> </p>"},{"location":"Tech-Python/#import-is-a-4-letter-word","title":"Import is a 4 letter word","text":"<p>Oy, where do I start.</p> <p> </p>"},{"location":"Tech-Python/#executable-non-class-code-runs-on-import","title":"Executable - non-class code runs on import","text":"<p>First, imports are executable... so what does that mean.</p> <ul> <li> <p>The key underlying fact is that Python does not require all code to be in a class.  </p> </li> <li> <p>On import, all the non-class/function code actually runs.  It is not just setting up paths.</p> </li> <li> <p>If you want to know whether your module was run (directly) or imported, use:</p> </li> </ul> determine run directly vs. import<pre><code>if __name__ == '__main__':   # prounounced:   \"dunder name\" == \"dunder main\"\n    pass  # I was run directly\nelse:\n    pass  # I was imported\n</code></pre> <p> </p>"},{"location":"Tech-Python/#imports-often-fail-to-compile","title":"Imports often fail to compile","text":"<p>Note: import compile failures and circular imports are unlikely to be issues for API Logic Server projects, since these are created correctly.  The following alerts are for using full Python for complex requirements.</p> <p>I still do not understand where Python and the IDE figure out what I can import.  You'll find lots of Stack Overflow articles on imports (e.g., sibling imports).</p> <p>For me, it usually degenerates into a trial and error exercise.</p> <ul> <li> <p>You might find sibling imports  a useful project to fiddle with.</p> </li> <li> <p>You can also see many import examples in the created project.</p> </li> </ul> <p>Note that imports often require a \"module\", which means you create a (usually empty) file called <code>__init.py__</code>.</p> <p> </p>"},{"location":"Tech-Python/#circular-imports","title":"Circular Imports","text":"<p>I understand that Python's 1-pass nature means your imports have to be in a certain order to work.  I have spent days battling this.  I hope you have better luck, but at least you have a heads up.  As always, introduce changes in small numbers to avoid having lots of potential problems.</p> <p>One technique is to put the offending import into a class or function, instead of at the top.  See, for example, \"circular import\" comment in <code>security/authentication_provider/keycloak/auth_provider.py</code>.</p> <p> </p>"},{"location":"Tech-Python/#mac-installs","title":"Mac Installs","text":"<p>If you like imports, you'll love Mac installs.</p> <p>Way back when, Apple installed Python.  Python 2.  Which is very old - Python3 is now the standard.</p> <p>But Mac was stuck with Python == Python2.  Which probably gets you the wrong version.</p> <p>I guess as folks dealt with this, there arose many ways of installing - brew, the Python installer, maybe others.</p> <p>And that was further compounded by alternate ways of running Pip, things like <code>venv</code>.</p> <p>As I flailed, I tried many of them.  The end result was that I finally concluded I did not know what I was running.</p> <p>So, and I hope you avoid this, I wound having to re-install my computer.  Just wow.</p> <p>Where I wound up was simple:</p> <ul> <li>stick with the Python.org installer</li> <li>I am not using <code>venv</code> or <code>pip</code> directly; I use them with Python(3) so I know they are consistent:</li> </ul> <pre><code>python3 -m venv venv  # of course, it *might* be Python, not Python3 (!)\npython3 -m pip install ApiLogicServer\n</code></pre>"},{"location":"Tech-Python/#debugging","title":"Debugging","text":"<p>Python is very well supported by modern IDEs, with code completion, syntax checking, docstrings, and the debugger.</p> <p>In addition to expected debug support (break, inspect, step, watch etc), Python's fully interpretive nature means you can enter Python code while the program is running.  This enables you to test expressions etc.  See, for example, the <code>Debug Console</code> in VSCode.</p>"},{"location":"Tech-Slack/","title":"Using Slack","text":"<p>We use Slack for internal communication and support: apilogicserver.slack.com.</p> <p>We have seen issues in Windows users gaining access to huddle screen sharing.  Note huddles have a dedicated window for this:</p> <p></p>"},{"location":"Tech-Summary/","title":"Welcome to GenAI-Logic","text":""},{"location":"Tech-Summary/#welcome-to-genailogic","title":"Welcome to GenAI\u2011Logic","text":""},{"location":"Tech-Summary/#the-aireviewed-enterprisevalidated-edition","title":"The AI\u2011Reviewed, Enterprise\u2011Validated Edition","text":"<p>This edition integrates architectural feedback from Claude\u00a04.5, GPT\u20115, and Perplexity \u2014 independent AI reviewers that converged on the same conclusion: GenAI\u2011Logic represents a unique and mature declarative architecture for enterprise automation. Their feedback helped refine clarity, scope, and evidence, transforming initial curiosity into consensus on the product\u2019s technical depth and enterprise readiness.</p>"},{"location":"Tech-Summary/#the-declarative-foundation-behind-enterprise-vibe-automation","title":"The Declarative Foundation Behind Enterprise Vibe Automation","text":"<p>Short version: Most AI \"app builders\" generate procedural glue that decays. GenAI-Logic adds the missing half \u2014 a declarative runtime for logic and API \u2014 so natural-language descriptions (\"vibes\") become governed, explainable, production systems you can own and extend.</p> <p>[Diagram 1 \u2013 Declarative vs Procedural Logic] Five compact rules replace hundreds of lines of event code \u2014 illustrating why a rules engine matters.</p>"},{"location":"Tech-Summary/#why-code-generation-isnt-enough","title":"Why Code Generation Isn't Enough","text":"<p>Codegen emits controllers, handlers, and validators that appear functional on first inspection. But testing reveals the true cost: critical correctness bugs as documented here. The generated code fails to handle: - Foreign key changes (updating both old and new parent records) - Dependency ordering (which calculations must execute first) - Cascading updates (changes that ripple through related data) - Before/after value comparisons (detecting what actually changed)</p> <p>This isn't a \"good start that needs refinement\"\u2014it's Franken-code that represents instant tech-debt: - Generated code you don't understand - Implementation details that obscure business intent - Bugs that require deep analysis to diagnose - Maintenance burden that grows with each change</p>"},{"location":"Tech-Summary/#the-real-problem-no-one-solved-reactive-dependency-propagation-for-backend-logic","title":"The Real Problem: No One Solved Reactive Dependency Propagation for Backend Logic","text":"<p>Think about how spreadsheets work. When you change cell A1, Excel doesn't make you write code to update B5, C3, and D10 in the correct order. It automatically: - Detects which cells depend on A1 - Determines the correct execution order - Recalculates only what changed - Guarantees consistency</p> <p>This is reactive dependency propagation \u2014 and it's been proven in spreadsheets for 40 years and in UI frameworks like React, Vue, and MobX for the last decade.</p>"},{"location":"Tech-Summary/#the-innovation-spreadsheet-engine-for-your-database","title":"The Innovation: Spreadsheet Engine for Your Database","text":"<p>GenAI-Logic applies reactive dependency propagation to backend transactional business logic.</p> <p>Nobody has successfully combined: - Reactive programming patterns - Applied to database transactions - With automatic dependency detection - Optimized for delta propagation (not full recomputation) - Exposed via declarative DSL - At enterprise scale</p> <p>Example: The \"Baby Born in New York\" Pattern</p> <p>When updating related data, most code does this: <pre><code>Baby born in New York\n\u2192 Query: SELECT COUNT(*) FROM people WHERE state = 'NY'\n\u2192 Scan millions of rows\n\u2192 Return new total\n</code></pre></p> <p>GenAI-Logic does this: <pre><code>Baby born in New York\n\u2192 Current count: 19,453,561\n\u2192 Adjustment: +1\n\u2192 New count: 19,453,562\n</code></pre></p> <p>This incremental adjustment pattern (O(1) instead of O(n)) is what makes a 3-minute operation become 3 seconds. Applied across all business rules in an enterprise system, this is the difference between unusable and production-grade performance.</p> <p>GenAI-Logic behaves like a spreadsheet for enterprise apps \u2014 change one value and dependent totals, constraints, and validations cascade automatically. No event code to chase, no hidden side-effects, no manual dependency tracking.</p>"},{"location":"Tech-Summary/#the-core-architecture-dsl-runtime-engine","title":"The Core Architecture: DSL + Runtime Engine","text":"<p>GenAI-Logic stores intent as declarative DSLs interpreted by runtime engines \u2014 not scattered in generated code.</p> <ul> <li>Logic DSL + Engine (LogicBank): rules such as <code>Rule.sum</code>, <code>Rule.formula</code>, <code>Rule.constraint</code>. The engine handles dependency detection, correct ordering, and incremental (delta) recompute inside the transaction.  </li> <li>API DSL + Engine (JSON:API/SAFRS): entities are registered, not hard-coded. The runtime dynamically exposes REST endpoints; no per-table controllers or serializers to regenerate.</li> </ul> <p>The SQL Analogy: We don't ask GenAI to build a database engine; we ask it to write SQL. Likewise, we don't ask it to hand-code logic; we ask it to express logic as declarative DSL, leaving correctness and performance to the runtime.</p> <p>This is not a rules engine in the traditional sense (like RETE for pattern matching). This is reactive dependency graph execution \u2014 the same pattern that powers spreadsheets and modern UI frameworks, now applied to backend data transactions.</p> <p>[Diagram 2 \u2013 Vibe the Full Stack] One \"vibe\" prompt updates the model, logic, API, UI, and integrations together.</p>"},{"location":"Tech-Summary/#vibe-the-full-stack","title":"Vibe the Full Stack","text":"<p>A single natural-language \"vibe\" can create or extend every layer. Change a field or rule once; it propagates coherently.</p> <p>Layers created automatically: - Database schema and ORM (SQLAlchemy) - Business logic rules (LogicBank runtime) - REST APIs (JSON:API / Flask / SAFRS) - Admin and customer UIs (React source, YAML descriptors) - Integration rules (Kafka, webhooks, REST)</p> <p>You own the source. The UI is real React/TypeScript; the backend is standard Python. No lock-in.</p>"},{"location":"Tech-Summary/#best-backend-for-any-vibe-plays-well-with-others","title":"\"Best Backend for Any Vibe\" \u2014 Plays Well with Others","text":"<p>GenAI-Logic doesn't compete with front-end Vibe tools like Copilot or Claude \u2014 it completes them. Use your favorite prompt tooling to shape UX and flows; let GenAI-Logic supply the deterministic foundation: real database, declarative logic, governed API, and integrations.</p> <p>Vibe the front-end with Copilot; vibe the backend with GenAI-Logic.</p> <p>Or use our trained Copilot for sophisticated UIs: We've also trained Copilot to generate production-grade React front-ends directly from your models \u2014 with trees, cards, maps, and custom layouts. This provides an end-to-end option when you want both backend and frontend from a single source. But the backend remains open and composable \u2014 use any front-end tool you prefer.</p>"},{"location":"Tech-Summary/#diagram-here","title":"&lt;&lt; diagram here &gt;&gt;","text":""},{"location":"Tech-Summary/#from-low-code-to-vibe-driven-automation","title":"From Low-Code to Vibe-Driven Automation","text":"<p>Low-code accelerated screens and workflows \u2014 a useful step. But business logic remained procedural, hidden in scripts and triggers. GenAI-Logic brings the same simplicity to behavior, with open models, rule transparency, and deployment freedom.</p> <p>Think of it as low-code evolved for the GenAI era \u2014 same goal of speed, but now transparent and ownable.</p>"},{"location":"Tech-Summary/#proprietary-builders-vs-standard-enterprise-foundations","title":"Proprietary Builders vs. Standard Enterprise Foundations","text":"<p>In-platform builders focus on convenience within proprietary workspaces. GenAI-Logic works at the enterprise architecture layer \u2014 database-centric, API-native, and deploy-anywhere.</p> <p>Platform tools create apps inside their walls. GenAI-Logic builds systems that connect the walls.</p>"},{"location":"Tech-Summary/#a-place-for-both-shared-platform-for-business-it","title":"A Place for Both \u2014 Shared Platform for Business + IT","text":"<p>Large enterprises need both:</p> <p>Productivity layer: fast departmental apps within suites. Enterprise backbone: durable, governed logic spanning data, APIs, and integrations.</p> <p>Suite builders deliver agility; GenAI-Logic ensures consistency, reuse, and governance \u2014 business users create via WebGenAI (conversational interface for tables, rules, screens), developers extend by downloading the standard project into their IDE. Behind the scenes, conversations become models, APIs, and declarative rules \u2014 avoiding shadow IT while keeping speed.</p> <p>[Diagram 3 \u2013 WebGenAI on Declarative Foundations] Business user speaks \"vibes\" in WebGenAI; engine generates DB + Logic + API; IT retains governance.</p>"},{"location":"Tech-Summary/#impact-at-enterprise-scale","title":"Impact at Enterprise Scale","text":"<p>An enterprise with ~100 tables and 2,000 rules typically requires tens of thousands of lines of procedural glue. Declarative logic collapses that to a few thousand declarative lines \u2014 a 40\u00d7 reduction, verified in a Copilot comparison study.</p> <p>Real-World Performance Impact: In production deployments, the delta adjustment pattern has achieved 60\u00d7 performance improvements \u2014 reducing operations from 3 minutes to 3 seconds. This isn't theoretical; it's the predictable outcome of switching from O(n) full recomputation to O(1) incremental updates.</p> <p>Maintaining procedural F-Code is like maintaining assembler listings \u2014 technically correct, practically unmaintainable. Declarative rules keep you at the right abstraction level.</p> <p>Reference: Declarative vs Procedural Comparison (study)</p>"},{"location":"Tech-Summary/#enterprise-ready-by-design-confidence-control-and-governance","title":"Enterprise-Ready by Design \u2014 Confidence, Control, and Governance","text":"<p>Open-source safety and transparency GenAI-Logic and the LogicBank runtime are fully open source, built on standard Python, Flask, and SQLAlchemy. Enterprises can inspect, fork, or extend the runtime directly \u2014 ensuring no lock-in, no opaque dependencies, and long-term independence.</p> <p>Escape hatches when DSLs aren't enough Declarative automation doesn't mean loss of control. GenAI-Logic provides standard Python event hooks \u2014 intercept or extend any transaction with your IDE and libraries. If a rule is too complex for the DSL, handle it in Python \u2014 full freedom, full control.</p> <p>In practice: 97% declarative coverage At Versata, we measured this empirically using an Automation Analyzer across several dozen production enterprise systems. Result: 94-97% of deployed systems were declarative rules, only 3-6% custom code.</p> <p>This wasn't a theoretical limit\u2014developers had full freedom to write custom code anywhere, but chose declarative rules for 97% of functionality.</p> <p>The 3-6% custom code typically handled: integration adapters, complex multi-step workflows, custom reporting, and business-specific algorithms. Exactly where custom code belongs.</p> <p>GenAI-Logic follows the same architectural approach, proven at enterprise scale across insurance, banking, manufacturing, and healthcare.</p> <p>Rule persistence and recoverability Rules are ordinary Python DSL code \u2014 no hidden metadata. They live in source control and version naturally in Git. Backup, restore, and promotion work exactly like any other enterprise codebase.</p> <p>Developer trust and transparency The LogicBank runtime provides full logging and step-through debugging. Developers can see every rule that fires, inspect the affected state, and debug inside a rule. Transparency replaces \"magic\" with confidence.</p>"},{"location":"Tech-Summary/#where-genai-logic-fits-best","title":"Where GenAI-Logic Fits Best","text":"<p>Appropriate for: - Data-intensive enterprise apps with complex logic. - Declarative, rule-driven systems needing transparency and governance. - Teams that want speed without lock-in, using standard open-source tech. - Projects requiring explainable, testable automation.  </p> <p>Not appropriate for: - Lightweight workflow or document automation tools. - One-off internal forms apps that live entirely in proprietary suites. - Projects requiring real-time, event-driven streaming beyond business-logic scope.  </p> <p>GenAI-Logic complements, rather than replaces, suite-based builders. Use both: one for surface agility, the other for durable logic and integration.</p>"},{"location":"Tech-Summary/#frequently-asked-questions","title":"Frequently Asked Questions","text":"<p>Q: Isn't GenAI unreliable and prone to hallucinations? A: No. GenAI-Logic uses AI only as a translator from natural language into declarative DSLs. The deterministic runtime guarantees correctness, order, and safety \u2014 AI speed and simplicity, with engineering discipline.</p> <p>Q: What if my business logic is too complex for a DSL? A: GenAI-Logic supports full Python event hooks, allowing procedural extensions for any edge case.</p> <p>Q: How are rules stored and backed up? A: Rules are standard Python files, versioned in Git with schema and API definitions. Backup and restore use your existing DevOps process \u2014 no special tooling required.</p> <p>Q: How do I debug or audit the system? A: Every rule execution is logged. Developers can step into a rule in their debugger, view dependencies, and trace results. Full transparency \u2014 no \"magic.\"</p> <p>Q: Can I integrate it with my existing APM and observability tools? A: Yes. Standard Python logging and Flask hooks integrate with DataDog, Dynatrace, and Splunk. Rule metrics can be exported for dashboards or alerts.</p> <p>Q: What if I need real-time streaming or orchestration? A: Use event rules (Kafka, webhooks, REST) to integrate with workflow or orchestration systems. GenAI-Logic focuses on data-integrity logic; orchestration remains external.</p> <p>Q: How do I promote and govern rules across environments? A: Because rules are versioned source, promotion is via Git branches or CI/CD. Rule changes can be reviewed, tested, and deployed like any other code.</p> <p>Q: Is this ready for mission-critical scale? A: Yes. The runtime is stateless, containerized, and proven in production-class deployments. It runs efficiently under load because dependency pruning avoids redundant recompute.</p>"},{"location":"Tech-Summary/#the-next-phase-probabilistic-deterministic","title":"The Next Phase: Probabilistic + Deterministic","text":"<p>As AI shifts to agentic systems, enterprises need deterministic rails for reliability. GenAI-Logic provides them \u2014 declarative rules that validate and orchestrate probabilistic outcomes, explainably and at scale.</p> <p>AI acts as a DSL translator, not a code generator. The runtime enforces correctness, ordering, and integrity, removing the root cause of hallucinations \u2014 asking AI to do too much.</p> <p>Probabilistic tools explore. The declarative engine ensures.</p>"},{"location":"Tech-Summary/#what-you-get-in-practice","title":"What You Get in Practice","text":"<ul> <li>Speed with ownership: vibe to a running system in minutes, keep full source.  </li> <li>Fewer defects: eliminates dependency and ordering bugs.  </li> <li>Lower TCO: shrinks the regression surface dramatically.  </li> <li>Future-proof: declarative models evolve safely with AI assistance.  </li> <li>Real performance gains: 60\u00d7 improvements from incremental computation, not just code reduction.</li> </ul>"},{"location":"Tech-Summary/#whats-new-nov-2025","title":"What's New (Nov 2025)","text":"<p>Automatic Test Creation: generates executable test suites for rules and edge cases, turning weeks of QA scaffolding into minutes. AI-Driven Tutorial Builder: builds guided tutorials directly from your models and data, shortening onboarding from days to hours.</p> <p>Together, these move GenAI-Logic from \"system generation\" to full SDLC assistance \u2014 model \u2192 logic \u2192 API \u2192 UI \u2192 tests \u2192 learning.</p>"},{"location":"Tech-Summary/#making-declarative-logic-learnable","title":"Making Declarative Logic Learnable","text":"<p>One advantage of the declarative approach: business logic distills into 5 core learnable patterns that appear across all industries:</p> <ol> <li>Chain Up \u2014 Parent aggregates from children (order totals, department budgets)</li> <li>Constrain a Derived Result \u2014 Validate aggregated values (credit limits, stock levels)</li> <li>Chain Down \u2014 Parent changes cascade to children (price changes, status updates)</li> <li>State Transition Logic \u2014 Handle before/after comparisons (shipping, approvals)</li> <li>Counts as Existence Checks \u2014 Business rules based on presence (can't ship empty orders)</li> </ol> <p>Think spreadsheet for multi-table databases: - In Excel: cell C1 = A1 + B1, cell D1 = C1 \u00d7 2 - Change A1 \u2192 C1 recalcs \u2192 D1 recalcs automatically</p> <p>Same here: - Item.amount = quantity \u00d7 price - Order.total = sum(Item.amount) - Customer.balance = sum(Order.total) - Change quantity \u2192 cascading recalculation in correct order</p> <p>Combined with AI-driven tutorials that generate from your specific data model, new developers master the patterns in hours, not weeks. This addresses the learning curve concern: it's not learning arbitrary syntax, it's learning 5 patterns that map to how business users already think.</p> <p>[Diagram 5 \u2013 Best Backend for Any Vibe] Front-end vibes (Copilot/GPT/Claude) connect to GenAI-Logic's declarative backend (DB + Logic + API + Integration).</p>"},{"location":"Tech-Summary/#the-breakthrough-why-this-matters","title":"The Breakthrough: Why This Matters","text":"<p>This is not just another rules engine. This is reactive dependency propagation for backend transactions \u2014 a pattern proven in spreadsheets and UI frameworks, now applied to enterprise data systems.</p> <p>The innovation combines: - Reactive programming (automatic dependency tracking) - Database transactions (ACID guarantees) - Delta propagation (O(1) updates, not O(n) recalculation) - Declarative DSL (intent, not implementation) - Enterprise scale (production-proven)</p> <p>No one has done this before. That's why it's a genuine architectural breakthrough, not an incremental improvement on existing tools.</p> <p>When you hear \"spreadsheet engine for your database,\" that's the essence: bring the reactive dependency model that makes Excel powerful to the backend systems that run enterprises.</p>"},{"location":"Tech-Summary/#learn-more","title":"Learn More","text":"<ul> <li>Declarative GenAI \u2014 The Architecture Behind Enterprise Vibe Automation   https://medium.com/@valjhuber/declarative-genai-the-architecture-behind-enterprise-vibe-automation-1b8a4fe4fbd7  </li> <li>Living with Logic   https://medium.com/@valjhuber/living-with-logic-7e202782d0c5  </li> <li>Declarative GenAI \u2014 Business User / IT Collaboration   https://medium.com/@valjhuber/declarative-genai-business-user-it-collaboration-c5547776ff7d  </li> <li>Vibe With Copilot and GenAI-Logic   https://medium.com/@valjhuber/vibe-with-copilot-and-genai-logic-925894574125  </li> <li>Declarative vs Procedural Comparison   https://github.com/ApiLogicServer/ApiLogicServer-src/blob/main/api_logic_server_cli/prototypes/basic_demo/logic/procedural/declarative-vs-procedural-comparison.md</li> </ul> <p>Learn more or access the open-source project at genai-logic.com.</p> <p>Written by Val Huber \u2014 Founder &amp; Chief Architect, GenAI\u2011Logic</p> <p>\u00a9\u00a02025\u00a0GenAI\u2011Logic.\u00a0All\u00a0rights\u00a0reserved.</p>"},{"location":"Tech-Toaster/","title":"API Appliance","text":"<p> TL;DR - An API Appliance</p> <p></p> <p>Just as you can plug in a toaster, and  add bread,</p> <p>You can plug this appliance into your database, and  add Rules and Python.</p> <p>Automation can provide:</p> <ul> <li>Remarkable agility and simplicity</li> <li>With all the flexibility of a framework</li> </ul> <p> </p>"},{"location":"Tech-Toaster/#1-plug-it-into-your-database","title":"1. Plug It Into Your Database","text":"<p>Here's how you plug the appliance into your database:</p> <pre><code>$ ApiLogicServer create-and-run --project-name=sample_ai --db-url=sqlite:///sample_ai.sqlite\n</code></pre> <p>No database?  Create one with AI, as described here.</p> <p> </p>"},{"location":"Tech-Toaster/#it-runs-admin-app-and-api","title":"It Runs: Admin App and API","text":"<p>Instantly, you have a running system as shown on the split-screen below: </p> <ul> <li>a multi-page Admin App (shown on the left), supported by...</li> <li>a multi-table JSON:API with Swagger (shown on the right)</li> </ul> <p></p> <p>So, right out of the box, you can support:</p> <ul> <li>Custom client app dev, and </li> <li>Ad hoc application integration</li> <li>Agile Collaboration, based on Working Software</li> </ul> <p>Unlike weeks of complex and time-consuming framework coding, you have working software, now.</p> <p> </p>"},{"location":"Tech-Toaster/#containerize","title":"Containerize","text":"<p>API Logic Server can run as a container, or a standard pip install.  In either case, you can containerize your project for deployment, e.g. to the cloud.</p> <p> </p>"},{"location":"Tech-Toaster/#2-add-rules-for-logic","title":"2. Add Rules for Logic","text":"<p>Instant working software is great, but without logic enforcement it's little more than a cool demo. </p> <p>Behind the running application is a standard project.  Open it with your IDE, and </p> <ul> <li>Declare logic with code completion</li> <li>Debug it with your debugger</li> </ul> <p></p> <p>Instead of conventional procedural logic, the code above is declarative.  Like a spreadsheet, you declare rules for multi-table derivations and constraints.  The rules handle all the database access, dependencies, and ordering.</p> <p>The result is quite remarkable: the 5 spreadsheet-like rules above perform the same logic as 200 lines of Python.  The backend half of your system is 40X more concise.</p> <p>Similar rules are provided for granting row-level access, based on user roles.</p> <p> </p>"},{"location":"Tech-Toaster/#3-add-python-for-flexibility","title":"3. Add Python for Flexibility","text":"<p>Automation and Rules provide remarkable agility, but you need flexibility to deliver a complete result.  Use Python and popular packages to complete the job.  </p> <p>Here we customize for pricing discounts, and sending Kafka messages:</p> <p></p> <p> </p>"},{"location":"Tech-Toaster/#extensible-declarative-automation","title":"Extensible Declarative Automation","text":"<p>The screenshots above illustrate remarkable agility.  This system might have taken weeks or months using conventional frameworks.</p> <p>But it's more than agility.  The level of abstraction here is very high, bringing a level of simplicity that enables you to create microservices -- even if you are new to Python, or Frameworks such as Flask or SQLAlchemy.</p> <p>There are 3 key elements that deliver this speed and simplicity:</p> <ol> <li> <p>Microservice Automation: instead of slow and complex framework coding, just plug into your database for a running API and Admin App</p> </li> <li> <p>Logic Automation with Declarative Rules: instead of tedious code that describe how logic operates, rules express what you want to accomplish</p> </li> <li> <p>Extensibility: finish the remaining elements with your IDE, Python and standard packages such as Flask and SQLAlchemy.</p> </li> </ol>"},{"location":"Tech-Training/","title":"Training","text":"<p> Lab-Focused Training</p> <p>Instead of hours of concepts, many propose that training be organzied around a series of Labs.  This page outlines such a course, presuming:</p> <ul> <li>WebGenAI-focused</li> <li>Java background - new to Python</li> </ul>"},{"location":"Tech-Training/#initial-background","title":"Initial Background","text":"<p>Review the GenAI Architecture, and take a quick scan of Python for Java programmers. </p>"},{"location":"Tech-Training/#installation-and-configuration","title":"Installation and Configuration","text":"<p>While WebGenAI is available via your browser - you will want to have a local version of Python, ApiLogicServer, VSCode (and optionally Docker Desktop) running.  This has been documented here:</p> <ol> <li>Python 3.12 Installation</li> <li>Understand Virtual Environments, and als notes</li> <li>ApiLogicServer Installation</li> <li>VSCode for Python</li> <li>Docker Desktop Install</li> <li>Sample Docker Databases are available for learning.</li> </ol> <p> </p>"},{"location":"Tech-Training/#core-webgenai","title":"Core WebGenAI","text":"<p>In this series of labs, you will </p> <ol> <li>create and run projects</li> <li>debug them, both in WebGanAI and the IDE</li> <li>explore iterations</li> </ol> <p> </p>"},{"location":"Tech-Training/#using-webgenai-in-the-browser","title":"Using WebGenAI in the Browser","text":"<p>You can run WebGenAI locally on your desktop or your company may have a cloud version running. WebGenAI uses OpenAI ChatGPT and requires the configuration of both a license and an OpenAI API Key.  Watch the video here</p> <p>In this lab:</p> <ol> <li>Create the demo project from a prompt Prompt Engineering Basics</li> <li>Verify the logic by navigating to a Customer with an unshipped order, and altering one of the items to have a very large quantity</li> <li>Explore debugging logic using your Browser</li> </ol> <p> </p>"},{"location":"Tech-Training/#using-your-ide","title":"Using your IDE","text":""},{"location":"Tech-Training/#download-aka-export","title":"Download (aka Export)","text":"<p>The web-based interface is great for rapid creation, but you will enjoy much better debugging using your IDE.  We'll explore that in these next labs.</p> <p>Please see Export.</p> <p>Use the 'Project Download' link from the '2&gt; develop' page or the project page (as a tar file). Unzip or un-tar the file and copy to the manager or developer workspace.</p> <p> </p>"},{"location":"Tech-Training/#start-the-manager","title":"Start the Manager","text":"<p>The Manager is a pre-configured VSCode with samples used to help new developers learn about ApiLogicServer.  See the Manager documentation.</p> <p>See the procedure below (<code>cd ApiLogicServer; code .</code>)</p> <p> </p>"},{"location":"Tech-Training/#copy-your-project-to-the-manager-directory","title":"Copy your Project to the Manager Directory","text":"<p>As explained in Export.</p> <p> </p>"},{"location":"Tech-Training/#start-your-project","title":"Start your project","text":"<p>The Manager has a readme which explains how to run projects from inside the manager.  When you are getting started, it's easiest just to launch another instance of VSCode.  In the termimal window of VSCode:</p> <pre><code>cd &lt;your project&gt;\ncode .\n</code></pre> <p> </p>"},{"location":"Tech-Training/#explore-logic-debugging","title":"Explore Logic Debugging","text":"<p>Refer to the docs on logic debugging.</p> <ol> <li>Put a breakpoint on the constraint</li> <li>Start the Server (F5)</li> <li>Start the App in the Browser</li> <li>Verify the logic by navigating to a Customer with an unshipped order, and altering one of the items to have a very large quantity   * Observe the log, showing each rule firing with the row data</li> </ol> <p> </p>"},{"location":"Tech-Training/#explore-rule-concepts","title":"Explore Rule Concepts","text":"<p>ApiLogicServer provides a rule engine (LogicBank) to allow the developer to add derivations, constraints and events to any API endpoint.  These rules can be created by WebGenAI natural language or using the VSCode IDE manually entered.</p> <ol> <li>Rule Type Patterns </li> </ol> <p> </p>"},{"location":"Tech-Training/#webgenai-iterations","title":"WebGenAI Iterations","text":"<p>Explore WebGenAI iteration services:</p> <ol> <li>Use the 'Iterate' button to modify the created project</li> <li>Use the 'Logic'     button and the 'Suggestion' to create natural language rules</li> <li>Use the 'Update Model' button if the rules fail to activate</li> </ol> <p> </p>"},{"location":"Tech-Training/#dev-strategy-webgenai-ide-or-both","title":"Dev Strategy: WebGenAI, IDE, or Both?","text":"<p>You will find WebGenAI remains useful, particularly for updating the data model (e.g., as required for logic).  The system provides Import/Merge services to sync WebGenAI changes with IDE changes.</p> <p>If you elect to focus on IDE development, analogous services are provided with Rebuild from Model / Database, and Alembic support.</p> <p> </p>"},{"location":"Tech-Training/#concepts-and-facilities","title":"Concepts and Facilities","text":""},{"location":"Tech-Training/#command-line-basics","title":"Command Line Basics","text":"<p>The command line (cli) is the key to use all of the features of ApiLogicServer.  Note that each command may have a set of additional arguments: use --help to see the additional features (e.g. als genai --help).</p> <pre><code>als --help\nWelcome to API Logic Server {version}\n\nUsage: als [OPTIONS] COMMAND [ARGS]...\n\n      Creates [and runs] logic-enabled Python database API Logic Projects.\n\n          Creation is from your database (--db-url identifies a SQLAlchemy database)\n\n          Doc: https://apilogicserver.github.io/Docs\n          And: https://apilogicserver.github.io/Docs/Database-Connectivity/\n\n      Suggestions:\n\n          ApiLogicServer start                                # create and manage projects\n          ApiLogicServer create --db-url= --project-name=     # defaults to Northwind sample\n\n\nOptions:\n  --help  Show this message and exit.\n\nCommands:\n  about                  Recent Changes, system information.\n  add-auth               Adds authorization/authentication to curr project.\n  add-cust               Adds customizations to northwind, genai,...\n  add-db                 Adds db (model, binds, api, app) to curr project.\n  app-build              Builds runnable app from: ui/&lt;app&gt;/app-model.yaml\n  app-create             Creates Ontomize app model: ui/&lt;app&gt;/app-model.yaml\n  create                 Creates new customizable project (overwrites).\n  create-and-run         Creates new project and runs it (overwrites).\n  create-ui              Creates models.yaml from models.py (internal).\n  curl                   Execute cURL command, providing auth headers...\n  curl-test              Test curl commands (nw only; must be r)\n  examples               Example commands, including SQLAlchemy URIs.\n  genai                  Creates new customizable project (overwrites).\n  genai-create           Create new project from --using prompt text.\n  genai-iterate          Iterate current project from --using prompt text.\n  genai-logic            Adds (or suggests) logic to current project.\n  genai-utils            Utilities for GenAI.\n  login                  Login and save token for curl command.\n  rebuild-from-database  Updates database, api, and ui from changed db.\n  rebuild-from-model     Updates database, api, and ui from changed models.\n  run                    Runs existing project.\n  start                  Create and Manage API Logic Projects.\n  tutorial               Creates (updates) Tutorial.\n  welcome                Just print version and exit.\n</code></pre> <ol> <li>Explore cli create, add-auth, app-build, app-create, rebuild-from-database</li> <li>GenAI cli </li> </ol> <p> </p>"},{"location":"Tech-Training/#connect-to-sql","title":"Connect to SQL","text":"<p>If the project has an existing SQL DBMS (MySQL, PostgreSQL, SQL Server, Oracle) - ApiLogicServer can connect to SQL and build a detailed API. Review the documentation of Data-Model design, examples, keys, quoted identifiers, etc. In this lab - we will connect to the northwind database. <pre><code>als create --project-name=myproject --db-url=nw+\ncd myproject\ncode .\n</code></pre> Open database/models.py</p> <ol> <li>Data-Model-Design </li> <li>Primary Keys on each table</li> <li>Relationships (foreign keys) many-to-one (parent), one-to-many (children) (or many-to-many)</li> <li>Accented characters (als create --db-url=... --quote) quoted identifiers</li> <li>SQLAlchemy ORM model.py </li> <li>Run Server (F5) with or without security</li> <li>Start React Application (http://localhost:5656)</li> <li>Review OpenAI (Swagger) (http://localhost:5656/api) JSON API</li> </ol> <p> </p>"},{"location":"Tech-Training/#integration","title":"Integration","text":"<p>Some applications may require integration with other services (e.g. email, payment, workflow, etc)  In this lab - explore how to use the existing services to integration with Kafka or Workflow.</p> <ol> <li>Integration and Configuration Kafka</li> <li>Send a message to Kafka (event driven) by topic </li> <li>Listen for incoming Kafka message by topic</li> <li>Integration with Workflow (n8n) - Using WebHooks</li> <li>Configuration of Kafka or n8n (config.py)</li> </ol>"},{"location":"Tech-Training/#ontimize-angular-application","title":"Ontimize Angular Application","text":"<p>OntimizeWeb from Imatia is an Angular application that is automatically created from the command line. In this lab - review the Ontimize process here</p> <p>Start ApiLogicServer first (note: must enable security: als add-auth --provider-type=sql) <pre><code>als app-create --app=app\nals app-build --help\n example:\n\n      ApiLogicServer app-build \u2014app=name=app1\n\n      ApiLogicServer app-build \u2014app=name=app1 \u2014api-endpoint=Orders \n      # only build Orders          This creates app1/app-model.yml. \n\nOptions:\n  --project-name TEXT  Project containing App\n  --app TEXT           App directory name\n  --api-endpoint TEXT  API endpoint name\n  --template-dir TEXT  Directory of user defined Ontimize templates\n  --help               Show this message and exit.\n\n\nals app-build --app=app\ncd ui/app\nnpm install &amp;&amp; npm start  # http://localhost:4299\n</code></pre></p> <ol> <li>Create an Ontimize application</li> <li>Build (rebuild) Ontimize Application or Page</li> <li>Yaml File Basics</li> <li>Working with Templates </li> <li>Application Model Editor</li> <li>Advanced Filters (enable)</li> </ol> <p>Note: This version uses the Ontimize API Bridge - work is being done to use JSON API</p> <p> </p>"},{"location":"Tech-Training/#configure-security","title":"Configure Security","text":"<p>The ability to secure your application is an important part of the creation of any API Microservice application.  In this lab - review and try:</p> <ol> <li>Who Can Access - Authentication</li> <li>What can they Do - Authorization (role-based access control)</li> <li>Use KeyCloak local docker image</li> <li>Use SQL login</li> </ol>"},{"location":"Tech-Training/#deployment-devops","title":"Deployment (devops)","text":"<p>ApiLogicServer has a suite of tools for devops to build and deploy Docker containers. </p> <ol> <li>Build a Docker Image</li> </ol> <p> </p>"},{"location":"Tech-Training/#adv-project","title":"Adv Project","text":"<ol> <li>Adding attributes if they are not added automatically</li> <li>SQLIte to PostgreSQL migration (sqlite3 db.sqlite .dump &gt; postgres.sql)</li> <li>Rebuild test data (?)</li> </ol>"},{"location":"Tech-Training/#be-aware-of","title":"Be Aware Of","text":"<ol> <li>Behave Testing (optional)</li> <li>Alembic Schema Migration</li> </ol>"},{"location":"Tech-Training/#appendices","title":"Appendices","text":""},{"location":"Tech-Training/#start-the-manager_1","title":"Start the Manager","text":"<p>The Manager is a pre-configured VSCode with samples used to help new developers learn about ApiLogicServer.  See the Manager documentation.</p> <p>Recall you installed the manager when you installed API Logic Server. In a terminal window or powershell:</p> <pre><code>mkdir ApiLogicServer\ncd ApiLogicServer\npython -m venv venv\nsource venv/bin/activate      # windows: venv\\Scripts\\activate\npip install ApiLogicServer\nApiLogicServer start\n</code></pre> <p>Explore the NorthWind (nw) example to learn about ApiLogicServer.  Each folder represents a key concepts (e.g. config, api, database, logic, security, devops, test, ui)</p> <p>Later, when you exit VSCode, you can restart the Manager:</p> <pre><code>cd ApiLogicServer\ncode .\n</code></pre> <p> </p> <p> </p>"},{"location":"Tech-Training/#explore-the-folders","title":"Explore the folders","text":"<ol> <li>Config/config.py - runtime settings</li> <li>Database/models.py - SQLAlchemy ORM </li> <li>Api/custom_api.py - Custom API endpoints</li> <li>logic/declare_logic.py</li> <li>security declare_security.py and security/system/authentication.py </li> <li>devops containers - various docker scripts </li> <li>ui/admin admin.yaml - React back office</li> <li>test - behave testing</li> </ol>"},{"location":"Tech-Welcome/","title":"Welcome","text":""},{"location":"Tech-Welcome/#welcome-to-genai-logic","title":"Welcome to GenAI-Logic","text":"<p>By Val Huber, Sep 2025</p>"},{"location":"Tech-Welcome/#big-vision","title":"Big Vision","text":"<p>As AI accelerates change, business agility has never been more important. Our IT systems must keep up: It Should Be As Simple to Create a System as It Is to Imagine It potential impact.</p>"},{"location":"Tech-Welcome/#big-problem","title":"Big Problem","text":"<p>But that impact is held up by a big problem: Nearly half the effort in an IT system is the backend \u2014 the logic, the integration. But GenAI technology \u2014 on its own \u2014 turns a simple 5 line logic requirement into 200 lines of FrankenCode. And it\u2019s buggy. maintain the byte code of your compiler. We want to maintain the high level of abstraction of natural language.</p>"},{"location":"Tech-Welcome/#big-solution","title":"Big Solution","text":"<p>So, this means: We should not be asking GenAI to explode our 5 lines of logic into 200 lines of procedural code. We should be asking GenAI to translate our 5 lines of logic into rigorous, executable code at the same level of abstraction \u2014 just executable. That\u2019s Declarative GenAI. It\u2019s unique to GenAI-Logic. And it looks like this: Declarative GenAI translates 5 lines of logic into 5 lines of executable code, executable via the Declarative Rules Engine. NOT 200 lines of FrankenCode. This is the missing half of GenAI, enabling it to close the adoption gap for GenAI. For more on Declarative GenAI, click here.</p>"},{"location":"Tech-Welcome/#complete-enterprise-platform","title":"Complete Enterprise Platform","text":""},{"location":"Tech-Welcome/#but-declarative-logic-is-just-the-foundation-genai-logic-provides-a-complete","title":"But declarative logic is just the foundation. GenAI-Logic provides a complete","text":"<p>enterprise platform:</p>"},{"location":"Tech-Welcome/#declarative-automation","title":"Declarative Automation","text":""},{"location":"Tech-Welcome/#works-with-what-you-have","title":"Works With What You Have","text":"<p>modernize existing databases. In one minute, wrap any legacy database with a modern API, declarative business logic, and MCP integration. No rip-and- replace required. Enterprise Performance Traditional RETE engines and ORMs recalculate aggregates unconditionally, using expensive queries that slow down as data grows. Our engine prunes logic when it\u2019s not required, and uses an adjustment pattern approach to update incrementally. These have delivered constant regardless of database size. Automatic Governance Requirements traceability isn\u2019t a feature we added \u2014 it\u2019s built into the architecture. Natural language scenarios become executable rules that are transparent to business users. Run tests and get automatic documentation showing exactly which rules implemented which requirements, with complete execution logs. Auditors can trace any requirement from intent to execution.</p>"},{"location":"Tech-Welcome/#true-business-it-collaboration","title":"True Business-IT Collaboration","text":"<p>vision: \u201ca unified technology stack where business users can kick start systems that can be handed off to IT to complete as required.\u201d That\u2019s exactly what we built. Business users create working systems in minutes, iterate to get requirements right, then hand off standard Python projects to IT for completion. Big Impact: Organizational Business Agility This is more than developer productivity. It\u2019s organizational business agility: business and IT collaborating on systems that can evolve as fast as the business itself. Unlike traditional low-code tools that often pit business users against IT,</p>"},{"location":"Tech-Welcome/#genai-logic-enables-true-collaboration-business-users-draft-it-refines","title":"GenAI-Logic enables true collaboration \u2014 business users draft, IT refines,","text":"<p>and the system stays governable. We can now: to get the requirements right: First Draft of a System \u2014 this runs, ready to collaborate / iterate to get requirements right This creates an executable system in about a minute \u2014 web app, api with logic, and database: The Prompt above creates a Database, a User Interface, and an API with Swagger 2. Developers can (as required) download the project to finish it off. For more information, click here. They can vibe custom UIs, in minutes, that leverage the APIs and logic: Developers can use Vibe to create Custom User Interfaces 3. Developers can add MCP support \u2014 including logic \u2014 to existing databases, which in turn enables Business Users to compose their own services that adhere to organizational policies. Both scenarios depend on Declarative GenAI logic, unique to GenAI-Logic. Proviso: No Automation Tax OK\u2026 but to get this technology, we should not be required to lose the value of our existing tools and methodologies. Achieving the full potential requires it should leverage our existing IDEs (such as Copilot), source code management, testing, deployment, monitoring, etc. Developers can Customize Logic and APIs with their Favorite Tools For more on Living with Logic, click here, and here. Check It Out</p>"},{"location":"Tech-Welcome/#the-takeaway-genai-logic-isnt-just-developer-productivity-it-closes-the","title":"The takeaway: GenAI-Logic isn\u2019t just developer productivity. It closes the","text":"<p>adoption gap that has stalled enterprise AI by making business logic \u2014 half the project effort \u2014 declarative, governable, and real. Explore GenAI-Logic, free and open source: Try our free WebGenAI tool \u2014 see what complete Declarative GenAI looks like. Build future-ready systems in 1 minute, then download the working code to your IDE.</p>"},{"location":"Tech-Welcome/#install-genai-logic-locally-create-run-debug-projects-in-your-ide-for","title":"Install GenAI-Logic locally \u2014 create, run, debug projects in your IDE, for","text":"<p>existing or new databases. Create a B2B system in minutes with Copilot vibe and GenAI-Logi\u2026 Watch on Supporting Articles: Vibe a B2B System With Copilot Enterprise Vibe Automation \u2014 click here Declarative GenAI \u2014 the architecture underneath Enterprise Vibe Automation \u2014 click here The Missing Half of GenAI \u2014 and Why Microsoft\u2019s CEO Says It\u2019s the Future \u2014 click here Living with Logic in the Enterprise \u2014 click here Vibe an MCP Server: Declarative GenAI Logic \u2014 click here</p>"},{"location":"Tech-Welcome/#vibe-with-copilot-and-genai-logic-click-here","title":"Vibe With CoPilot and GenAI-Logic \u2014 click here","text":"<p>Declarative GenAI \u2014 Business User / IT Collaboration \u2014 click here Declarative Logic: Living in a Procedural World \u2014 click here Probabilistic and Deterministic Logic \u2014 click here What\u2019s your take on this? I\u2019d love to hear your story in the comments. Vibe Coding</p>"},{"location":"Tech-Welcome/#summing-up","title":"Summing Up","text":"<p>[Figure placeholders restored here if applicable]</p>"},{"location":"Tech-m1/","title":"M1 Mac","text":"<p>This page documents my move from a 2019 Intel MBP 16 to a 2021 M1 Pro 14 (32G).</p>"},{"location":"Tech-m1/#requirements","title":"Requirements","text":"<p>Besides typical home use, I rely on this machine for API Logic Server dev.  That entails testing across</p> Aspect Specifics Using OS Mac, Windows 11, Unix (Ubuntu) Parallels 14 DB Sqlite, MySql, Sql/Server, Postgres Docker IDE VSCode, Pycharm Docs GitHub Pages, MKDocs, Google Docs, slides Other Better Touch Tool"},{"location":"Tech-m1/#notes","title":"Notes","text":""},{"location":"Tech-m1/#parallels-windows11","title":"Parallels / Windows11","text":"<p>This was rather remarkable.  Under MBP 16 / VMWare Fusion / Windows 10, boot time was 70 seconds.  Under M1 / Parallels / Windows 11, it is 8-10 seconds.</p>"},{"location":"Tech-m1/#docker-for-apilogicserver","title":"Docker - For ApiLogicServer","text":"<p>Installs and runs without issue.  </p>"},{"location":"Tech-m1/#initially-slower","title":"Initially slower","text":"<p>It is slower, however, on M1.  For example, once started, the <code>ApiLogicServer welcome</code> command takes under a second on x86, but 7-9 on M1.</p>"},{"location":"Tech-m1/#update-arm-based-images-are-quite-fast","title":"Update - ARM-based images are quite fast","text":"<p>On investigation, you can create separate docker images for x86 vs. ARM.  The ARM version starts instantly.</p>"},{"location":"Tech-m1/#building-dual-docker-images-failing","title":"Building Dual Docker Images - failing","text":"<p>It appears to be possible to build images that run on both AMD and ARM, but I have not been able to address that.   Initial attempt failed with:</p> <pre><code>multiarch-support:amd64 : Depends: libc6:amd64 (&gt;= 2.3.6-2) but it is not inst\n</code></pre> <p>Researching this.</p>"},{"location":"Tech-m1/#install-initially-failed-due-to-psycopg2-postgres","title":"Install initially failed due to <code>psycopg2</code> (Postgres)","text":"<p>Ran into significant drame with Postgres support - <code>psycopg2</code>.  Under investigation.  Evidently this is not supported out of the box.  There are various approaches that work if you are willing to install Postgres locally.  I had been using Docker, so this remains an open item.</p> <p>So that M1 Macs work, API Logic Server version 05.03.34 has removed the psycopg2 from the install, so it needs to be installed manually.</p>"},{"location":"Tech-m1/#resolved-m1-support-released","title":"Resolved - M1 support released","text":"<p>Update: as of Oct 2022, the most recent release of <code>psycopg2</code> provides ARM support.  With this, Postgres happily runs fine.  As of 6.1.2, it will no longer require manual install.</p>"},{"location":"Tech-m1/#docker-databases-running","title":"Docker Databases - running","text":"<p>The Docker database images work for M1 Macs, except SQL/Server (it fails to start). It is architecture specific.</p> <p>These solutions were successful as described here.  Many thanks for the following information:</p> <ul> <li> <p>ODBC Driver</p> </li> <li> <p>SQL/Server</p> </li> </ul>"},{"location":"Tech-mkdocs-material/","title":"Mkdocs Material","text":"<p>When I first started the project, I used GitHub Wiki for docs.  It worked, but... meh.  In particular, combining site and page navigation into 1 tree on the right obscured the organization of the docs... and product.  That's a serious problem.</p> <p>I was delighted to discover GitHub Docs where you can build a minimal web site of static pages.</p> <p>But what really made it work was the addition of mkdocs-material, which is now the basis for the current docs.  It enabled me to define navigation (the left tree), and automitically creates the table of contents on the right.  I think you'll agree the transformation was magical.</p> <p>It was not to hard to set up, since my pages were all markdown.  Hightlights, to perhaps save you some time:</p> <ol> <li> <p>Create a docs folder</p> <ul> <li>If you have wiki docs, you can get all the pages using the link in the lower right</li> </ul> </li> <li> <p>Create a <code>mkdocs.yml</code> (navigation, etc)</p> </li> <li> <p>Create a GitHub Workflow so that when you commit doc changes, the doc site is rebuilt.</p> </li> </ol> <p>There was 1 confusion, which was nearly funny.  I read the gh-pages docs to say that I should put my pages in that branch.  Uh-uh.  That's the branch used to build the html output; when it built, it overwrote my source pages.  Not a big problem, but a surprise you probably want to avoid.</p>"},{"location":"Troubleshooting/","title":"Troubleshooting","text":"<p>Please report bugs as GitHub Issues.</p>"},{"location":"Troubleshooting/#using-discord","title":"Using Discord","text":"<p>We use Discord for support - join here.  You should install the Discord app.</p> <p>It can be tricky to use Discord for screen sharing - here is the procedure for a mac:</p> <ol> <li>Start a call with a contact</li> <li>Share your screen:</li> </ol> <p></p> <p> </p>"},{"location":"Troubleshooting/#install-failures","title":"Install Failures","text":""},{"location":"Troubleshooting/#pyodbc-fails-to-install","title":"<code>pyodbc</code> fails to install","text":"<p>For API Logic Server releases 5.02.16 and earlier, installation may fail with issues such as:</p> <pre><code>sql.h not found - your console log might include:\n...\n    src/pyodbc.h:56:10: fatal error: 'sql.h' file not found\n</code></pre> <p>Resolve these as explained here.</p>"},{"location":"Troubleshooting/#unsupported-architecture-macos","title":"Unsupported Architecture - MacOS","text":"<p>You may experience alarming messages when you <code>pip install</code> API Logic Server.  These can occur installing <code>pyodbc</code>, and can occur when installing API Logic Server, or creating <code>venv</code> for created API Logic Projects.  We've seen the following:</p> <pre><code>  \u00d7 Running setup.py install for pyodbc did not run successfully.\n      /Library/Developer/CommandLineTools/SDKs/MacOSX.sdk/usr/include/sys/cdefs.h:807:2: error: Unsupported architecture\n      #error Unsupported architecture\n</code></pre> <p>Resolve this by adding this to your <code>~/.zprofile</code>:</p> <pre><code>PATH=\"/Library/Frameworks/Python.framework/Versions/3.10/bin:${PATH}\"\nexport PATH\nexport ARCHFLAGS=\"-arch x86_64\"  # &lt;=== enable this line\n</code></pre> <p> </p>"},{"location":"Troubleshooting/#initial-project-creation","title":"Initial Project Creation","text":"<p>Project Creation involves 2 steps that can cause errors, described in the following sub-sections.</p>"},{"location":"Troubleshooting/#database-failed-to-open","title":"Database failed to open","text":"<p>The <code>db_url</code> argument is a SQLAlchemy database uri.  For several examples we use in our testing, click here.</p>"},{"location":"Troubleshooting/#check-connectivity-using-sql-tools","title":"Check Connectivity using SQL Tools","text":"<p>A typical cause is lack of connectivity to the database.  Use your local database tools to verify connectivity from your machine to the database.</p>"},{"location":"Troubleshooting/#oracle-connectivity","title":"Oracle Connectivity","text":"<p>You may require thick mode.</p> <p>Also, note that API Logic Server provides 2 diagnostic programs as shown in the link above.</p>"},{"location":"Troubleshooting/#dynamic-model-import-failed","title":"Dynamic model import failed","text":"<p>After the database is opened, it is introspected to build <code>database/models.py</code>, classes used by SQLAlchemy and the API for database access.  The models file may fail to compile, often due to unexpected names.</p> <p>Watch for entries like this in the console log:</p> <pre><code>6. Create api/expose_api_models.py and ui/basic_web_app/app/views.py (import / iterate models)\n.. ..Dynamic model import using sys.path: /Users/val/dev/servers/sqlserver-types/database\n\n===&gt; ERROR - Dynamic model import failed\n\n===&gt; ERROR - Unable to introspect model classes\n.. Using db for meta (models not found)\n.. See ../Troubleshooting#manual-model-repair\n.. ..WARNING - no relationships detected - add them to your database or model\n.. ..  See https://github.com/valhuber/LogicBank/wiki/Managing-Rules#database-design\n</code></pre> <p>You may also encounter errors when the system attempts to start the server, due to invalid model files. These may look like this:</p> <pre><code>Run created ApiLogicServer with command: python /Users/val/dev/servers/sqlserver-types/api_logic_server_run.py localhost\nTraceback (most recent call last):\n  File \"/Users/val/dev/ApiLogicServer/api_logic_server_cli/cli.py\", line 253, in find_meta_data\n</code></pre>"},{"location":"Troubleshooting/#repair-the-model-and-rebuild_from_model","title":"Repair the model, and <code>rebuild_from_model</code>","text":"<p>The system will log errors and attempt to proceed with project creation.  You can then:</p> <ol> <li>Open the project in your IDE, and manually correct the <code>models.py</code> file    * E.g., specify proper class names</li> <li>Rerun <code>ApiLogicServer</code>, specifying the <code>rebuild_from_model</code> parameter, like this: <pre><code>ApiLogicServer rebuild-from-model\\\n--project_name=~/dev/servers/sqlserver-types\\\n--db_url=mssql+pyodbc://sa:Posey3861@localhost:1433/SampleDB?\\driver=ODBC+Driver+17+for+SQL+Server&amp;trusted_connection=no\n</code></pre></li> <li>You will most likely want to activate the api and app files:    * <code>api/expose_api_models_created.py</code> - this file is not used in actual operation, but provided so you can merge or copy it over <code>api/expose_api_models.py</code>    * <code>ui/admin/admin-created.yaml</code> - this file is not used in actual operation, but provided so you can merge or copy it over <code>ui/admin/admin.yaml</code></li> </ol> <p>For more on rebuild, see Rebuilding.</p> <p></p> <p> </p> <p> </p>"},{"location":"Troubleshooting/#database-issues","title":"Database Issues","text":"<p>Database access requires:</p> <ul> <li> <p>Connectivity: for more information, see connectivity</p> </li> <li> <p>Configuration: ensure your project is correctly configured; see Container Configuration</p> </li> <li> <p>Proper database definition: see these notes on Postgresql auto-generated keys.</p> </li> </ul> <p> </p>"},{"location":"Troubleshooting/#docker-api-logic-server-connecting-to-dockerized-databases","title":"Docker API Logic Server connecting to dockerized databases","text":"<p>Even when you can access the database to create the project, your dockerized project may fail to connect.  This is often caused by not enabling your project for network access.  See the link above.</p> <p> </p>"},{"location":"Troubleshooting/#sql-server-requires-pyodbc","title":"SQL Server - requires `pyodbc'","text":"<p>SqlServer requires the <code>pyodbc</code> package.  You can't just <code>pip install</code> it.  Attempting to do so will cause errors such as:</p> <pre><code>sql.h not found - your console log might include:\n...\n    src/pyodbc.h:56:10: fatal error: 'sql.h' file not found\n</code></pre> <p>Resolve these as explained in the Quick Start.</p> <p> </p>"},{"location":"Troubleshooting/#sqlite-delete-adjustments-fail","title":"Sqlite delete adjustments fail","text":"<p>Sqlite requires special considerations for cascade delete.  For more information, click here.</p> <p> </p>"},{"location":"Troubleshooting/#docker","title":"Docker","text":"<p>Docker can dramatically simplify installation, but be aware of the topics described in the sub-sections below:</p>"},{"location":"Troubleshooting/#docker-on-windows","title":"Docker on Windows","text":"<p>Docker requires Windows Pro for a native install, using hyper-v.  If Docker Desktop fails to start, check these instructions.</p> <p>If you have Windows Home, be aware it's not supported, but some brave souls have found ways.</p> <p>Docker sometimes fails with multi-level virtualization, such as running Mac &gt; Windows on Fusion.</p>"},{"location":"Troubleshooting/#vs-code-with-docker-unable-to-open-file-unable-to-read-file","title":"VS Code with Docker - unable to open file, unable to read file","text":"<p>Under circumstances still unclear, your container may be unable to locate internal files. Port conflicts can cause re-assignments that need corrections.</p> <p>These are easy to resolve as explained here.</p>"},{"location":"Troubleshooting/#vs-code-damaged-container","title":"VS Code - damaged container","text":"<p>You may need to rebuild your container, as described here.</p>"},{"location":"Troubleshooting/#vs-code-damaged-port-settings","title":"VS code - damaged port settings","text":"<p>You may encounter unexpected port changes, such as using <code>localhost:5657</code> instead of the usual <code>localhost:5656</code>.  Resolve this as shown below:</p> <p></p>"},{"location":"Troubleshooting/#permission-denied-homeapi_logic_projectinstance","title":"Permission denied: <code>/home/api_logic_project/instance</code>","text":"<pre><code>Traceback (most recent call last):\n  File \"/home/api_logic_project/./api_logic_server_run.py\", line 323, in &lt;module&gt;\n    api_logic_server_setup(flask_app, args)\n  File \"/home/api_logic_project/./api_logic_server_run.py\", line 229, in api_logic_server_setup\n    db.init_app(flask_app)\n  File \"/usr/local/lib/python3.11/site-packages/flask_sqlalchemy/extension.py\", line 325, in init_app\n    self._apply_driver_defaults(options, app)\n  File \"/usr/local/lib/python3.11/site-packages/flask_sqlalchemy/extension.py\", line 576, in _apply_driver_defaults\n    os.makedirs(app.instance_path, exist_ok=True)\n  File \"&lt;frozen os&gt;\", line 225, in makedirs\nPermissionError: [Errno 13] Permission denied: '/home/api_logic_project/instance'\n</code></pre> <p>This appears to occur when:</p> <ol> <li>You create the same-named image from 2 different directories (e.g, a staging test)</li> <li>And you are using sqlite (default apps use the image for the database)</li> </ol> <p>Currently under investigation.</p>"},{"location":"Troubleshooting/#ide-issues","title":"IDE Issues","text":""},{"location":"Troubleshooting/#code-completion-fails","title":"Code Completion fails","text":"<p>Code completion depends on a properly installed <code>venv</code>.  The digram below shows how code completion exposes valuable services provided by <code>logic_row</code>, and how to verify your <code>venv</code> setting for VSCode:</p> <p></p>"},{"location":"Troubleshooting/#venv-setup","title":"<code>venv</code> Setup","text":"<p><code>venv</code> setup is automatic for Docker installs.  For local installs, we have seen the issues below.</p> <p> </p>"},{"location":"Troubleshooting/#pycharm","title":"PyCharm","text":"<p>In some installations, PyCharm may fail when your <code>venv</code> is pre-created.  I have found it best to let PyCharm create the <code>venv</code>, like this:</p> <p></p> <p>If you encounter issues, consider these suggestions.</p> <p> </p>"},{"location":"Troubleshooting/#vscode-fails-to-discover-venv","title":"VSCode fails to discover <code>venv</code>","text":"<p>In most cases, VSCode discovers <code>venv</code> environments, whether created prior to launching VSCode, or created inside the newly created project.</p> <p>However, this process occasionally fails.  For example, if you create the project successfully, then delete and recreate it, VSCode may not discover your <code>venv</code>.  This is usually resolved by:</p> <ol> <li>Create the <code>venv</code> as described in the Quick Start</li> <li>Exit / restart VSCode</li> <li>Use View &gt; Command Palette &gt; Python: Select Interpreter, and select the entry <code>\"venv\u201d: venv</code>.  See the diagram below.</li> </ol> <p>It's a good idea to verify your <code>venv</code>, as described in the next section.</p> <p></p>"},{"location":"Troubleshooting/#verify-your-python-environment","title":"Verify your Python environment","text":"<p>A common mistake is to install API Logic Server globally, with no <code>venv</code>.  This global version might still be in use, even if there were subsequent installs of newer versions.  If you then run the recent install without a <code>venv</code>, you'll be running the older global version.</p> <p>Note you need to install and run under the new version of <code>venv</code>.</p> <p>On Macs and Linux:</p> <pre><code>% ApiLogicServer        # will identify version\n% which ApiLogicServer  # should include your venv in path, like this:\n/Users/val/dev/ApiLogicServer/venv/bin/ApiLogicServer\n</code></pre> <p>As of release 5.02.10, you can run <code>venv_setup/py.py sys-info</code>, either</p> <ul> <li>Using Command Line Python (e.g, <code>python venv_setup/py.py sys-info</code>), or</li> <li>In VSCode, select the file and use the Launch Configuration Python: Current File.</li> <li>Note: this may properly update the Python <code>venv</code> information if it was not properly set</li> </ul> <p></p> <p> </p>"},{"location":"Troubleshooting/#python-issues","title":"Python Issues","text":""},{"location":"Troubleshooting/#macos-installs","title":"MacOS Installs","text":"<p>Such installs can be daunting:</p> <ul> <li>Which installer: Python.org installer, or brew?</li> <li>Additional utlities required: Rely on additional tooling, such as <code>pyenv</code> or <code>venv</code>?</li> <li>Install history: is the Mac default Python (2) installed?  Are there prior installs, using one or both of the methods above</li> <li><code>pyodbc</code> is particularly challenging</li> </ul>"},{"location":"Troubleshooting/#choose-simple-case","title":"Choose simple case","text":"<p>With so many variables, I have researched the simplest possible scenario:</p> <ul> <li>Clean Monterey install (no existing Python)</li> <li>Using <code>zsh</code> (not <code>bash</code>)</li> <li>Use (only) the Python.org installer</li> </ul>"},{"location":"Troubleshooting/#1-basic-install-with-command-line-tools","title":"1. Basic install - with Command Line Tools","text":"<p>Run the installer, including certificates and updates to your shell. </p> <p>Python operations (such as <code>pip install</code>) often require command line tools (<code>c</code> compiler, etc).  You have 2 ways to get these:</p> <ol> <li> <p>Basic command line tools: you have 2 options:</p> </li> <li> <p>As described here</p> </li> <li> <p>Or, many installs (including API Logic Server) will recommend this with a popup dialog (for example, see this article) - do so unless you require <code>xcode</code>...</p> </li> <li> <p>Installation of <code>xcode</code> from the Apple App Store (<code>xcode</code> install takes a long time -- like, all day)</p> </li> </ol> <p>Next, verify the items below.</p>"},{"location":"Troubleshooting/#2-verify-python3-runs","title":"2. Verify <code>python3</code> runs","text":"<p>This enables not only python, but provides access to required utilities:</p> <pre><code>python3 --version\npython3 -m venv --help    # creates a venv\npython3 -m pip --version  # install from PyPi\n</code></pre>"},{"location":"Troubleshooting/#3-optionally-enable-python-as-default","title":"3. Optionally, enable <code>python</code> as default","text":"<p>The basic install requires you use <code>python3</code> and <code>pip3</code>, as shown above.  This can affect command scripts, and is a bit clumsy.  You can make <code>python</code> and <code>pip</code> work, by altering these 2 files:</p> <p>My <code>~/.zshrc</code>:</p> <pre><code>alias python=/Library/Frameworks/Python.framework/Versions/3.10/bin/python3\n\nsetopt interactive_comments\nPATH=~/.local/bin:$PATH\n# python ~/py.py # discussed below\n</code></pre> <p>My <code>~/.zprofile</code>:</p> <pre><code>PATH=\"/Library/Frameworks/Python.framework/Versions/3.10/bin:${PATH}\"\nexport PATH\n# export ARCHFLAGS=\"-arch x86_64\"  \n</code></pre>"},{"location":"Troubleshooting/#4-verify-your-python-environment","title":"4. Verify your Python environment","text":"<p>With all these moving parts, I found it necessary to verify my environment every time I start the terminal:</p> <ol> <li> <p>Obtain <code>py.py</code> from your API Logic Server install - create a project, and copy <code>venv_setup/py.py</code> to your home folder</p> </li> <li> <p>Enable the commented out line in <code>~/.zshrc</code></p> </li> </ol> <p> </p>"},{"location":"Troubleshooting/#certificate-failures","title":"Certificate Failures","text":"<p>You may see this in the console log when running <code>ApiLogicServer run</code>:</p> <pre><code>1. Create ui/basic_web_app with command: flask fab create-app --name /Users/me/Documents/Development/ApiLogicServer/api_logic_server/ui/basic_web_app --engine SQLAlchemy\nresult: Something went wrong &lt;urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1123)&gt;\\nTry downloading from https://github.com/dpgaspar/Flask-AppBuilder-Skeleton/archive/master.zip\n</code></pre> <p>This may be due to a certificate issue.  The <code>python.org</code> installer includes a script for this, or try this, or like this.</p> <p> </p>"},{"location":"Troubleshooting/#azure-cloud-deployment","title":"Azure Cloud Deployment","text":""},{"location":"Troubleshooting/#use-sqlserver-auth","title":"Use SqlServer Auth","text":"<p>Login failed for user ''. The server is not currently configured to accept this token."},{"location":"Troubleshooting/#sqlserver-auth-type-ad-vs-sqlserver-auth","title":"SqlServer Auth Type (AD vs SQLServer Auth)","text":""},{"location":"Troubleshooting/#pyodbc-version","title":"pyodbc version","text":""},{"location":"Troubleshooting/#browser-cache","title":"Browser Cache","text":"<p>Browser caches can interfere with changes to Apps and Keycloak security.  You can completely clear your Browser cache, or clear it just for your local dev:</p> <ul> <li>Safari</li> </ul> <p></p> <ul> <li>Chrome</li> </ul> <p></p>"},{"location":"Tutorial-3/","title":"Detailed Tutorial","text":""},{"location":"Tutorial-3/#about-this-detailed-tutorial","title":"About this Detailed Tutorial","text":"<p>Use this Detail Tutorial to introduce using API Logic facilities, and for coding examples.  Use your IDE to search for <code>#als</code> -- you'll a list of examples we believe you'll find useful.</p> <p>It is designed for these scenarios:</p> <ul> <li> <p>You are using codespaces / VSCode, open to either the tutorial project, or app_fiddle.</p> </li> <li> <p>You are using a local install (pip install) version of API Logic Server, and have reviewed the tutorial readme.</p> </li> <li> <p>You are using a docker version of API Logic Server, and have reviewed the tutorial readme.</p> </li> <li> <p>Projects are pre-configured for VS Code with <code>.devcontainer</code> and <code>launch configurations,</code> so these instructions are oriented around VS Code.</p> </li> <li> <p>You are reviewing the docs, and want to get a sense of the software</p> </li> </ul> <p>In this tutorial, we will explore:</p> <ul> <li> <p>create - we will briefly review what actually happens during the create process.</p> </li> <li> <p>run - we will first run the Admin App and the JSON:API.  These will illustrate how automation creates an app and API from a data model.  You can then infer what you'd get for one of your databases.</p> </li> <li> <p>customize - we will then explore some customizations already done for the API and logic, and how to debug them.</p> </li> </ul> <p> </p>"},{"location":"Tutorial-3/#key-underlying-concepts","title":"Key Underlying Concepts","text":"<p>This tutorial illustrates some key concepts:</p>"},{"location":"Tutorial-3/#declarative-models-not-code","title":"Declarative Models, not code","text":"<p>Observe that the files for the Admin App and API are models that describe what, not how.  This makes it much easier to understand than large amounts of generated code.</p>"},{"location":"Tutorial-3/#preserve-customizations","title":"Preserve Customizations","text":"<p>The system is designed to enable <code>rebuild</code>, so you can iterate the data model - without losing your customizations.  In general, such customizations are kept in separate files from the model files.  So, the model files can be rebuilt without affecting customization files.</p>"},{"location":"Tutorial-3/#logic-automation","title":"Logic Automation","text":"<p>A unique feature of API Logic Server is provision for spreadsheet-like rules, customizable with Python.  Rules address update logic (multi-table derivations and constraints), and security (authorization).</p> <p> </p>"},{"location":"Tutorial-3/#create","title":"Create","text":"<p>The diagram above summarizes the create / run / customize process.  When you issue the <code>ApiLogicServer create</code> CLI command, the system reads your schema and creates a customizable API Logic Project.</p> <p>It's a video - click to view.</p> <p> </p>"},{"location":"Tutorial-3/#create-and-establish-python-environment","title":"Create and establish Python Environment","text":"<p>After creation, you must establish your Python environment:</p> <ul> <li>This is already complete for Codespace users</li> <li>Other users - please  see Quick Start &gt; Express Install.  Note there are different instructions, depending on how your install / IDE.</li> </ul> <p> </p>"},{"location":"Tutorial-3/#start-the-server-and-admin-app","title":"Start the Server and Admin App","text":"<p>Stop any running servers that might still be running from the readme - \u00a0\u00a0(square red button at top in \"Show me how\", below).</p> <p>Now (see Show me how, below, for details):</p> <ol> <li>Start the server with Run and Debug &gt;&gt; 2. API Logic Project: Instant, Open, and then </li> <li>Start the Browser at localhost:5656 by clicking the url shown in the console log.</li> </ol>  Show me how  <p> </p> <p>To run the ApiLogicProject app:</p> <ol> <li> <p>Start the Server:</p> <ol> <li>Click Run and Debug</li> <li>Use the dropdown to select 3. API Logic Project: Logic, and</li> <li>Click the green button to start the server </li> </ol> </li> <li> <p>Start the Browser at localhost:5656 by clicking the url shown in the console log.</p> </li> </ol> <p> </p>"},{"location":"Tutorial-3/#run","title":"Run","text":"<p>With the server started and the Admin App open in your Browser, we are ready to explore the Admin App and the API.</p> <p> </p>"},{"location":"Tutorial-3/#admin-app-multi-page-multi-table-automatic-joins","title":"Admin App: Multi-Page, Multi-Table, Automatic Joins","text":"<p>After starting the server and browser, explore the Admin App in your browser:</p> <ol> <li>Navigate to <code>Customer</code><ul> <li>Depending on your screen size, you may need to hit the \"hamburger menu\" (top left) to see the left menu</li> </ul> </li> <li>Click the first Customer row  to see Customer Details</li> <li>Observe the <code>Placed Order List</code> tab at the bottom</li> <li>Click the first Order row</li> <li>Observe the <code>Order Detail List</code> tab at the bottom</li> <li> <p>Observe the elements shown in the diagram</p> <ul> <li>Multi-Page - 2 pages for each table (list, with search, and display)</li> <li>Multi-Table - database relationships (typically from foreign keys) used to build master/detail pages</li> <li>Automatic Joins - the Order Detail table contains <code>ProductId</code>, but the system has joined in the <code>Product Name</code>.  You can edit the <code>admin.yaml</code> file to control such behavior.</li> </ul> </li> <li> <p>Leave the server and browser running</p> </li> </ol> <p></p> <p> </p> <p>Key Take-away: instant multi-page / multi-table admin apps, suitable for back office, and instant agile collaboration.</p> <p> </p>"},{"location":"Tutorial-3/#jsonapi-related-data-filtering-sorting-pagination-swagger","title":"JSON:API - Related Data, Filtering, Sorting, Pagination, Swagger","text":"<p>Your API is instantly ready to support ui and integration development, available in swagger, as shown below.  JSON:APIs are interesting because they are client configurable to reduce network traffic and minimize organizational dependencies.</p> <p>The creation process builds not only the API, but also swagger so you can explore it.  The Admin App Home page provides a link to the swagger.  In the browser:</p> <ol> <li>Click Home to open the Home Page</li> <li>Click \"2. API with oas/Swagger\" to see the swagger</li> <li>(Leave the swagger and server running)</li> </ol> <p></p> <p> </p> <p>Key Take-away: instant rich APIs, with filtering, sorting, pagination and swagger.  Custom App Dev is unblocked.</p> <p> </p>"},{"location":"Tutorial-3/#customize-and-debug","title":"Customize and Debug","text":"<p>That's quite a good start on a project.  But we've all seen generators that get close, but fail because the results cannot be extended, debugged, or managed with tools such as git and diff.</p> <p>Let's examine how API Logic Server projects can be customized for both APIs and logic.  We'll first have a quick look at the created project structure, then some typical customizations.</p> <p>To run the customized app:</p> <ol> <li>Stop the server</li> <li>Restart the server with Run and Debug &gt;&gt; 3. API Logic Project: Logic, and then</li> <li>Start the Browser at localhost:5656 by clicking the url shown in the console log.</li> <li>Re-access the swagger, and authorize (see below):    * Click \"2. API with oas/Swagger\" to see the swagger (as you did above)    * Get an access_token and authorize (see Show me how, below)</li> </ol>  Show me how  <p> </p> <p>Get <code>access_token</code>:</p> <ul> <li>Click the <code>auth/Post</code> endpoint (at the end of the swagger)</li> <li>Click Try it out</li> <li>Click Execute (you'll need to scroll down a bit)</li> <li>Copy the <code>access_token</code> to your clipboard</li> </ul> <p> Authenticate with your <code>access_token</code></p> <ul> <li>Scroll up to the top of the swagger, and click Authorize</li> <li>Enter Bearer, add a space, paste your <code>access_token</code>, click Authorize, and Close the dialog </li> </ul> <p> </p>"},{"location":"Tutorial-3/#project-structure","title":"Project Structure","text":"<p>Use VS Code's Project Explorer to see the project structure under 3. ApiLogicProject_Logic:</p> Directory Usage Key Customization File Typical Customization <code>api</code> JSON:API <code>api/customize_api.py</code> Add new end points / services <code>database</code> SQLAlchemy Data Model Classes <code>database/customize_models.py</code> Add derived attributes, and relationships missing in the schema <code>logic</code> Transactional Logic <code>logic/declare_logic.py</code> Declare multi-table derivations, constraints, and events such as send mail / messages <code>security</code> Admin App <code>security/declare_security.py</code> Control role-based access to data rows <code>integration</code> Consume Kafka Messages <code>integration/kafka/kafka_consumer.py</code> Application Integration <code>ui</code> Admin App <code>ui/admin/admin.yaml</code> Control field display, ordering, etc. <p>Let's now explore some examples.</p>"},{"location":"Tutorial-3/#admin-app-customization","title":"Admin App Customization","text":"<p>There is no code for the Admin app - it's behavior is declared in the <code>admin.yaml</code> model file.  Alter this file to control labels, hide fields, change display order, etc:</p> <ol> <li>In your IDE, open Explorer &gt; 3. ApiLogicProject_Logic/ui/admin/admin.yaml    * Find and alter the string <code>- label: 'Placed Order List'</code> (e.g, make it plural)    * Click Save</li> <li>Load the updated configuration: in the running Admin App, click Configuration &gt; Reset and Apply</li> <li>Revisit Customer &gt; Order to observe the new label</li> </ol> <p> </p> <p>Key Take-away: you can alter labels, which fields are displayed and their order, etc -- via a simple model.  No need to learn a new framework, or deal with low-level code or html.</p> <p> </p>"},{"location":"Tutorial-3/#api-customization","title":"API Customization","text":"<p>While a standards-based API is a great start, sometimes you need custom endpoints tailored exactly to your business requirement.  You can create these as shown below, where we create an additional endpoint for <code>add_order</code>.</p> <p>To review the implementation: </p> <ol> <li>In your IDE, open Explorer &gt; 3. ApiLogicProject_Logic/api/customize_api.py:</li> <li>Set the breakpoint as shown in <code>add_order</code></li> <li>Use the swagger to access the <code>ServicesEndPoint &gt; add_order</code>, and</li> <li>Try it out, then </li> <li>execute</li> <li>Your breakpoint will be hit</li> <li>You can examine the variables, step, etc.</li> <li>Click Continue on the floating debug menu (upper right in screen shot below)</li> </ol> <p></p> <p> </p>"},{"location":"Tutorial-3/#logic","title":"Logic","text":"<p>API and UI automation are impressive answers to familiar challenges.  Logic automation is a unique answer to a significant and unaddressed problem:</p> <p>For transaction systems, backend constraint and derivation logic is often nearly half the system.  This is not addressed by conventional approaches consisting only of \"your code goes here\".</p> <p>The logic portion of API Logic server is a declarative approach - you declare spreadsheet-like rules for multi-table constraints and derivations.  The 5 rules shown below represent the same logic as 200 lines of Python - a remarkable 40X.</p> <p>Since they automate all the re-use and dependency management, rules are 40X more concise than code.  Like a spreadsheet, rules watch for changes, react by automatically executing relevant rules, which can chain to activate other rules; you can visualize the process here.</p> <p>Logic consists of rules and conventional Python code.  Explore it like this:</p> <ol> <li>Open Explorer &gt; 3. ApiLogicProject_Logic/logic/declare_logic.py:    * Observe the 5 rules highlighted in the diagram below.  These are built with code completion.</li> <li>Set a breakpoint as shown in <code>congratulate_sales_rep</code>    * This event illustrates that logic is mainly rules, customizable with standard Python code</li> <li>Using swagger, re-execute the <code>add_order</code> endpoint</li> <li>When you hit the breakpoint, expand <code>row</code> VARIABLES list (top left)</li> </ol> <p></p> <p>Internally, rules execute by listening to SQLAlchemy <code>before_flush</code> events, as described here.</p> <p>This rule architecture ensures that rules are always re-used across all client applications and integrations.  This avoids common \"fat client\" approaches that embed logic in user interface controllers, which leads to replication and inconsistency.</p> <p> </p>"},{"location":"Tutorial-3/#security-logic","title":"Security Logic","text":"<p>The declarative approach addresses not only multi-table derivations and constraint logic, it addresses security.  This controls who can login, and what data they see.  </p> <p>The overview Tutorial noted how grants on the <code>Category</code> table controlled what rows users like u1 and u2 were able to see.  The grant logic is in <code>security/declare_security.py</code>.  For more on security, see here.</p> <p> </p>"},{"location":"Tutorial-3/#test","title":"Test","text":"<p>You can test using standard api and ui test tools.  We recommend exploring the Behave framework.  This can be used as part of an overall agile approach as described in the Logic Tutorial.</p> <p>TL;DR - features and test scripts are predefined in the sample; to run them (with the server running):</p> <ol> <li>Run Launch Configuration <code>Behave Run Behave</code> </li> <li>Run Launch Configuration <code>Behave Logic Report</code> </li> <li>Open <code>test/api_logic_server_behave/reports/Behave Logic Report.md</code></li> </ol> <p> </p> <p>The sample Scenarios below were chosen to illustrate the basic patterns of using rules. Open the disclosure box (\"Tests - and their logic...\") to see the implementation and notes.   </p> <p>For more information, see Testing with Behave.</p> <p> </p>"},{"location":"Tutorial-3/#wrap-up","title":"Wrap up","text":"<p>Let's recap what you've seen:</p> <ul> <li> <p>ApiLogicProject Creation and Execution - a database API and an Admin App - created automatically from a database, in moments instead of weeks or months</p> </li> <li> <p>Customizable - the UI, API and Logic - using Visual Studio code, for both editing and debugging</p> </li> </ul>"},{"location":"Tutorial-3/#next-steps","title":"Next Steps","text":"<p>After the Tutorial, these are excellent next steps:</p> <ul> <li>Try other databases - here are some installed samples, and try your own</li> <li>Explore the Logic Tutorial.</li> </ul>"},{"location":"Tutorial-3/#docker-cleanup","title":"Docker cleanup","text":"<p>VS Code leaves the container and image definitions intact, so you can quickly resume your session.  You may wish to delete this. It will look something like <code>vsc-ApiLogicProject...</code>.</p> <p> </p>"},{"location":"Tutorial-AI/","title":"API Logic Server","text":"<p> AI-Driven Automation with ChatGPT Delivers the Agile Vision</p> <p>Agile wisely advises getting Working Software as fast as possible, to facilitate Business User Collaboration and Iteration.  ChatGPT and API Logic Server deliver this vision, with 1 hour project cycles:</p> <ol> <li>Create Database With ChatGPT</li> <li> <p>Create Working Software Now with API Logic Server:</p> <ul> <li>Creates executable, customizable projects from databases: API with Swagger, Admin App</li> <li>Declare logic and security with spreadsheet-like rules, using your IDE</li> </ul> </li> <li> <p>Deploy for Collaboration with API Logic Server: e.g. to the Azure Cloud</p> </li> <li>Iterate: add additional rules, with a pinch of Python as required</li> </ol> <p>This process leverages your existing IT infrastructure: your IDE, GitHub, the cloud, your database\u2026 open source.</p> <p>To give it a try, click here.  Allow 20 minutes, a bit more if you are new to Azure.</p> <p>, </p>"},{"location":"Tutorial-Agile/","title":"Agile Tutorial","text":"<p> AI-Driven Automation Delivers the Agile Vision</p> <p>Agile wisely advises getting Working Software as fast as possible, to facilitate Business User Collaboration and Iteration.  ChatGPT and API Logic Server deliver this vision, with 1 hour project cycles:</p> <ol> <li>Start with an existing SQL database</li> <li> <p>Create Working Software Now with API Logic Server:</p> <ul> <li>Self-serve API: ready for UI Dev, no custom server dev required</li> <li>Admin App: ready for Business User collaboration</li> </ul> </li> <li> <p>Deploy for Collaboration with API Logic Server: e.g. to the Azure Cloud</p> </li> <li>Iterate: using:<ul> <li>Rules: 40X more concise than code for the backend half of your system</li> <li>Python: as required for complete flexibility</li> </ul> </li> </ol> <p>This process leverages your existing IT infrastructure: your IDE, GitHub, the cloud, your database\u2026 open source.</p> <p>To give it a try, click here.  Allow 20 minutes, a bit more if you are new to Azure.</p> <p>, </p>"},{"location":"Tutorial-Deployment/","title":"Deployment Tutorial","text":"<p> TL;DR - Working Software, Now</p> <p>Agile wisely advises getting Working Software as fast as possible, to facilitate Business User Collaboration and Iteration:</p> <ol> <li> <p>Instant Creation: create working software from a database.</p> </li> <li> <p>Publish to GitHub: for dev team collaboration</p> </li> <li> <p>Dev Deploy to the Cloud: use the working software to collaborate with Business Users</p> </li> </ol> <p>With API Logic Server, if you have a database, you can create and dev deploy within an hour.</p> <p></p>"},{"location":"Tutorial-Deployment/#deployment-tutorial","title":"Deployment Tutorial","text":"<p>In this Tutorial, we start with a database, and:</p> <ol> <li> <p>Create a Project, and verify it works</p> </li> <li> <p>Create a Docker Image, and verify it works</p> </li> <li> <p>Create a docker-compose application (project + database), and verify it works</p> </li> <li> <p>Deploy it to Azure - collaboration-ready for UI Developers and Business Users</p> </li> </ol> <p>The entire process takes about 20 minutes.</p> <p>While your team is collaborating, you can proceed to declare logic and security, augmented with Python code.</p> <p>To begin, click here.</p>"},{"location":"Tutorial/","title":"Sample Application Tutorial","text":""},{"location":"Tutorial/#api-logic-server-sample-tutorial","title":"API Logic Server Sample Tutorial","text":"<p>Welcome to API Logic Server - thanks for giving it a try!</p> <p>This is the sample app.  It was created from the pre-installed sqlite Northwind database (Customer, Order, OrderDetail, Product, etc.).</p> <p>In this tutorial, we will explore:</p> <ol> <li> <p>Create - we will briefly review what actually happened during the create process.</p> </li> <li> <p>Run - we will first run the Admin App and the JSON:API.  These will illustrate how automation creates an app and API from a database.  Use this to infer what you'd get for one of your databases.</p> </li> <li> <p>Customize - we will then explore customizing and debugging the project.</p> </li> </ol> <p> </p>"},{"location":"Tutorial/#key-underlying-concepts","title":"Key Underlying Concepts","text":"<p>This tutorial illustrates some key concepts:</p>"},{"location":"Tutorial/#declarative-models-not-code","title":"Declarative Models, not code","text":"<p>Observe that the files for the Admin App and API are models that describe what, not how.  This level of abstratction is much easier to understand than large amounts of generated code.</p>"},{"location":"Tutorial/#automated-automation","title":"Automated Automation","text":"<p>Not only do models automate functionality, the models themselves are automated, created instantly when you create a project.  That means you have instant Working Software.</p>"},{"location":"Tutorial/#customize-using-standard-tools","title":"Customize - using standard tools","text":"<p>The system is designed for you to customize the UI, Logic, Security and API, using standard tools - your IDE for code editing / debugging, git, etc.</p>"},{"location":"Tutorial/#iterate-preserve-customizations","title":"Iterate - Preserve Customizations","text":"<p>The system is designed to enable <code>rebuild</code>, so you can iterate the data model - without losing your customizations.  In general, such customizations are kept in separate files from the model files.  So, the model files can be rebuilt without affecting customization files.</p>"},{"location":"Tutorial/#logic-automation","title":"Logic Automation","text":"<p>A unique feature of API Logic Server is provision for spreadsheet-like rules, customizable with Python.  Rules address update logic (multi-table derivations and constraints), and security (authorization).</p> <p> </p>"},{"location":"Tutorial/#development-overview","title":"Development Overview","text":"<p>The diagram above summarizes the create / run / customize process.</p> <p>It's a video - click to view.</p> <p> </p>"},{"location":"Tutorial/#1-create-instant-project","title":"1. Create: Instant Project","text":"<p>The CLI command below creates an <code>ApiLogicProject</code> by reading your schema.  </p> <p>Note: the <code>db_url</code> value is defaulted to the pre-installed sample project; you would normally supply a SQLAlchemy URL.  </p> <p><pre><code>$ ApiLogicServer create --project_name= --db_url=    # create ApiLogicProject\n</code></pre> </p>"},{"location":"Tutorial/#2-run","title":"2. Run","text":"<p>You can then open the project in your IDE, and run it as follows:</p> <ol> <li> <p>Create <code>venv</code>: as shown in the Readme (not required for VSCode or Docker)</p> </li> <li> <p>Start the Server: F5 (PyCharm: Ctl-D).</p> </li> <li> <p>Start the Admin App: either use the links provided in the IDE console, or click http://localhost:5656/.  The screen shown below should appear in your Browser.</p> </li> </ol> <p>The system has created an API and an Admin App.  Let's explore them.</p>"},{"location":"Tutorial/#2a-self-serve-api-ad-hoc-integration","title":"2.a Self-Serve API: Ad hoc Integration","text":"<p>The system creates a JSON:API with end points for each table, providing filtering, sorting, pagination, optimistic locking and related data access.</p> <p>The API is self-serve: consumers can select their own attributes and related data, eliminating reliance on custom API development.  Our self-serve API meets requirements for Ad Hoc Application Integration, and Custom UI Dev.</p> <p></p>"},{"location":"Tutorial/#2b-admin-app-multi-page-multi-table-automatic-joins","title":"2.b Admin App: Multi-Page, Multi-Table, Automatic Joins","text":"<p>The <code>create</code> command also creates an Admin App: multi-page, multi-table with automatic joins -- ready for business user agile collaboration, and back office data maintenance.  This complements custom UIs you can create with the API.</p> <p>After starting the server and browser, explore the Admin App in your browser:</p> <ol> <li>Navigate to <code>Customer</code><ul> <li>Depending on your screen size, you may need to hit the \"hamburger menu\" (top left) to see the left menu</li> </ul> </li> <li>Click the first Customer row  to see Customer Details</li> <li>Click the <code>ORDERLIST</code> tab at the bottom</li> <li>Click the first Order row</li> <li>Observe the <code>ORDERDETAILLIST</code> tab at the bottom</li> <li> <p>Observe the elements shown in the diagram</p> <ul> <li>Multi-Page - 2 pages for each table (list, with search, and display)</li> <li>Multi-Table - database relationships (typically from foreign keys) used to build master/detail pages</li> <li>Automatic Joins - the Order Detail table contains <code>ProductId</code>, but the system has joined in the <code>Product Name</code>.  You can edit the <code>admin.yaml</code> file to control such behavior.</li> </ul> </li> </ol> <p></p> <p>Key Takeaway: Microservice AutomationWith 1 command, we have created an executable project with a self-serve API, for ad hoc application integration and custom UI development.  Our Admin App can be used for agile business user collaboration.</p> <p> </p>"},{"location":"Tutorial/#3-customize-and-debug-in-your-ide","title":"3. Customize and Debug: in your IDE","text":"<p>While API/UI automation is a great start, we now require Custom APIs, Logic and Security.</p> <p>You normally apply such customizations using your IDE, leveraging code completion, etc.  To accelerate this sample, you can apply the customizations with <code>ApiLogicServer add-cust</code>.   We'll review the customizations below.</p>  Show me how -- apply customizations  <p> </p> <p>The following <code>add-cust</code> process simulates:</p> <ul> <li>Adding security to your project using a CLI command, and</li> <li> <p>Using your IDE to:</p> <ul> <li>declare logic in <code>logic/declare_logic.sh</code></li> <li>declare security in <code>security/declare_security.py</code></li> <li>implement custom APIs in <code>api/customize_api.py</code>, using <code>OrderShipping</code> declared in <code>integration/row_dict_maps</code></li> </ul> </li> </ul> <p>These customizations are shown in the screenshots below.</p> <p>To apply customizations, in a terminal window for your project:</p> <p>1. Stop the Server (Red Stop button, or Shift-F5 -- see Appendix)</p> <p>2. Apply Customizations: in the terminal window of your IDE:</p> <pre><code>ApiLogicServer add-cust\nApiLogicServer add-auth --db_url=auth  # version 10.3.14 or greater\n</code></pre> <p>3. Restart the server, login as <code>admin</code></p> <p></p> <p>In the sections below, we will explore:</p> <ul> <li>a. UI Customizations</li> <li>b. Logic Customizations</li> <li>c. Security Customizations</li> <li>d. Application Integration Customizations</li> </ul>"},{"location":"Tutorial/#3a-customize-ui-declare-ui-behavior","title":"3.a Customize UI: Declare UI Behavior","text":"<p>The admin app is not built with complex html and javascript.  Instead, it is configured with  <code>ui/admin/admin.yml</code>, automatically created from your data model by <code>ApiLogicServer create</code>.</p> <p>You can customize this file in your IDE to control which fields are shown (including joins), hide/show conditions, help text etc.  The <code>add-cust</code> process above has simulated such customizations.</p> <p>To see customized Admin app in action, with the restarted server:</p> <p>1. Start the Admin App: http://localhost:5656/</p> <p>2. Login as <code>ALFKI</code>, password <code>p</code></p> <p>3. Click Customers</p> <p>4. Click the first Customer</p> <p>5. Click <code>Add New Order</code> (bottom of page)</p> <p>6. Click <code>Employee</code> and choose the first one</p> <p>7. Click <code>SAVE AND SHOW</code></p> <p>8. Click <code>ADD NEW ORDER DETAIL</code></p> <p>9. Lookup <code>CHAI</code> and enter an excessive Quantity as shown below</p> <p>One customization has been to hide several Order fields (search <code>ui/admin/admin.yml</code> for <code>show_when: isInserting == false</code>).  This makes it convenient to use the Admin App to enter an Order and OrderDetails:</p> <p></p> <p> </p> <p>Note the automation for automatic joins (Product Name, not ProductId) and lookups (select from a list of Products to obtain the foreign key).  If we attempt to order too much Chai, the transaction properly fails due to the Check Credit rules, described below.</p> <p> </p>"},{"location":"Tutorial/#3b-customize-logic-declare-check-credit-rules","title":"3.b Customize Logic: Declare Check Credit Rules","text":"<p>Such logic (multi-table derivations and constraints) is a significant portion of a system, typically nearly half.  API Logic server provides spreadsheet-like rules that dramatically simplify and accelerate logic development.</p>"},{"location":"Tutorial/#ide-declare-and-debug","title":"IDE: Declare and Debug","text":"<p>The 5 check credit rules are shown below in <code>logic/declare_logic.py</code>.  </p> <p>Rules are 40X more concise than legacy code, as shown here.</p> <p>Rules are declared in Python, simplified with IDE code completion.  The <code>add-cust</code> process above has simulated the process of using your IDE to declare logic.</p> <p>Observe rules can be debugged using standard logging and the debugger:</p> <p></p> <p> </p> <p>Rules operate by handling SQLAlchemy events, so apply to all ORM access, whether by the api engine, or your custom code.  Once declared, you don't need to remember to call them, which promotes quality.</p> <p>The rules shown above prevented the too-big order with multi-table logic to copy the Product Price, compute the Amount, roll it up to the AmountTotal and Balance, and check the CreditLimit.  </p> <p>These same rules also govern changing orders, deleting them, picking different parts - about 9 transactions, all automated.  Implementing all this by hand would otherwise require about 200 lines of code.</p>"},{"location":"Tutorial/#agility-quality","title":"Agility, Quality","text":"<p>Rules are a unique and significant innovation, providing meaningful improvements over procedural logic:</p> CHARACTERISTIC PROCEDURAL DECLARATIVE WHY IT MATTERS Reuse Not Automatic Automatic - all Use Cases 40X Code Reduction Invocation Passive - only if called Active - call not required Quality Ordering Manual Automatic Agile Maintenance Optimizations Manual Automatic Agile Design <p> </p> <p>Key Takeway -  Logic: Multi-table Derivations and Constraint Rules, Extensible with Python  Rules are: 1. Declared in your IDE - 40X more concise 2. Activated on server start 3. Executed - automatically -  on updates (using SQLAlchemy events) 4. Debugged in your IDE, and with the console log For more on rules, click here.</p> <p> </p>"},{"location":"Tutorial/#3c-customize-security-declare-grants","title":"3.c Customize Security: Declare Grants","text":"<p>The <code>add-cust</code> process above has simulated the <code>ApiLogicServer add-auth</code> command, and using your IDE to declare security in <code>logic/declare_security.sh</code>.</p> <p>To see security in action:</p> <p>1. Logout (upper right), and Login as <code>AFLKI</code>, password <code>p</code></p> <pre><code>* This authorized user has 2 roles: `customer` and 'tenant`\n</code></pre> <p>2. Click Customer - observe you now see only 1 customer (per the <code>customer</code> role)</p> <p></p>"},{"location":"Tutorial/#login-row-filtering","title":"Login, Row Filtering","text":"<p>Declarative row-level security ensures that users see only the rows authorized for their roles.  Observe you now see only customer ALFKI, per the security declared below.  Note the console log at the bottom shows how the filter worked.</p> <p></p> <p> </p> <p>Key Takeway -  Row-Level Security: Customers Filtered</p> <p> </p>"},{"location":"Tutorial/#3d-application-integration-b2b-and-shipping","title":"3.d Application Integration: B2B and Shipping","text":"<p>We now have a running system - an API, logic, security, and a UI.  Now let's see how integrate with:</p> <ul> <li>Incoming B2B partners: we'll create a B2B Custom Resource</li> <li>Outgoing OrderShipping: we add logic to Send an OrderShipping Message</li> </ul> <p> </p>"},{"location":"Tutorial/#b2b-custom-resource","title":"B2B Custom Resource","text":"<p>The self-serve API does not conform to the format required for a B2B partnership.  We need to create a custom resource.</p> <p>You can create custom resources by editing <code>customize_api.py</code>, using standard Python, Flask and SQLAlchemy.  A custom <code>OrderB2B</code> resource is shown below.</p> <p>The main task here is to map a B2B payload onto our logic-enabled SQLAlchemy rows.  API Logic Server provides a declarative <code>RowDictMapper</code> class you can use as follows:</p> <ol> <li> <p>Declare the mapping -- see the <code>OrderB2B</code> class in the lower pane</p> <ul> <li>Note the support for lookup, so partners can send ProductNames, not ProductIds</li> </ul> </li> <li> <p>Create the custom API endpoint -- see the upper pane:</p> <ul> <li>Add <code>def OrderB2B</code> to <code>customize_api/py</code> to create a new endpoint</li> <li>Use the <code>OrderB2B</code> class to transform a api request data to SQLAlchemy rows (<code>dict_to_row</code>)</li> <li>The automatic commit initiates the same shared logic described above to check credit and reorder products</li> </ul> </li> </ol> <p></p> <p> </p> <p>Key Takeway -  Custom Endpoint - 7 lines of codeSo, our custom endpoint required about 7 lines of code, along with the API specification.  We use standard Python, Flask and SQLAlchemy.  Note the logic is automatically factored out, and re-used for all APIs, both custom and self-serve.</p> <p> </p>"},{"location":"Tutorial/#produce-ordershipping-message","title":"Produce <code>OrderShipping</code> Message","text":"<p>Successful orders need to be sent to Shipping, again in a predesignated format.</p> <p>We could certainly POST an API, but Messaging (here, Kafka) provides significant advantages:</p> <ul> <li>Async: Our system will not be impacted if the Shipping system is down.  Kafka will save the message, and deliver it when Shipping is back up.</li> <li>Multi-cast: We can send a message that multiple systems (e.g., Accounting) can consume.</li> </ul> <p>The content of the message is a JSON string, just like an API.</p> <p>Just as you can customize apis, you can complement rule-based logic using Python events:</p> <ol> <li> <p>Declare the mapping -- see the <code>OrderShipping</code> class in the right pane.  This formats our Kafka message content in the format agreed upon with Shipping.</p> </li> <li> <p>Define a Python <code>after_flush</code> event, which invokes <code>send_order_to_shipping</code>.  This is called by the logic engine, which passes the SQLAlchemy <code>models.Order</code> row.</p> </li> <li> <p><code>send_order_to_shipping</code> uses the <code>OrderShipping</code> class, which maps our SQLAlchemy order row to a dict (<code>row_to_dict</code>).</p> </li> </ol> <p></p> <p> </p> <p>Key Takeway -  Extensible Rules, Kafka Message ProducedRule-based logic is extensible with Python, here producing a Kafka message with 20 lines of code.</p> <p> </p>"},{"location":"Tutorial/#3e-customize-the-data-model","title":"3.e Customize the Data Model","text":"<p>You can also alter the data model, while preserving customizations.  For more information, see Database Design Changes.</p> <p> </p>"},{"location":"Tutorial/#testing","title":"Testing","text":""},{"location":"Tutorial/#behave","title":"Behave","text":"<p>You can test using standard api and ui test tools.  We recommend exploring the Behave framework.  This can be used as part of an overall agile approach as described in the Logic Tutorial.</p> <p>TL;DR - features and test scripts are predefined in the sample; to run them (with the server running):</p> <ol> <li>Run Launch Configuration <code>Behave Run</code> </li> <li>Run Launch Configuration <code>Behave Logic Report</code> </li> <li>Open <code>test/api_logic_server_behave/reports/Behave Logic Report.md</code></li> </ol> <p> </p> <p>The sample Scenarios below were chosen to illustrate the basic patterns of using rules. Open the disclosure box (\"Tests - and their logic...\") to see the implementation and notes.   </p> <p>For more information, see Testing with Behave.</p> <p> </p>"},{"location":"Tutorial/#test-it","title":"Test it","text":"<p>Use your IDE terminal window to simulate a business partner posting a B2BOrder.  You can set breakpoints in the code described above to explore system operation.</p> <p><pre><code>ApiLogicServer curl \"'POST' 'http://localhost:5656/api/ServicesEndPoint/OrderB2B'\" --data '\n{\"meta\": {\"args\": {\"order\": {\n    \"AccountId\": \"ALFKI\",\n    \"Surname\": \"Buchanan\",\n    \"Given\": \"Steven\",\n    \"Items\": [\n        {\n        \"ProductName\": \"Chai\",\n        \"QuantityOrdered\": 1\n        },\n        {\n        \"ProductName\": \"Chang\",\n        \"QuantityOrdered\": 2\n        }\n        ]\n    }\n}}}'\n</code></pre> </p>"},{"location":"Tutorial/#summary","title":"Summary","text":"<p>After the Tutorial, these are excellent next steps:</p> <ul> <li>Further explore Application Integration - open the Sample Integration tutorial<ul> <li>It will show how to activate Kafka so that the message above is actually sent</li> <li>It will ilustrate to the consume Kafka messages</li> <li>You've already created most of it, so...<ul> <li>Scan the intro</li> <li>See Show me how -- apply customizations, start Kafka</li> <li>And Consuming Messages</li> </ul> </li> </ul> </li> <li>Try other databases - here are some installed samples, and try your own</li> <li>Explore the Logic Tutorial.</li> </ul> <p>The standard readme now follows.</p>"},{"location":"WebGenAI-CLI/","title":"GenAI CLI","text":"<p> TL;DR - Create Microservice from Natural Language Prompt using CLI</p> <p>API Logic Server / GenAI provides CLI commands that accept a Natural Language prompt (e.g, CRM system), and produces:</p> <ul> <li>an executable database system: an Admin App, a JSON API and logic</li> <li>the underlying project that you can download and customize in your IDE using rules and Python</li> <li>which can be deployed as a container using automatically generated scripts.</li> </ul> <p>API Logic Server / GenAI uses: </p> <ul> <li>GenAI services (ChatGPT) for data model creation, and </li> <li>API Logic Server for project creation.</li> </ul> <p>You can also use GenAI services via the GenAI WebSite.  For Web/GenAI architecture, click here.</p> <p> </p>"},{"location":"WebGenAI-CLI/#overview","title":"Overview","text":"<p>To use GenAI to create projects</p> <ol> <li>Establish your virtual environment (suggestion: use the Manager)</li> <li>Provide a <code>--using</code> prompt in either a file or a directory:</li> </ol> Project creation with GenAI<pre><code>als genai --using=system/genai/examples/genai_demo/genai_demo.prompt\n</code></pre> <p>Projects are created in the currrent working directory, here, the manager.</p> <p> </p>"},{"location":"WebGenAI-CLI/#configuration","title":"Configuration","text":"<p>GenAI uses ChatGPT, which requires an API Key.  The simplest approach is to</p> <ol> <li>Obtain one from here or here</li> <li>Authorize payments here</li> <li>Create an environmental variable <code>APILOGICSERVER_CHATGPT_MODEL</code></li> </ol> <p> </p>"},{"location":"WebGenAI-CLI/#create-projects","title":"Create Projects","text":"<p>You can use the als cli to create projects with logic.  See the example provided in the Manager:</p> <p></p> <p>Note:</p> <ol> <li>Logic files can contain derivations and constraints</li> <li>The system will create model attributes for derived columns.</li> </ol> <p> </p>"},{"location":"WebGenAI-CLI/#key-directories-temp-and-docs","title":"Key Directories: Temp and Docs","text":"<p>When you create projects, the system saves prompts and responses.  This provided for documentation, error recovery, and iterations (described below):</p> <p></p> <p> </p>"},{"location":"WebGenAI-CLI/#iterating-projects","title":"Iterating Projects","text":"<p>You can review created projects by using the app, and/or reviewing the data model.  Of course, it's simple to resubmit a new prompt and re-create the project.</p> <p>However, this will be a completely new rendition of your idea, and it may change things you like about the project.  Iterations enable you to keep what you already have, while making desired changes.</p> <p>When you create a project, the API Logic Server / GenAI saves your prompt and response in a conversation-directory.  Iterations are saved in 2 different conversation-directories:</p> <ul> <li> <p>the manager's <code>system/genai/temp/&lt;project&gt;</code> directory</p> </li> <li> <p>the created project's <code>doc</code> directory.</p> </li> </ul> <p>The <code>--using</code> argument can be a file, or a directory.  That means you can iterate by adding files to the  manager's <code>system/genai/temp/&lt;project&gt;</code> directory.  See the example provided in the Manager:</p> <p></p> <p> </p>"},{"location":"WebGenAI-CLI/#add-prompt-to-docs-directory","title":"Add Prompt to docs directory","text":"<p>The approach for an iteration is to create a new project from an existing one:</p> <ol> <li>add another prompt to an existing projects' <code>docs</code> directory, specifying your changes</li> <li>use <code>als genai</code>, specifying <ul> <li><code>--using</code> existing projects <code>docs</code> directory, and </li> <li><code>--project-name</code> as the output project</li> </ul> </li> </ol> <p>See the readme of the Manager for examples.</p> <p> </p>"},{"location":"WebGenAI-CLI/#ide-nat-language-docslogic","title":"IDE Nat Language: <code>docs/logic</code>","text":"<p>As shown below, you can add Natural Language logic to existing projects.  Using an existing project located under the Manager:</p> <ol> <li> <p>Create a prompt such as <code>docs/logic/check_credit.prompt</code></p> <ul> <li>Create logic files in <code>docs/logic</code></li> <li>Use a descriptive name to denote the purpose of the logic</li> <li>Your <code>docs/logic</code> can contain multiple files; only <code>.prompt</code> files are processed</li> </ul> </li> <li> <p>In the terminal window:</p> </li> </ol> Create logic from docs/logic prompt files<pre><code>cd &lt;project root&gt;\nals genai-logic\n</code></pre> <ol> <li>Your logic is created in <code>logic/logic_discovery</code>.  For more information, see Managing Logic.</li> </ol> <p>Notes:</p> <ul> <li>See the notes above for creating new projects with logic</li> <li>Unlike new projects, columns are not created automatically for derived attributes.  You can create these as described in data model changes.</li> <li>Most likely, you will maintain the logic in the <code>logic_discovery</code> directory.<ul> <li>When you are done, you might want to rename the <code>docs/logic</code> files (e.g., change the file extension) so they are not processed on future runs.</li> </ul> </li> </ul> <p></p> <p> </p>"},{"location":"WebGenAI-CLI/#logic-suggestions","title":"Logic Suggestions","text":"<p>You can ask GenAI to suggest logic for your system.  This can help you learn about rules, and can inspire your own imagination about required logic.</p> <p>It's AI, so or course you will want to review the suggestions carefully.</p> <p></p> <p>Explore suggestions using the Manager:</p> 1. Create Project, without Rules<pre><code># 1. Create Project, without Rules\nals genai --project-name='genai_demo_no_logic' --using=system/genai/examples/genai_demo/genai_demo_no_logic.prompt\n</code></pre> 2. Request Rule Suggestions<pre><code># 2. Request Rule Suggestions\ncd genai_demo_no_logic\nals genai-logic --suggest\n</code></pre> <p>You can review the resultant logic suggestions in the <code>genai_demo_no_logic</code> project:</p> <ul> <li>See and edit: <code>docs/logic_suggestions/002_logic_suggestions.prompt</code> (used in step 3, below)<ul> <li>This corresponds to the WebGenAI Logic Editor - Logic View in the WebGenAI web app</li> </ul> </li> </ul> 3. See the rules for the logic<pre><code># 3. See the rule code for the logic\nals genai-logic --suggest --logic='*'\n</code></pre> <p>Important notes about suggestions and generated code:</p> <ul> <li><code>--suggest --logic='*'</code> is intended to enable you to identify logic that does not translate into proper code</li> <li>The example above was pretty good, but sometimes the results are downright silly:<ul> <li>Just run suggest again, or</li> <li>Repair <code>docs/logic_suggestions/002_logic_suggestions.prompt</code></li> </ul> </li> </ul> <p>Also...</p> <ul> <li>It is not advised to paste the code into <code>logic/declare_logic.py</code><ul> <li>The suggested logic may result in new data model attributes</li> <li>These are created automatically by running <code>als genai</code> (next step)</li> </ul> </li> </ul> <p>The logic suggestions directory (<code>genai_demo_no_logic/docs/logic_suggestions</code>) now contains the prompts to create a new project with the suggested logic. When you are ready to proceed: 1. Execute the following to create a new project (iteration), with suggested logic:</p> 4. Create a new project with the Rule Suggestions<pre><code># 4. Create a new project with the Rule Suggestions\ncd ..  # important - back to manager root dir\nals genai --project-name='genai_demo_with_logic' --using=genai_demo_no_logic/docs/logic_suggestions\n</code></pre> <p>Observe:</p> <ol> <li>The created project has the rule suggestions in <code>logic/declare_logic.py</code></li> <li>A revised Data Model in <code>database/models.py</code> that includes attributes introduced by the logic suggestions</li> <li>Revised test database, initialized to reflect the derivations in the suggested logic</li> </ol> <p> </p>"},{"location":"WebGenAI-CLI/#fixup-add-missing-attributes","title":"Fixup: Add Missing Attributes","text":"<p>Fixes project issues by updating the Data Model and Test Data.  When adding rules, such as using suggestions, you may introduce new attributes. If these are missing, you will see exceptions when you start your project.</p> <p>The <code>genai-utils --fixup</code> fixes such project issues by updating the Data Model and Test Data.  For more information, see Fixup.</p> <p> </p>"},{"location":"WebGenAI-CLI/#rebuild-test-data","title":"Rebuild Test Data","text":"<p>The following is provided to fix project issues by rebuilding the database to conform to the derivation rules.  This procedure is available in the Manager README (see Explore Creating Projects &gt; Rebuild the test data).</p> <ol> <li>Create genai_demo:  <pre><code>als genai --using=system/genai/examples/genai_demo/genai_demo.prompt --project-name=genai_demo\n</code></pre></li> <li>Rebuild: <pre><code>cd genai_demo\nals genai-utils --rebuild-test-data\n</code></pre></li> </ol> <p> </p> <p>Fixup</p> <p>To Fix it: 1. Run FixUp to add missing attributes to the fixup response data model<pre><code># 1. Run FixUp to add missing attributes to the data model\ncd genai_demo_fixup_required\nals genai-utils --fixup\n</code></pre></p> <p>Finally, use the created fixup files (<code>genai_demo_fixup_required/docs/fixup</code>) to rebuild the project: 2. Rebuild the project from the fixup response data model<pre><code># 2. Rebuild the project from the fixup response data model\ncd ../\nals genai --repaired-response=genai_demo_fixup_required/docs/fixup/response_fixup.json --project-name=fixed_project\n</code></pre></p> <p>\u00a0 The created project may still report some attributes as missing. (ChatGPT seems to often miss attributes mentioned in sum/count where clauses.)  To fix:</p> <ol> <li>Note the missing attributes(s) from the log</li> <li>Add them to <code>docs/003_suggest.prompt</code></li> <li>Rebuild the project: <code>als genai --project-name='genai_demo_with_logic' --using=genai_demo_no_logic/docs</code></li> </ol> <p>Internal Note: this sequence available in the run configs (f1/f2).</p> <p> </p>"},{"location":"WebGenAI-CLI/#customized-project-sync","title":"Customized Project Sync","text":"<p>In the prior section, the result was a recreated project.  If you have customized the project, you can preserve your customizations as follows:</p> <ol> <li>Copy <code>database/models.py</code> and <code>db.sqlite</code> from the GenAI to your customized project</li> <li> <p>In your customized project, use <code>als rebuild-from-model</code> </p> <ul> <li>For further information, see Database Design Changes.</li> </ul> </li> </ol> <p> </p>"},{"location":"WebGenAI-CLI/#export","title":"Export","text":"<p>You can export your project from WebGenAI, either from the Browser or from GitHub:</p> <p></p> <p>This enables you to verify all aspects of project operation, and extend GenAI functionality in your local IDE.</p> <p> </p>"},{"location":"WebGenAI-CLI/#open-in-your-ide","title":"Open in your IDE","text":"<p>Once have exported and expanded the tar file:</p> <p></p> <ol> <li>Optionally, copy the project folder to your manager folder (where you installed API Logic Server).<ul> <li>This is not required, but it keeps your projects organized, and provide quick access to the Samples that illustrate typical customizations.</li> </ul> </li> <li> <p>Setup your virtual environment - see Virtual Environment.  </p> <ul> <li> <p>You can create a new venv, but it's simplest just to use the one used by the Manager.</p> </li> <li> <p>Note: in some configurations of VSCode (e.g., mac multiple projects in the same window), it may not allow you to specify your virtual environment.  You can fix this:</p> <ul> <li>Set the proper virtual environment in <code>.vscode/settings.json</code>: <code>\"python.defaultInterpreterPath\": \"~/dev/ApiLogicServer/ApiLogicServer-dev/build_and_test/ApiLogicServer/venv/bin/python\"</code></li> <li>Rename the project</li> </ul> </li> </ul> </li> <li> <p>Verify your default value settings, as shown below (typically True)</p> </li> <li>You should then be able to open and run the exported project in your IDE.  In the terminal window of your IDE:<ul> <li>`cd  <li><code>code .</code></li> <p></p> <p> </p>"},{"location":"WebGenAI-CLI/#wg_rules-and-ide-rules","title":"wg_rules and IDE rules","text":"<p>The system is designed to support concurrent ongoing Multi-Team Development from WebGenAI, and from traditional development.  For more information, see Import / Merge WebGenai.</p> <p>To simplify the file mechanics during merge, WebGenAI rules are stored separately from rules created in the IDE:</p> Logic Source Stored Source of Truth - Manage In WebGenAI Rules <code>logic/wg_rules</code> The WebGenAI system.  Import / merge projects into local dev environment using Import / Merge WebGenAI IDE Rules <code>logic/declare_logic.py</code>, and (optionally) as files in <code>logic/logic_discovery</code> IDE / Source control <p>Note: when using the project in the IDE, you can force wg_rules mode by setting environment variable <code>WG_PROJECT</code>.  This can be useful in problem diagnosis</p> <p></p> <p> </p>"},{"location":"WebGenAI-CLI/#multi-read-only-wg_rules-files","title":"Multi read-only wg_rules files","text":"<p>Consider that WebGenAI and IDEs are quite different environments.  For example, IDEs support code completion and highlight errors, while WebGenAI uses Natural Language (which does not have 'syntax errors').</p> <p>Without an IDE, WebGenAI users still require diagnostics about which rules fail to properly compile.  This requires the system to break each rule into a separate file, as shown above.</p> <p>Since the source of truth is the WebGenAI system, you should not alter the wg_rules.  You can and should use these files to:</p> <ul> <li>Review and verify the logic created by WebGenAI</li> <li>Debug the logic using the debugger and the logic log; see Debugging Logic.</li> </ul> <p> </p>"},{"location":"WebGenAI-CLI/#active_rules_exportpy","title":"active_rules_export.py","text":"<p>The separate wg_rules files are gathered into a single <code>active_rules_export.py</code> file.  This simplifies verification / debugging (see above).  </p> <p>This is a different execution path for IDE execution vs. WebGenAI execution.  You can force the WebGenAI execution path using the environment variables shown above.  This is normally not necessary.</p> <p> </p>"},{"location":"WebGenAI-CLI/#multi-team-development","title":"Multi-Team Development","text":"<p>Since the logic is in separate directories, the system is able to support ongoing development in both WebGenAI and your IDE.</p> <p>Please see Import / Merge GenAI.</p> <p></p>"},{"location":"WebGenAI-CLI/#dashboard-graphics","title":"Dashboard Graphics","text":"<p>Release 14.04 provides a technology preview of Dashboard Graphics:</p> <p></p> <p>Dashboard Graphics have already been installed in <code>samples/nw_sample</code>, using the following creation process after installing the Manager:</p> <ol> <li>Open project: <code>samples/nw_sample</code></li> <li>Observe <code>docs/graphics/count_orders_by_category.prompt</code> (contains <code>Graph number of sales per category, for dashboard</code>)</li> <li>In a terminal window: <code>genai-logic genai-graphics</code>; observe this creates:<pre><code>* `database/database_discovery/graphics_services.py` - methods in data model classes to return group by results\n* `api/api_discovery/dashboard_services.py` to return dashboard information\n</code></pre> <ol> <li>Update <code>ui/admin/home.js</code> to include the following (e.g., before the line containing Welcome to GenAI-Logic/API Logic Server): </li> </ol> </li> </ol> <pre><code>'&lt;div class=\"dashboard-iframe\"&gt;' +\n\n'&lt;iframe id=\"iframeTargetDashboard\" src=\"http://localhost:5656/dashboard\" style=\"flex: 1; border: none; width: 100%; height: 200px;\"&gt;&lt;/iframe&gt;' +\n\n'&lt;/div&gt;' +\n</code></pre> <p>As always, generative AI can make mistakes.  You may need to issue the <code>als genai-graphics</code> command more than once.</p>"},{"location":"WebGenAI-CLI/#appendices","title":"Appendices","text":""},{"location":"WebGenAI-CLI/#error-recovery","title":"Error Recovery","text":"<p>AI results are not consistent, so you may sometimes need to correct errors and resume.  This requires a bit of background about genai processing.</p> <p> </p>"},{"location":"WebGenAI-CLI/#genai-processing","title":"GenAI Processing","text":"<p><code>genai</code> processing is shown below (internal steps denoted in grey):</p> <ol> <li> <p>You create your .prompt file, and invoke <code>als genai --using=your.prompt</code>.  genai then creates your project as follows:</p> <p>a. Submits your prompt to the <code>ChatGPT API</code></p> <p>b. Writes the response to file, so you can correct and retry if anything goes wrong</p> <p>c. Extracts model.py from the response</p> <p>d. Invokes <code>als create-from-model</code>, which creates the database and your project</p> </li> <li> <p>Your created project is opened in your IDE, ready to execute and customize.  </p> <p>a. Review <code>Sample-Genai.md</code>, Explore Customizations.</p> </li> </ol> <p></p> <p> </p>"},{"location":"WebGenAI-CLI/#recovery-options","title":"Recovery options","text":"<p>AI somtimes fails - here's how to recover after you correct the response or the model file.</p>"},{"location":"WebGenAI-CLI/#from-the-model-file","title":"From the Model File","text":"<p>You can find the models file at <code>system/genai/temp/model.py</code>.  You can correct the model file, and then run:</p> <pre><code>als create --project-name=genai_demo --from-model=system/genai/temp/create_db_models.py --db-url=sqlite\n</code></pre>"},{"location":"WebGenAI-CLI/#from-the-response","title":"From the Response","text":"<p>Or, correct the chatgpt response, and</p> <pre><code>als genai --using=genai_demo.prompt --repaired-response=system/genai/temp/chatgpt_retry.response\n</code></pre>"},{"location":"WebGenAI-create/","title":"Web GenAI","text":"<p> WebGenAI - Web Interface for GenAI-Logic</p> <p>Access WebGenAI via your browser to</p> <ul> <li>Create systems from a Natural Language prompt: databases, APIs, an Admin Web App</li> <li>Iterate them (add new tables, columns etc)</li> <li>Add Logic</li> <li>Download the project to your local desktop</li> <li>Execute the project in GitHub Codespaces</li> </ul> <p>For more information, click here.</p>"},{"location":"WebGenAI-install/","title":"WebGenAI Installation","text":"<p> WebGenAI - Installing the Docker Container</p> <p>WebGenAI is a web app that creates database systems from a Natural Language prompt.  For background, see Why WebGenAI.</p> <p>You can access WebGenAI either at:</p> <ul> <li>the public trial site, or </li> <li>as a docker container - described here</li> </ul> <p> </p>"},{"location":"WebGenAI-install/#webgenai-docker-installation","title":"WebGenAI Docker Installation","text":"<p>If you have installed API Logic Server (recommended, but not required), the Manager Readme includes install instructions.</p> <p>Otherwise, you can run it locally as shown below:</p> Run the WebGenAI Docker Container<pre><code>mkdir ApiLogicServer\ncd ApiLogicServer\nmkdir webgenai\ncd webgenai\ndocker run -it --rm --name webgenai apilogicserver/web_genai\n</code></pre> <p>This will guide you through the registration process.  </p> <p>This is particularly good way to jump-start vibe-coding: use WebGenAI to create a database and API - with logic - and then your IDE AI Coding Tools for custom UIs.</p> <p>After installing, verify WebGenAI operation.</p> <p>Note: the Suggestion: ApiLogicServer start is for API Logic Server users using the Manager with the Docker images; you can ignore this message).</p> <p> </p>"},{"location":"WebGenAI-install/#install-api-logic-server","title":"Install API Logic Server","text":"<p>You can iterate WebGenAI projects, for example to tune the data model and add logic.</p> <p>If you want to customize further with Python, then install API Logic Server.  Use the <code>ApiLogicServer</code> directory you created above, and proceed as described in Express Install.</p> <p> </p>"},{"location":"WebGenAI-install/#concurrent-webgenai-and-api-logic-server","title":"Concurrent WebGenAI and API Logic Server","text":"<p>You can continue using both WebGenAI and API Logic Server on the same project - see IDE-Import-WebGenAI.</p>"},{"location":"WebGenAI-llm-usage/","title":"Internals - LLM","text":"<p> WebGenAI - Projects from Prompts</p> <p>LLM (Large Language Model) usage is currently based on OpenAI, for:</p> <ul> <li>Creating SQLAlchemy data models</li> <li>Translating NL (Natural Language) logic into Python rules</li> </ul> <p> </p>"},{"location":"WebGenAI-llm-usage/#llm-technology-usage","title":"LLM Technology Usage","text":""},{"location":"WebGenAI-llm-usage/#learning","title":"Learning","text":"<p>When you install the Manager, it creates the structures shown below.  These are used to \"train\" ChatGPT about how to create models, and how to translate logic.</p> <p></p> <p> </p>"},{"location":"WebGenAI-llm-usage/#invocation","title":"Invocation","text":"<p>The <code>api_logic_server_cli/genai</code> files are called by the CLI (which is called by WebGenAI) to create projects, iterate them, repair them, and so forth.  <code>api_logic_server_cli/genai/genai_svcs.py</code> is a collection of common services used by all, including the function <code>call_chatgpt()</code> shown below.  </p> <p></p> <p> </p>"},{"location":"WebGenAI-llm-usage/#chatgpt-results-wgresult","title":"ChatGPT Results: WGResult","text":"<p>Initially, we called ChatGPT and got the standard response, which in our case was a text file of code.  We parsed that to find the code we wanted, and merged it into the project.</p> <p>That proved to be an unstable choice.  So, we now train ChatGPT results to return smaller code snippets, in json format.  This is defined by <code>WGResults</code>.It also contains the definitions of the <code>WGResult</code> objects.  Note these are defined both in the learnings, amd in <code>genai_svcs.py</code>.</p> <p> </p>"},{"location":"WebGenAI-llm-usage/#docs-requests-and-responses","title":"<code>docs</code>: requests and responses","text":"<p>Requests and responses are stored in the project, which can be used for subsequent requests and error correction.  They can be stored in the location noted below (both the <code>docs</code> directory and its sub-directories):</p> <p></p> <p>Observe that a typical call the ChatGPT is a \"conversation\" - a list of <code>messages</code> (requests and responses) provided as an argument to ChatGPT.</p>"},{"location":"WebGenAI-llm-usage/#genai-project-creation-overview","title":"GenAI Project Creation Overview","text":"<p>GenAI is a wrapper around the existing API Logic Server project-creation flow.  API Logic Server already knows how to build an API + Admin UI from a database (or a SQLAlchemy model).  GenAI's twist is to let you start with a natural-language prompt: it has ChatGPT describe the model, feeds that model to the standard API Logic Server pipeline, and keeps trying until a compilable model appears.  The dominant design constraint is that LLM output can be wrong, so GenAI treats every request as a three-attempt mission with automatic retries, diagnostics capture, and manual escape hatches.</p>"},{"location":"WebGenAI-llm-usage/#execution-stack","title":"Execution Stack","text":"<ol> <li>CLI (<code>api_logic_server_cli/cli.py</code>) \u2013 the <code>genai</code> click command collects prompt options (<code>--using</code>, <code>--retries</code>, <code>--repaired-response</code>, etc).</li> <li>Retry wrapper (<code>genai_cli_with_retry</code> in <code>genai.py</code>) \u2013 for each attempt it spins up a standard project run, catches failures, snapshots diagnostics, and decides whether to try again.</li> <li>GenAI core (<code>GenAI.create_db_models</code>) \u2013 called from <code>ProjectRun</code>; it asks ChatGPT for a model, fixes obvious issues, writes <code>system/genai/temp/create_db_models.py</code>, and records <code>post_error</code> if the model is unusable.</li> <li>Project runner (<code>ProjectRun.create_project</code> in <code>api_logic_server.py</code>) \u2013 the same engine used for database- and model-driven starts; it compiles the generated model, creates the SQLite database, scaffolds the project, and merges logic comments.</li> </ol> <p>Each layer reports errors upward; the retry wrapper decides whether to try again, toggle safeguards, or stop.</p>"},{"location":"WebGenAI-llm-usage/#flow-diagram","title":"Flow Diagram","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 CLI         \u2502\n\u2502 genai()     \u2502\n\u2514\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n     \u2502 (1)\n     \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 GenAI module                \u2502\n\u2502  genai_cli_with_retry()     \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u2502\n\u2502  \u2502 attempt loop (up to 3)\u2502\u25c4\u2500\u2518\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n              \u2502 (2)\n              \u25bc\n     \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n     \u2502 api_logic_server.ProjectRun  \u2502\n     \u2502  \u21b3 GenAI.create_db_models()  \u2502\n     \u2502  \u21b3 create_db_from_model.py   \u2502\n     \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                 \u2502 (3)\n                 \u25bc\n           \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n           \u2502 Generated    \u2502\n           \u2502 project      \u2502\n           \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"WebGenAI-llm-usage/#inside-a-single-attempt","title":"Inside a Single Attempt","text":"<ol> <li>Resolve the prompt \u2013 <code>GenAI.get_prompt_messages()</code> reads the <code>--using</code> argument (text, <code>.prompt</code> file, or conversation directory) and prepends any training inserts.</li> <li>Call ChatGPT \u2013 <code>genai_svcs.call_chatgpt()</code> returns JSON with <code>models</code>, <code>rules</code>, and <code>test_data_rows</code> (or, with <code>--repaired-response</code>, a saved JSON file is used instead of an API call).</li> <li>Fix and emit the model \u2013 <code>genai_svcs.fix_and_write_model_file()</code> cleans the JSON, writes <code>create_db_models.py</code>, and populates <code>post_error</code> if the response still can't compile (eg, tables instead of classes).</li> <li>Persist diagnostics \u2013 <code>save_prompt_messages_to_system_genai_temp_project()</code> copies prompts, responses, and the generated model into <code>system/genai/temp/&lt;project&gt;</code>.</li> <li>Hand off to API Logic Server \u2013 <code>ProjectRun</code> executes <code>create_db_models.py</code>, builds the SQLite database, scaffolds the project, and merges the prompt logic comments into <code>declare_logic.py</code>.</li> </ol> <p>During this flow no exceptions are raised inside GenAI; instead <code>self.post_error</code> carries the message back to <code>ProjectRun</code>, which raises when non-empty so the retry loop can react.</p>"},{"location":"WebGenAI-llm-usage/#three-attempt-strategy","title":"Three-Attempt Strategy","text":"<p>The retry logic in <code>genai_cli_with_retry()</code> keeps project creation resilient:</p> <ul> <li>Loop control \u2013 the CLI supplies <code>retries</code> (defaults to three).  The wrapper keeps looping until one attempt finishes or the budget is exhausted.</li> <li>Failure detection \u2013 any exception from <code>ProjectRun.create_project()</code> or a non-empty <code>gen_ai.post_error</code> marks the attempt as failed.</li> <li>Automatic diagnostics \u2013 work files are copied to <code>system/genai/temp/&lt;project&gt;_&lt;try#&gt;</code> before the next attempt; in-place conversation folders have the latest <code>.response</code> removed so the user can iteratively repair the conversation.</li> <li>Adaptive retry \u2013 if the failure mentions \u201cCould not determine join condition\u201d the next run toggles <code>use_relns=False</code> (foreign keys remain, only inference is skipped).</li> <li>Exit conditions \u2013 success breaks the loop; persistent failure logs and exits with status 1 so calling automation can react.</li> </ul> <p>This approach mirrors real-world LLM behaviour: one response might be malformed, but a clean run usually appears within three tries, and each failure leaves a breadcrumb trail for debugging.</p> <p>Note the same <code>pr</code> instance variable is used for all 3 tries, so initialization that would normally occur in <code>init()</code> is in <code>GenAI.create_db_models()</code>.</p>"},{"location":"WebGenAI-llm-usage/#pseudo-code","title":"Pseudo-code","text":"<p>Note the Key Module Map at the end of genai.py:</p> <pre><code>def key_module_map():\n    \"\"\" does not execute - strictly fo find key modules \"\"\"\n    import api_logic_server_cli.api_logic_server as als\n    import api_logic_server_cli.create_from_model.create_db_from_model as create_db_from_model\n\n    genai_cli_with_retry()                          # called from cli.genai for retries\n                                                    # try/catch/retry loop!\n    als.ProjectRun()                                # calls api_logic_server.ProjectRun\n\n    genai = GenAI(Project())                        # called from api_logic_server.ProjectRun\n    genai.__init__()                                # main driver, calls...  \n    genai.get_prompt_messages()                     # get self.messages from file/dir/text/arg\n    genai.fix_and_write_model_file('response_data') # write create_db_models.py for db creation\n    genai.save_files_to_system_genai_temp_project() # save prompt, response and create_db_models.py\n                                                    # returns to api_logic_server, which...\n    create_db_from_model.create_db()                #   creates create_db_models.sqlite from create_db_models.py\n                                                    #   creates project from that db; and calls...\n    genai.insert_logic_into_created_project()       #   merge logic (comments) into declare_logic.py\n</code></pre>"},{"location":"WebGenAI-llm-usage/#manual-recovery-hooks","title":"Manual Recovery Hooks","text":"<ul> <li>Repaired responses \u2013 run <code>ApiLogicServer genai --using prompt_dir --repaired-response system/genai/temp/chatgpt_retry.response</code> after editing the JSON.  The retry loop treats this as the last attempt (no additional retries needed).</li> <li>Conversation iteration \u2013 reuse the same <code>--using</code> directory; GenAI appends numbered prompt/response files so you can evolve a design across attempts.</li> <li>Logic review \u2013 generated logic is inserted as commented guidance in <code>declare_logic.py</code>; keep <code>--active-rules</code> disabled until you have reviewed the suggestions.</li> </ul>"},{"location":"WebGenAI-llm-usage/#genai-module-files","title":"GenAI Module Files","text":""},{"location":"WebGenAI-llm-usage/#core-files","title":"Core Files","text":"<ul> <li><code>genai.py</code> - Main GenAI class and project creation driver</li> <li><code>genai_svcs.py</code> - Internal service routines used by other genai scripts (ChatGPT API calls, model fixing, response processing)</li> <li><code>genai_utils.py</code> - Additional CLI functions for GenAI utilities and operations</li> </ul>"},{"location":"WebGenAI-llm-usage/#specialized-generators","title":"Specialized Generators","text":"<ul> <li><code>genai_react_app.py</code> - Creates React projects inside an existing GenAI project</li> <li><code>genai_graphics.py</code> - Generates graphics and visualizations for GenAI projects</li> <li><code>genai_logic_builder.py</code> - Builds and suggests business logic rules</li> <li><code>genai_mcp.py</code> - Model Context Protocol integration</li> </ul>"},{"location":"WebGenAI-llm-usage/#supporting-files","title":"Supporting Files","text":"<ul> <li><code>client.py</code> - Client interface utilities</li> <li><code>json2rules.py</code> - Converts JSON rule definitions to LogicBank rules</li> <li><code>genai_fatal_excp.py</code> - Fatal exception handling for GenAI operations</li> <li><code>logic_bank_apiX.prompt</code> - Prompt template for LogicBank API training</li> </ul>"},{"location":"WebGenAI-llm-usage/#deferred-error-handling","title":"Deferred Error Handling","text":"<p>The <code>post_error</code> instance variable implements a deferred error reporting pattern in the GenAI module, allowing the system to detect and recover from common ChatGPT response formatting issues through an automated retry mechanism.</p>"},{"location":"WebGenAI-verify/","title":"WebGenAI Verification","text":"<p>Open your browser at http://localhost:8282/admin-app/#/Home?demo=genai_demo, and follow these steps:</p> <p> </p> <p>The constraint is produced by the business logic:</p> <ul> <li>The quantity change recomputed the amount (rule 4)</li> <li>The amount adjusted the amount_total (rule 3)</li> <li>The amount_total adjusted the balance (rule 2)</li> <li>The balance exceeded the credit limit (rule 1), which produced the message and reverted the transaction</li> </ul> <pre><code>Use case: Check Credit    \n    1. The Customer's balance is less than the credit limit\n    2. The Customer's balance is the sum of the Order amount_total where date_shipped is null\n    3. The Order's amount_total is the sum of the Item amount\n    4. The Item amount is the quantity * unit_price\n    5. The Item unit_price is copied from the Product unit_price\n</code></pre>"},{"location":"WebGenAI/","title":"Web GenAI","text":"<p> WebGenAI - Web Interface for GenAI-Logic</p> <p>GenAI is a web app that creates database systems from a Natural Language prompt.  For background, see Why WebGenAI.</p> <p>You can access WebGenAI either at:</p> <ul> <li>the public trial site, or </li> <li>as a docker container.</li> </ul> <p>The site includes the code, and storage for the created projects and their SQLite databases.</p> <p>To use GenAI:</p> <ol> <li>Create systems from a Natural Language prompt: database, API, an Admin Web App<ul> <li>Prompts describe the database structure and business logic, including application integration</li> </ul> </li> <li>Iterate them (add new tables, columns, rules etc) to get the requirements right</li> <li>Export the project to your local desktop to customize (add endpoints, complex logic, etc)</li> </ol> <p>Web/GenAI is based on API Logic Server.  API Logic Server provides the CLI functions used by WebGenAI.</p> <ul> <li> <p>For more on the GenAI CLI, click here</p> </li> <li> <p>For Web/GenAI architecture, click here</p> </li> </ul> <p> </p> <p></p>"},{"location":"WebGenAI/#create","title":"Create","text":"<p>Click the image below to watch a 2 minute video:</p> <p></p> <p>In addition to running in the browser, the website provides a docker command to run the created project locally.</p> <p> </p>"},{"location":"WebGenAI/#prompt-design","title":"Prompt Design","text":"<p>Prompt design is \"AI Programming\".  Your prompt can be very general, or quite specific.  Consider the alternatives and examples described below.</p> Approach Notes Example Business Area Provide a very general prompt * <code>an auto dealership</code>, or* <code>a restaurant</code> Database Oriented Provide a specific prompt that identifies specific tables, columns and relationships <code>Create a system for Customer, Orders, Items and Products</code> With Logic Declare backend behavior with rules See below - With Logic Detailed Database and Logic Complete Natural Language projects See below - Detailed Database and Logic <p> </p>  With Logic  Database, API, Web App and Logic<pre><code>Create a system with customers, orders, items and products.\n\nInclude a notes field for orders.\n\nUse LogicBank to enforce the Check Credit:\n\n1. Customer.balance &lt;= credit_limit\n2. Customer.balance = Sum(Order.amount_total where date_shipped is null)\n3. Order.amount_total = Sum(Item.amount)\n4. Item.amount = quantity * unit_price\n5. Store the Item.unit_price as a copy from Product.unit_price\n</code></pre> <p>You can verify this by altering a sample order/item with a very high quantity, and verifying the credit limit is checked.  (Note this is not trivial - 3 table transaction.)</p> <p>For more, see </p> <ul> <li>the logic editor</li> <li>natural languge logic</li> </ul> <p> </p>  Detailed Database and Logic - A Time Tracking System  <p>This example illustates:</p> <ol> <li>More control on database structure</li> <li>Logic</li> <li>Organized by Use Case</li> </ol> Time Tracking System<pre><code>Generate a project time tracking and invoice application\n\nUse these names for tables and attributes:\n* Client (id, name, email, phone, total_hours, total_amount, budget_amount, is_over_budget)\n* Project ( id, client_id, name, total_project_hours, total_project_amount, project_budget_amount, is_over_budget, is_active)\n* Invoice: (id, invoice_date, project_id, invoice_amount, payment_total, invoice_balance, is_paid, is_ready,task_count,completed_task_count)\n* InvoiceItem(id, invoice_id, task_id, task_amount, is_completed)\n* Task (id, project_id, name, description, total_task_hours_worked, total_task_amount_billed, task_budget_hours, is_over_budget,is_completed)\n* Person (id, client_id, name, email, phone, billing_rate, total_hours_entered, total_amount_billed)\n* Timesheet (id,task_id, person_id, date_worked, hours_worked, billing_rate, total_amount_billed, is_billable)\n* Payment (id, invoice_id, amount, payment_date, notes)\n\nUse decimal(10,2) for: hours_worked, total_hours, hours_entered, total_amount, billing_rate, total_task_amount_billed, project_budget_amount, total_project_amount, total_project_hours\nDefault hours_worked, total_hours, hours_entered, total_amount, billing_rate, total_task_amount_billed, project_budget_amount, total_project_amount, total_project_hours to zero\nCreate relationships between all tables\n\nUse LogicBank to enforce business logic.\n\nUse case: Person\nTotal Hours entered is sum of timesheet hours worked\nTotal amount billed is total hours entered times billing rate\nBilling rate must be greater than 0 and less than 200\n\nUse case: Timesheet\nCopy billing rate from Person billing rate\nThe total amount billed is the billing rate times hours worked\nHours worked must be greater than 0 and less than 15\n\nUse Case: Task\nTotal task hours worked is the sum of the Timesheet hours worked\nTotal task amount billed is the sum of the Timesheet total amount billed\nFormula: is Over Budget  when total task hours worked exceeds task budget hours\n\nUse Case: Project\nTotal project hours is the sum of Task total task hours worked\nTotal project amount is the sum of Task total amount billed\nFormula: is Over Budget when total project amount exceeds project budget amount\n\nUse Case: Client\nTotal hours is the sum of Project total project hours\nTotal amount is the sum of Project total project amount\nFormula: is Over Budget equals true when total amount exceeds budget amount\n\nUse Case: Invoice\nInvoice Amount is the sum of InvoiceItem task amount\nPayment total is the sum of Payment amount\nInvoice balance is invoice amount less payment total\nFormula: is_paid when invoice balance is than or equal to zero\nTask Count is count of InvoiceItem \nTask completed count is count of InvoiceItem where is_completed is True\nFormula: is ready when Task Count is equal to Task Completed Count\nWhen Invoice is_ready send row to Kafka with topic 'invoice_ready'\n\nUse Case: InvoiceItem\nInvoiceItem task amount is copied from Task total task amount billed\nTask is_completed is sum of InvoiceItem is_completed\n\nCreate at least 8 tables (models).\n</code></pre> <p>For more information, see this article.</p> <p> </p>"},{"location":"WebGenAI/#using-logic","title":"Using Logic","text":"<p>Backend Logic is nearly half the effort in a transactional system.  Instead of procedural code, WeGenAI provides declarative rules that are 40X more concise.  They can be expressed in Python, or Natural Language as described here.</p> <p>It's often a good idea to create your project with an initial focus on structure: tables, columns, relationships.  As you review and iterate, you will likely want to introduce multi-table derivations and constraints. </p> <p>You can use normal iterations, or the Logic Editor.</p> <p>For more on logic, including patterns and examples, see Logic.</p> <p> </p>"},{"location":"WebGenAI/#using-iterations","title":"Using Iterations","text":"<p>You can iterate your project, and include logic.  This is a good approach when you are familiar with logic, and reasonably clear on what you want to do.</p> <p> Important - test data recreated</p> <p>The system rebuilds a new project and database with new test data on each iteration.  If you have entered important data, it is still available in the previous iteration.</p> <p> </p>"},{"location":"WebGenAI/#using-the-logic-editor","title":"Using the Logic Editor","text":"<p>You can also the the Logic Editor:</p> <p></p> <p>Create logic by clicking Rule Prompt, or Suggest.  For each element, you can reject or accept.</p> <ul> <li>When you accept, the system translates the logic prompt (Natural Language) into Code (a Logic Bank Rule expressed in Python), shown in back.</li> </ul> <p>Errors shown in red.  Correct errors in Natural Language using the black icon button by providing a new / altered prompt.</p> <p>Logic may introduce new attributes.  These must be added to the data model, using Update Data Model.  When you run, this will update the database and test data.</p> <p> </p>"},{"location":"WebGenAI/#logic-suggestions","title":"Logic Suggestions","text":"<p>You can ask GenAI to suggest logic for your system.  See Suggest Rules in the diagram above.  This can help you learn about rules, and can inspire your own imagination about required logic.</p> <p>It's AI, so or course you will want to review the suggestions carefully.</p> <p>For more information, see Suggestions CLI.</p> <p> </p>"},{"location":"WebGenAI/#debugging-logic","title":"Debugging Logic","text":"<p>Logic can fail to load at runtime.  The system will</p> <ul> <li> <p>restart the project with rules disabled, so you can still see your data.  You should generally not update when logic is in error.</p> </li> <li> <p>report the errors back to the Logic Editor, where you can correct them.</p> </li> </ul> <p>Logic can also fail when you make an update.  You can:</p> <ol> <li>Review the log to see the state of the row(s) as each rule fires (see below)</li> <li>Download the project and use standard logic debugging.</li> </ol> <p></p> <p> </p>"},{"location":"WebGenAI/#using-existing-databases","title":"Using Existing Databases","text":"<p>You can create projects from existing databases, for example, using the Docker Test Databases:</p> <p> </p>"},{"location":"WebGenAI/#iterate","title":"Iterate","text":"<p>You can iterate your prompt to include more tables etc, while preserving the design you have already created.</p> <ul> <li>This enables you to break your system down into a set of \"Use Cases\", solving one at a time, and integrating back to the others.</li> </ul> <p> </p>"},{"location":"WebGenAI/#fixup","title":"Fixup","text":"<p>Fixes project issues by updating the Data Model and Test Data. When adding rules, such as using suggestions, you may introduce new attributes. If these are missing, you will see exceptions when you start your project.</p> <p>Use the Update Model button on the screen shot above.</p> <p> </p>"},{"location":"WebGenAI/#export-customize","title":"Export / Customize","text":"<p>You can explore the created microservice on your own computer.</p> <ol> <li> <p>Export your project (customize in your IDE to add logic &amp; security)</p> <ul> <li>Observe the project is a set of models - not a huge pile of difficult-to-understand code</li> </ul> </li> <li> <p>Use Python and your IDE services.  For more information, see Customize in Your IDE.</p> </li> </ol> <p> </p> <p> </p>"},{"location":"WebGenAI/#appendices","title":"Appendices","text":""},{"location":"WebGenAI/#limitations","title":"Limitations","text":"<p>The created systems are basic database applications, not completed systems with sophisticated functionality such as images, custom screens, etc.</p> <p>You can \"build out\" the project by downloading it and using your IDE with Python and rules, or perform the same functions using Codespaces (a browser-based version of VSCode - a link is provided for this).</p> <p> </p>"},{"location":"WebGenAI/#context","title":"Context","text":"<p>This explains the premise behind GenAI, and how it fits into a project life cycle.</p> <p> </p>"},{"location":"WebGenAI/#why-genai","title":"Why GenAI","text":"<p>A common project experience is:</p> <ul> <li>Weeks (or months) to get running screens</li> <li>Then, when Business Users explore the screens, it becomes clear there were basic misunderstandings</li> </ul> <p>Which leads to our premise:</p> <ol> <li>Instant screens (Agile \"Working Software\"); collaborate, and iterate to get the requirements right</li> <li> <p>Kickstart the project with a solid backend - a Database, API and Logic from declarative / Natural Language models</p> <ul> <li> <p>Logic in particular is key: security and multi-table derivations / constraints constitute as much as half your project: declarative rules make them 40X more concise  \u00a0 </p> </li> <li> <p>The remaining logic is built in your IDE using standard Python, providing the speed and simplicity of AI - including logic - with the flexibility of a framework</p> </li> </ul> </li> </ol> <p> </p>"},{"location":"WebGenAI/#project-life-cycle","title":"Project Life Cycle","text":"<p>As shown in the Life Cycle outline below, this approach is complementary to your existing UI Dev tools such as UI frameworks or Low Code Screen Painters. </p> <ul> <li>In addition to existing UI Dev tools, please explore automation support for Ontimize.</li> </ul> <p>As illustrated by the green graphics below, we seek to provide value in the Inception Phase (get the requirements right), and for backend development. </p> <p></p> <p> </p>"}]}